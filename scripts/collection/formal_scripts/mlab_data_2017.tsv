post_id	title	date_epoch	date_ymd	author	content	replies
0	monthly-download-speeds	1652279409.0	2022-05-11 07:30:09	Marlene Wendl	Hi,  I'm looking for monthly average mobile download speed data by country, specifcally from 2011 onwards (the earlier the better though).  So far I've only been able to find data from 2021.  Can anyone help me with that? I'd be really greatful for any advice!  Thanks in advance!	"{0: {'username': 'laurent smeets', 'response_date': 'May 20, 2022, 6:57:24 AM (12 days ago) ', 'response_content': 'I will follow this, as I am looking to do something fairly similar. The final product I am looking for a  collection of  map (either as raster or a shapefile) of a country (for example Belgium) with local average internet speeds (based on the web100 test) for different years going back to 2010 (so one map per year). The higher the spatial resolution the better, but for now I am thinking of 0.1x0.1 degree lat/lon as the resolution.  I am comfortable in geospatial analysis, but new to BigQuery. Could you help me point to a location where I can find more information on how to construct a query like this or help me create it. \ue5d3'}, 1: {'username': 'Lai Yi Ohlsen', 'response_date': 'May 20, 2022, 11:30:01 AM (11 days ago) ', 'response_content': 'H both,   Thanks for reaching out. Marlene, would you be able to share the query that\'s only sharing data for 2021?   Laurent, I these blog posts might be of use to you:  Exploring NDT Data by Geography in Baltimore City Analysis Recommendations in Context - ARC of Research pt. 1: Asking the Right Questions ARC of Research pt. 2: Exploring Data Sources Relevant to Our Questions  The first one particularly, as it describes how we annotate locations in more detail. In short, we use the IP address and annotate it using the MaxMind GeoIP database with a resolution that is much less specific than the one you\'re looking for. I\'d be happy to learn more about your work offline to better understand how we are meeting or not meeting your use case.    \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/3f4440dc-60f6-4908-96a4-e66032201f28n%40measurementlab.net.   -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society'}}"
1	new-ookla-speedtest-app-for-ios	1652279412.0	2022-05-11 07:30:12	Dave Taht	"The latest ookla speedtest app (just for apple's ios presently), is finally tracking ""working latency"", and ""responsiveness"".  Try it!  -- FQ World Domination pending: https://blog.cerowrt.org/post/state_of_fq_codel/ Dave Täht CEO, TekLibre, LLC"	{}
2	hiccup-on-denver-pod?	1646346320.0	2022-03-03 15:25:20	Glenn Fishbine	We had some unusual results come back today from testing out of Utah through the Denver pod which were  extremely low.  By any chance is there a way to see if the pod had a hiccup today, or is there a way to see if a pod is up or down?	"{0: {'username': 'Nathan Kinkade', 'response_date': 'Mar 4, 2022, 12:10:55 PM', 'response_content': 'Hi Glenn,  Nothing is obviously wrong with the sites in Denver. There are 4 sites in Denver: den02, den04, den05, den06. Do you happen to know which of those the suspect tests are running against? If you are using the Locate Service for testing (which you probably are), then your tests should be running to one of those sites somewhat randomly.  Each site has 3 production machines: mlab1, mlab2, mlab3. If you are testing from a browser, then you should be able to determine which site and machine is being tested against by looking at either the javascript console, or by looking at network connections.  At a glance, everything at the Denver sites is healthy and average throughput on the switches is very far below each site\'s capacity. Over the past 6 hours I\'m only seeing roughly 200-300Mbit/s on the interfaces, and these sites are all connected on 10Gbit/s uplinks.  Do you have any additional details that might help us troubleshoot?  Thanks,  Nathan  On Thu, Mar 3, 2022 at 3:25 PM Glenn Fishbine <glen...@gmail.com> wrote: We had some unusual results come back today from testing out of Utah through the Denver pod which were  extremely low.  By any chance is there a way to see if the pod had a hiccup today, or is there a way to see if a pod is up or down? -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/177dde82-5e22-4566-a3e0-21f3b160b92an%40measurementlab.net.'}, 1: {'username': 'Glenn Fishbine', 'response_date': 'Mar 4, 2022, 2:18:50 PM', 'response_content': ""I'm not sure if there was an issue.  Yesterday morning we got multiple reports of 1 gig circuits providing 1 meg download speeds.  The problem seemed to go away by afternoon.  The problems all originated from a particular ISP, Emery, so it may have been on their side. \ue5d3""}, 2: {'username': 'Glenn Fishbine', 'response_date': 'May 3, 2022, 6:36:40 AM', 'response_content': ""I'm getting new reports about low performance out of the Denver pod.  By example, two consecutive tests showed latency of 21 and 42 ms, and the test results dropped by 50% naturally with the 42 ms.  The raw circuit speed was about 200mbps and the mlab tests came in at around 20.  Unfortunately the reports are coming from folks who can't identify which of the 4 servers was involved.  This seems to be a consistent problem where testing is occurring in Utah.  I'm going to try to get traceroutes to see if the problem can be narrowed down to one of the hops or not, but if you could please take a look again at the status on the servers, I'd appreciate it.  By comparison, tests done on the Chicago pod are never questioned by our users.  Is there an easy way to force angular-route.js to return only the Denver route so I can build up a library of tests that may or may not indicate anything?  \ue5d3""}, 3: {'username': 'Lai Yi Ohlsen', 'response_date': 'May 3, 2022, 6:38:26 AM', 'response_content': ""Hi Glenn,   Thanks for reporting. The M-Lab team will be at our annual planning meeting for the next 3 days, but we'll respond asap.   \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/de1dad19-5bce-4d88-b4e9-9ac71d88e5f9n%40measurementlab.net.   -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society""}, 4: {'username': 'Nathan Kinkade', 'response_date': 'May 6, 2022, 11:00:30 AM', 'response_content': 'Hi Glenn,  There are actually 4 ""pods"" (i.e., M-Lab sites) in Denver. Each site has 3 production machines (total of 12 production machines in Denver). The sites are as follows:  den02: Lumen (Level3) den04: Zayo den05: Telia den06: GTT  I would be very surprised to find out that, for any given client, performance would differ between any of the machines at a given site. It would not surprise me, however, if performance differed (possibly substantially) between any of the sites. My best guess would be poor peering between the client\'s ISP and one of the transit providers we use in Denver.  The first step will be to find out to which of those providers the users are seeing very poor performance. Once you\'ve found the problematic transit provider on the M-Lab side, the next step would be to have the client run some traceroutes to one of the machines at the impacted M-Lab site. If it does indeed turn out that the issue is poor peering, then someone could perhaps reach out to the ISP to let them know of the issue, and to see if there anything the ISP can do about. For small ISPs, there may not be much they can do, likely because of a monetary constraint.  For an ndt7 test, there is no easy way to force the test to a particular server. For ndt5, someone could run a client locally, and specify the exact server. For now, you could perhaps have any user reporting these disparities run traceroutes to one machine at each M-Lab site in Denver, looking for any that might have a suboptimal or long path. For example, to these hosts:  mlab1-den02.mlab-oti.measurementlab.net mlab1-den04.mlab-oti.measurementlab.net mlab1-den05.mlab-oti.measurementlab.net mlab1-den06.mlab-oti.measurementlab.net  Thanks,  Nathan  \ue5d3'}}"
3	itu-standards	1651251685.0	2022-04-29 10:01:25	Bobby Wilson	Hi there,  I am working with a group that is interested in using M-Lab for monitoring the performance of various ISPs.  A requirement of the project is the use of a tool that follows or is based on the International Telecommunication Union standards.  From what I've found so far, M-Lab has been involved with ITU but I can't find anything specifically mentioning that it follows or is based on ITU standards.  Can anyone help provide more information and links on this topic?  Thank you!	"{0: {'username': 'Lai Yi Ohlsen', 'response_date': 'May 2, 2022, 12:53:26 PM', 'response_content': 'Hi Bobby,   Our involvement might have predated my time at M-Lab (mid 2019). I\'ll ask around and get back to you - thanks.   \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/8f5312c9-673f-4361-97c0-8851645ba682n%40measurementlab.net.   -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society'}}"
4	"ndt7-client-go-client-""-server""-option-error"	1651072366.0	2022-04-27 08:12:46	frog...@gmail.com	Hi, It looks like the -server option in ndt7-client-go is not working. I can run the test using default setting. ~/godir/src/ndt7-client-go/cmd/ndt7-client$ go run main.go download in progress with ndt-mlab3-dfw02.mlab-oti.measurement-lab.org Avg. speed  :   463.9 Mbit/s download: complete upload in progress with ndt-mlab3-dfw02.mlab-oti.measurement-lab.org Avg. speed  :   194.7 Mbit/s upload: complete          Server: ndt-mlab3-dfw02.mlab-oti.measurement-lab.org          Client: 2001:48d0:101:501:da9e:f3ff:fe86:e62d         Latency:    46.0 ms        Download:   463.9 Mbit/s          Upload:   194.7 Mbit/s  Retransmission:    0.15 %   However, I got handshake errors when I try to run NDT again using the same server. ~/godir/src/ndt7-client-go/cmd/ndt7-client$ go run main.go -server=ndt-mlab3-dfw02.mlab-oti.measurement-lab.org download failed: websocket: bad handshake  download: complete upload failed: websocket: bad handshake  upload: complete exit status 2  What should I put into the server option?  Thank you for your help. Ricky	{}
5	decommission-of-the-v1-data-pipeline:-may-9th	1650915231.0	2022-04-25 12:33:51	Stephen Soltesz	"Starting May 9th, we will begin to decommission the v1 data pipeline.  If you only use the ndt.unified_uploads and ndt.unified_downloads views, you will experience no changes.  If you continue to use any of the ""*_legacy"" datasets, these will stop being updated with new data or being reprocessed after May 9th. This includes: ndt_raw.ndt5_legacy ndt_raw.tcpinfo_legacy ndt_raw.paris1_legacy ndt_raw.web100_legacy After May 9th, prefer the undecorated ndt5 and tcpinfo tables, which will continue to be updated daily.  We do not yet plan to delete these views or the v1 tables. So, they will remain available for reference or as a point of comparison."	{}
6	mobile-speed-test-data-for-india	1650494918.0	2022-04-20 15:48:38	Lizaveta Radzevich	Hello,  I'm looking for mobile speed test data for India (ideally in a format close to Mlab, lat/long attributed included). Is there any noteworthy sources for it except Mlab (or any way to single out the mobile test in Mlab).  Thank you! Liz	{}
7	query-keeps-giving-errors	1650464332.0	2022-04-20 07:18:52	poonam parab	"Hello   I am trying to find the latest upload and download speed data for Rhode Island.  this is the syntax I am trying to run.   SELECT * FROM   `measurement-lab.ndt.unified_downloads` WHERE    date BETWEEN ""2022-01-01"" AND ""2022-03-01""   AND client.Geo.Region = ""RI""   AND client.Geo.country_code = ""US"" GROUP BY zip_code, ASN ORDER BY zip_code, ASN  It keeps giving me an error. Can you please help me resolve this?   Thank you,  Poonam "	"{0: {'username': 'Phillipa Gill', 'response_date': 'Apr 20, 2022, 7:35:17 AM', 'response_content': 'Hi Poonam,  3 things jump out at me looking at this query: (1) We recently shifted from using client.Geo.Region for the state to using client.Geo.Subdivision1ISOCode (2) The country information is in client.Geo.CountryCode (3) zip_code and ASN are not defined in the query snippet you sent.   Hope this helps.  -Phillipa  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/179d5e10-90b8-49a9-8c7a-863544250f75n%40measurementlab.net.'}}"
8	unconscious-physiological-effects-of-search-latency-on-users-and-their-click-behaviour	1650464341.0	2022-04-20 07:19:01	Dave Taht	"""As the response latency of the search engine reaches higher val-ues, the arousal and the negative valence of the experienced emotions increase as well. Although those effects did not produce changes on the *self-reported data*, their impact on users’ physiological responses was evident. Thus, even if such short latency increases of under 500ms are not consciously perceived, they have sizeable physiological effects.""  GOOD paper:  https://www.researchgate.net/publication/282009221_Unconscious_Physiological_Effects_of_Search_Latency_on_Users_and_Their_Click_Behaviour  3sec is the maximum pain point....    -- I tried to build a better future, a few times: https://wayforward.archive.org/?site=https%3A%2F%2Fwww.icei.org  Dave Täht CEO, TekLibre, LLC"	{}
9	migration-to-the-v2-data-pipeline	1644446126.0	2022-02-09 15:35:26	Stephen Soltesz	TL;DR - If you typically use the `measurement-lab.ndt.unified_uploads` or `measurement-lab.ndt.unified_downloads` views, then nothing will change.  In the coming days and weeks, we are updating the ndt5, switch, and tcpinfo schemas, removing obsolete views, and renaming some views in preparation for improving ease of use and documentation.  You can find more details here: https://www.measurementlab.net/blog/v2-data-pipeline-migration/  Please let us know if you have any questions, Stephen	"{0: {'username': 'Stephen Soltesz', 'response_date': 'Feb 28, 2022, 11:44:23 AM', 'response_content': 'This week and next we plan to begin making the changes outlined in the blog post.  If you have not already updated your queries, please do so now.  Specifically: removing v1 views from the ""ndt"" dataset. Use equivalents in ""ndt_raw"" dataset instead removing views from the ""library"" dataset. These are obsolete completing the migration of the ndt5 datatype to the v2 data pipeline completing the migration of the switch datatype to the v2 data pipeline We also updated the blog post for a clarifying name change to the legacy traceroute v1 views, preferring `paris1_legacy` to explicitly name the underlying datatype and reserve ""traceroute"" as a category for all such datatypes, e.g. paris1, scamper1, single-path variants, etc. \ue5d3'}, 1: {'username': 'Stephen Soltesz', 'response_date': 'Mar 2, 2022, 1:34:49 PM', 'response_content': 'Update: measurement-lab.ndt.ndt5 is publishing data processed by the v2 data pipeline, but the complete history is not yet fully reprocessed. This should be complete by March 8th.  \ue5d3'}, 2: {'username': 'Cristina Leon', 'response_date': 'Mar 25, 2022, 11:39:47 AM', 'response_content': 'In line with the migration to the v2 Data Pipeline, we will be making the following changes on Monday, April 4th.  If you have any queries using the `ndt_raw.traceroute_legacy` view, please update them now to use `ndt_raw.paris1_legacy` and `ndt_raw.scamper1`. We will delete the v1 `ndt_raw.traceroute_legacy` view. It will be replaced with the `ndt_raw.paris1_legacy` (data from the Paris Traceroute command) and the `ndt_raw.scamper1` (data from the Scamper tool) views. Please note that the ""scamper1"" view has a different schema from the legacy views.  As well, in GCS, the data from the https://console.cloud.google.com/storage/browser/archive-measurement-lab/$expriment/traceroute bucket (replace $experiment with ndt/host/neubot, accordingly) has been copied to the new https://console.cloud.google.com/storage/browser/archive-measurement-lab/$experiment/scamper1 bucket. The former bucket will be removed.  More documentation about traceroute can be found here.   Thanks, Cristina \ue5d3'}, 3: {'username': 'Stephen Soltesz', 'response_date': 'Apr 11, 2022, 12:15:30 PM', 'response_content': 'Update: We will delete the `measurement-lab.ndt.traceroute` view today. The data previously accessible there remains available from `ndt_raw.paris1_legacy` and/or `ndt_raw.scamper1`. Best, Stephen \ue5d3'}, 4: {'username': 'Cristina Leon', 'response_date': 'Apr 15, 2022, 10:28:45 AM', 'response_content': 'Update: In line with the changes described in the Data Pipeline Migration, on April 25th, we will replace the `aggregate.traceroute` view with `traceroute.scamper1` and `traceroute.paris1_legacy`. Thanks, Cristina \ue5d3'}}"
10	download-sppeds-desreprencies-when-running-speed-test	1649867881.0	2022-04-13 09:38:01	Paul Zahra	I noticed when I run your speed test at times the dpwnload speeds are much, much lower then when using OOkla,   This moing test showed  sub 1 MB , but OOKLA showed at least 40MB  .Can you explain the possible differences?   My connection does seem slow.   Thaks for any insight you can provide,  Regards, Paul Zahra	"{0: {'username': 'Lai Yi Ohlsen', 'response_date': 'Apr 13, 2022, 3:15:43 PM', 'response_content': 'Hi Paul,   Thanks for your question. The simplest way to answer, is that M-Lab’s NDT and Ookla’s SpeedTest measure fundamentally different things. They differ in three key ways: 1. M-Lab measures to servers in off-net locations, Ookla measures to on-net locations. 2. NDT measures bulk transport capacity, SpeedTest attempts to measure link capacity and 3. NDT is a single stream test, SpeedTest is a multi-stream  Here is a more in depth explanation of each characteristic:  1. Off-net vs. on-net measurement: All of M-Lab’s measurement services, including NDT, are hosted on our off-net platform. “On-net” refers to measurements performed on the same network as the network it is measuring, such as an Internet Service Provider (ISP) measuring itself. It only captures one segment of any path that data is likely to be traversing. In contrast, “off-net” measurements extend beyond a user’s access provider’s network to measure the complete path across the Internet from user to content including interconnections. By definition, on-net measurement can not even detect the effects of any performance limitations at interconnects between ISPs. All of the measurement services hosted by M-Lab inherit the off-net platform methodology for nearly all users. 2. Link capacity vs. bulk transport: When using NDT tests specifically, Internet users are sometimes confused when their individual results don’t confirm the speeds promised by their Internet service provider. “Speed” is often associated with “link capacity,” which is the maximum bitrate of a link; in other words, the best performance possible. However, NDT measures “bulk transport capacity” — the rate that TCP can deliver data across the end-to-end path; in other words, the reliability of that connection. It is important to note that many link problems (such as low level packet loss and reordering) typically adversely impact both MLab measurements and real application performance.  These two ways of measuring performance, link capacity and bulk transport capacity, are different and are often conflated when both concepts are referred to as “Internet speed.” When using NDT data to discuss speed, it is important to clarify these terms to have more effective conversations about Internet speed. 3. Single-stream vs. multi-stream tests: NDT measures the single-stream performance of bulk transport capacity. While modern web browsers will use multiple streams of data, testing for multiple streams can compensate for data delivery problems that are exposed by a single stream. A multi-stream test can return measurements closer to link capacity but it would not represent the adverse performance impact of low-level packet loss. By testing for single-stream performance, NDT is an effective baseline for measuring a user’s Internet performance.  In short, NDT does not answer the question “how big is your pipe” but rather “how well is your pipe transferring data.” We consider both metrics to be important for understanding connectivity. For more reading, you can reference How fast is my Internet? Speed Tests, Accuracy, NDT & M-Lab which digs more into the definition of “speed” and NDT Data in NTIA Indicators of Broadband Need, which though focuses on the US federal mapping resource, helps describe the difference between the aggregated datasets for the purpose of research.  Additionally, any given test result is impacted by a number of factors, including the network management and topology of the path, the traffic on the network at the time of the test, and other environmental factors. One of the reasons M-Lab finds it so important to publish this data openly, is so we can study these factors in a more statistically rigorous way as part of a sample vs. in the one-off context of individual tests.   I hope this answer addresses your question, but please let me know if I can explain anything further.   \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/a609ce0e-7be6-4b4e-a231-227d7cd4106bn%40measurementlab.net.   -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society'}, 1: {'username': 'Paul Zahra', 'response_date': 'Apr 13, 2022, 5:17:26 PM', 'response_content': 'Thank you for this explanation,  Very well explained and makes total sense to me now.   Regards, Paul  \ue5d3'}, 2: {'username': 'Livingood, Jason', 'response_date': 'Apr 14, 2022, 10:03:11 AM', 'response_content': 'Great explanation & summary of issues, Lai!   Semi-related: Since at root NDT is not a speed test, I hope one day Google will stop promoting NDT as the default recommended speed test when someone searches for “speed test” on their site. This IMO does a disservice to end users that are searching for an actual speed test that measures their aggregate link capacity. ;-)   Jason   \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcMg5JOuFWy4Fd6G4CKnE3CQN0m0nWXCbCGoZg_S1vcuxw%40mail.gmail.com.'}, 3: {'username': 'Lai Yi Ohlsen', 'response_date': 'Apr 14, 2022, 10:32:18 AM', 'response_content': 'Hey Jason,  Glad you liked the summary and found it useful. Regarding the Google Search integration: the test volume generated by that integration is significant and it would be a great loss to the research community to see a decrease (of any size) in the amount of open Internet performance data that is made publicly available, especially when there are so few alternatives. That said, your point about service to the end user is well taken and as you might have noticed through our community calls, blog posts and public comments, we are interested in working with the M-Lab community to discern what information is most useful to provide to the end user inquiring about their connectivity and as part of that effort, expanding the notion of Internet performance beyond “speed”.  Happy to talk more offline! Take care.   -    \ue5d3'}, 4: {'username': 'jpartr...@gmail.com', 'response_date': 'Apr 14, 2022, 2:41:23 PM', 'response_content': 'To M-Lab\'s credit, you all have repeatedly acknowledged:  -""access link capacity is not what NDT measures"" -""Ookla\'s speedtest.net...{is} better suited for researchers looking to only measure the last-mile connection"" -ISP services ""would be best measured by a multi-stream test"" -""NDT from M-Lab on the other hand, isn\'t intended to be a measurement of an Internet connection\'s maximum capacity"" -and now yesterday, ""NDT does not answer the question how big is your pipe""  The problem is that many stakeholders, and the public at large, are misinterpreting and misrepresenting NDT data. Whether they are doing it naively, or willfully and maliciously, they are holding up NDT data as being indicative of performance that M-Lab has repeatedly stated it is not. And that is problematic! M-Lab would actually be assisting the research community by removing this misinformation, rather than simply issuing disclaiming caveats. As Sara Wedeman and David Clark noted in their paper, ""In short, NDT was a diagnostic tool, not a measuring stick. The purpose was not to evaluate or compare residential broadband speeds delivered by ISPs, but rather to find and fix network problems."" At another point they observed: ""Our high-level conclusions {are} that these are not tests that reveal variation in the access technology, and computing a mean or median of these measurements will tell us nothing about the speed of the access link."" And finally, Wedeman and Clark also observe: ""The data from M-Lab is free and publicly available - and despite M-Lab’s cautionary messages on its Web site, M-Lab data can be, and has been used inappropriately on more than one occasion."" As noted earlier, this is problematic!     \ue5d3'}, 5: {'username': 'Glenn Fishbine', 'response_date': 'Apr 14, 2022, 5:26:25 PM', 'response_content': ""Just my 2 cents worth.  Before declaring that MLab is not a speed test, first you have to have agreement as to what a speed test is.  A speed test measures something.  That something has a context usually related to usability for a purpose.  If the purpose is to determine the size of the pipe maybe MLab isn't the best choice.  If the purpose is to determine if a specific task can be accomplished, maybe Mlab is the best choice.  There is a clear difference on the type of speed test to be used if:  1.  you want to know if you can stream Netflix 4k videos without buffering  2.  If Johnny can get responses to his homework answers in less than 3 seconds.  3.  If you can hold a video conference call on a service that has single port streaming.  I'm sure there are other answers, but it depends on what purpose you have in mind when you declare a speed test adequate, or not, for that purpose.  Let me point out that our dear friends at the FCC built Mlab into their mobil speed test, and further point out that their own research subsequently declared that MLab was a more than adequate test for their purposes in a way that was acceptable, albeit different, from Ookla, which was also acceptable.      \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/fdf7d530-20f0-41b4-b136-59b26ba45de2n%40measurementlab.net.""}, 6: {'username': 'Ethan Katz-Bassett', 'response_date': 'Apr 14, 2022, 5:26:28 PM', 'response_content': 'I think this is a great summary of key differences!   However, as an additional caveat in interpreting the data, it\'s not clear to me what off-net vs on-net measurements meaningfully represent in terms of ""the complete path across the Internet from user to content."" For many (probably most) Internet users, much (probably most) of their traffic comes either from an on-net Content Delivery Network (CDN) node or across a dedicated network interconnection to the content provider. So it\'s not clear to me that traffic crossing one or a few particular network interconnections between me and the assigned MLab server is a more meaningful measure of the performance I\'d get to content than a measurement to an on-net server -- I suspect that neither exercises any interdomain interconnections that my traffic encounters when using YouTube, Netflix, Facebook, services hosted on the major cloud providers, services hosted on a number of widely-used CDNs, etc. If the NDT measurement is constrained by issues at the interconnection, the issues could apply to any services I use that happen to share that interconnection, but that\'s probably not the case for most services I use, and it requires a good amount of Internet measurement to understand which ones do share it.  Ethan   \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcMg5JOuFWy4Fd6G4CKnE3CQN0m0nWXCbCGoZg_S1vcuxw%40mail.gmail.com.'}, 7: {'username': 'Nick Feamster', 'response_date': 'Apr 15, 2022, 5:23:52 AM', 'response_content': 'A few thoughts:  1. All of these tests are subject to severe sampling bias, particular under-representation of samples in communities where connectivity gaps are most dire.  This I believe is a fundamental issue that is common across *all* of today’s methodologies. Client-based tests face severe sampling limitations; even the MBA program stratifies its sample by ISP and thereby severely undersamples most geographies, making it not very useful for many types of studies.  See our TPRC paper for some initial discussion of these issues: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3786158  2. All of these tests are subject to various issues with client-based measurements, from WiFi bottlenecks to limitations of the radios on (old) client devices. A particular issue we discovered at one point was that many NDT tests on higher speed links were being performed from old iPhones whose radios did not support speeds of greater than 100 Mbps. In short, the NDT test was measuring the radio of the mobile device, not the ISP. See our CACM paper for more discussion on that. https://dl.acm.org/doi/pdf/10.1145/3372135  3. I am not sure it is accurate to say that NDT answers the question of “how well is you pipe transferring data”. A more precise statement would be that it measures the transfer rate across a single transport connection—at one point a fairly outmoded version of TCP, and now a single BBR stream.  And so it might represent how well the connection transfers data across that transport, but it’s also worth pointing out that no modern application that seeks to maximize capacity relies on a single transport connection—everything from browsers to streaming clients on smart TVs use multiple parallel connections (some do so in rather extreme fashion, but that’s another topic).  4. Off-net measurements have their own caveats. One notable one—which came to light in none other than an M-Lab report!—was that as a result of an end-to-end path to an off-net server that crossed Cogent, the report mis-diagnosed the location of congestion (and its resolution).  Cogent’s CEO also acknowledged this particular issue (read my FCC filing on the issue for more about that: https://www.fcc.gov/ecfs/file/download/DOC-578d040705800000-A.pdf).  5. To the point about the Google search “one box”—characterizing the loss of NDT measurements as a “great loss to the research community” presumes that “more data is better” and “open data is better""—independent of the *quality* of those measurements.  But, I’d argue we need to rethink that. As Jim and Jason have both pointed out, the data has been actively misused and mischaracterized over many years—and this continues to happen. Part of the reason I believe this to be the case is the reason Lai Yi mentions: there are “so few alternatives”.  It’s time to change that because regardless of the facts, people will take the path of least resistance. Casting it in the most charitable light—while some stakeholders may be willfully misrepresenting the data, I suspect others simply don’t have the time or interest in understanding the nuance that this group is familiar with. Taking shortcuts like that is sloppy and unscientific—something that has bothered me for quite some time—but I think some groups have gotten away with it because there’s little denying that there *are* gaps in infrastructure, connectivity, etc.—nevermind that the data itself doesn’t actually tell you much about the specific nature of any particular problem, people are happy to talk in broad strokes and handwave if the data conveniently speaks to an agenda. But now, as we think about actually *solving* problems, this becomes a more serious problem—the existing tools and methods—measurement techniques, data, sampling approaches—do very little in helping anyone actually work towards fixing these problems.  I believe that’s where we should be turning our focus in the next 5-10 years. \ue5d3'}, 8: {'username': 'Lai Yi Ohlsen', 'response_date': 'Apr 15, 2022, 6:41:23 AM', 'response_content': ""Hi everyone,  Thank you all for your thoughtful notes. It’s evident that there are a number of shared goals, the most prominent being to use data to improve Internet performance for end users. More specifically, I agree with the latter parts of Nick’s last statement about the need for measurements that help end users and their public representatives actually solve problems. M-Lab is also keen to make progress here.  There’s a lot of details here that we could go back and forth on but I’m curious how we can channel the obvious energy on these topics into actionable, consensus-driven plans. Afterall, our shared goals are not small :) and would only benefit from a cooperative approach. Would the folks in this thread (including anyone following along) be interested in participating in a working group focused on these topics (e.g. “speed” tests,  network topologies, data collection methodologies etc.) and supporting M-Lab’s efforts to contribute here?  Please let me know if so! A reply to this email works great.  As/If the thread continues, I'll insert a gentle reminder of our community guidelines. Take care all.   \ue5d3""}, 9: {'username': 'Livingood, Jason', 'response_date': 'Apr 15, 2022, 9:10:49 AM', 'response_content': 'Good idea on channeling energy towards a constructive activity – I’d suggest considering adding a speed test (aggregate capacity) to the M-Labs platform. This could potentially leverage some of the open source tests out there or new standards such as https://datatracker.ietf.org/doc/html/draft-ietf-ippm-capacity-protocol.   It is worth bearing in mind that my concern over (mis)use & (mis)representation of NDT data is not theoretical. There are tens of billions of dollars of public grant money in the United States that will be spent over the next few years to build Internet connectivity to areas that are currently unserved. I have observed instances of grant decision-makers being told in public meetings which areas have no service based on the purported results of NDT “speed tests” and of grant applicants using NDT “speed tests” to show where broadband is not available or suggesting NDT “speed tests” can be used after the fact to confirm that the new address is receiving broadband service.   Jason   From: Lai Yi Ohlsen <la...@measurementlab.net> Date: Friday, April 15, 2022 at 09:41 To: Nick Feamster <feam...@gmail.com> Cc: discuss <dis...@measurementlab.net>, ""etha...@gmail.com"" <etha...@gmail.com>, ""pza...@logitech.com"" <pza...@logitech.com> Subject: [EXTERNAL] Re: [M-Lab-Discuss] Download sppeds desreprencies when running Speed test   Hi everyone, \ue5d3 \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcMm0_4h4k1s%3D8%3D5smXzC4gCNxP3Za9qND%2BCNgWz9s6_7A%40mail.gmail.com.'}, 10: {'username': 'Paul Zahra', 'response_date': 'Apr 15, 2022, 9:10:52 AM', 'response_content': 'Hello Lai and Group,  Just some more info on my exploits here.  I continued to see the differences in Speed test results yesterday.  I decided to reboot my router and  the speed test results changed to where NDT and OOKLA are measuring the same fast speeds . 50MB.  Woke up this morning and ran the tests and again, speed differences showed up  sub 1MB and 50MB,  rebooted and then the speeds were the same again > 50MB.     Regards, Paul  \ue5d3'}, 11: {'username': 'rjmcmahon', 'response_date': 'Apr 15, 2022, 10:28:20 AM', 'response_content': 'A few thoughts from somebody testing WiFi chips for over a decade now and someone maintaining iperf 2.  On Latency: is not the same as RTT or ping. We\'ve added one-way delay in iperf 2. It does require synchronized clocks. We measure packet times, write to read times, et.. GPS atomic time is quite accurate.  On actionable engineering: For sure end/end is interesting but defining key telemetry on the sub-graphs seems required. Interesting nodes are things like wired to wireless and last-mile *peering points* to end-user device. It seems like ""on-net"" should include servers at the peering points used by the major content providers vs optimizing the last mile only. A flight to a major hub for an airline matters more than a southwest flight between Austin and Dallas. These hubs are critical to flight times (and to flight delays.)  The measurement institution(s) have to be at arms length.  Bob \ue5d3 >> community guidelines [1]. Take care all. \ue5d3 >> In short, NDT does not answer the question “how big is yourA few >> notes.  On LLatency is not the same as RTT or ping. We\'ve added one way delay in iperf 2. It does require synchronized clocks.  >> pipe” but rather “how well is your pipe transferring data.” We >> consider both metrics to be important for understanding >> connectivity. For more reading, you can reference How fast is my >> Internet? Speed Tests, Accuracy, NDT & M-Lab [2] which digs more >> into the definition of “speed” and NDT Data in NTIA Indicators >> of Broadband Need [3], which though focuses on the US federal \ue5d3 >> [4]. >> >> -- >> >> Lai Yi Ohlsen >> >> Director, Measurement Lab [5] >> Code for Science & Society [6] >> >> -- >> You received this message because you are subscribed to the Google >> Groups ""discuss"" group. >> To unsubscribe from this group and stop receiving emails from it, >> send an email to discuss+u...@measurementlab.net. > >> To view this discussion on the web visitA few notes.  On LLatency is not the same as RTT or ping. We\'ve added one way delay in iperf 2. It does require synchronized clocks.  >> > https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcMg5JOuFWy4Fd6G4CKnE3CQN0m0nWXCbCGoZg_S1vcuxw%40mail.gmail.com >> [7]. > > -- > > Lai Yi OhlsenA few notes.  On LLatency is not the same as RTT or ping. We\'ve added one way delay in iperf 2. It does require synchronized clocks.  > > Director, Measurement Lab [5] > Code for Science & Society [6] > > -- > You received this message because you are subscribed to the Google > Groups ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, send > an email to discuss+u...@measurementlab.net. > To view this discussion on the web visit > https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAK0jp%2B-rE_c6oPASz4D5gdBBaac-WP71eXgD_D_k_CuTHeqRpA%40mail.gmail.com > [8]. > > > Links: > ------ > [1] https://www.measurementlab.net/community-guidelines/ > [2] > https://www.measurementlab.net/blog/speed-tests-accuracy/#how-fast-is-my-internet?-speed-tests,-accuracy,-ndt-&amp;-m-lab > [3] > https://www.measurementlab.net/blog/ntia/#ndt-data-in-ntia-indicators-of-broadband-need > [4] > https://groups.google.com/a/measurementlab.net/d/msgid/discuss/a609ce0e-7be6-4b4e-a231-227d7cd4106bn%40measurementlab.net?utm_medium=email&amp;utm_source=footer > [5] http://www.measurementlab.net > [6] https://codeforscience.org/ > [7] > https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcMg5JOuFWy4Fd6G4CKnE3CQN0m0nWXCbCGoZg_S1vcuxw%40mail.gmail.com?utm_medium=email&amp;utm_source=footer > [8] > https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAK0jp%2B-rE_c6oPASz4D5gdBBaac-WP71eXgD_D_k_CuTHeqRpA%40mail.gmail.com?utm_medium=email&utm_source=footer'}, 12: {'username': 'Dave Taht', 'response_date': 'Apr 15, 2022, 10:28:41 AM', 'response_content': 'Ironically, one of my big pushes to get into the NTIA $70B broadband buildout is better, , more secure, constantly upgraded, and more standards compliant, home routers and CPE, and to find ways to regulate better reliability into them in the first place.  CeroWrt\'s routers had uptimes measured in *years*. So my suggestion would be to get a better router. I\'m big on reflashing older ones to openwrt, and installing ""smart queue managemen"" (SQM), which will change the characteristics of your NDT results for the better, but the kind of the results you get now may well be a reflection of the kind of bugs in your router than millions share. Turris and evenroute are also pretty good. \ue5d3 > To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAK0jp%2B-rE_c6oPASz4D5gdBBaac-WP71eXgD_D_k_CuTHeqRpA%40mail.gmail.com.    -- I tried to build a better future, a few times: https://wayforward.archive.org/?site=https%3A%2F%2Fwww.icei.org  Dave Täht CEO, TekLibre, LLC'}}"
11	ndt-query-access-denied	1649955788.0	2022-04-14 10:03:08	Jacob Lester	"I'm new to BigQuery and SQL, that sid, I followed the quickstart guide but when attempting to run even a saved query, am told I lack access.   Or the case of the NTIA.county.sql query "" No matching signature for operator != for argument types: INT64, STRING. Supported signature: ANY != ANY at [50:48]""  any insight is appreciated"	"{0: {'username': 'Stephen Soltesz', 'response_date': 'Apr 14, 2022, 10:07:31 AM', 'response_content': 'Hello, Jacob, can you share the query you\'re using?  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/542e9c36-d5bb-4499-b588-dab7a027782cn%40measurementlab.net.'}}"
12	updates-to-geo-filters-in-unified-views	1649094330.0	2022-04-04 10:45:30	Stephen Soltesz	"As part of our ""Migration to the v2 Data Pipeline"", we discovered that the unified_upload and unified_download views were mixing three different generations of handling geographic annotations. Today we are publishing updates that complete a transition to using a single geographic annotation convention. https://www.measurementlab.net/blog/updates-to-geo-filters/ Starting today, M-Lab will only support the Geo2 ISO3166-2 Subdivision labels in the v2 data pipeline and in the unified views. Practically, this means the ""Region"" field (originally from the Geo1 FIPS-10-4 standard) is no longer populated. BigQuery queries using this field must be updated.  More details are at the blog post above.  Best, Stephen"	"{0: {'username': 'Tao Fineberg', 'response_date': 'Apr 8, 2022, 1:38:51 PM', 'response_content': 'Looks like there is a typo on the blog post   It says ""client.Geo.Subdivsion1ISOCode"" but it should be ""client.Geo.Subdivision1ISOCode""  https://www.measurementlab.net/blog/updates-to-geo-filters/  Thank you for providing this service  Kind regards  Tao   \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/59b14532-8fc1-446c-8696-21d566fdb61cn%40measurementlab.net.   -- Tao   + 41 77 911 59 77'}, 1: {'username': 'Stephen Soltesz', 'response_date': 'Apr 8, 2022, 3:16:58 PM', 'response_content': 'Thank you, Tao, we have a fix pending review. It should be published early next week.  On Friday, April 8, 2022 at 4:38:51 PM UTC-4 tao...@gmail.com wrote: Looks like there is a typo on the blog post   It says ""client.Geo.Subdivsion1ISOCode"" but it should be ""client.Geo.Subdivision1ISOCode""  https://www.measurementlab.net/blog/updates-to-geo-filters/  Thank you for providing this service  Kind regards  Tao   On Mon, Apr 4, 2022 at 7:45 PM Stephen Soltesz <sol...@measurementlab.net> wrote: As part of our ""Migration to the v2 Data Pipeline"", we discovered that the unified_upload and unified_download views were mixing three different generations of handling geographic annotations. Today we are publishing updates that complete a transition to using a single geographic annotation convention. https://www.measurementlab.net/blog/updates-to-geo-filters/ Starting today, M-Lab will only support the Geo2 ISO3166-2 Subdivision labels in the v2 data pipeline and in the unified views. Practically, this means the ""Region"" field (originally from the Geo1 FIPS-10-4 standard) is no longer populated. BigQuery queries using this field must be updated.  More details are at the blog post above.  Best, Stephen   -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/59b14532-8fc1-446c-8696-21d566fdb61cn%40measurementlab.net. \ue5d3'}}"
13	reverse-traceroute-data	1648420322.0	2022-03-27 15:32:02	frog...@gmail.com	Hi,  I would like to check out some reverse traceroute data collected by M-Lab. However, the link to the storage bucket (https://console.cloud.google.com/storage/browser/m-lab_revtr) provided in https://www.measurementlab.net/data/ seems to be invalid.  Can the support update the path to the data? Thanks. Best, Ricky	"{0: {'username': 'Saied Kazemi', 'response_date': 'Mar 28, 2022, 11:26:16 AM', 'response_content': 'Hi Ricky,  Thank you for reporting the problem and sorry that the location access policy changed without us being able to prevent it.  We have not yet completed plans to publish it in an alternate location.  As soon as the data is publicly available again, we will let the community know.  Best,  --Saied  \ue5d3'}, 1: {'username': 'Saied Kazemi', 'response_date': 'Mar 30, 2022, 10:16:34 AM', 'response_content': 'Rocky,  Further to my previous reply, you may want to contact Ethan Katz-Bassett (et...@ee.columbia.edu) of the Reverse Traceroute team for the status of the effort to upload their data to a new third-party GCS bucket that would be publicly accessible.  Best,  --Saied \ue5d3'}, 2: {'username': 'Ricky Mok', 'response_date': 'Mar 30, 2022, 3:42:06 PM', 'response_content': 'Hi Saied, No problem. I will contact Ethan. Thanks. Best, Ricky  Saied Kazemi <sa...@measurementlab.net> 於 2022年3月30日週三 上午10:16寫道： \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/d5e7b4e8-19a5-4c49-9d33-0f87f3dc0375n%40measurementlab.net.   -- FrogGA'}}"
14	seeking-feature-suggestions-for-a-new-python-library-for-ndt-data-access	1648401356.0	2022-03-27 10:15:56	Mingwei Zhang	Greetings!  I'm Mingwei Zhang from BGPKIT. I'm an M-Lab fellow and I'm building a new Python library to make it easier for developers to access M-Lab's NDT data on the BigQuery platform without human intervention (for backend data pipelines) and without the need to explicitly construct SQL statements.  Please let me know if you have any specific need for accessing BigQuery with Python. I am happy to add additional features based on requests.  Thank you! Mingwei Zhang	{}
15	queries-that-use-client.geo.region-returning-0-results	1647638127.0	2022-03-18 14:15:27	Lai Yi Ohlsen	Hi all,   As some data users might have already noticed, queries that use client.Geo.region and date >= 2019-07-18 will now turn 0 results. To address this, you can replace client.Geo.region with client.Geo.Subdivsion1ISOCode. For queries with date < 2019-07-18, you may continue to use client.Geo.Region, though soon client.Geo.Subdivsion1ISOCode will be used across all dates.   We apologize for any inconvenience our delayed notification of this change might have caused and will follow up with a more in depth explanation next week.  Have a great weekend.   -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society	{}
16	fixed---access-error-when-accessing-ndt.unfied_downloads	1647545768.0	2022-03-17 12:36:08	Lai Yi Ohlsen	"Users who ran queries to the tables in `measurement-lab.ndt` e.g. `measurement-lab.ndt.unified_downloads` earlier today might have experienced a permissions error such as ""Access Denied: Table mlab-oti:ndt.ndt5: User does not have permission to query table mlab-oti:ndt.ndt5.""  This was due to an etl-schema release that caused a permissions issue. We have fixed this issue and redeployed a new version. You should not receive any errors when running queries to these tables at this time, but please let us know if you do.  Thank you to the users who reported the behavior and apologies for any inconvenience.   -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society"	{}
17	access-denied-error-for-unified-ndt-tables	1647521976.0	2022-03-17 05:59:36	jamescrr	When trying to query any tables in `measurement-lab.ndt` e.g. `measurement-lab.ndt.unified_downloads` I get permission errors like:  > Access Denied: Table mlab-oti:ndt.ndt5: User does not have permission to query table mlab-oti:ndt.ndt5.  I am able to access the raw tables e.g. `measurement-lab.ndt_raw.ndt7`  I've not accessed M-Lab in a few years, so this might explain it. Looking forward to looking at the data again!  Thanks!  James	"{0: {'username': 'Cristina Leon', 'response_date': 'Mar 17, 2022, 6:09:33 AM', 'response_content': 'Hi James,  Thanks for reporting this. It should be fixed now.  Thanks, Cristina  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/69060a67-03ea-453a-a51e-8472b01e2cd6n%40measurementlab.net.'}, 1: {'username': 'jamescrr', 'response_date': 'Mar 17, 2022, 10:36:56 AM', 'response_content': ""Thanks so much Cristina! confirming it's fixed \ue5d3""}}"
18	access-denied:-table-measurement-lab:measurement-lab.ndt:-user-does-not-have-permission-to-query-table-measurement-lab:measurement-lab.ndt.	1647521979.0	2022-03-17 05:59:39	Marcos Carvalho	Hello everyone,   I am trying to create a map containing the MLAB Speed Test Data for Brazil. But I am receiving the following error when trying to retrieve data from the NDT table: Access Denied: Table measurement-lab:measurement-lab.ndt: User does not have permission to query table measurement-lab:measurement-lab.ndt.  I tried to create a service account under the MLab project but I am not allowed to do anything. Does anyone ran in this problem before and can help me to solve this? 	"{0: {'username': 'Cristina Leon', 'response_date': 'Mar 17, 2022, 6:11:02 AM', 'response_content': 'Hi Marcos,  Thanks for reporting this. Can you try now? It should be fixed.  Thanks, Cristina  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/f2d242f5-5de5-4e6f-b4ca-e4b2018f4442n%40measurementlab.net.'}}"
19	invitation:-user-privacy-&-research-usability-town-hall---03/16/2022-at-11:00a-eastern	1646077530.0	2022-02-28 12:45:30	Lai Yi Ohlsen	Date: Wednesday, March 16, 2022 at 11am Eastern  Summary: Presentation on the benefits and challenges of M-Lab’s collection of IP addresses and potential alternatives    Description: As an open, crowd-sourced dataset, M-Lab aims to protect the privacy of users who submit their data while also not limiting researchers’ ability to draw meaningful conclusions. We currently collect the client’s IP address as a means of identifying each individual data point, but are considering alternatives that could potentially improve the elusive equilibrium of privacy and usability. While we are in the Design Phase, the M-Lab team would like to consult with the users of our data, to better understand what the requirements of this effort ought to include. More specifically, we will ask: what do you use the IP address for when using the data? How well would the proposed alternatives work for these use cases?   If you can’t make it, but want to provide feedback, the session will be recorded. If you can attend though, please do, so we can engage in an active group dialogue as much as possible.   To RSVP: - If you have previously RSVP’d to our community calls, you should have already received a calendar invite with a Zoom link included. If not, please reply directly to this email.  - If you have not previously RSVP’d, but would like to attend, please do so here. You’ll be sent a Zoom link shortly after.  Please note: - We welcome audience questions, answers, challenges, and discussion. The discussion will be technical but no familiarity with M-Lab is required; all we ask is that participants review and respect our community guidelines.  - Our conversation will be recorded. If you attend, you will be asked to give your consent to being recorded. The recording will be published and distributed openly.    If you have any questions, please feel free to reply to this email directly or write to la...@measurementlab.net.    -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society	{0: {'username': 'Lai Yi Ohlsen', 'response_date': 'Mar 15, 2022, 1:05:46 PM', 'response_content': 'Hi everyone,   A reminder that our Town Hall on User Privacy & Research Usability is taking place tomorrow 3/16 at 11am Eastern. Hope you can join us!  \ue5d3'}}
20	ndt7-browser-and-node-upload-inconsistencies	1642004263.0	2022-01-12 09:17:43	Freddie du Plessis	We seem to be facing upload speed inconsistencies with the nodejs example run locally, compared to the browser based test: the nodejs gets about 70% the upload speed the browser version does. download speeds are similar. We have tested this on multiple connections, on multiple platforms and in multiple locations and the inconsistency remains consistent. Upload servers all report locations close to the tests. Is there perhaps a reason for this we may have missed or has anyone else experienced the same?	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jan 13, 2022, 9:43:33 AM', 'response_content': 'Thanks for reporting this issue.  In general, we do expect that the NodeJS client will perform better than the browser version, but you are experiencing the opposite. Our engineering team would like to know more information that could aide in diagnosing and/or replicating this issue. As a starting point, could you please share the operating system and the NodeJS version you are using? \ue5d3'}, 1: {'username': 'Freddie du Plessis', 'response_date': 'Jan 14, 2022, 6:35:09 AM', 'response_content': ""Hi Chris, Thanks for getting back to me. We've had this on a few platforms: OSX Monterey, nodejs 12 and 16 Raspbian buster, nodejs 14.17  Here are some outputs as well:  ran on macosx, nodejs 16. Output from node-client.js, line is 50up/50down, Testing to: {   machine: 'removed for privacy',   locations: { city: 'Same city as where test ran', country: '' } } Download test is complete:     Instantaneous server bottleneck bandwidth estimate: 50.93732 Mbps     Mean client goodput: 49.1293758889882 Mbps Upload test is complete:     Mean server throughput: 45.3462064 Mbps     Mean client goodput: 38.880539325946515 Mbps Browser results report 47.65 down, 47.85 up, same client, same server \ue5d3""}, 2: {'username': 'Freddie du Plessis', 'response_date': 'Feb 9, 2022, 7:41:58 AM', 'response_content': 'Hi Chris, any update on this? \ue5d3'}, 3: {'username': 'Chris Ritzo', 'response_date': 'Feb 9, 2022, 7:46:49 AM', 'response_content': 'I think some testing has been happening but will need to defer to our engineering folks to respond with more detail. \ue5d3'}, 4: {'username': ""Roberto D'Auria"", 'response_date': 'Feb 15, 2022, 9:02:48 AM', 'response_content': 'Hello, thank you for reporting this issue! The different behavior seems to be caused by nodejs\' implementation of WebSockets (specifically, the ""ws"" library that is used to provide WebSocket support in nodejs).                         TL;DR: always use the server-side throughput since it is based on how much data the server has received at the end of the upload measurement and is not affected by WebSocket implementation quirks.  Take the following with a grain of salt as I\'m not an expert in nodejs internals by any means, but here\'s a possible explanation for what you are observing:  The application-level rate (""goodput"" in the client\'s output) is computed as (bytes_sent - bytes_in_buffer) / elapsed_time * 8. While the client knows exactly how many bytes it tried to send (bytes_sent), to determine bytes_in_buffer we rely on the bufferedAmount property of the WebSocket object. The nodejs WebSocket library includes both the WebSocket frame bytes (~10B per frame) and some internal net.Socket buffer in bufferedAmount, potentially causing the bytes_in_buffer to be overestimated and report some data already sent as still in the buffer. This, in turn, causes the computed rate to be lower.  The server-side throughput (based on the last TCPInfo snapshot from the server) is computed as TCPInfo.BytesReceived / TCPInfo.ElapsedTime * 8. It includes TCP/WebSocket/TLS overheads, provides the most accurate rate regardless of the client, and should be used to show the result to the user instead of MeanClientMbps.  I have recently updated our examples to only show the server-side throughput (https://github.com/m-lab/ndt7-js/blob/main/examples/node-client.js#L30) Hope this helps!  -Roberto  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/38ff5a8f-703d-4448-ab0f-fb3ef53e6770n%40measurementlab.net.'}, 5: {'username': 'Freddie du Plessis', 'response_date': 'Feb 16, 2022, 6:15:06 AM', 'response_content': ""Thank you Roberto! I'll implement this and let you know how it goes! \ue5d3""}, 6: {'username': 'Freddie du Plessis', 'response_date': 'Feb 28, 2022, 12:10:17 PM', 'response_content': 'Hi Roberto, Just wanted to let you know we got much better results after implementing your suggestions \ue5d3'}, 7: {'username': ""Roberto D'Auria"", 'response_date': 'Mar 1, 2022, 4:18:07 AM', 'response_content': 'Hi Freddie, Glad to hear that, and thank you for reporting the results!  -Roberto \ue5d3'}}"
21	speed-test-issues-when-using-cellphone-browser	1644946397.0	2022-02-15 10:33:17	Magellan Advisors	We are using Alcehmer for our surveys and have the speed tests built in.  The speed test on cell phones returns what seems to be invalid speeds on the upload test.  Returns extremely high speeds.  Download test seems reasonable.  Anyone who can help our team with this?  -Kelly	"{0: {'username': ""Roberto D'Auria"", 'response_date': 'Feb 15, 2022, 10:58:07 AM', 'response_content': 'Hi Kelly, Thanks for reporting this. I assume you are using the ndt7 protocol via the ndt7-js client library? There is a known issue with Webkit-based browsers where the upload speed is reported incorrectly, and I think this might be what you are seeing. It has already been reported upstream on the WebKit bug tracker and we\'re currently waiting for a reply (https://bugs.webkit.org/show_bug.cgi?id=235707)  We have recently updated our example client code (https://github.com/m-lab/ndt7-js/blob/main/examples/client.html#L48) to report the upload speed using server-side measurements rather than the rate reported by the browser.  Would you be willing to replace the rate calculation in the uploadMeasurement and uploadComplete callbacks with the ones in the example linked above and see if that fixes the issue? Thanks!  -Roberto  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/418692db-cfc3-4cd2-a148-04534736bdb3n%40measurementlab.net.'}}"
22	ndt-results-suboptimal-for-10gbps-paths	1643213523.0	2022-01-26 09:12:03	Tate Baumrucker	Good morning, We're seeing lower than expected tput results from a self-served NDT server for tests across a locally switched 10Gbps path.  iperf3 test results over the same path between the same client/server yield bidirectional > 5Gbps, but NDT results are ~1Gbps down and ~300Mbps up.  Tcpdump reveals significant tcp zero windows during the NDT session.  The server host is running BBR with appropriately tuned stack variables (proven by iperf3 tests).    Are there any known limitations for 10Gbps link speeds?  Any hints for tuning or places to investigate further? Thanks in advance, Tate	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jan 27, 2022, 3:07:58 PM', 'response_content': ""Thanks for writing to ask about self-provisioned use of ndt-server, tuning, and benchmarking on high capacity links.  On our own servers, M-Lab provisions up to 10 Gbps links at maximum, and this is shared across many clients of course. In fact, we have a rate limiter kicking in at 2.5Gb/s which will stop the subsequent test if one exceeds 2.5 in order to preserve measurement quality across all users of a given server at a given moment.  If your goal is to measure the full capacity of the link, you might be better off using iPerf since NDT is a single TCP stream test anyway.   However, we would be interested in your findings as it could show previously undetected bugs. If you could provide the following that would be very useful: pcaps for affected measurements hardware specs for your server,  ndt-server version/git commit you are running and the client code and version/git commit you are using to test It would also be interesting to know whether you're using our ndt-server image from Dockerhub, running code directly from ndt-server's master branch on github, or a tagged release from github.  Thanks again for reporting this, and testing/benchmarking ndt-server. We hope to hear back from you on the info above. \ue5d3""}, 1: {'username': 'Robert Enger', 'response_date': 'Jan 27, 2022, 7:31:16 PM', 'response_content': 'AT&T has recently announced availability of 5Gbps FTTH.  And Qualcomm touts up to 10Gbps capability in the X65 modem for 5G.  Artificially capping results at 2.5Gbps would seem to introduce some bias in aggregate datasets.  E.g. lowering average speed results, which some may be referencing for policy making decisions. (It may also be a lost opportunity to provide objective evidence that the 5 and 10Gbps promises are fictitious in real-world deployment?)  Perhaps it may be appropriate to redesign the server SW to queue requests and serve only one client simultaneously?  (And bolster Mlab servers with carefully implemented higher capacity interfaces and ISP connectivity?)  If consumers are finally being provided with fast connections (or empty promises of such), objective tests should be there to recognize the circumstance.  https://about.att.com/aboutus/pressrelease/2022/fastest-major-internet-provider.html   https://www.qualcomm.com/news/onq/2021/06/28/snapdragon-x65-breaks-record-download-speeds-exceeding-10-gbps-through-5g-mmwave    \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/5eafcc16-15ed-4279-b57d-d9992f6122c0n%40measurementlab.net.'}, 2: {'username': ""Roberto D'Auria"", 'response_date': 'Jan 28, 2022, 5:15:32 AM', 'response_content': 'Robert: I agree with your concern and, in fact, we considered this in the platform design. Further clarifying Chris\' point: M-Lab does not cap results at 2.5Gbps. When a measurement exceeding 2.5Gbps is detected, the server won\'t accept new measurements until that one is complete, to preserve the measurement quality, essentially implementing the ""one client at a time"" policy for a limited time. Clients should move on to the next server provided by the Locate load balancer in case one of them becomes temporarily unavailable due to this.  The above is only true on the M-Lab infrastructure and does not apply to self-hosted ndt-server instances, which are only limited by the link speed and the hardware capabilities of the machines used to run the test.  Almost all the M-Lab sites have 10Gbps uplink, with some exceptions (10 sites that can be found searching for ""1g"" on https://siteinfo.mlab-oti.measurementlab.net/v2/sites/sites.json).  Hope this helps!  -Roberto   \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CA%2Bih9UZsPWqVKMUFxr53OCTF%3D_V3bMKfHgOpMg%2Be-ZtbeCMd9A%40mail.gmail.com.'}, 3: {'username': 'Chris Ritzo', 'response_date': 'Jan 28, 2022, 6:03:44 AM', 'response_content': 'Thanks for adding that detail, Roberto, and clarifying that the initial question posed in this thread concerned testing of a self-provisioned ndt-server. Regarding M-Lab\'s production servers though, one other thing that should be mentioned is that if providers are advertising 5 Gbps and higher link speeds, I am certain that those speeds would only be within their network. Since M-Lab servers are always hosted in peering locations and networks, and NDT is a single stream test, we shouldn\'t expect measurements via those connections to be of total possible link capacity.  Best, Chris  \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/5eafcc16-15ed-4279-b57d-d9992f6122c0n%40measurementlab.net. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3'}, 4: {'username': 'Tate Baumrucker', 'response_date': 'Jan 28, 2022, 6:03:54 AM', 'response_content': 'Can this functionality be added to the self-hosted versions?   Thanks, Tate \ue5d3'}, 5: {'username': ""Roberto D'Auria"", 'response_date': 'Jan 28, 2022, 8:18:55 AM', 'response_content': 'Can this functionality be added to the self-hosted versions?    Assuming you\'re on a Linux environment, yes. This is implemented in the github.com/m-lab/access Go package and enabled via ndt-server\'s command-line flags:  -txcontroller.max-rate=<rate in bits/s> -txcontroller.device=<interface name>  This will monitor the data usage on the specified interface and prevent new measurements from starting when it exceeds max-rate. You can verify that it worked by starting a measurement faster than max-rate, then a separate one in parallel. It should fail to connect until the first measurement has been completed.  Please note, however, that this approach has a known issue. Specifically, if the client runs a download measurement and an upload measurement immediately afterward and the download speed was above max-rate, the upload will fail to connect. The download and upload measurements are independent events with regard to the ndt7 protocol, even if all the clients I know of run both by default. You can find more details at https://github.com/m-lab/ndt-server/issues/334  -Roberto   \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/5eafcc16-15ed-4279-b57d-d9992f6122c0n%40measurementlab.net. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}, 6: {'username': 'Matt Mathis', 'response_date': 'Jan 28, 2022, 8:20:53 AM', 'response_content': 'Robert, the changes you suggest would either raise the cost of our fleet by 10x or reduce our service capacity by 1000x.  (You can\'t tell when a test starts if it needs a dedicated server.)  Today we see a few tests per day at rates  in excess of 1Gb/s, and some minority of these tests cause congestion within our infrastructure and affect other measurements.  In aggregate across the entire fleet (~500 servers) we see a few congested seconds per day.  But there is a deeper problem.  I am not aware of any consumer grade applications* that actually need more than about 100 Mb/s.   The race for more speed is a  stunt (""mine is bigger!"" and ""we have to keep up"") by the marketing departments at all ISPs and are universally hated^H^H^H^H dreaded by the engineering team at the same ISPs.  What is actually happening is there are other problems in the network (typically queuing issues) that cause application stalls unrelated to raw throughput.  The current situation is sort of analogous to fixing the flat tire by upgrading the engine to 5,000 HP.  The mechanic installing the new engine has to beef up the rest of the drivetrain and along the way might accidentally fix the root problem.  But in any case the (new) tires don\'t have enough traction to do anything useful with 5k HP, so the car doesn\'t actually go any faster than the original design (which might indeed be faster than driving on flats).  We (the network testing community) are part of the problem, because we routinely publish performance numbers that are so high that they are not relevant.   This is why we are pivoting to do better diagnosis, so we can help people fix the right problem.  We need to stop wasting vast resources fixing the wrong problem.  I have often toyed with the idea of somehow redacting all results above some threshold (200 Mb/s?) in an attempt to reduce the insanity, but we too are part of an irrelevant race to an irrelevant goal.  *The only exception would be people trying to run commercial grade services on consumer grade connectivity.  Our tools aren\'t designed for them.   At some point we may have to put in stop lists to reject tests from non-consumer grade users.  \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CA%2Bih9UZsPWqVKMUFxr53OCTF%3D_V3bMKfHgOpMg%2Be-ZtbeCMd9A%40mail.gmail.com.   -- Thanks, --MM--'}, 7: {'username': 'Robert Enger', 'response_date': 'Jan 31, 2022, 7:49:02 AM', 'response_content': 'Matt:  A consumer-grade user may be increasingly hard to define, as more and more of us work from home. I am retired and do volunteer work.  I have sent large ""pro video"" source files up to file sharing services to be transferred to editors.    GOOGLE DRIVE allows sustained upload at over 500Mbps, which really cuts down on the wait time.  10GiByte file uploads complete in a few minutes. (It would be nice to be faster, but the bottleneck appears to be at GoogleDrive or Google\'s PI with the ISP).   Mlab and other speed test measurements inform that finger pointing.)  In the LA area, there are many folks who produce and edit from home (for a living), and need to upload and download large files. While folks in LA (and other pro content creation hubs) are shooting with professional camera gear, consumer generation of large video files may become more common as higher image fidelity creation is supported on mobile devices. (Apple sponsors its ""Shot on iPhone"" program.  And other device manufacturers, including Google, are including improved camera sensors in their phones.  I\'ve seen ""shot on iphone"" short films run at film festivals.  Submittal to the festival was by online upload.)  Velma does clinical monitoring of advanced cancer treatments.  While she travels to research centers, she does have a home office and accesses some resources remotely from time to time.  I understand from her and the media that remote-reading of medical imaging occurs frequently.  (The radiologist that evaluates a given test may be in another state or country.)   As the imaging resolutions improve, transferred files will get larger.  (Detail counts when looking for lesions.)  We repeatedly hear that there is a  groundswell of employee support for ""work from home"".   High performance FTTH implementations make that increasingly feasible.  MLAB testing can ensure that the promises of FTTH providers are actually delivered. Disparaging high performance seems like the old ""no one will need more than 640k"" mantra. I prefer ""if you build it they will come"".    I certainly enjoy being able to download OS patches and new SW ""quasi-instantaneously"".  Indeed, downloads are so fast now that when a CDN errantly serves you from sub-optimal source (say one half-way around the globe in Europe) the degradation is readily apparent.  When Velma\'s company\'s IT staff first deployed a remote update to her (then new) machine, they called her and told her they suspected it was not working correctly, as it completed so quickly.  (At the time she had one of the newest machines in her company.  It is M.2 based, and she is GigE attached to the home LAN, with Gig FTTH ISP service.)  Windows-11 will force a lot of folks to replace their legacy PCs.  A whole lot of folks will be getting their hands on newer machines, many will be built upon M.2 NVMe.   This will remove yet another layer of performance impediment from the consumer-grade user. Ditto for migrations to wifi-6E mesh systems, and mm-wave 5G for mobile devices (at least in good signal areas).  I think Mlab and the other test services can continue to add value, even as consumer last-mile bottlenecks are removed (albeit at a seeming glacial pace with some ISPs). I hope Mlab will continue to support testing of high-speed connections, including the multi-Gig FTTH being deployed by Google, AT&T and some municipal ISPs.  Bob Enger \ue5d3'}, 8: {'username': 'Matt Mathis', 'response_date': 'Feb 8, 2022, 8:50:03 AM', 'response_content': 'One of my regrets about MLab is that we have been overly focused on whether rich people are getting what they want, rather than whether poor people are getting what they need.  You are correct, we could raise our performance ceiling.   I first started working on Internet performance at the Pittsburgh Supercomputing Center in 1990.   That year, I was trying to get PSC -> SDSC to run faster than 5 Mb/s.  For many years, my day job was ""TCP tuning"", and every few years we would fix one global problem, but then have a new goal and a new set of problems to debug and deploy.  Yes we could raise MLab\'s target performance to 10 Gb/s.  Improving our  tools is probably doable, but upgrading our fleet would be problematic.  However, today I worry far more about the other end of the spectrum.    I fear there are several billion of people (including millions of Americans) who don\'t have sufficient Internet to do basic things that the rest of us now take for granted.    We do not know if MLab tools get reliable measurements below 1 Mb/s, and that means we can\'t effectively measure Internet coverage for a huge number of people.  We do know that some of the optimizations that are likely to help the high end have the potential to hurt measurements at the low end (specifically larger buffers).  We do know the data collection and processing pipeline is capable of reporting all the way down to about 1kbit/sec, but the each diagnostic client has it\'s own limits.  You might find this plot useful: it was on my home page at PSC for many years:     \ue5d3 -- Thanks, --MM--'}}"
23	api-to-validate/get-a-specific-ndt7-result	1643139416.0	2022-01-25 12:36:56	Yihwan Kim	"Hi, is it possible to ""validate"" or GET a specific NDT7 result, perhaps using id/uuid?  The idea is to create an app that stores and presents speed test results in a useful way. However, I'd like to protect against malicious behavior (e.g., hammering my app with fake data). One way to do this might be to only send the UUID of a test result to my server, which would then GET all the desired fields using that UUID.   Also open to any other suggestions or considerations too. Thanks in advance for your help. "	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jan 26, 2022, 6:39:31 AM', 'response_content': 'Each NDT7 client we provide should return the test results to the app upon completion, as well as messages during the test. Both could be used within your presentation to the end user.  The UUID is helpful if you wish to look up the test results once they are parsed into BigQuery, which happens within ~24-48 hours of the test time. This could provide more detailed information that could be used, such as the TCP snapshots gathered during the test, variables like RTTVar (jitter), traceroutes between our server and the client, or comparison to tests from similar clients in the surrounding geographic region. All that would need to be designed of course, and should include review by someone who knows TCP/IP well in order represent the data accurately for what it is measuring.  I hope this helps. Perhaps others who have developed NDT clients would have more to share. \ue5d3'}, 1: {'username': 'Yihwan Kim', 'response_date': 'Jan 27, 2022, 7:31:20 PM', 'response_content': ""Thanks, Chris! Yes, I was able to get a basic speed test working in my web app (purely on the client using Next.js). I was amazed by how easy it was to set-up, so kudos to the team who put together the ndt7-js library.   The idea was to then take those results (displayed on the client) and persist them back to my own server. That's why I was thinking about how to protect against possible (albeit probably unlikely) attacks that could POST fake data into my server. Sounds like there might be a way to do this by cross-referencing test results after they have been parsed into BigQuery, so I'll take a look at that next.   I'm also open to any other options too, just let me know! :)  \ue5d3""}, 2: {'username': 'Yihwan Kim', 'response_date': 'Jan 28, 2022, 5:34:07 AM', 'response_content': 'Just a quick follow-up to verify my understanding of how the data in BigQuery works, I just ran two tests from my app.  In the `downloadComplete` callback, I see that the `data` arg looks something like this:  LastClientMeasurement: ElapsedTime: 9.632 MeanClientMbps: 243.02399169435216 NumBytes: 292600886 [[Prototype]]: Object LastServerMeasurement: BBRInfo: {BW: 55256258, MinRTT: 4999, PacingGain: 256, CwndGain: 512, ElapsedTime: 9477684} ConnectionInfo: Client: ""[2600:1700:8ca0:8020:19e9:932c:8885:f302]:56770"" Server: ""[2001:438:fffd:2e::216]:443"" UUID: ""ndt-zpjqw_1642802044_00000000000593D9"" I interpret this to mean that my ""Download speed"" is ~243 Mbps.   Then, in the `uploadComplete` callback, the `data` arg looks like:  LastClientMeasurement: {ElapsedTime: 9.802399999976158, NumBytes: 146327000, MeanClientMbps: 119.42136619632409} LastServerMeasurement: BBRInfo: {BW: 328800, MinRTT: 7185, PacingGain: 739, CwndGain: 739, ElapsedTime: 9534053} ConnectionInfo: Client: ""[2600:1700:8ca0:8020:19e9:932c:8885:f302]:56812"" Server: ""[2001:438:fffd:2e::216]:443"" UUID: ""ndt-zpjqw_1642802044_00000000000593DD"" [[Prototype]]: Object TCPInfo: ... BytesRetrans: 1286 BytesSent: 48621 I calculate the ""Upload speed"" by using this formula: data.LastServerMeasurement.TCPInfo.BytesReceived / data.LastServerMeasurement.TCPInfo.ElapsedTime) * 8, which works out to about 117.67 Mbps.  Would it be correct to query the `ndt_unified_ndt7_downloads` and `ndt_unified_ndt7_uploads` tables respectively, using `a.uuid` for each respective test? If so, can I get the `MeanThroughputMbps` value for both the upload/download speeds?   Thanks in advance for your patience. I\'m very new to all of this, and I\'m still learning a lot!  \ue5d3'}, 3: {'username': 'Chris Ritzo', 'response_date': 'Jan 28, 2022, 5:54:43 AM', 'response_content': ""The upload result also includes MeanClientMbps within LastClientMeasurement. This is the upload throughput in Mbps.  And yes, it is correct to query `measurement-lab.ndt.unified_downloads` and `measurement-lab.ndt.unified_uploads` for each test matching on `a.UUID`. Filtering on a date or range of dates is required also for querying those views.  One additional thing to note is that the unified_uploads and _downloads views are curated to include only tests that meet our team's best and current understanding of completeness and quality as outlined here. If the test errors or otherwise doesn't conform to those specs, they won't be found in unified views, but will be found by matching UUID in `measurement-lab.ndt.ndt7`. \ue5d3""}, 4: {'username': 'Yihwan Kim', 'response_date': 'Feb 8, 2022, 7:13:35 AM', 'response_content': ""Thanks Chris! Just to circle back on this, I requested BigQuery API access a while back by emailing support@, but I haven't heard back yet. Do you know if BigQuery API access is still available?   Happy to share my intended use case or any other information that'd be helpful  \ue5d3""}, 5: {'username': 'Chris Ritzo', 'response_date': 'Feb 8, 2022, 7:16:49 AM', 'response_content': ""By BigQuery API, may I assume you mean SQL querying using BigQuery? There isn't an API, it's just querying the NDT data. You can use this guide to get your account on the access list: https://measurementlab.net/quickstart \ue5d3""}}"
24	data-by-device-type	1643826414.0	2022-02-02 11:26:54	Lizaveta Radzevich	Hi,  Is there any way to see what device speed test was run on (PC vs mobile)?  Also, I remember I had my hands on some documentation for the meaning of each column, but cannot find it again. 	"{0: {'username': 'Chris Ritzo', 'response_date': 'Feb 4, 2022, 4:50:01 AM', 'response_content': ""Thanks for writing with this question.  Today there is not a field that flags a test as coming from a mobile network or other service delivery media, but the tests can be segmented in analyses using ipinfo.io's API. See this past post for more info. I have suggested this as a feature for our annotations for some time now, so if this is something that would be helpful to your research please reply to let the team know.  Regarding documentation on the meaning of each column, we assume you mean the NDT tables, but let us know if you mean otherwise. Also, I'm sorry that's been in a bit of transition as the engineering team has been moving our datatypes to a standard column layout. This has delayed publication of a final schema and description for several tables and views.  However, you can find much of this information in a couple places for your immediate use. First, the best place to get the most current schemas with field names and data types is to use the BigQuery UI or `bq` command line tool. For example,this link will display the Schema for `measurement-lab.ndt.unified_downloads`. Unfortunately, the field or column descriptions are not published there (yet).  On the ndt7 datatype page you can find a table with descriptions of the fields/columns in `measurement-lab.ndt.ndt7`, many of which are the same as in the unified_ views. If you are using ndt5 or web100 datatypes, those pages also have complete field descriptions.  I hope this is helpful. \ue5d3""}, 1: {'username': 'Glenn Fishbine', 'response_date': 'Feb 4, 2022, 11:51:31 AM', 'response_content': 'To supplement this, there are two fields, MNC and MCC in the ipinfo return which if non-zero indicate the cellular country and company.  If they are empty or zero, the IP address is not generated on a cellular network.  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/65008612-5bd3-4459-befe-2587d2a5cbe1n%40measurementlab.net.'}}"
25	traceroute-rfc---request-for-feedback-by-end-of-january	1642550261.0	2022-01-18 16:57:41	Lai Yi Ohlsen	Hi everyone,   M-Lab has published an RFC discussing our transition from MDA traceroute data. If you use our traceroute dataset or plan to in the future, please take a look at the RFC and send us your feedback by the end of January. Excerpt below.   ----  Background M-Lab’s traceroute-caller (TRC) tool was designed and developed in early 2019 as a sidecar service running on M-Lab servers. Its purpose is to collect traceroute data to any remote IP address after it closes its TCP connection to an M-Lab server. TRC uses the scamper tool for running traceroutes.   The initial version of TRC called scamper to run the tracelb command and saved the resulting traceroute as traceroute datatype which was renamed to scamper1 datatype.  As described in scamper’s manual page, the tracelb command is used to infer all per-flow load-balanced paths between a source and destination using the Multipath Discovery Algorithm (MDA). Starting in 1Q22, TRC also supports regular traceroutes which take much less time to run and return a simpler result that is saved as scamper2 datatype.  M-Lab would like to start collecting regular traceroutes (in addition to MDA traceroutes) in 1Q22 and stop collecting MDA traceroutes by the end of 2Q22.  Request for Comments We are publishing this RFC to get feedback from the community regarding our decision to stop running MDA traceroutes by the end of 2Q22 and, instead, run regular traceroutes with the Paris traceroute algorithm.  If you use MDA traceroutes (scamper1 datatype) and this decision impacts you, please let us know via reply to the dis...@measurementlab.net mailing list. Also, please let us know if you are planning research that would benefit from regular traceroutes (scamper2 datatype).  Based on your feedback, we will decide if we need to continue running MDA traceroutes and how to support it beyond what we already have.  Read the full RFC on our website.  Thanks! Happy New Year.   -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society	"{0: {'username': 'Timur Friedman', 'response_date': 'Jan 19, 2022, 12:39:26 PM', 'response_content': 'Hello Lai Yi,  Am I correct in understanding that two things motivate this change?  - The complexity of parsing the multipath traceroute data structure - The time that it takes to run the MDA in order to collect a multipath traceroute  If so, there are alternatives to abandoning the collection of multipath traceroutes. After all, M-Lab has the largest set of multipath traceroutes (well over one billion!) going back over many years. Anyone who wants to study how multipath routing has evolved over time in the internet would be hard-pressed to find any other comparable dataset.  Regarding the complex data structure, a single-path traceroute could easily be extracted from a multipath traceroute via post-processing. It would not be necessary to conduct the measurement twice.  And regarding the time that it takes, the problem has been solved in Kevin Vermeulen\'s Diamond-Miner work.  https://www.usenix.org/conference/nsdi20/presentation/vermeulen  While Kevin\'s work focuses on rapidly collecting traceroutes towards all of the internet\'s routable prefixes in a short period of time, the principles behind the speed-up apply equally well to a trace towards a single destination. In a first round of probing, packets to all hop-counts can be sent in parallel, and ten rounds of probing are almost always enough to complete a multipath traceroute, meaning the time required is slightly less than the time required for a classic traceroute, which has a time requirement that scales with the length of the route.  We\'ve distilled the Diamond-Miner probing engine into free open-source liberally licensed code that we call Caracal.  https://github.com/dioptra-io/caracal  With Caracal, we could easily speed up M-Lab\'s multipath route tracing while producing both multipath and single path outputs in the existing formats that M-Lab provides.  Incidentally, we are producing daily surveys from a single vantage point of multipath traceroutes to all routable IPv4 prefixes in the internet, and these are available to any researcher upon request through our Iris platform.  https://iris.dioptra.io/#/  So if M-Lab continues to collect multipath traceroutes, it will no longer be alone in doing so, which should enhance the value of M-Lab\'s multipath data for the research community.  Kind regards,  Timur   \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcO1ReqyZNtqn57MSws33khjyTMW%2B6MoSQtsRj%3DdZAgjew%40mail.gmail.com.'}, 1: {'username': 'Stephen Soltesz', 'response_date': 'Jan 19, 2022, 1:16:21 PM', 'response_content': 'Thank you, Timur, comments below.  On Wed, Jan 19, 2022 at 2:39 PM Timur Friedman <t...@oxus.net> wrote: Hello Lai Yi,  Am I correct in understanding that two things motivate this change?  - The complexity of parsing the multipath traceroute data structure - The time that it takes to run the MDA in order to collect a multipath traceroute  From my perspective, the primary challenge is using the multipath traceroute data. People often expect the single-path traceroutes, or may require this when combining this dataset with other datasets.  If so, there are alternatives to abandoning the collection of multipath traceroutes. After all, M-Lab has the largest set of multipath traceroutes (well over one billion!) going back over many years. Anyone who wants to study how multipath routing has evolved over time in the internet would be hard-pressed to find any other comparable dataset.  I like this point. M-Lab was founded to collect longitudinal data. ""Don\'t throw out the baby with the bath water"" so to speak. Do you know anyone who is doing this type of research on multipath traceroutes?  Regarding the complex data structure, a single-path traceroute could easily be extracted from a multipath traceroute via post-processing. It would not be necessary to conduct the measurement twice.  Can you say more about how to easily extract a single-path traceroute from a multi-path traceroute? We touched on this conversationally but the mechanism was unclear. There are two potential users here: those who wish to process the raw archive files themselves, those who wish to use BigQuery.  Best, Stephen'}, 2: {'username': 'Timur Friedman', 'response_date': 'Jan 19, 2022, 2:11:12 PM', 'response_content': 'Hi Stephen,  From time to time there have been systematic studies of multipath routing in the internet, the most recent that comes to mind being Rafael Almeida\'s doctoral thesis in 2019 on ""Classification of Load Balancing in the Internet"" (he\'s also the lead author on an IEEE Infocom 2020 paper of the same name), but I am not sure that, besides our own group, Dioptra.io, and, of course, M-Lab, there are groups that are engaged in long-term efforts to document it.  Multipath routing is one of those things like MPLS tunnels and IP anycast that reflect ongoing fundamental changes in how things work in the internet. To me, it would be a pity to see a break in this key dataset that allows people in the future to study how this particular architectural aspect of the network has evolved.  In order to extract a single-path traceroute, one simply needs to focus on a single flow identifier, what the RIPE Atlas folks call the ""Paris ID"", and pick out the interface at each hop that corresponds to that identifier in the multipath traceroute.  There are some implementation details to be addressed, such as what happens in the rare case that a per-packet load balancer is traversed, and the same Paris ID returns multiple interfaces at the same hop; or which path to prefer if one is longer than another, or has a better response rate from interfaces than another. So long as the design decisions are well documented, I do not see any fundamental difficulties.  Users would not need to do this processing themselves if it were provided as a post-processed output from the multipath traceroute tool itself. The tool could provide both the multipath traceroute and an example single-path traceroute corresponding to a single Paris ID.   Kind regards,  Timur \ue5d3'}, 3: {'username': 'Kavé Salamatian', 'response_date': 'Jan 19, 2022, 3:07:38 PM', 'response_content': 'Hello all,   I am also using these data and I am aware of some people in Columbia also using these data.   All the bests  Rgds    \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/9c7b5e18-8af6-41fd-b357-18523549f689n%40measurementlab.net.'}, 4: {'username': 'Timur Friedman', 'response_date': 'Jan 20, 2022, 6:23:08 AM', 'response_content': 'Hello Matt,  Agreed: multipath tracing ought not come at the cost of obtaining a decent single-path trace.  This strikes me as an implementation issue that could be addressed by tweaking the current tracing tool.  It is possible to design a route tracing tool so that classic Traceroute\'s demultiplexing issue goes away.   The original insight was Rob Beverly\'s: to craft the traceroute probe packets in such a way that the ICMP replies are entirely self-identifying. This does away with the need to maintain state on each probe packet sent, in order to match each reply with its corresponding probe packet. He based his high-speed single-path probing tool Yarrp on this insight.  Kevin Vermeulen extended the same principle to multipath probing: his Diamond-Miner tool similarly crafts the probe packets so that the ICMP replies are self-identifying, including, in this case, the flow identifiers, or ""Paris IDs"", of each probe packet that provoked a reply.  Now, our Iris measurement platform regularly runs Diamond-Miner route traces towards all routable IPv4 prefixes of the internet at a rate of 100,000 probe packets per second. Under these conditions, there are hundreds of thousands of outstanding probe packets at any given moment, and when the replies do come in, they are successfully associated with the trace of a particular route or, occasionally, if the reply is corrupted in some way, discarded.  The 100,000 probe packet per second limit is self-imposed so as not to trigger warnings with our ISP. Otherwise, Diamond-Miner could be scaled to run faster, say at a million probe packets per second or more, while all the time correctly identifying the replies.  We have embodied this behavior in our liberally-licensed free open-source Caracal probing engine. As I mentioned, earlier in this thread, we could easily provide the route tracing tool that M-Lab needs on the basis of this engine. It would be sure to obtain a single-path route trace alongside each multipath trace. And it would withstand whatever case load you send its way. I\'m including Maxime Mouchet, the lead developer and maintainer of the current version of Caracal, in the conversation.   Kind regards,  Timur     On Thu, Jan 20, 2022 at 5:58 AM Matt Mathis <mattm...@google.com> wrote: Another consideration is that multipath traceroute is more likely to outright fail (zero output) on some of the most interesting paths, because it reaches a time limit or some other resource limit.  My wish would be to increase the  coverage of the single path traceroutes, possibly by relaxing the coverage on the multipath traceroute.  My chronic worry is our ability to assure that we are properly demuxing the ICMP replies, under our worst case loads.   Thanks, --MM-- The best way to predict the future is to create it.  - Alan Kay  We must not tolerate intolerance;        however our response must be carefully measured:              too strong would be hypocritical and risks spiraling out of control;             too weak risks being mistaken for tacit approval.   \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/13004FCF-BDCF-4FD6-8FCC-BEB2C14EAD20%40univ-savoie.fr.'}, 5: {'username': 'Matt Mathis', 'response_date': 'Jan 20, 2022, 6:23:08 AM', 'response_content': 'Another consideration is that multipath traceroute is more likely to outright fail (zero output) on some of the most interesting paths, because it reaches a time limit or some other resource limit.  My wish would be to increase the  coverage of the single path traceroutes, possibly by relaxing the coverage on the multipath traceroute.  My chronic worry is our ability to assure that we are properly demuxing the ICMP replies, under our worst case loads.   Thanks, --MM-- The best way to predict the future is to create it.  - Alan Kay  We must not tolerate intolerance;        however our response must be carefully measured:              too strong would be hypocritical and risks spiraling out of control;             too weak risks being mistaken for tacit approval.   On Wed, Jan 19, 2022 at 2:07 PM Kavé Salamatian <kave.sa...@univ-savoie.fr> wrote: \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/13004FCF-BDCF-4FD6-8FCC-BEB2C14EAD20%40univ-savoie.fr.'}, 6: {'username': 'Ethan Katz-Bassett', 'response_date': 'Jan 20, 2022, 1:02:23 PM', 'response_content': 'Chiming in as one of the people at Columbia Kavé mentioned as using the data....  [I\'m also adding the other people on my MLab project ot the thread, including Kevin who developed the Diamond-Miner tool that Timur mentioned]  I agree with everything that Timur said: - Most of the drawbacks of multipath tracing that have been mentioned have been solved or seem to be addressable. - I hope you\'ll continue issuing multipath measurements. - It seems to make sense to extract (in post processing, when storing the data) a single path measurement from each of those and ""present"" that as the basic traceroute that many users will use without looking at the multipath measurement. The multipath measurements can be in a separate table for those who want them, perhaps with a foreign key to join between the two.  Our most common use case has been when we are working on something related to Internet routing/measurement and need a large set of multipath routes or load balancing routers, to help us test the behavior of our measurements in that setting or to help us interpret those results. It\'s useful to have large sets of such measurements already available (from Timur\'s platform and/or M-Lab) that we can easily use to join with our measurements.  Ethan  \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CADXAtJ43xRVxwTgxxPPGgRByki6uYF_f9U03Nn9FtApg0S6f-A%40mail.gmail.com.'}, 7: {'username': 'Lai Yi Ohlsen', 'response_date': 'Jan 21, 2022, 12:21:15 PM', 'response_content': 'Hi everyone,   Thank you so much for your feedback thus far. It is clear there is an interest in M-Lab continuing to collect multipath traceroutes. We have some follow-up questions that we will circle back with next week.   Have a great weekend!  \ue5d3 \ue5d3'}, 8: {'username': 'Lai Yi Ohlsen', 'response_date': 'Jan 31, 2022, 3:26:11 PM', 'response_content': 'Hi again,  As noted by Saied in our follow-up to discuss@ (""Traceroute Format Change RFC Results""), we will continue to collect MDA traceroutes as before and archive them as scamper1 datatype. With this decision, we have some follow-up questions about implementation and are in the process of organizing a meeting with the participants on this thread to discuss these details.   If you would like to also be included in this discussion re: MDA traceroutes or have recommendations for others to include, please let me know by replying to this email. We are also seeking feedback about the use of our traceroute data more broadly -- please see the thread ""Accessing Traceroute data"" for more information.   Thanks!  \ue5d3'}}"
26	accessing-traceroute-data	1643326233.0	2022-01-27 16:30:33	Saied Kazemi	"It seems like there is some confusion about accessing M-Lab's recent traceroutes due to a change in its datatype name.  Up until early September 2021, MDA traceroutes were archived in Google Cloud Storage (GCS) as ""traceroute"" datatype.  Since then, they are archived as ""scamper1"" datatype without any changes to the content.  You can visit the links below to access traceroute archives obtained by the ""host"", ""ndt"", and ""neubot"" experiments (replace $experiment accordingly).  Before 2021-09-11: https://console.cloud.google.com/storage/browser/archive-measurement-lab/$expriment/traceroute After 2021-09-11: https://console.cloud.google.com/storage/browser/archive-measurement-lab/$experiment/scamper1  We will soon update the Traceroute page on M-Lab's website to cover the name change and also provide links to ""scamper1"" datatype.  Saied Kazemi Software Engineer"	{}
27	traceroute-format-change-rfc-results	1643326048.0	2022-01-27 16:27:28	Saied Kazemi	Thanks to everyone who provided feedback to our Traceroute RFC.  We are glad that the community is finding M-Lab's traceroute data useful and is actively using it.  Based on the feedback we have received, we will continue to collect MDA traceroutes as before and archive them as scamper1 datatype.  We are eager to hear from you how you use traceroute data.  In particular, we appreciate you letting us know: Do you use the traceroute archives in GCS or do you query traceroute data in BigQuery? What tools do you use to analyze traceroute data? What dashboards, reports, citations, etc. have you created? Your answers will help us further improve our traceroute collection and archival processes.  Saied Kazemi Software Engineer	{}
28	webkit-bug-report-filed-re:-recently-reported-issues-with-safari,-ios,-etc.	1643311909.0	2022-01-27 12:31:49	Chris Ritzo	In response to our team's research into issues encountered by NDT clients conducting tests via browsers using Webkit, as well recently reported threads here re: iOS, Safari, etc., M-Lab's engineering team has submitted this bug report:  Bug 235707 Summary: WebSocket.send() overflows the buffer but bufferedAmount is zero https://bugs.webkit.org/show_bug.cgi?id=235707  If this bug is affecting your integration of the NDT test, please consider commenting on the issue as reported to the Webkit team.	{}
29	are-community-calls-recorded-anywhere?-+-quality/performance-disclosures	1642623617.0	2022-01-19 13:20:17	marin...@gmail.com	Hi everyone!  As the FCC prepares to kick off a comment period around broadband disclosure labels and what to include in them to better inform US consumers[1], I'm interested in what ideas have been floated in this community around the topic of broadband performance.  I noticed some community calls have touched on the issue and I'm curious if the recordings get posted anywhere.  Also, if anyone knows of any additional resources (papers, talks, webinars, people, etc) around communicating quality of service/quality of experience metrics to consumers and can point me to them, I'd appreciate it!  [1] https://docs.fcc.gov/public/attachments/DOC-378983A1.pdf	"{0: {'username': 'Lai Yi Ohlsen', 'response_date': 'Jan 19, 2022, 1:54:19 PM', 'response_content': 'Hello!   Thank you for starting this conversation, I\'m looking forward to hearing the community\'s thoughts on the topic.   Regarding our community call recordings -- we did not record the calls at first in an effort to keep things casual, but did begin to record in August 2021. Here\'s the video of Latency, Bufferbloat and Responsiveness with Matt Mathis, Christophe Paasch and Dave Taht, who discussed metrics for broadband performance alternative to bandwidth (which some feel has been overemphasized/optimized for). And more recently, Dave Clark and Sara Wedeman from MIT discussed their paper Measurement, Meaning and Purpose which explored the M-Lab NDT dataset and its ability to assess broadband performance. The video of that call has not been uploaded yet, but I will post to this discuss@ list when it has.    From an academic, network research perspective, you might find the papers of the recent IAB workshop on Network Quality interesting and relevant. The summary of that event is quite useful. And from a digital inclusion perspective, you might be interested in joining the Marconi Society-led Broadband Mapping Coalition, a network of orgs advocating for the use of open data in broadband planning.   For M-Lab data specifically, we\'ve written a set of best practices to help guide the use of our data in broadband advocacy and policy work. We\'ve also written a guide to NTIA\'s Indicators of Broadband Need map for researchers trying to make sense of the similar but quite different methodologies that the map draws upon. More broadly, as the national conversation around broadband performance continues to unfold, M-Lab will continue to be a resource by providing open Internet performance data and aim to adapt that resource as needed. Whether that\'s in new analyses of our current data or additions to the measurements that we host, we\'ll be listening for feedback about how we can best contribute.   Hope this helps, happy to provide more detail.    \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/2d7d5080-a429-447c-9967-1882e3691902n%40measurementlab.net.   -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society'}, 1: {'username': 'Christine Parker', 'response_date': 'Jan 20, 2022, 7:29:02 AM', 'response_content': "" While broadband pricing transparency/speeds are the focus of this report from the Institute for Local Self Reliance, it does discuss some important points about broadband labels that I think will be applicable in regards to broadband performance.    Christine Parker, PhD (she/her) GIS & Data Visualization Specialist | Community Broadband Networks Institute for Local Self Reliance  My working hours may not be your working hours. Please don't feel obliged to reply to this email outside of your normal working hours.   \ue5d3 \ue5d3 -- \ue5d3""}, 2: {'username': 'Livingood, Jason', 'response_date': 'Jan 20, 2022, 7:53:32 AM', 'response_content': 'The label question is an interesting one, Christine. I hope whatever we end up with isn’t (1) like the cookie notices on websites where users just click past them or (2) the bank/credit card policies that I still get in print form annually, in what seems like 5-point font. Perhaps it could benefit from the expertise of behavioral economists[1] and UI/UX designers, because I worry what end users will be presented with will be overwhelming & confusing. (I’m not debating the need to communicate the info – just how to do it in a way that is comprehensible, etc.)   Jason   [1] Something the USG recognized back in 2015 https://obamawhitehouse.archives.gov/the-press-office/2015/09/15/executive-order-using-behavioral-science-insights-better-serve-american \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAAJZi1LpQ_3oYxumS3VS3p3tOnjrAfE-Fu1-p0j4x_As%2BheG0w%40mail.gmail.com.'}, 3: {'username': 'Livingood, Jason', 'response_date': 'Jan 20, 2022, 7:53:32 AM', 'response_content': 'In addition to Lai’s excellent list of references below, I suggest CAIDA’s reports on their two “WOMBIR” workshops. See https://www.caida.org/workshops/wombir/2101/ and https://www.caida.org/workshops/wombir/2104/. And also the Workshop on Tracking QoE in the Internet at https://www.aqualab.cs.northwestern.edu/wp-content/uploads/2019/02/p55-bustamante.pdf.   Jason   From: Lai Yi Ohlsen <la...@measurementlab.net> Date: Wednesday, January 19, 2022 at 15:54 To: ""marin...@gmail.com"" <marin...@gmail.com> Cc: discuss <dis...@measurementlab.net> Subject: [EXTERNAL] Re: [M-Lab-Discuss] Are community calls recorded anywhere? + Quality/Performance Disclosures   Hello!  \ue5d3 \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcNy-oUu1gthC9keQQ22YphN9crH_iQEHMBno2dGaZhVrQ%40mail.gmail.com.'}, 4: {'username': 'Livingood, Jason', 'response_date': 'Jan 20, 2022, 8:00:34 AM', 'response_content': 'A few additional thoughts… IMO each ISP will need to choose (and be prepared to defend) the measurement methodology & system behind each specific performance line item. I would guess that such data will usually tend to come from measurement agents installed in user CPE (or device) or via a sample of users that have installed extra probes (a la the FCC MBA program). But perhaps also some can be pulled directly from the FCC MBA data or other independent sources.   Beyond that, I am not sure the community yet has consensus on a common approach to measuring each item and there is perhaps some incremental work to do there. I’m giving a little thought to how to potentially do so (with broad involvement – not just ISPs) – anyone interested can feel free to ping me 1:1 off-list.   Jason \ue5d3'}, 5: {'username': 'marin...@gmail.com', 'response_date': 'Jan 21, 2022, 7:17:47 AM', 'response_content': ""Many thanks for all the resources and thoughts being shared.  The current FCC proposal would have ISPs share the following info with consumers on performance metrics by speed service tier:  - Typical speed downstream (Mbps) - Typical speed upstream (Mbps) - Typical latency (Milliseconds) - Typical packet loss (%)  (you can view the entire proposed label in appendix B of the PDF I mentioned previously--it's meant to look like a 'nutrition facts' label)  The Latency, Bufferbloat and Responsiveness discussion was really interesting and raised some questions for me around using these traditional metrics. I'm currently making my way through the IAB workshop papers in search of additional perspectives. Thanks so much for all the reading material suggestions, I will do my best to read through it all.  -Marina \ue5d3""}}"
30	m-lab-research-fellows-announced-for-spring-2022	1642174263.0	2022-01-14 08:31:03	Lai Yi Ohlsen	Hi everyone,  I'm excited to announce the selection of M-Lab Fellows for our first Research Fellowship, starting this month and culminating in May 2022. The cohort was selected for the merit, rigor, and feasibility of their proposed project as well as their research’s relevance to improvement for end-user Internet performance. You can learn more about their work in our new blog post and I look forward to sharing more about their work throughout the next six months.   Thank you again to everyone who took the time to apply to the program and to Internet Society for their generous support. Have a great weekend!   -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society	{}
31	blog-posts-&-community-call-updates	1626988622.0	2021-07-22 14:17:02	Lai Yi Ohlsen	Hi all,   Hope you're doing well and staying safe. Writing to share some M-Lab updates from the months of June and July.   Blog posts M-Lab's Murakami Tool - Supporting Structured Research Data Collection from the User Perspective discusses the work of the MIRA project, a joint initiative of Internet Society and AFRINIC, and their use of Murakami, an open source tool which offers three key features: a method for collecting standardized data; automatic, recurring measurements; and support for multiple measurement methodologies. Read more if you'd like to use Murakami in your research or help develop the tool in the future. Thank you to the MIRA team for your collaboration and IMLS for the project's initial support.    NDT Data in NTIA Indicators of Broadband Need is a follow-up to the release of the NTIA Indicators of Broadband Need, a needed and welcome contribution to US broadband mapping. In this blog post, we discuss the inclusion of data from our Network Diagnostic Tool (NDT) in the NTIA map and dig into the detail of each dataset provided in the Indicators of Broadband Need map. The post gives readers a deeper understanding of the differences and context to the various datasets in the NTIA Indicators of Broadband Need Map, as well as our understanding of how each relates to the 25/3 national broadband standard. Thanks to NTIA for including M-Lab data in the map as well as Benton Institute for including our article in your newsletter.   And on June 29th, 2021 we published an update about recent developments to ndt7, including fixes for Safari and Firefox integrations and more. Thank you to all the community contributors who helped with the core contribution team with these updates.   Community Calls According to the schedule we released at the beginning of the year, we are scheduled to host an Internet Research call next week on Wednesday, July 28th, 2021. This call will be rescheduled to a date TBA. As with all our calls, it will take place on a Wednesday at 11am Eastern. If you have received invites to previous calls, you will receive an invite once it is scheduled. If you have not already RSVP'd to our calls, you can do so here.   That's all for now -- have a great weekend! Talk to you soon when I inevitably remember other updates I forgot to put in this email. As always feel free to reach out with any questions, either to the list or me directly.   -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society	"{0: {'username': 'Glenn Fishbine', 'response_date': 'Jan 12, 2022, 9:17:44 AM', 'response_content': 'Possible re-emerging iPhone issue.  Running the current NDT7, we have several cases where different iPhone 11s will show an upload speed of 1.3Gbps, and then 0 for download.  Two parts of this are curious, according to Apple, the iPhone 11 should max out at 500 Mbps, it shouldn\'t be able to get to 1.3Gbps.  The problem occurs under both Safari and Chrome.  The testing is over AT&T mobility (cellular) in Tallahassee, Florida which should have an average download of around 75 Mbps on 5G connections.  Thoughts?.  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcOfvYSMg4FJZLfo4OQqb%2BLOKWRiF6QvNP5NkB_LgZ3UMQ%40mail.gmail.com.'}, 1: {'username': 'Chris Ritzo', 'response_date': 'Jan 13, 2022, 11:57:26 AM', 'response_content': ""Thanks for reporting these issues.  I'm not sure if this is the exact issue you're users are experiencing, but as you may know the M-Lab engineering team identified some issues with iOS browsers' last June, which were documented in this blog post. Two issues were both related to upstream issues with Safari's WebKit implementation of websockets. Our team will be submitting bug report(s) to Apple soon. Both Safari and Chrome on iOS are affected. Apple now requires apps to use WebKit for accessing the web, so basically Chrome on iOS uses the same engine as Safari, and inherits this problem.  If you were able to capture JavaScript console logs from an iOS device that is experiencing this, our team could confirm if the above mentioned bugs are the cause. Additionally, if you are comfortable sharing more details about your testing device (date/time of tests, public IP address of the iOS device when the tests were run, or if you have it the UUID of the test result provided back from our servers) this might help our team further diagnose the issue, and potentially provide more detail for the bug report.  Please feel free to email sup...@measurementlab.net with the above information if you prefer to not post it here in our public group.  -- Chris Ritzo (he/him) User Experience Advocate & Data Support Specialist, Code for Science & Society \ue5d3""}, 2: {'username': 'David Sandel', 'response_date': 'Jan 13, 2022, 12:55:23 PM', 'response_content': 'Hi Glenn,  We had the same problem for all iPhones running M-Labs NDT. This was for WiFi or ATT mobile.  testtype=BPS seems to have solved the problem for the moment across all iPhones and Apple Pads we tested.  Sent from my iPhone David Sandel  iNeighborhoods.us St. Louis, MO. Austin, TX. EinsteinDesigns.center 314-435-3658   On Jan 12, 2022, at 11:17 AM, Glenn Fishbine <glen...@gmail.com> wrote:  \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CABs%2BJ_AtS__2DtF7Tu%3DOA2Mm%3DM8Z8QQqVaWe6GSp4%2BSAMdUFCg%40mail.gmail.com.'}, 3: {'username': 'Glenn Fishbine', 'response_date': 'Jan 13, 2022, 12:55:23 PM', 'response_content': ""Thanks Chris, we have a work-around for now so this is not urgent.  I don't have all the information but here's what I do have.  Date was 2022-01-11 around 10 a.m. central ASN AS20057 IP 107.62.178,208 mcc 310 mnc 16 Actual upload speed was probably < 15mbps Actual download speed was probably > 17 mbps  two test summaries for an IPhone 11 below::  Safari: Miami 0.0     download 1366.85 upload -ms latency NaN% retransmission   Chrome: Miami 1.0     download 1300.55 upload -ms latency NaN% retransmission \ue5d3""}}"
32	[m-lab-discuss]-latest-traceroutes-data	1642004264.0	2022-01-12 09:17:44	Muhammad Abdullah	Hi Folks,  I'm trying to fetch the latest traceroute data. However, I see that traceroutes from only up until 09/2021 are available on the cloud storage (screenshot attached). Is the latest traceroute data not published yet or am I looking in the wrong place?   Moreover, what's the publishing frequency for traceroute data? Let say if I want to get traceroute data from a day before, how long would I have to wait?  Best, Muhammad	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jan 13, 2022, 12:52:56 PM', 'response_content': ""Thanks for reaching out about accessing traceroute data.  First, I'll note that there are multiple locations for traceroute data in GCS, which represent traces for connections to the various measurement services that M-Lab provides, as well as for connections to the host servers themselves. These are documented on the traceroute page on our website. The screenshot you shared refers to the traces for connections to our host servers.  Beginning in 09/2021, the M-Lab engineering team began publishing a new traceroute datatype, scamper1, replacing the previous datatype, traceroute. The raw traces for scamper1 can be found in: gs://archive-measurement-lab/host/scamper1 - traces to IPs connecting to our host servers gs://archive-measurement-lab/ndt/scamper1 - traces to IPs connecting to the NDT measurement service gs://archive-measurement-lab/neubot/scamper1 - traces to IPs connecting to the Neubot DASH measurement service Regarding publication frequency, traces in all of the buckets listed here should be available at least up to the day prior to today, and is published on an ongoing basis. So there are likely traces collected today in these buckets as well.  Processed traces are also available in BigQuery for the NDT measurement service, with one day overlap between the traceroute and scamper1 datatypes: For traces to IPs connecting to the NDT service prior to and including 2021-09-09, see: measurement-lab.ndt.traceroute For traces from 2021-09-08 to present, see: measurement-lab.ndt_raw.scamper1 I hope this is helpful, but if there are additional questions, of course let us know.  Finally, readers of this thread may be interested in our blog post this week, Traceroute Format Change Request for Comments. Our engineering team is requesting community input on proposed format changes to the planned scamper2 datatype.  Best, -- Chris Ritzo (he/him) User Experience Advocate & Data Support Specialist, Code for Science & Society \ue5d3""}}"
33	question-about-inconsistent-upload-speeds-on-iphone-and-duplicate-results-using-ndt7-client-library	1639164632.0	2021-12-10 12:30:32	Albert Liang	We have a speed test instance leaning on the javascript NDT7 client library.  We are starting to notice a couple of interesting things:  - Some repeated speed tests have wildly varying upload speeds.  One data block that we're observing ran the same speed test 21 time in a row, and reported 5 data points ~1 Mbps and 12 data points over 1 Gbps.  The download speeds did not vary between any of these runs (held steady between 9-10 Mbps).  The user is on DSL and was using an iPhone and mobile browser to run the test.  We were able to replicate it using an iPhone as well.  - We are also noticing duplicate results that are spaced less than 10 seconds apart.  All result values are identical except for the timestamp.  We don't think it's a user running back-to-back tests because it takes ~20 seconds to complete a test.  Has anyone else experienced these things before?  -- Albert Liang Software Developer Intermediate  akl...@merit.edu | 734.527.5763 p | 713.301.8907 c | www.merit.edu 880 Technology Drive, Suite B | Ann Arbor, MI 48108-8963       Learn More About Merit Services	"{0: {'username': 'frog...@gmail.com', 'response_date': 'Dec 10, 2021, 2:23:39 PM', 'response_content': 'Did you check whether the measurements were targeted to the same servers? Ricky  \ue5d3'}, 1: {'username': 'Chris Ritzo', 'response_date': 'Jan 13, 2022, 11:46:19 AM', 'response_content': ""Thanks for reporting these issues.  I'm not sure if this is the exact issue you're users are experiencing, but the M-Lab engineering team identified some issues with iOS browsers' last June, which were documented in this blog post. Two issues were both related to upstream issues with Safari's implementation of websockets. Our team will be submitting bug report(s) to Apple soon. Both Safari and Chrome on iOS are affected.  If you were able to capture JavaScript console logs from an iOS device that is experiencing this, our team could confirm if the above mentioned bugs are the cause. If you are comfortable sharing more details about your testing device (date/time of tests, public IP address of the iOS device when the tests were run, or if you have it the UUID of the test result provided back from our servers) this might help our team further diagnose the issue.  Please feel free to email sup...@measurementlab.net with the above information if you prefer to not post it here in our public group.  -- Chris Ritzo (he/him) User Experience Advocate & Data Support Specialist, Code for Science & Society  \ue5d3""}}"
34	is-there-any-way-to-obtain-most-recent-data-on	1642004263.0	2022-01-12 09:17:43	Mario Antonio Ramirez	Zip Codes or Cities with the most availability with speeds ranging  100-1000 MBPS?	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jan 13, 2022, 9:41:21 AM', 'response_content': ""You can use BigQuery to search for NDT tests by zip code and/or city within the measured performance ranges of interest. We recommend using these two BigQuery Views: measurement-lab.ndt.unified_downloads measurement-lab.ndt.unified_uploads In those views, the field a.MeanThroughputMbps contains the download or upload performance measurement, and the fields client.Geo.PostalCode and client.Geo.City contain the zip code and city as identified by IP address geolocation in MaxMind's Geolite 2 database.  I hope this is helpful. \ue5d3""}}"
35	problem-with-saving-all-rows	1639595140.0	2021-12-15 12:05:40	Reza Abdi	"Dear all,  I am trying to save all rows of my m-lab query based on this message I understand that I need to use the ""save to BigQuery table"" option: Message: To save all rows, use the export to BigQuery table action instead. However, I get the following error message of access denied:  Access Denied: Dataset measurement-lab:ndt: Permission bigquery.tables.create denied on dataset measurement-lab:ndt (or it may not exist).    Wondering if anyone had faced the same problem before? Any idea how to solve it?  Thanks, Reza"	"{0: {'username': 'Fabion Kauker', 'response_date': 'Dec 15, 2021, 3:36:11 PM', 'response_content': 'Hi Reza  not for this project but in general BigQuery.  1. Save to a new table in a project you own or have access to see screenshot:   2. Export to file on GCS   Hope this helps.  Fabion  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/9d4637d3-8236-4b41-9ec2-1085d9002319n%40measurementlab.net.'}}"
36	call-for-traceroute-schema-feedback	1638975287.0	2021-12-08 07:54:47	Lai Yi Ohlsen	Hi everyone,   The M-Lab team is working on BigQuery table schemas for our traceroute data and we want to ensure the data is as easy and useful to work with for the community's research purposes.   We are looking for 1-2+ current or future traceroute data users to spend some time discussing, reviewing and giving feedback. Please reply directly to this email if you are interested.   We'll continue to publish updates to our blog as we make progress.   Take care,    -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society	"{0: {'username': 'Emile Aben', 'response_date': 'Dec 10, 2021, 12:30:35 PM', 'response_content': 'Hi!  The RIPE NCC have a prototype service in the google cloud platform that puts RIPE Atlas traceroutes in BigQuery: https://labs.ripe.net/tools/ripe-atlas-on-bigquery/ripe-atlas-on-bigquery/ If it\'s not already on your radar, it would be great to figure out if the same schema would work for your data, and if not what the differences would be.  cheers, Emile  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcNSfzYJtswsvdSS%2BROFfUzaNWZSvG-egbS8XGBtDSwRyQ%40mail.gmail.com.'}}"
37	call-for-m-lab-research-fellows---due-monday,-december-6	1637004700.0	2021-11-15 12:31:40	Lai Yi Ohlsen	Hi everyone,   I am pleased to share M-Lab's new funding opportunity for researchers, generously supported by Internet Society. Details below, and posted on our website. Please distribute to others who might be interested and feel free to reach out to ap...@measurementlab.net with any questions.   Link to share: https://bit.ly/325L1OT Tweet to share: https://twitter.com/MeasurementLab/status/1460306745578995712  Looking forward,   Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society  --  Open Call for M-Lab Research Fellows - due Monday, December 6  How can M-Lab’s data and platform be used to improve the experience of the Internet for the end user?   Measurement Lab is seeking three Research Fellows to expand Internet performance research beyond the measurement and optimization for bandwidth. Fellows will utilize M-Lab’s longitudinal, open dataset and/or platform to identify under-recognized Internet performance metrics that can be used to improve end user performance.   Each fellow will be awarded 30,000 USD, paid directly to the researcher, and will be responsible for documenting the process and outcome of their research as well as sharing their work at a workshop at the end of the fellowship. The fellowship will begin in January 2022 and complete in May 2022. The M-Lab team will provide data analysis support, research guidance and community networking opportunities.   Topics of interest include but are not limited to: Relation between QoE and network metrics like bandwidth/latency/loss Novel metrics that can be computed on existing NDT data New measurements/experiments that could be deployed on M-Lab to diagnose network bottlenecks Characterizing paths measured by M-Lab clients; stability of paths, relation to paths of interest (eg., paths to content) or network characterization  Proposals for new experiments to be hosted on the M-Lab platform Identification of biases in M-Lab data  Implementing ideas introduced during M-Lab’s Community Call on Latency, Bufferbloat and Responsiveness and/or the IAB workshop on Network Quality  Eligibility: Students, post docs and independent researchers are welcome to apply.  Important dates: Proposal due: December 6, 2021 Fellowship start: January 1, 2022 Mid-fellowship progress check-in: March 15, 2022 Fellowship end: May 30, 2022 Workshop: May 2022, exact date TBD  To apply please provide:   a two page (12pt single space) description of the research project, including a brief timeline for completing the work,   the applicant’s CV  a brief summary of the applicant’s experience & background.  Applications will be reviewed for feasibility of the project plan, qualifications of the researcher and demonstrated understanding and relevance to the stated goals of the fellowship.   Applications should be sent to ap...@measurementlab.net by December 6, 2021 23:59 in the applicant’s local time zone.  The M-Lab Research Fellowship is made possible by the generous support of Internet Society. 	{0: {'username': 'Lai Yi Ohlsen', 'response_date': 'Nov 30, 2021, 10:14:30 AM', 'response_content': 'Hi everyone,   A little under 1 week until the deadline! Please feel free to reach out directly with any questions. Looking forward to learning more about your work.  \ue5d3 -- \ue5d3'}, 1: {'username': 'Lai Yi Ohlsen', 'response_date': 'Dec 6, 2021, 8:25:00 AM', 'response_content': 'Last day to submit a proposal for the M-Lab Research Fellowship! Please feel free to reach out if you have any questions.  \ue5d3'}, 2: {'username': 'Lai Yi Ohlsen', 'response_date': 'Dec 7, 2021, 1:55:03 PM', 'response_content': 'Thank you to everyone who submitted an application! If you did not receive a confirmation e-mail in response, please reach out to ap...@measurementlab.net.  \ue5d3'}}
38	m-lab-community-call-with-david-clark-and-sara-wedeman-next-wednesday-12/15/2021	1638910032.0	2021-12-07 13:47:12	Lai Yi Ohlsen	Hi all,  Writing to share information about our upcoming community call next Wednesday, December 15, 2021 from 11am-12pm Eastern.   At TPRC 2021, Dave Clark and Sare Wedeman presented “Measurement, Meaning and Purpose: Exploring the NDT Dataset” which raises relevant and timely questions about M-Lab’s NDT dataset and its potential applications. Please join us for a presentation from the authors and a discussion with the M-Lab community.    Abstract The speed of a data transfer over the Internet connection is a measure of great interest. It can directly influence quality of experience, it can serve as a measure of equitable access, and it can reveal whether or not the speed matches that which was advertised. One of earliest and longest-standing tools to contain a speed test is the Network Diagnostic Tool (NDT), currently supported by Measurement Lab (M-Lab). NDT, in its various forms, has been used across the globe since 2003. There are billions of measurements archived by M-Lab, with a rich collection of metadata for each measurement. This data allows an in-depth analysis of each measurement, and potentially supports analysis across aggregates of measurements.  The original purpose of NDT was diagnostic: why is my connection operating as it is? However, the archive of this data invites its use in aggregate form to draw conclusions about the overall behavior of the Internet. Such use, however, is confounded by the fact that the individual measurements are triggered by users for a range of reasons: simple curiosity, debugging, anger, bragging rights, or automated checking of operational status (in some cases as often as once a minute). NDT measures network speed, but it equally - if indirectly - measures human behavior.  The goals of this paper are to explore the archived NDT data in order to provide insights about how it can be interpreted; and to distinguish between appropriate uses of the data from uses that may lead to unwarranted conclusions.   Dave Clark, Senior Research Scientist at MIT's Computer Science and Artificial Intelligence Laboratory David Clark is a Senior Research Scientist at the MIT Computer Science and Artificial Intelligence Laboratory. Since the mid-70s, he has played a leading role in the development of the Internet; from 1981-1989 he acted as Chief Protocol Architect, and chaired the Internet Activities Board. His recent research has focused on the re-definition of the architectural underpinnings of the Internet and the relation of technology and architecture to economic, societal and policy considerations. Specific research areas include Internet security and Internet measurement.  Sara Wedeman, Senior Collaborating Researcher at MIT’s Computer Science and Artificial Intelligence Laboratory.   Sara Wedeman is a Senior Collaborating Researcher at the MIT Computer Science and Artificial Intelligence Laboratory. With a background in psychology, measurement, and technology, she held senior management positions in Banking and Consulting, before founding, in 2003, one of the first  firms to focus explicitly on the practical application of Behavioral Economics. Sara has been working with computers since 1984 and is expert at conducting action research in technology and the behavioral/social sciences, using advanced data analytics to uncover actionable results. She has over 25 years' experience in Consulting, having brought empirically-based guidance to technology and  financial services companies, academic institutions, and others - including the NTIA's Broadband Measurement program.   To RSVP:  - If you have previously RSVP’d to our community calls, you should have already received a calendar invite with a Zoom link included. If not, please reply directly to this email.  - If you have not previously RSVP’d, but would like to attend, please do so here and indicate that you’d like to be attended to the “Internet Research” meetings. You’ll be sent a Zoom link shortly after.  Please note:  - We welcome audience questions, answers, challenges, and discussion. The discussion will be technical but no familiarity with M-Lab is required; all we ask is that participants review and respect our community guidelines.  - Our conversation will be recorded. If you attend, you will be asked to give your consent to being recorded. The recording will be published and distributed openly.    If you have any questions, please feel free to reply to this email directly or write to la...@measurementlab.net.   Take care,   -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society	{}
39	ability-to-queue-concurrent-tests?	1637169257.0	2021-11-17 10:14:17	Tate Baumrucker	Hello, I'm running a self-hosted NDT server and wondering if there are means to limit the number of concurrent tests (perhaps queue requests).  This was a feature way back in the web100 days.   I saw a prior thread which indicates clients are limited to a certain quantity of tests per day.  I'm wondering how this is accomplished too. Thanks, Tate	{}
40	ndt7-tcp-metrics-bigquery	1637152661.0	2021-11-17 05:37:41	Ryan Fox	"Hi all  I'm trying to run the below query of the NDT7 data to calculate the average of raw.Download.ServerMeasurements.TCPInfo.RTTVar grouped by country name and month:  select client.Geo.CountryName as country, extract(month from date) as month, extract(year from date) as year,  avg(a.MinRTT), avg(raw.Download.ServerMeasurements.TCPInfo.RTTVar) from `measurement-lab.ndt.ndt7` where date between '2010-01-01' and '2021-12-31' group by client.Geo.CountryName, extract(year from date), extract(month from date)  However, when I try to run the query to do this, I get the below error: "" Cannot access field TCPInfo on a value with type ARRAY<STRUCT<AppInfo STRUCT<NumBytes INT64, ElapsedTime INT64>, BBRInfo STRUCT<BW INT64, MinRTT INT64, PacingGain INT64, ...>, TCPInfo STRUCT<State INT64, CAState INT64, Retransmits INT64, ...>>> at [1:163]  ""  I'm quite new to the NDT data/BigQuery platform so I am unsure how to interpret the error code. I did notice that NDT7 page does state that ""Data from the ndt7 test is currently available in raw format in Google Cloud Storage and will be made available in queryable format in BigQuery in the third quarter of 2020"".  Any help on this would be greatly appreciated.  Many thanks, Ryan"	{}
41	bandwidth-unit	1636993645.0	2021-11-15 09:27:25	Sidik	Dear all, After ndt test, json files are stored. please i have an incertitude about something, what is the unit of bandwidth recorded by BBR in the json file  Thanks in advance	{}
42	mile-high-video-2022---final-call-for-contributions-due-oct-22nd	1634649244.0	2021-10-19 06:14:04	Cise Midoglu	Dear all,  please find below the final call for contributions for MHV'22 (deadline extended to Friday). The venue is most appropriate for multimedia topics that can benefit from an industry-academia collaboration, and measurements + insights from the networking community would be of great interest. If you have any questions, please do not hesitate to contact the TPC co-chair Christian Timmerer (christian...@aau.at).  Best, Cise  *  ACM Mile High Video (MHV) 2022 March 1-3, 2022, Denver, CO  Web site: https://mile-high.video/call.php Abstract submission deadline: Oct. 22, 2021 Prospective speakers are invited to submit an abstract (i.e., approx. 400 words or up to one page using the ACM template) that will be peer-reviewed by the ACM MHV technical program committee (TPC) for relevance, timeliness and technical correctness.  After running as an independent event for several years, starting with 2022, Mile High Video (MHV) will be organized by the ACM Special Interest Group on Multimedia (SIGMM) to grow further. ACM MHV’22 will establish a unique forum for participants from both industry and academia to present, share and discuss innovations from content production to consumption.  ACM MHV’22 welcomes contributions from industry to share real-world problems and solutions as well as novel approaches and results from basic research typically conducted within an academic environment. ACM MHV’22 will provide a unique opportunity to view the interplay of the industry and academia in the area of video technologies.  ACM MHV contributions are solicited in, but not limited to the following areas: • Content production, encoding and packaging • Encoding for broadcast, mobile and OTT, and using AI/ML in encoding • New and developing audio and video codecs • HDR, accessibility • Quality assessment models and tools, and user experience studies • Workflows • Virtualized headends, cloud-based workflows for production and distribution • Redundancy and resilience in content origination • Ingest protocols • Ad insertion • Content delivery and security • Developments in transport protocols and new delivery paradigms • Protection for OTT distribution and tools against piracy • Analytics • Streaming technologies • Adaptive streaming and transcoding • Low latency • Player, playback and UX developments • Content discovery, promotion and recommendation systems • Protocol and Web API improvements and innovations for streaming video • Industry trends • Advances in interactive and immersive (xR) video • Video coding for machines • Cloud gaming and gaming streaming • Provenance, content authentication and deepfakes • Standards and interoperability • New and developing standards in the media and delivery space • Interoperability guidelines  Prospective speakers are invited to submit an abstract (i.e., approx. 400 words or up to one page using the ACM template) that will be peer-reviewed by the ACM MHV technical program committee (TPC) for relevance, timeliness and technical correctness.  The authors of the accepted abstracts will be invited to optionally submit a full-length paper (up to six pages + references) for possible inclusion into the conference proceedings. These papers must be original work (i.e., not published previously in a journal or conference) and will also be peer-reviewed by the ACM MHV TPC.  Accepted abstracts and full-length papers will be presented at the ACM MHV conference and will be published in the conference proceedings in the ACM Digital Library.  All prospective ACM authors are subject to all ACM Publications Policies, including ACM's new Publications Policy on Research Involving Human Participants and Subjects.  How to Submit an Abstract  Prospective authors are invited to submit an abstract here: https://mhv22.hotcrp.com/  Important Dates • Abstract submission deadline: Oct. 22, 2021 • Notification of abstract acceptance: Nov. 15, 2021 • (Optional) Full-length paper submission deadline: Nov. 30, 2021 • Notification of full-length paper acceptance: Dec. 31, 2021 • Camera-ready submission (abstracts/full-length papers) deadline: Jan. 31, 2022  ACM MHV’22 Program Chairs • Christian Timmerer (AAU; christian.timmerer AT aau.at) • Dan Grois (Comcast; dgrois AT acm.org)  ACM MHV'22 Program Committee Members • Florence Agboma (Sky, UK) • Saba Ahsan (Nokia, Finland) • Ali C. Begen (Ozyegin University, Turkey) • Imed Bouazizi (Qualcomm, USA) • Alan Bovik (University of Texas at Austin, USA) • Pablo Cesar (CWI, The Netherlands) • Pankaj Chaudhari (Hulu, USA) • Luca De Cicco (Politecnico di Bari, Italy) • Jan De Cock (Synamedia, Belgium) • Thomas Edwards (Amazon Web Services, USA) • Christian Feldmann (Bitmovin, Germany) • Simone Ferlin-Reiter (Ericsson, Sweden) • Carsten Griwodz (University of Oslo, Norway) • Sally Hattori (Disney, USA) • Carys Hughes (Sky, UK) • Mourad Kioumgi (Sky, Germany) • Will Law (Akamai, USA) • Zhu Li (University of Missouri, Kansas City, USA) • Zhi Li (Netflix, USA) • John Luther (JW Player, USA) • Maria Martini (Kingston University, UK) • Rufael Mekuria (Unified Streaming, The Netherlands) • Marta Mrak (BBC, UK) • Matteo Naccari (Audinate, UK) • Mark Nakano (WarnerMedia, USA) • Sejin Oh (Dolby, USA) • Mickael Raulet (ATEME, France) • Christian Rothenberg (University of Campinas , Brazil) • Lucile Sassatelli (Universite Cote d'Azur, France) • Tamar Shoham (Beamr, Israel) • Gwendal Simon (Synamedia, France) • Lea Skorin-Kapov (University of Zagreb, Croatia) • Michael Stattmann (castLabs, Germany) • Nicolas Weil (Amazon Web Services, USA) • Roger Zimmermann (NUS, Singapore)  ACM MHV Steering Committee Members • Balu Adsumilli (YouTube, USA) • Ali C. Begen (Ozyegin University, Turkey), Co-chair • Alex Giladi (Comcast, USA), Co-chair • Sally Hattori (Walt Disney Studios, USA) • Jean-Baptiste Kempf (VideoLAN, France) • Thomas Kernen (NVIDIA, Switzerland) • Scott Labrozzi (Disney Streaming Services, USA) • Maria Martini (Kingston University, UK) • Hatice Memiguven (beIN Media, Turkey) • Ben Mesander (Wowza Media Systems, USA) • Mark Nakano (WarnerMedia, USA) • Madeleine Noland (ATSC, USA) • Yuriy Reznik (Brightcove, USA) • Tamar Shoham (Beamr, Israel)  -- Cise Midoglu Simula Research Laboratory https://www.simula.no	{}
43	renaming-ndt-datasets-and-views-in-bigquery	1617599826.0	2021-04-04 22:17:06	Matt Mathis	We are reorganizing our NDT datasets and views to make them easier to find and navigate. The new datasets and views will be created on Wednesday, Apr 7th, including updating the documentation to match.   There are no schema changes in this update, but all dataset and view  names are changing.   Newly named datasets and views will be published on Wednesday, April 7th, and the following Wednesday, April 14th, old datasets and views will be deleted.  Please update your queries to use the new names as soon as possible.  This update also includes some minor bug fixes, that should not affect any properly functioning user queries: some web100 queries that were causing BigQuery exceptions incorrect congestion control algorithms were being reported for upload tests a small amount of pre-production data that was collected on mlab4 nodes (0.1%)  during early platform migration will be suppressed from production data.  Updated documentation on all newly named datasets and views will be published at:  https://www.measurementlab.net/tests/ndt/ on Wednesday.  Summary of new NDT datasets and views:  Unified Views (only bug fixes): measurement-lab.ndt.unified_downloads measurement-lab.ndt.unified_uploads  Dataset Renaming This update will change the name of two NDT datasets:  New Dataset Name  Old Dataset Name ndt_intermediate   intermediate_ndt ndt_raw           raw_ndt  Extended views in ndt_intermediate: ndt_intermediate.extended_ndt7_downloads ndt_intermediate.extended_ndt7_uploads ndt_intermediate.extended_ndt5_downloads ndt_intermediate.extended_ndt5_uploads ndt_intermediate.extended_web100_downloads ndt_intermediate.extended_web100_uploads (These were previously published in the intermediate_ndt dataset.)  Raw Views Renaming  In the ndt_raw dataset, several views will also be renamed. All views to be published are listed below, with their previous name if applicable: New View Name          Old View Name ndt_raw.ndt7                       raw_ndt.ndt7 ndt_raw.annotation             raw_ndt.annotation ndt_raw.ndt5_legacy           ndt.ndt5 ndt_raw.web100_legacy     ndt.web100 ndt_raw.tcpinfo_legacy       ndt.tcpinfo ndt_raw.traceroute_legacy  ndt.traceroute  Thanks, --MM-- The best way to predict the future is to create it.  - Alan Kay	"{0: {'username': 'Livingood, Jason', 'response_date': 'Apr 5, 2021, 6:57:22 AM', 'response_content': 'Hi Matt – Are there more detailed release notes pertaining to the bug fixes? In particular on the query exceptions and congestion control algorithms. Since all old datasets and views will be replaced it seems helpful to be able to better understand the changes.   Thanks Jason \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAEsRLK_oDemNaJZtx4RY63vwnMy61uwm-joJxz24gi0T3JY%3DnA%40mail.gmail.com.'}, 1: {'username': 'Matt Mathis', 'response_date': 'Apr 6, 2021, 2:47:57 PM', 'response_content': 'Hi Jason -   No data was harmed in this update!  These are just changes to the views that present the data from BQ tables.   The bug fixes were extremely minor - they were all corners cases that can not materially affect proper user queries.  You do raise a valid point about release notes though: we need to do better.  We are adding notes to the documentation.  Some of our users were looking at the details of how we are filtering the data, and encountered a problem with some rows that are normally excluded by our default filtering but also had invalid or corrupted geo annotations.  This caused exceptions from queries that attempted to do geo filtering on the extended views without row filtering.   I added BQ SAFE operators to force corrupted geo data to be expressed as NULLs.  Since these rows were also incomplete in other ways they never appeared in regular user queries.  Upload tests were reporting the server\'s Congestion Control Algorithm as the client\'s CCA.  This is partially a legacy of the old web100 based tooling, that reported upload and download results in the same row.  As far as I know, none of the current clients get this information at all, furthermore most clients use runtime environments that won\'t ever have access to it, due to sandboxes, etc.  Any queries that attempted to use the client\'s CCA were not functioning as intended.  In the bigger picture, MLab is moving to a reproducibility model that I nickname the ""NASA model"" - every bit of raw data is (and has been) archived carefully because it is precious.   As we improve our present tools we have an opportunity to use long running clients (aka beacons) to improve our understanding of past data, and to make improvements to our data pipeline, for example to infer noise sources, such as WiFi bottlenecks, ""testing in anger"", ""learned helplessness"", etc.   It currently takes us about 3 months to regenerate 3 B rows of BigQuery data from 11+ years of archived historical data.  The vision for this reproducibility model includes resources for A/B testing or comparisons across all processing changes, including recreating important reports such as the 2014 Interconnection study.   I am working on a more comprehensive explanation for a future blog post and presentation. \ue5d3 -- Thanks, --MM--'}, 2: {'username': 'Matt Mathis', 'response_date': 'Oct 13, 2021, 4:37:12 PM', 'response_content': 'It has come to my attention that I failed to complete some of the cleanup following the table and view renaming announced earlier this year.  All of the new tables have been in place since the announcement, but I failed to remove the old names.  I will start updating a couple of overlooked internal references to the old names, and then disabling access to them.  If this causes any problems, the first step will be to confirm that you are using the correct names as listed below.  We are not anticipating any user visible changes.  Thanks, --MM-- \ue5d3 -- Thanks, --MM--'}}"
44	data-for-montenegro---urgent	1633007055.0	2021-09-30 06:04:15	Danilo Janković	Dear colleagues,  Can you please tell me how to extract download speed, upload speed, RTT by operator in Montenegro? Which database to use?  This info is urgent so I will appreciate a quick response.  Kind regards, Danilo.	"{0: {'username': 'Fabion Kauker', 'response_date': 'Sep 30, 2021, 8:28:40 AM', 'response_content': 'Hi Danilo  Not sure if this is what you need but here is what I have done for Kenya. You\'ll need to modify the SELECT to get operator.  The process is as follows:  1. Goto the BigQuery project - https://console.cloud.google.com/bigquery?project=measurement-lab 2. Enter this query -  SELECT client.Geo.longitude, client.Geo.latitude, test_date FROM `measurement-lab.ndt.unified_downloads_20201026x` WHERE date < \'2020-08-31\' AND client.Geo.country_name = \'Kenya\' 3. Wait ~10 minutes 4. Export to GDrive 5. Download csv 6. (optional) Run unique.sh or cmd - cat bq-results-20210831-223756-jbpp8ss4yyac.csv  | cut -f1-2 -d , | uniq > kenya_unique.csv  Fabion  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CALkOHCrwQXNs_rgwDU1x-247gQ_03AfR4E_%2BmDyKj_B5FAwUzQ%40mail.gmail.com.'}, 1: {'username': 'Chris Ritzo', 'response_date': 'Sep 30, 2021, 9:01:52 AM', 'response_content': 'Thanks for sharing, Fabion. I was curious if you were using the table: `measurement-lab.ndt.unified_downloads_20201026x` instead of: `measurement-lab.ndt.unified_downloads`  Additionally, I wanted to mention that M-Lab\'s statistics pipeline service now provides aggregate statistics by day for various global geographies. Currently data from 2020-01-01 to present is available.   The data from the statistics service may be accessed in several ways: Data Studio interactive reports listed on this page BigQuery tables in `measurement-lab.statistics` JSON API documented here For Danilo\'s question, I would recommend querying `measurement-lab.statistics.v0_countries_asn` or using the corresponding JSON API endpoint.  I hope this is helpful.  Best, Chris  On Thursday, September 30, 2021 at 11:28:40 AM UTC-4 f.ka...@gmail.com wrote: Hi Danilo  Not sure if this is what you need but here is what I have done for Kenya. You\'ll need to modify the SELECT to get operator.  The process is as follows:  1. Goto the BigQuery project - https://console.cloud.google.com/bigquery?project=measurement-lab 2. Enter this query -  SELECT client.Geo.longitude, client.Geo.latitude, test_date FROM `measurement-lab.ndt.unified_downloads_20201026x` WHERE date < \'2020-08-31\' AND client.Geo.country_name = \'Kenya\' 3. Wait ~10 minutes 4. Export to GDrive 5. Download csv 6. (optional) Run unique.sh or cmd - cat bq-results-20210831-223756-jbpp8ss4yyac.csv  | cut -f1-2 -d , | uniq > kenya_unique.csv  Fabion  On Thu, Sep 30, 2021 at 6:04 AM Danilo Janković <danilo.j...@gmail.com> wrote: Dear colleagues,  Can you please tell me how to extract download speed, upload speed, RTT by operator in Montenegro? Which database to use?  This info is urgent so I will appreciate a quick response.  Kind regards, Danilo. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3'}, 2: {'username': 'Danilo Janković', 'response_date': 'Sep 30, 2021, 9:31:57 AM', 'response_content': 'Dear Fabion, Chris,  Thank you very much for your help and reply.  Kind regards, Danilo.   \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}}"
45	australian-speed-test-data-outliers	1632252779.0	2021-09-21 12:32:59	Bradley Kalgovas	Hi Chris,  We are looking into the Australian Speed Test data and we noticed that there are some outliers which don't make any sense to us. Specifically, since 1 Jan 2021: Within the Lower Murray SA3 (10902) which is comprise two SA2s (10902 1178 and 10902 1179) the 10902 1179 SA2 area has 274210 speed tests. This is much greater than Sydney Inner City SA3 (11703) which has 27,409 speed tests (see screenshot 1 and 2).  Also within the North Canberra SA3 (259,123), there are 259,123 speed tests. While this seems ok as it is the nation's capital, it is confusing as the areas around that do not have such a high level of speed tests (see screenshot 3) Kind regards, Bradley	"{0: {'username': 'Chris Ritzo', 'response_date': 'Sep 22, 2021, 10:47:25 AM', 'response_content': ""Hi Bradley,  I think what you may be seeing here as outliers is more an issue of how NDT test results are geolocated.  The lat/lon coordinates in each NDT test row are a geolocation of the client IP address, as identified by the Maxmind Geolite 2 database. The coordinates are not the location of the person running the test, but the location of the infrastructure that provided them an IP address. A related field in the dataset, client.Geo.AccuracyRadiusKm, also comes from Maxmind and might be useful in your analyses.  To illustrate, I identified the geographies I think you're using, and loaded them into my GIS program along with all grouped lat/lons from NDT download tests in Australia this year. The results are seen in the maps below. First, the whole country, where we see what I might assume are clusters of tests mostly in the most populated areas. The second image is a zoom in on parts of Sydney, NSW, where you can also see some areas that don't contain geolocated tests.  I hope this helps explain what you're seeing, but please let us know if you have other questions.  Best, Chris   \ue5d3""}}"
46	record-count-vs-ul/dl-samples	1630079163.0	2021-08-27 08:46:03	Patrick Duffy	"Hello!  I am working on a small project using M-Lab data and had a question. If I am looking at data for a city broken out by the day, what does the variable ""record count"" mean and how would that differ from the sum of ""Ul Samples"" or the sum of ""Dl Samples""?   For example, I have data for a particular date that says record count = 24 and sum of Ul Samples = 1248. Does that mean only 24 speed tests were conducted on that day?   Sorry for being a total beginner and thanks for any help!  Best, Patrick "	"{0: {'username': 'Chris Ritzo', 'response_date': 'Sep 8, 2021, 12:55:32 PM', 'response_content': 'Hi Patrick, Sorry for the delay in responding to your questions.  Could you be more specific about the data source? I think you are looking at aggregated data from one of our DataStudio reports, not querying the data using BigQuery. Is that right? ""record count"" sounds like a field provided by a DataStudio report.   In general, because of the way the NDT test works, the number of upload and download samples could be different. For example, if someone runs the test it appears to be one thing, but the upload and download measurements are stored separately. If a test is cancelled after the upload test completes but before the download does, then there would be one less download measurement than upload. The reverse is also possible depending on where the user ran the test. For example the Google search integration of the test runs download first, but other versions runs upload first.  Let us know more information about where you\'re getting Record Count and samples for a day, and if you are running a query, please feel free to share it as well.   Best, Chris \ue5d3'}}"
47	non-aggregated-ndt-data-from-m-lab’s-bigquery	1628001963.0	2021-08-03 07:46:03	Lizaveta Radzevich	Hi, I’m trying to access non-aggregated NDT data from M-Lab’s BigQuery. I’ve tired on public datasets before (set up a project, create service account and key), but it seems like I’m missing some steps to be able to get NDT data. I think you need to set up a service account for me and add it to your access group. You can use my account from discussion group: lizaveta...@gmail.com. I’ll attach code and error message I’m getting, so it would be nice if you can let me know if my theory about service account is wrong! Thank you, Lizaveta	"{0: {'username': 'Chris Ritzo', 'response_date': 'Aug 3, 2021, 7:52:53 AM', 'response_content': ""Hi Lizaveta, Thanks for writing about this issue. While your membership on this group provides access to the BigQuery datasets using this email, using a service account requires an additional step. As you surmised, that step is getting your service account added to the access group.  To add the service account, you will need to look for it's ID within your project or in the service account key file itself. It looks like an email address, similar to: <project>@<project>.iam.gserviceaccount.com  You can email that privately to sup...@measurementlab.net  and we will add the account to the access group. After that the error you shared should go away and you can use the service account in your application.  Best, Chris - M-Lab Support \ue5d3""}, 1: {'username': 'Bradley Kalgovas', 'response_date': 'Aug 3, 2021, 2:41:02 PM', 'response_content': 'Hi Chris,  We want to obtain the data for each test in the from the measurement-lab.ndt.unified_downloads table. However, when we are trying to get the data out we are getting errors that the extract size is too big to load into google drive. Is it possible to have 15 mins on the phone to talk on how to extract it without having to pay $2k for some slots. Thanks!  Bradley \ue5d3'}, 2: {'username': 'Chris Ritzo', 'response_date': 'Aug 4, 2021, 6:13:57 AM', 'response_content': 'Hi Bradley,  If you need to pull individual tests from our datasets, you will likely need to incur some costs. M-Lab subsidizes the queries only. However, there are some techniques I could recommend, and might be helpful to others on the group.  My first suggestion is to think about limiting the number of individual test results you need to export in some way. That could be by date ranges, or specific geographies. You may have a specific focus already, but still the data size is too large for export to Google Drive.  Another option is to save your query results to a BigQuery table in your Google Cloud Project, then export the table contents to Cloud Storage as CSVs, and you can then download the CSVs to work with in your analyses. This link provides some overview of options for extracting data: https://cloud.google.com/bigquery/docs/exporting-data  You might also consider working with a subset of individual test rows in a series of test cases to refine your workflow. An initial, exploratory analysis could give you a sense of the individual fields and what you want to do with them. If that includes specific analyses that could be done within your query, you could then return to BigQuery and do that analysis in SQL to limit the final export you need to a smaller size.  However, if you are using other analysis tools and want to do that with individual rows, then you may need to incur some costs to do the export. Some analysis tools like R Studio for example, a have support for BigQuery, and could be used to extract data.  I hope this is helpful.  Best regards, Chris \ue5d3'}, 3: {'username': 'Lizaveta Radzevich', 'response_date': 'Aug 9, 2021, 3:12:13 PM', 'response_content': 'Hi Chris,  So far Bradley and I were able to aggregate NDT data to the exportable size. I\'m having trouble getting to the median value (since SQL does not have direct median function). Can you help me spot the mistake in the following query? I\'m trying to get a set grouped by NUTS 3 code and date. BigQuery shows syntax error on WITHIN GROUP statement, but I don\'t now other way to get median values.   SELECT      date,     avg(a.MeanThroughputMbps) as Mbps,      PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY a.MeanThroughputMbps) OVER (PARTITION BY LEVL_CODE, date) AS MedianMbps,     max(a.MeanThroughputMbps) as maxMbps,     min(a.MeanThroughputMbps) as minMbps,     count(a.MeanThroughputMbps) as number_speed_tests,     avg(a.MinRTT) as latency,     count(client.Network.ASNumber) as number_ISP,     LEVL_CODE,  FROM `measurement-lab.ndt.unified_downloads` as unified_downloads JOIN `measurement-lab.geographies.eu_NUTS_3_2021_01m` as geo ON ST_Within(ST_GeogPoint(client.Geo.Longitude, client.Geo.Latitude),geo.geometry) WHERE date >= ""2021-01-01"" and client.Geo.CountryCode = ""DE""  group by LEVL_CODE, date  Thank you! \ue5d3'}, 4: {'username': 'Chris Ritzo', 'response_date': 'Aug 9, 2021, 3:18:11 PM', 'response_content': 'Hi Lizaveta,  Median aggregation is achievable in BigQuery using the APPROX_QUANTILES function. You can also get other quantiles/percentiles using options in the same function. The sub-queries calculating stats-per-day from our statistics pipeline service will be instructive on the use of APPROX_QUANTILES. See this line for an example of median.  I hope this is helpful.  Best regards, Chris  \ue5d3'}, 5: {'username': 'Gregory Russell', 'response_date': 'Aug 10, 2021, 8:02:56 AM', 'response_content': 'Looks like percentile_cont is also supported, but perhaps not the syntax in your query.  https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators#percentile_cont  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/cd736098-9f68-4a0a-8493-09a6f50ee207n%40measurementlab.net.'}, 6: {'username': 'Lizaveta Radzevich', 'response_date': 'Aug 11, 2021, 10:47:29 AM', 'response_content': ""Hi,  Now I'm trying to get the same data as query I shared but for US county (previous was for NUTS3). In short, I need average download speed, max download speed , number of tests, and number of distinct ASNs per US county. I can get the first three from `measurement-lab.statistics.v0_us_counties` table, but there is no data on ASNs. I can use non-aggregated ndt table, but I don't see any county-appropriate file in geographies (I mapped non-aggregated ndt to NUTS3 this way). Is there walkaround to get the number of ASNs per county?   \ue5d3""}, 7: {'username': 'Chris Ritzo', 'response_date': 'Aug 11, 2021, 11:04:23 AM', 'response_content': ""Hello!  The tables for US County rely on the table, `bigquery-public-data.geo_us_boundaries.counties`, provided by Google's Public Datasets program.  At each geographic level in the statistics API and tables, we also provide aggregation by ASN. See this document for complete details, but in short, you can query the table: `measurement-lab.statistics.v0_us_counties_asn`.  One additional note about the geography tables in `measurement-lab.geographies`- these have been published temporarily for specific internal needs or collaborations and may be eventually be removed. If you need tables such as eu_NUTS_3_2021_01m, we would advise creating them or copying them to your own Google Cloud Project.  Chris - M-Lab Support \ue5d3""}, 8: {'username': 'Lizaveta Radzevich', 'response_date': 'Aug 23, 2021, 10:37:54 AM', 'response_content': 'Hi Chris,  Quick question regarding US GIDs in global_gadm36_2 table. I want to map those codes to FIPS, is there any way to do it? \ue5d3'}, 9: {'username': 'Chris Ritzo', 'response_date': 'Aug 23, 2021, 2:23:59 PM', 'response_content': ""Hi Lizaveta, I'm not super familiar with the GIDs in the gadm.org tables. However, Maxmind provides a CSV that maps FIPS to ISO 3166 on this page: https://dev.maxmind.com/geoip/whats-new-in-geoip2  M-Lab annotates NDT test data with the ISO 3166 standard now, but older vintages were annotated with FIPS. See this post for more details: https://www.measurementlab.net/blog/evolution-of-annotations/  Best, Chris \ue5d3""}}"
48	latency,-bufferbloat,-responsiveness-&-internet-quality---discussion-(next)-wednesday,-august-25	1629312050.0	2021-08-18 11:40:50	Lai Yi Ohlsen	"Internet performance is often measured by download and upload “speed” but there are other metrics that can help measure connectivity, such as latency, bufferbloat and a more recently discussed metric: responsiveness. Join us next Wednesday, August 25, 2021 from 11am-12:30pm Eastern for a conversation with Internet Measurement researchers with expertise and interest in each of these metrics including:   Matt Mathis, Senior Research Scientist, Measurement Lab, Google Matt Mathis has been working on Internet performance research and development since 1990.  His work includes measurement tools, models and improvements to protocol standards.  He participated in MLab from its inception in 2009, and came to Google in 2010 to find a larger platform on which to stand.  Dave Taht  Dave Taht and members of the Bufferbloat Project have made vast improvements to the Internet and to WiFi, as described in the book, “Bufferbloat and Beyond”. He has lectured at Stanford and MIT, NANOG, RIPE, USENIX, IEEE, and the IETF. His R&D work on AQM/FQ technologies on the Internet have been integrated into the Linux, OSX, and IOS kernels, cable modems, and many WiFi chips, and he has created and managed Internet improvement initiatives such as CeroWrt, make-wifi-fast, cake, and more. From these projects we have seen major innovations in congestion control algorithms such as BQL, FQ_codel, FQ_pie, and BBR.   Christoph Paasch, Networking Architect, Apple Christoph Paasch has been working on transport layer networking since 2010. Focusing on extensions to TCP, like Multipath TCP or TCP Fast Open. From specification (in the case of MPTCP) and research to the implementation and large scale deployments at Apple. Lately he has shifted his focus on improving the network properties that really matter to the end-user experience by exposing measurement tools to raise awareness to these issues. ""Responsiveness under working conditions"" being now the first primary target.  The conversation will be moderated by Lai Yi Ohlsen, Director of Measurement Lab, a fiscally sponsored project of Code for Science & Society.   Our casual conversation will include discussion about the significance of these metrics as well as the challenges their collection presents. We welcome audience questions, answers, challenges, and discussion. The discussion will be technical but no familiarity with M-Lab is required; all we ask is that participants review and respect our community guidelines.   If you have previously RSVP’d to our community calls, you should have already received a calendar invite with a Zoom link included. If not, please reply directly to this email.   If you have not previously RSVP’d, but would like to attend, please do so here and indicate that you’d like to be attended to the “Internet Research” meetings. You’ll be sent a Zoom link shortly after.  Please note that our conversation will be recorded. If you attend, you will be asked to give your consent to being recorded. The recording will be published and distributed openly.    If you have any questions, please feel free to reply to this email directly or write to la...@measurementlab.net.   -- Lai Yi Ohlsen Director, Measurement Lab Code for Science & Society"	"{0: {'username': 'rjmcmahon', 'response_date': 'Aug 23, 2021, 4:48:24 AM', 'response_content': 'Hi Lai,  We\'re very interested in this new test. We may want to support a functionally equivalent test using open source iperf 2, a new test to be written in python 3 using the open source flows code. I\'ve ok\'d any all test work done at Broadcom per our WiFi group as being something we can release as open source, including scripts developed per this test. https://sourceforge.net/p/iperf2/code/ci/master/tree/flows/  As an aside, we\'ve done a lot of work in iperf 2 around better TCP testing including things like --reverse w/small xfers, connect time measurements, write to read latencies, scheduling per clock_nanosleep, etc. More here https://iperf2.sourceforge.io/iperf-manpage.html  One recent feature we find extremely useful is support for TCP_NOTSENT_LOWAT and select() based writes. We really appreciate some of the experts here pushing that through the network industry. The iperf 2 option is --tcp-write-prefetch <bytes>. It really helps with WiFi latency measurements to remove the send side bloat.  Thanks, Bob  > Internet performance is often measured by download and upload > “speed” but there are other metrics that can help measure > connectivity, such as latency, bufferbloat and a more recently > discussed metric: responsiveness. Join us next Wednesday, August 25, > 2021 from 11am-12:30pm Eastern for a conversation with Internet > Measurement researchers with expertise and interest in each of these > metrics including: > Matt Mathis, Senior Research Scientist, Measurement Lab, Google > > Matt Mathis has been working on Internet performance research and > development since 1990. His work includes measurement tools, models > and improvements to protocol standards. He participated in MLab from > its inception in 2009, and came to Google in 2010 to find a larger > platform on which to stand. > Dave Taht > > Dave Taht and members of the Bufferbloat Project [1]have made vast > improvements to the Internet and to WiFi, as described in the book, > “Bufferbloat and Beyond [2]”. He has lectured at Stanford and MIT, > NANOG, RIPE, USENIX, IEEE, and the IETF. His R&D work on AQM/FQ > technologies on the Internet have been integrated into the Linux, OSX, > and IOS kernels, cable modems, and many WiFi chips, and he has created > and managed Internet improvement initiatives such as CeroWrt, > make-wifi-fast [3], cake, and more. From these projects we have seen > major innovations in congestion control algorithms such as BQL, > FQ_codel, FQ_pie, and BBR. > Christoph Paasch, Networking Architect, Apple > > Christoph Paasch has been working on transport layer networking since > 2010. Focusing on extensions to TCP, like Multipath TCP or TCP Fast > Open. From specification (in the case of MPTCP) and research to the > implementation and large scale deployments at Apple. Lately he has > shifted his focus on improving the network properties that really > matter to the end-user experience by exposing measurement tools to > raise awareness to these issues. ""Responsiveness under working > conditions"" being now the first primary target. > The conversation will be moderated by Lai Yi Ohlsen, Director of > Measurement Lab, a fiscally sponsored project of Code for Science & > Society. > Our casual conversation will include discussion about the significance > of these metrics as well as the challenges their collection presents. > We welcome audience questions, answers, challenges, and discussion. > The discussion will be technical but no familiarity with M-Lab is > required; all we ask is that participants review and respect our > community guidelines [4]. > If you have previously RSVP’d to our community calls, you should > have already received a calendar invite with a Zoom link included. If > not, please reply directly to this email. > If you have not previously RSVP’d, but would like to attend, please > do so here [5] and indicate that you’d like to be attended to the > “Internet Research” meetings. You’ll be sent a Zoom link shortly > after. > Please note that our conversation will be recorded. If you attend, you > will be asked to give your consent to being recorded. The recording > will be published and distributed openly. > If you have any questions, please feel free to reply to this email > directly or write to la...@measurementlab.net. > > -- > > Lai Yi Ohlsen > > Director, Measurement Lab [6] > Code for Science & Society [7] > > -- > You received this message because you are subscribed to the Google > Groups ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, send > an email to discuss+u...@measurementlab.net. > To view this discussion on the web visit > https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcNzVfcBT%3DRFK%3DK17srP_GVSje%2B%3Dsayj5ws42rV9dWBapQ%40mail.gmail.com > [8]. > > > Links: > ------ > [1] https://www.bufferbloat.net/projects/ > [2] https://blog.tohojo.dk/media/bufferbloat-and-beyond.pdf > [3] https://lwn.net/Articles/705884/ > [4] https://www.measurementlab.net/community-guidelines/ > [5] > https://docs.google.com/forms/d/e/1FAIpQLSeHKN2MUP1IAReB8KNJM9jIdbazpaUQscdj0zZ5PbbO9K0fTA/viewform?usp=sf_link > [6] http://www.measurementlab.net > [7] https://codeforscience.org/ > [8] > https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcNzVfcBT%3DRFK%3DK17srP_GVSje%2B%3Dsayj5ws42rV9dWBapQ%40mail.gmail.com?utm_medium=email&utm_source=footer'}}"
49	accuracy-of-lat-and-long-in-speed-tests	1629461431.0	2021-08-20 05:10:31	Bradley Kalgovas	Hi There,   How accurate are the lat and long of speed tests? Do you anonymize them in any way or are they pretty accurate to the location where the speed test actually occured.   Kind regards, Bradley	"{0: {'username': 'Chris Ritzo', 'response_date': 'Aug 20, 2021, 5:17:29 AM', 'response_content': 'Hi Bradley, Thanks for asking about this. The latitude and longitude of each test are not the exact location where the test was run, but the IP address geo-location. M-Lab uses the Maxmind Geolite 2 dataset to provide these fields. Related, the field, AccuracyRadiusKm, is also pulled from Maxmind.  Best regards, Chris \ue5d3'}, 1: {'username': 'b.ra...@gmail.com', 'response_date': 'Aug 20, 2021, 7:15:32 AM', 'response_content': 'HI Chris,  Thanks for clarifying. I am curious – we are trying to look at the level of provision on broadband to businesses and wondering how we can split a test performed at a business vs at a home. Do you have any thoughts on this?  Thanks \ue5d3'}, 2: {'username': 'b.ra...@gmail.com', 'response_date': 'Aug 20, 2021, 7:15:47 AM', 'response_content': 'Also can you let us know what is the difference between the location IP address and the actual test device? Thanks!  From: Chris Ritzo <cri...@measurementlab.net> Sent: Friday, August 20, 2021 5:17 AM To: discuss <dis...@measurementlab.net> Cc: b.ra...@gmail.com <b.ra...@gmail.com> Subject: Re: Accuracy of lat and long in speed tests  Hi Bradley, \ue5d3'}, 3: {'username': 'Chris Ritzo', 'response_date': 'Aug 20, 2021, 7:29:08 AM', 'response_content': ""IP address geolocation is the location of whatever infrastructure hands your router an IP address, as opposed to a precise location from GPS. I wrote about the limits of IP address geolocation precision in this blog post, which outlines the differences in context: https://www.measurementlab.net/blog/exploring-geographic-limits-of-ip-geolocation/  Using the NDT crowdsourced data alone in BigQuery, unfortunately you can't segment tests by things like access media (cable, dsl, fiber, LTE, etc.), service tier of the subscription, or business vs. home connections. I think that this can be accomplished using an API such as https://ipinfo.io , by looking up individual IP addresses in the NDT dataset and pulling fields from their API. However, it's still crowdsourced data, so many things need to be accounted for when generating any aggregate analyses. See this post for a starting point: https://www.measurementlab.net/blog/mlab-data-policy-advocacy/  Perhaps others on the group have alternative suggestions as well. For example, collecting new data from known locations using a standardized and tested on-premise device is an approach researchers use to control for the issues that need to be addressed in crowdsourced data analyses.  Thanks, Chris \ue5d3""}, 4: {'username': 'Ralf Lübben', 'response_date': 'Aug 23, 2021, 4:47:46 AM', 'response_content': 'Hi,  just to complement, since we looked into the accuracy, too.  There is a report from 2017  https://www.caida.org/catalog/papers/2017_look_at_router_geolocation/look_at_router_geolocation.pdf  and MaxMind has some information, too  https://www.maxmind.com/en/geoip2-city-accuracy-comparison  Regards, Ralf \ue5d3 > -- > You received this message because you are subscribed to the Google > Groups ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, > send an email to discuss+u...@measurementlab.net. > To view this discussion on the web visit > https://groups.google.com/a/measurementlab.net/d/msgid/discuss/0a4cf65e-2a0b-4c8c-9436-b72f17731003n%40measurementlab.net > .'}}"
50	where-are-you-geograpichally;-i-didn't-find-that-on-your-main-webskite.	1628772993.0	2021-08-12 05:56:33	Dean Pennington	I appreciate your test but where you are running (hosting) it from may have more Internet hops in it than a test I'd run off a server local to me? Thanks, Dean	{0: {'username': 'Chris Ritzo', 'response_date': 'Aug 12, 2021, 6:00:44 AM', 'response_content': 'Our servers are located in middle mile peering data centers and Internet Exchanges by design, which is a topology that distinguishes M-Lab from other testing platforms. You can view details about all server locations, uplinks and the tier 1 and tier 2 providers that connect our servers to the Internet on our Infrastructure Status page: https://www.measurementlab.net/status/  Thanks, Chris - M-Lab Support \ue5d3'}}
51	m-lab-servers---speed-test-(ndt-servers-alone)	1587570207.0	2020-04-22 08:43:27	Ma Uttaram	The following gives all the m-lab servers and their geographic distribution. http://mlab-ns.appspot.com/admin/map/ipv4/all  I am trying to write speed test cli , hence I assume I need to find NDT servers alone. I can locate the nearest NDT server using locate api https://locate.measurementlab.net/ndt/. How do I get to see list of NDT servers alone and their geographical spread.	"{0: {'username': 'Chris Ritzo', 'response_date': 'Apr 22, 2020, 8:53:57 AM', 'response_content': 'Hello, thanks for posting this question.  You might consider using one of our existing command line clients: https://github.com/m-lab/ndt5-client-go https://github.com/m-lab/ndt7-client-go The ""mlab-ns"" service URL and the ""locate"" service are both backed by the same information, so the ""all"" query to mlab-ns should return the same servers available at the other URL. \ue5d3'}, 1: {'username': 'Ma Uttaram', 'response_date': 'Apr 23, 2020, 5:13:35 AM', 'response_content': 'Chris,  The client I am writing is for our routers (linux) and hence it supports only specific libset and python. Hence cant use go client. web100ctl is what I have in mind as we could try to compile platform specific.  To get the NDT server to run against , do I use locate url using ndt or ndt5 or ndt7? \ue5d3'}, 2: {'username': 'Chris Ritzo', 'response_date': 'Apr 23, 2020, 5:31:13 AM', 'response_content': 'I see. In this case, could you please describe your target system architecture? If the target architecture is 64bit, we recommend  using ndt7-client-go. If not, there are some ndt client examples developed by the M-Lab community which might work, but would be unsupported by M-Lab.   Regarding how to get the NDT server to run against, you can use the locate service URL as described on our Developer resources page. Which protocol you use (ndt5 or ndt7) will depend on the client implementation you choose. \ue5d3'}, 3: {'username': 'Ma Uttaram', 'response_date': 'May 8, 2020, 6:44:26 AM', 'response_content': 'We cannot use go client as our devices dont support go. Could you please point to ndt client examples? I understand that it is not supported  by M-lab but would be good place for us to write or use a custom client. \ue5d3'}, 4: {'username': 'Chris Ritzo', 'response_date': 'May 8, 2020, 8:57:36 AM', 'response_content': ""The available NDT client code options are provided on our Developer page: https://www.measurementlab.net/develop/#ndt Some are officially supported by M-Lab, and some are community maintained and supported. Not knowing anything about your target system architecture, you could build a Go client binary and copy it to your target system.  If you cannot use a Go binary, there is a client code option that uses C/C++ called libndt. It is part of the measurement-kit project: https://github.com/measurement-kit/libndt/  This client is not listed on our Developer page because we are unclear about whether the community maintainer will be continuing to support it. The project's primary measurement engine, measurement-kit (https://github.com/measurement-kit/measurement-kit), has been deprecate by the maintainer, so libndt's current status is unlcear.  That said, our team has used libndt and it does measure effectively on well-resourced systems, measuring links in excess of multiple Gbps. It also supports all current NDT protocols, including the newest BBR-based ndt7 protocol.  If you pursue an integration using libndt, we strongly recommend benchmarking its performance in measuring the link of a target device compared to its performance on other, more well resourced systems. Further, it is not supported by M-Lab, so you would need to contact the developer directly for support.  We definitely would discourage you from using the web100clt client at all. \ue5d3""}, 5: {'username': 'Ma Uttaram', 'response_date': 'May 15, 2020, 5:26:39 AM', 'response_content': 'We want to support for the following devices : arm 64 (armv8-a, armv7-a, armv8-a) mips (mips32r2 )  x86-64  Does the go client support the above archs? Are there any dependencies? Any tools that I could utilize to build binaries? \ue5d3'}, 6: {'username': 'Chris Ritzo', 'response_date': 'May 15, 2020, 5:33:18 AM', 'response_content': ""Yes, the Go client (https://github.com/m-lab/ndt7-client-go) supports x86_64, arm64 and armv7, though if using armv7 we recommend using plaintext tests, not TLS. I do not think the Go client will be usable on mips systems, but also I don't work with those systems anymore. If you do build a working Go client for mips, we would be interested to know about it. In all likelihood you will want to consider using the libndt library for mips.  Dependencies and build instructions are provided in the code repo's Readme. \ue5d3""}, 7: {'username': 'Chris Wu', 'response_date': 'Aug 10, 2021, 8:03:31 AM', 'response_content': ""Sorry for reviving an old thread but I'm in the same scenario. I have a Linux-based router I'd like to run tests from and I don't think Go is an option. I looked and libndt hasn't been updated in 2 years. Are there any other options that have come up since this thread last year? \ue5d3""}, 8: {'username': 'Chris Ritzo', 'response_date': 'Aug 10, 2021, 8:15:20 AM', 'response_content': ""Hi Chris, No problem with reviving an old thread.  For lower resourced machines like embedded routers, libndt was an option, but as you've found it is no longer maintained by the folks who built measurement-kit. Unfortunately, the M-Lab team does not plan to take on updates to libndt since our team is more focused on Go and lack sufficient C++11 expertise.  As a community-developed client, libndt and measurement-kit's former maintainers would I'm sure be open to new contributors and maintainers. Issues in the Github repo should be well documented and I think the community would welcome an updated version of new folks wanted to take on maintaining it.  If you or others on the list are potentially interested, please let us know, or reach out to the current maintainers on Github.  Best, Chris - M-Lab Support \ue5d3""}}"
52	connecting-nuts-3-(eu_nuts_3_2021_01m)-to-cities-(v0_cities_asn)	1627501672.0	2021-07-28 12:47:52	Bradley Kalgovas	Hi there, I want to connect the data in the cities table to the NUTS 3 tables that are in the database. However, in the cities table I can only see  ISO3166_2region1 as a potential linking code. How did map the cities data to NUTS 3? What do I join on? Thanks!! :)	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jul 28, 2021, 2:39:19 PM', 'response_content': ""Thanks for asking this question. The two tables you mentioned are perhaps more useful for different purposes.  While the table v0_cities_asn contains statistics by city and ASN as generated by our statistics pipeline service, it does not currently contain a field that could be joined to NUTS geographies. This could potentially be added to the statistics output in the future during the generation of the statistics.  The tables defining EU's NUTS geographies are useful for geographic joins, using BigQuery's GIS support. These tables define the shape outline of NUTS regions in the geometry field. During the generation of statistics, we can identify the geographic region in which individual NDT test rows were geolocated using GIS SQL functions. NDT rows have a latitude and longitude annotation derived from geolocation of the originating IP address, and a GIS function can be used to identify which region that point is within.  This blog post provides an example query that uses a different geographic area, but demonstrates the approach you could use with the geographies in the NUTS tables to join individual NDT tests with the NUTS geographies.  So in summary, I would suggest that joining `measurement-lab.geographies.eu_NUTS_3_2021_01m` with `measurement-lab.statistics.v0_cities_asn` is not the right approach to obtaining cities aggregate data for NUTS3 geographies.  Instead, you could take the base query that generates the cities-asn statistics, and modify it to select only tests within EU NUTS 3 geographies, using the Geographic join approach described above and in the blog post.  I hope this is helpful.  Best regards, Chris - M-Lab Support \ue5d3""}, 1: {'username': 'Bradley Kalgovas', 'response_date': 'Jul 30, 2021, 11:24:24 AM', 'response_content': 'Hi Chris, Thanks so much for the info, we ran the following query and got this error message: SELECT * FROM `measurement-lab.ndt.unified_uploads_20201026x` LIMIT 1    Yesterday it was working fine if you can figure out what happened that would be great :)  Kind regards, Bradley  \ue5d3'}, 2: {'username': 'Chris Ritzo', 'response_date': 'Jul 30, 2021, 11:27:22 AM', 'response_content': 'Hi Bradley,  The error message means you have to use a date limiter such as WHERE date >= ""2021-01-01"" in your SQL statement. This is the default for our tables so if it worked yesterday that would be an anomaly. This constraint is applied to our tables and views to encourage efficient queries. Just add something like the above to your query and it should work fine.  Best, Chris \ue5d3'}, 3: {'username': 'Bradley Kalgovas', 'response_date': 'Aug 2, 2021, 8:05:08 AM', 'response_content': 'Hi Chris, one final question. Sorry to bug you. In the cities table ( v0_cities_asn ) , there is min ( download_MIN )  and max download ( download_MAX ) speeds, but we only see average in the NDT ( unified_downloads )  table. How can we get min and max from the NDA ( unified_downloads) table? Thanks! \ue5d3'}, 4: {'username': 'Chris Ritzo', 'response_date': 'Aug 2, 2021, 8:13:47 AM', 'response_content': ""Hello Bradley, It's no problem.  I think an important distinction to note here is that ndt.unified_downloads and ndt.unified_uploads contain individual tests, where the tables in the statistics dataset, such as v0_cities_asn contain aggregated data based on the unified_downloads and unified_uploads tables.  The average field you are referring to in unified_downloads (meanThroughputMbps) is the throughput measurement of an individual test. When an NDT test is run, the server captures a series of snapshots or samples over the time the test is run. These samples are used to calculate meanThroughputMbps. You should not consider this value a mean or average really, unless you are exploring data from individual snapshots or samples within a single NDT test.  If you are wanting to get Min and Max from unified_downloads, I would expect you are wanting those metrics over all tests within a time range and location. You can use BigQuery's aggregation functions, combined with GROUP BY statements in your queries to do this.  See: https://cloud.google.com/bigquery/docs/reference/standard-sql/aggregate_functions https://cloud.google.com/bigquery/docs/reference/standard-sql/statistical_aggregate_functions  I hope this helps. - Chris \ue5d3""}, 5: {'username': 'b.ra...@gmail.com', 'response_date': 'Aug 2, 2021, 10:07:25 AM', 'response_content': 'Hi Chris,  Thank you for your help, I think we almost there.  One more clarification questions: if city aggregation tables forming from NDT table, how exactly is it aggregated: minimum of all the tests in the area, average of the bottom 5-10%, or any other way? Thank you! Also likewise how is the max calculated.  Kind regards, Bradley  From: Chris Ritzo <cri...@measurementlab.net> Sent: Monday, August 2, 2021 8:14 AM To: discuss <dis...@measurementlab.net> Cc: b.ra...@gmail.com <b.ra...@gmail.com>; Chris Ritzo <cri...@measurementlab.net> Subject: Re: Connecting NUTS 3 (eu_NUTS_3_2021_01m) to Cities (v0_cities_asn)  Hello Bradley, It\'s no problem.  I think an important distinction to note here is that ndt.unified_downloads and ndt.unified_uploads contain individual tests, where the tables in the statistics dataset, such as v0_cities_asn contain aggregated data based on the unified_downloads and unified_uploads tables.  The average field you are referring to in unified_downloads (meanThroughputMbps) is the throughput measurement of an individual test. When an NDT test is run, the server captures a series of snapshots or samples over the time the test is run. These samples are used to calculate meanThroughputMbps. You should not consider this value a mean or average really, unless you are exploring data from individual snapshots or samples within a single NDT test.  If you are wanting to get Min and Max from unified_downloads, I would expect you are wanting those metrics over all tests within a time range and location. You can use BigQuery\'s aggregation functions, combined with GROUP BY statements in your queries to do this.  See: https://cloud.google.com/bigquery/docs/reference/standard-sql/aggregate_functions https://cloud.google.com/bigquery/docs/reference/standard-sql/statistical_aggregate_functions  I hope this helps. - Chris   On Monday, August 2, 2021 at 11:05:08 AM UTC-4 b.ra...@gmail.com wrote: Hi Chris, one final question. Sorry to bug you. In the cities table ( v0_cities_asn ) , there is min ( download_MIN )  and max download ( download_MAX ) speeds, but we only see average in the NDT ( unified_downloads )  table. How can we get min and max from the NDA ( unified_downloads) table? Thanks! On Friday, 30 July 2021 at 11:27:22 UTC-7 Chris Ritzo wrote: Hi Bradley,  The error message means you have to use a date limiter such as WHERE date >= ""2021-01-01"" in your SQL statement. This is the default for our tables so if it worked yesterday that would be an anomaly. This constraint is applied to our tables and views to encourage efficient queries. Just add something like the above to your query and it should work fine.  Best, Chris  On Friday, July 30, 2021 at 2:24:24 PM UTC-4 b.ra...@gmail.com wrote: Hi Chris, Thanks so much for the info, we ran the following query and got this error message: SELECT * FROM `measurement-lab.ndt.unified_uploads_20201026x` LIMIT 1   Yesterday it was working fine if you can figure out what happened that would be great :)  Kind regards, Bradley \ue5d3'}, 6: {'username': 'Chris Ritzo', 'response_date': 'Aug 2, 2021, 10:08:54 AM', 'response_content': 'Hi Bradley, This information is described in the stats-pipeline documentation. I would suggest you start there and follow up with any questions or clarifications that are needed.  Best regards, Chris \ue5d3'}}"
53	what-exactly-is-mean-throughput-on-the-ndt7-test?	1626900639.0	2021-07-21 13:50:39	Kelsey Nanan	"Hi,   In the schema for the NDT7 test, a.MeanThroughputMbps is defined as follows:  ""The measured rate as calculated by the server. Presented in megabits per second, or Mbit/s, this value is the average of tcp-info snapshots taken at the beginning and end of an ndt7 measurement. Therefore it is identified as “MeanThroughputMbps”.""  I was wondering exactly what TCP Info snapshots are averaged to calculate Mean Throughput, since it seems as there are many TCP Info fields.  Also, does Mean Throughput average both upload and download speeds?   Thanks for any help! Kelsey"	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jul 23, 2021, 6:29:23 AM', 'response_content': 'Hi Kelsey, Thanks for asking this question.  The TCP info snapshots are like samples taken over the time an individual test is run. The many TCP info fields are the various metrics collected by TCP Info about the state of the connection during the test. As you note, there are many, and for researchers deeply familiar with TCP they will be more recognizable. For most people though, including myself, we summarize the metrics of highest interest like ""MeanThroughputMbps"".   As the NDT test runs, samples or snapshots of the ""speed"" or throughput are taken by TCP info, and the final field, MeanThroughputMbps is provided as the average of those samples. When an NDT test is run, to the user it\'s like running one test, but the upload and download measurements are saved as separate rows in our datasets. So MeanThroughputMbps is provided for download and upload measurements individually but not combined.  I hope this helps. If you have additional questions please let us know.  Best, Chris - M-Lab Support \ue5d3'}, 1: {'username': 'Kelsey Nanan', 'response_date': 'Jul 26, 2021, 5:19:20 AM', 'response_content': ""Hi Chris,   Thank you so much for your quick response! I ran the following query a while ago (before I knew a bit more about speed tests - upload vs download lol):     (Sorry for the poor image quality) But would the a.MeanThroughputMbps that I downloaded be average upload or download speed? And if I want to get the individual upload and download mean throughput values, what would those fields be called in the database? I'm looking at the BigQuery schema here - https://www.measurementlab.net/tests/ndt/ndt7/#ndt7-bigquery-schema , sorry if I seem to be missing it..   Thanks for your help!  Kelsey \ue5d3""}, 2: {'username': 'Chris Ritzo', 'response_date': 'Jul 26, 2021, 5:54:54 AM', 'response_content': 'Hi Kelsey,  I might back up and suggest that depending on your line of inquiry or research question, the ndt7 table may not be the right table to look at. If you are interested in looking at all ndt7 tests including those that failed, or were not complete, according to our team\'s best understanding, then continue using the ndt7 table.  However, if you are interested in only ndt7 tests that are considered by M-Lab to be complete and valid tests for understanding what ndt7 measures, then our NDT unified views should be your starting point for queries. For more information, this blog post discusses the NDT unified views and what they provide.  I also must recommend that you review our blog post, Using M-Lab Data in Broadband Advocacy and Policy, for our research recommendations when working with NDT data.  ndt.unified_uploads and ndt.unified_downloads allow you to query specifically for one or the other or both measurements, and these views are filtered to provide only tests that meet our team\'s understanding of test completeness. You can join the upload and download measurements using the UUID field if you want to get both...  To query the unified ndt views for only ndt7 tests, you can use the field node._Instruments in the WHERE part of your query. For example: WHERE node._Instruments = ""ndt7"" will return only ndt7 tests.  If the value of this field is ""tcpinfo"" then the test will be from the ndt5 protocol.  Specific to your questions about the schema pages and the measurements in the ndt7 table, my apologies that the schema descriptions on the website are not up to date. We hope to rectify that soon. The field names and descriptions are valid, but may not be complete or in the same order as those in the BigQuery tables. For the most current schema fields, I would rely in the listing in BigQuery as seen in the screenshot below, and for field descriptions, reference the pages on our website for now. The individual upload and download measurements in the ndt7 table are stored within the raw record section under raw.upload and raw.download. If the row is an upload measurement, the raw.upload fields will be present, and download fields will be blank or null. Vice versa for download measurements. So if you are looking at the field ndt7.a.MeanThroughputMbps, this value will be the upload measurement when the field raw.Upload.UUID is not null, and will be the value for a download measurement if the field raw.Download.UUID is not null.  I hope this helps.  Best, Chris \ue5d3'}}"
54	is-delivery-architecture-discoverable-by-m-lab?	1626709213.0	2021-07-19 08:40:13	V. Kelly Bellis	I'm studying data provided to me from a third party using M-Lab's speed test, and I'm just wondering, is it possible to determine what internet service delivery method is used when the speed test is performed. For example, LTE, CBRS, mobile wireless, fixed wireless, DSL, cable, fiber, etc. Thank you for any reply. Kind regards, Kelly	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jul 23, 2021, 6:16:31 AM', 'response_content': ""Thanks for asking this question. Currently M-Lab does not identify the internet service delivery method or access media when the NDT test is performed. We have discussed adding an annotation to results in the future, tagging each test as mobile/non-mobile based on what it possible to learn from the IP address.  It is possible now to segment mobile and non-mobile tests by looking up each test's IP address in a service like ipinfo.io, during your analysis. This research from 2018 did just that, to look at mobile NDT data specifically: https://a4ai.org/access-is-more-than-cost-measuring-the-quality-of-mobile-broadband-service/  I hope this helps.  Best regards, Chris - M-Lab Support \ue5d3""}}"
55	[cfp]-pluggable-transports-small-grants-program	1626287098.0	2021-07-14 11:24:58	Vasilis	Dear all,  Internews has announced the second round of the Small Grants program for projects involving pluggable transports.  The following activities are eligible for funding:  * Concept Development for new transports * Proof of Concept deployments * Deployment, App integration, and cross-platform functionality * Improving PT deployment and infrastructure stability  **The deadline for the second round of submissions is August 1st, 2021.**  More information: https://www.pluggabletransports.info/blog/small-grants-2021/  Submission form: https://cryptpad.fr/form/#/2/form/view/2I9uswe7Ibt88PnDfdiq31O5K+MHIw6+LMFVuTou5lY/   Greetings, ~Vasilis -- PGP Fingerprint: 8FD5 CF5F 39FC 03EB B382 7470 5FBF 70B1 D126 0162 PGP Public Key: https://keys.openpgp.org/vks/v1/by-fingerprint/8FD5CF5F39FC03EBB38274705FBF70B1D1260162	{}
56	new-person-needs-advice	1626089270.0	2021-07-12 04:27:50	Jim Brock	MY E-mail is (felada@charter;net) not fela...@gmail.com Deleted that mailbox a longtime ago but some messages still try to send to that address. I joined this conversation after  I ran speed test  Download  28.42 mb/s  upload 11.12 mb/s latency 26 ms.  Now Im reaching out to the community for some advice on how to improve my speed.  Cable company Spectrum (charter) communications.  I am renting their Modum and Router.  Have a wish to improve speed in my home.  Most things in house are connected by WIFI  . Watch a lot of movies on Netflix and Prime and some regular channels for news and sports.  Hate regular TV because of the over abundance  of commercials.  Any help would be great.  Take into consideration that I know very little about this subject.                  JB	{}
57	hitting-limit-of-csv-download	1623860175.0	2021-06-16 09:16:15	Cat Shoults	"Hello M-Lab Team, I am querying unified upload/download using the BigQuery SQL interface.  I hit the limit of the csv downloads to google drive (1 GB per file).  To resolve this issue, I looked into using client libraries to hit the API from python.  The documentation states that I need to enable the API, but I get the below alert denying permission.  Am I doing something wrong or is this feature not enabled for Mlab?  [Hmm, my screenshot isn't pasting.  Here is what it says, ""This API cannot be enabled at the moment.  You may lack appropriate permissions.""] Assuming that I can't use client libraries, do you have example queries when using Google Cloud SDK?  I am not familiar with command line and will need to see how others have created their queries.  I have tried the links on your website that direct to the Learning Resources but the page is empty. Thank you for your help and insights. Best regards, Cat"	"{0: {'username': 'Greg Russell', 'response_date': 'Jun 16, 2021, 9:25:03 AM', 'response_content': ""IIRC that limit does not apply to google cloud storage, so an alternative might be to use that as a temporary destination, then download the files from there.  I guess you would need to create a personal google cloud platform project.  The GCP free tier is fairly generous.  They require a credit card, but say:   We ask you for your credit card details to make sure that you are not a robot.    You won't be charged unless you manually upgrade to a paid account.  \ue5d3""}, 1: {'username': 'Chris Ritzo', 'response_date': 'Jun 16, 2021, 10:44:01 AM', 'response_content': ""Hi Cat,  As Greg suggested, you can save your query results to a Google Cloud Storage within your own project, using the free tier.  The reason you were denied permission to use the API is that while M-Lab does provide query access, we don't enable additional services like using the APIs, client libraries, etc. As Greg indicated, to use the client libraries using Google's APIs, you will need to set up and use your own Google Cloud Project, and enable the APIs you need to use there.   I hope this helps. Perhaps there are others on the list using this same method who could share more.  Best, Chris \ue5d3""}, 2: {'username': 'Cat Shoults', 'response_date': 'Jun 16, 2021, 11:57:55 AM', 'response_content': 'Thank you both very much.  This is helpful and, yes, any additional insights or tips are much appreciated.   \ue5d3'}, 3: {'username': 'Chris Ritzo', 'response_date': 'Jun 17, 2021, 5:29:32 AM', 'response_content': 'You\'re quite welcome. Glad this is helpful.  If you\'re looking for general analysis guidance, I can provide some possible resources. This blog post discusses our general recommendations to consider when analyzing NDT data for policy, advocacy, or really any research. Using M-Lab Data in Broadband Advocacy and Policy Using those recommendations, we provide an API of aggregated NDT statistics by various geographies. This resource may be useful to you if you\'re familiar with using APIs containing JSON data. NDT Statistics Pipeline Service Readme However, if you are most interested in learning about how to query NDT data for your own analyses, you might look at the queries used within the statistics pipeline service as a starting point. These are complex queries with several ""sub-queries"", but while they may look daunting depending on your experience with SQL, you could try different sub-queries separately as a way to learn more. Finally, we are working on revamping our learning resources. My apologies that there\'s nothing there at the moment. We hope to publish a series of new tutorials and resources in the coming months.  Best regards, Chris - M-Lab Support \ue5d3'}, 4: {'username': 'Cat Shoults', 'response_date': 'Jun 17, 2021, 7:02:51 AM', 'response_content': 'These resources look ideal.  I appreciate your taking the time to give me such a thorough answer.  If I run into issues, I will reach out but this certainly seems like what I need to move forward.  Have a good day! \ue5d3'}}"
58	web-api?	1623860185.0	2021-06-16 09:16:25	Vinay Lal	Hi,   How would it be possible to use MLab data via a web API? ie a user on a web page searches for internet speed data by location and receives MLab data via an API which then is displayed for the user on said web page.  Would I need a Custom Google Cloud Account and I pay for data queries or is there an existing API that MLab has I could use?  If there is an existing web API then can it use MLabs ability to query Big Query for free?  I saw that there were command line programs to do this but not web api's.  Thanks so much for any help!  V	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jun 16, 2021, 10:50:49 AM', 'response_content': ""Thanks for asking about this. We do provide an API for aggregated NDT statistics which does not require authentication: https://github.com/m-lab/stats-pipeline/#statistics-pipeline-service  If you are wanting non-aggregated NDT data or other M-Lab datasets however, you will need to use Google's web APIs to interact with BigQuery. For example, this is a link to Google's REST API for BigQuery: https://cloud.google.com/bigquery/docs/reference/rest  To use Google's APIs with our datasets, you will need to have your own Google Cloud Project: https://cloud.google.com/resource-manager/docs/creating-managing-projects and enable the APIs you need to use. Your account on this group can be used for authenticating your application. If you find that you need to use a service account for your application, you can let us know at sup...@measurementlab.net, and we'll add that service account to the access group.  Hope this helps.  Best, Chris \ue5d3""}, 1: {'username': 'Bob Ballance', 'response_date': 'Jun 16, 2021, 11:57:55 AM', 'response_content': 'Google also provides a number of BigQuery API client libraries for various languages: https://cloud.google.com/bigquery/docs/reference/libraries which can make the coding easer.  . . . Bob   \ue5d3 \ue5d3 --  You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/99a4f406-1d93-45fa-8eb0-947ca7aebe1an%40measurementlab.net.'}, 2: {'username': 'Vinay', 'response_date': 'Jun 17, 2021, 4:38:05 AM', 'response_content': ""Thanks guys, appreciate the tips! I'm looking through the pipeline to see if I can find what I want. I think the data is there but perhaps I may need to go deeper than current geo accuracy allows in aggregated data.  Couple questions: The pipeline mentions up coming additions and that 'block level' may be possible. If so, is that scheduled anytime soon or no plans as yet? Also, 'Cities are identified from the IP address annotations present in NDT data after it is published.' - is there a list of city codes or how else could I understand what this code is for any given city? Also, the docs for pipeline say any geo unit is possible but not necessarily accurate. Can I pull data (even if not considered accurate at this time) from geo units smaller than City also? V   \ue5d3 -- Vinay Lal oneth...@gmail.com""}, 3: {'username': 'Chris Ritzo', 'response_date': 'Jun 17, 2021, 5:17:54 AM', 'response_content': 'Hi Vinay,  On Thursday, June 17, 2021 at 7:38:05 AM UTC-4 oneth...@gmail.com wrote: Thanks guys, appreciate the tips! I\'m looking through the pipeline to see if I can find what I want. I think the data is there but perhaps I may need to go deeper than current geo accuracy allows in aggregated data.  Couple questions: The pipeline mentions up coming additions and that \'block level\' may be possible. If so, is that scheduled anytime soon or no plans as yet? Aggregation by US Census Tract is provided for comparison/advisory only, and we do not plan to add census block level at this time. Though this is possible, we do not advise aggregating below city or county level due to the limitations on the precision of IP address geo-location.  Also, \'Cities are identified from the IP address annotations present in NDT data after it is published.\' - is there a list of city codes or how else could I understand what this code is for any given city? When an NDT test is conducted, the IP address from the connection initiating the test and the measurement itself are collected on the server through which the test ran. From there, a service we maintain annotates the test using publicly available datasets. You can read more about how this is done, what datasets are used, and a history of NDT annotations in this blog post.  Cities in the API are provided in the statistics pipeline API by name, and if you need an index of city names you can use the Maxmind Geolite2 City dataset. I\'ll also make a note that index tables may be a useful addition to make available in a future release.  There are several types of codes or numbers used in the API: * if you are looking at a URL with `/asn/` in the path, this is the Autonomous System number of the provider assigned to a range of IPs in the selected geography * for the US County statistics, we use the GEOID of each county as identified by the US Census Bureau * other codes are all geographic and include: two character Continent Code, the two character Country Code, and the 2-3 alphanumeric Region Code. Region Code uses the ISO 3166-2 standard, which in the US identifies the state. For example, US-MD is the region code for the state of Maryland. Also, the docs for pipeline say any geo unit is possible but not necessarily accurate. Can I pull data (even if not considered accurate at this time) from geo units smaller than City also? As mentioned above, each test is annotated with geographic codes using Maxmind\'s free Geolite2 dataset. This includes latitude/longitude coordinates, but is not the same at all as a street address or GPS precise location. See this information from Maxmind regarding IP Geolocation Accuracy. For this reason, we do not advise using NDT statistics for geographies smaller than county or city at this time. This blog post provides more context, where I explored and demonstrated these limits.  If you desire, you can of course pull individual data using BigQuery, and aggregate by any geographic shape you would like, but we wouldn\'t advise that the aggregated statistics would be at all correct.  There is one option for aggregating NDT data at geo units smaller than City-- collecting new tests from the location of interest using your own NDT client integration. This means collecting new test data, where you ask for or know the exact location where the test was run. Some of the links on our Data / Tools page can enable this. For example, if you wanted to collect tests automatically from known locations using a small computer placed on premise, you could use Murakami. If you wanted to run a website to survey a particular area and ask users to run a test, you could use Piecewise. Both require new data collection, and campaigns/resources of course, and though the NDT test results from these tools still is sent to our public dataset in BigQuery, any additional location precision or survey results are not. Using these tools also then means you have to establish your own analysis workflow and tools. If using these tools to collect new data are of interest to your organization, we can advise and discuss with you. Reach out to us at sup...@measurementlab.net, or directly to my email address.  Best regards, Chris - M-Lab Support  V    On Wed, 16 Jun 2021 at 13:57, Bob Ballance <ballance@internet-is-infrastructure.org> wrote: Google also provides a number of BigQuery API client libraries for various languages: https://cloud.google.com/bigquery/docs/reference/libraries which can make the coding easer.  . . . Bob On Jun 16, 2021, at 11:50 AM, Chris Ritzo <cri...@measurementlab.net> wrote:  Thanks for asking about this. We do provide an API for aggregated NDT statistics which does not require authentication: https://github.com/m-lab/stats-pipeline/#statistics-pipeline-service  If you are wanting non-aggregated NDT data or other M-Lab datasets however, you will need to use Google\'s web APIs to interact with BigQuery. For example, this is a link to Google\'s REST API for BigQuery: https://cloud.google.com/bigquery/docs/reference/rest  To use Google\'s APIs with our datasets, you will need to have your own Google Cloud Project: https://cloud.google.com/resource-manager/docs/creating-managing-projects and enable the APIs you need to use. Your account on this group can be used for authenticating your application. If you find that you need to use a service account for your application, you can let us know at sup...@measurementlab.net, and we\'ll add that service account to the access group.  Hope this helps.  Best, Chris    On Wednesday, June 16, 2021 at 12:16:25 PM UTC-4 oneth...@gmail.com wrote: Hi,   How would it be possible to use MLab data via a web API? ie a user on a web page searches for internet speed data by location and receives MLab data via an API which then is displayed for the user on said web page.  Would I need a Custom Google Cloud Account and I pay for data queries or is there an existing API that MLab has I could use?  If there is an existing web API then can it use MLabs ability to query Big Query for free?  I saw that there were command line programs to do this but not web api\'s.  Thanks so much for any help!  V   --  You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/99a4f406-1d93-45fa-8eb0-947ca7aebe1an%40measurementlab.net.    -- Vinay Lal oneth...@gmail.com'}, 4: {'username': 'Vinay', 'response_date': 'Jun 17, 2021, 6:32:39 AM', 'response_content': ""Thank you Chris! I'll go digest all that info.  V  \ue5d3 Hi Vinay,  \ue5d3 V    \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/99a4f406-1d93-45fa-8eb0-947ca7aebe1an%40measurementlab.net.    -- Vinay Lal oneth...@gmail.com""}}"
59	ndt-server-widget.html-for-ndt7?	1622834602.0	2021-06-04 12:23:22	Tate Baumrucker	Anyone have an updated version of widget.html and/or associated js that uses NDT7 instead of NDT5? Or is there a fairly simple way of modifying the existing code to use the new test mechanism?   I like the presentation and the details delivered in the NDT5 interface, but would like to use the new NDT7 test method. Thanks, Tate	"{0: {'username': 'Nathan Kinkade', 'response_date': 'Jun 4, 2021, 2:07:31 PM', 'response_content': 'Tate,  M-Lab does not provide an updated version of the <iframe>-based widget, and I\'m not aware that anyone else has created any analog with ndt7. Not only does that widget use ndt5, but the javascript code behind it is very old, outdated and unmaintained. https://speed.measurementlab.net uses the much newer, maintained ndt7-js library. Your best bet may be to inspect that site to see how ndt7-js is leveraged there, and to create something custom on your own site.  Best,  Nathan  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CABNfQYO9FaaT6J_DLLyeqazaEaLi6kZyXmjbGaU4wkzE8YTUdg%40mail.gmail.com.'}}"
60	invitation:-using-data-in-broadband-advocacy-and-policy-work---discussion-(next)-wednesday,-may-26	1621544275.0	2021-05-20 13:57:55	Lai Yi Ohlsen	Want to discuss the use of Internet measurement data in broadband advocacy and policy work? Join us next Wednesday, May 26, 2021 from 11am-12pm Eastern for a conversation with experienced broadband researchers including:   Fenwick Mckelvey, Associate Professor at Concordia University Reza Rajabiun, Research Fellow, Ryerson University; CEO, eFilters Inc.  Chris Mitchell,  Director of the Community Broadband Networks Initiative, Institute for Local Self Reliance and moderated by Lai Yi Ohlsen, Director of Measurement Lab   Our casual conversation will include lessons learned from using measurement data in advocacy and policy, in both the US and Canada, as well as recommendations for its future. We welcome audience questions, answers, challenges, and discussion. No level of experience or familiarity with M-Lab is required; all we ask is that participants review and respect our community guidelines.   If you have previously RSVP’d to our community calls, you should have already received a calendar invite with a Zoom link included. If not, please reply directly to this email.   If you have not previously RSVP’d, but would like to attend, please do so here and indicate that you’d like to be attended to the “Broadband Advocacy/Policy” meetings. You’ll be sent a Zoom link shortly after.  If you have any questions, please feel free to reply to this email directly or write to la...@measurementlab.net.   Looking forward to it! Talk soon.  -- Lai Yi Ohlsen Project Director, Measurement Lab www.measurementlab.net	"{0: {'username': 'Scott Shawcroft', 'response_date': 'May 26, 2021, 7:25:35 AM', 'response_content': 'Will this be recorded and posted somewhere later? I have another meeting at the same time.  Thanks, Scott \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcOVBkxZ47ebcLnSKHyFM9FCNbK5X9%3D%2BDJ3DKdHL0P1%2BnA%40mail.gmail.com.'}, 1: {'username': 'Lai Yi Ohlsen', 'response_date': 'May 26, 2021, 7:27:19 AM', 'response_content': ""Hey Scott,   We haven't yet taken the steps to get each participant's consent for recording these calls, but it's good to know that's something you're interested in (others are as well) and is something that we can prioritize for future calls.   Best,    \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/2b6ffd64-5606-48ae-85d3-295e909a37f3%40www.fastmail.com. \ue5d3""}}"
61	regarding-accessing-data.	1621985605.0	2021-05-25 16:33:25	Uddipan	Dear all, I am new to Mlab and I don't know much about it. I am reading enough resources but yet I am not able to get all the information. As an assignment, I need to work on getting data of RTT, Avg throughput, Median uploads and downloads of different countries for comparison. I have seen on Big Query but unable to get the required information. Please tell me how to proceed and get those particular information of different countries. Thank you all. 	"{0: {'username': 'Amreesh Phokeer', 'response_date': 'May 26, 2021, 7:25:28 AM', 'response_content': 'Dear Uddipan,  First, you need to subscribe to this mailing list which you already did.  Then, the easiest way to access the data is to use Bigquery: https://console.cloud.google.com/bigquery  select ""measurement-lab""          > ndt               > ndt7  You can then run Standard SQL queries and export the results.  Or you can also run queries from the unified views: https://console.cloud.google.com/bigquery?project=measurement-lab&p=measurement-lab&d=ndt&t=unified_downloads&page=table https://console.cloud.google.com/bigquery?project=measurement-lab&p=measurement-lab&d=ndt&t=unified_uploads&page=table  Hope that helps.  -- Amreesh    \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/b0fd420f-077b-45b4-a396-170b6c6b04e6n%40measurementlab.net.   -- Amreesh Phokeer'}}"
62	ndt7-issue-on-raspberry-pi-/-ubuntu	1621616515.0	2021-05-21 10:01:55	Guilherme Martins	Dear,  we found this strange behavior running ndt7-client-go on ubuntu 20.04 raspberry pi 4. The speed seems to be limited at ~150Mbps (dw) even running on connections capable of >300Mbps.  The problem does not occur with Ookla's speedtest on the same device and it does not occur with Ndt7 running on Jetson Nano at all. Please let us know if there's anything we can do to help investigate this one. A full log of executions can be found here: https://github.com/m-lab/ndt7-client-go/issues/59.  Thank you,  Guilherme Martins	"{0: {'username': 'Simone Basso', 'response_date': 'May 21, 2021, 1:23:48 PM', 'response_content': '\ue5d3 \ue5d3 Thanks for the heads up, I\'ve replied directly on GitHub.  Thanks,  Simone  Thank you,  Guilherme Martins -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/f9703f5d-385f-4d96-8ffb-587bca635594n%40measurementlab.net.'}}"
63	question-about-client-rate-limits	1621280606.0	2021-05-17 12:43:26	Albert Liang	"Hello!  Wanted to ask for some clarification.  On the developer resources page (https://www.measurementlab.net/develop/), it says that one client can only run 40 tests a day.  If I create a speed test site (publicly open similar to Ookla's) for people to come test their internet speeds, my site will be limited to running 40 speed tests per day?  Or was the definition of a ""client"" the end-user who is hitting the ""Run test"" button?  That end-user can ""only"" run 40 tests a day, but my website overall is unaffected?  Thanks! Albert"	"{0: {'username': ""Roberto D'Auria"", 'response_date': 'May 19, 2021, 4:50:47 AM', 'response_content': 'Hello Albert,  When integrating the ndt7 speed test on a web page, the client is the user\'s browser. Even if they go through your website, each user runs the test from his own IP address to one of the M-Lab servers and is considered separately for rate-limiting purposes. Hope this helps!  Regards, Roberto D\'Auria  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/b128b484-f343-46b6-a182-87468e7359c2n%40measurementlab.net.'}, 1: {'username': 'Albert Liang', 'response_date': 'May 19, 2021, 11:25:39 AM', 'response_content': ""Thank you!  That's a relief!  Best, Albert \ue5d3""}}"
64	using-big-query-to-filter-via-asn	1621280600.0	2021-05-17 12:43:20	Aaron Lorenz	"Hi, am currently having difficulties using big query to query MLAB data and I would like to specify via an ASN. I am currently using client.Network.ASNumber = ""AS###"" however I get the error code, ""No matching signature for operator, for argument types: INT64, STRING. Supported signature ANY=ANY at [41:7]"". I apologize if this question is over-simplistic for this discussion group.  Thanks Aaron Lorenz"	"{0: {'username': ""Roberto D'Auria"", 'response_date': 'May 19, 2021, 4:40:41 AM', 'response_content': 'Hi Aaron, client.Network.ASNumber is an Integer field containing just the number (without the ""AS"" prefix). If you change the where clause to ""client.Network.ASNumber = ###"" (without quotes) it should work as expected.  Regards, Roberto D\'Auria  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/06908b65-6155-4c6d-a9d9-bca844c02257n%40measurementlab.net.'}}"
65	credentials-to-access-data-via-spark	1619043341.0	2021-04-21 15:15:41	Henry Mejía Osorio	Hey people,  I'm doing some exploratory workflow, for this I need to authenticate via PySpark script, so I can access 'measurement-lab:ndt' dataset. Can somebody please provide some service account credentials with read access to that DB. Or do you have any other workarround to access? My first approach was an automated console login to download data. Nevertheless, this is not a sustainable approach.   Thanks in advance for your help!	"{0: {'username': 'Chris Ritzo', 'response_date': 'Apr 21, 2021, 3:21:24 PM', 'response_content': 'Hello, Thanks for asking this question. You can use a service account from your own Google Cloud Project, but M-Lab doesn\'t provide that for you.  To do this, create your project and a service account using the Cloud Console in the IAM & Admin section. It will have an ""email"" associated with it listed on that page once created.  Send the service account email to sup...@measurementlab.net requesting it be added to the access list.  Once it\'s added, you\'ll be able to use it with your script to query the public datasets.  Hope this helps and we\'ll look for your email.  Best regards, Chris - M-Lab Support \ue5d3'}, 1: {'username': 'Data Engineering', 'response_date': 'Apr 27, 2021, 10:34:29 AM', 'response_content': ""Thanks Chris! We're going to send you an email. \ue5d3""}}"
66	mlab-speed-test-data-open-repository	1619262407.0	2021-04-24 04:06:47	Ankur Khanna	Hi,  Is Mlab open source repository with speed test data available? I need to analyze data on a global scale for a college project.	{0: {'username': 'Ankur Khanna', 'response_date': 'Apr 25, 2021, 10:51:34 AM', 'response_content': 'Hi,  I found the Google cloud platform with ndt7 data, which has upload and download folders with json file. Im not sure how to calculate the download n upload speeds from that data. Any help would be appreciated. Thanks \ue5d3'}, 1: {'username': 'Chris Ritzo', 'response_date': 'Apr 26, 2021, 4:32:45 AM', 'response_content': 'Hello and thank for reaching out.  Accessing the raw test archives in GCS is useful if you wish to study the raw measurements and associated pcap files from NDT tests. However, the recommended starting point for most people is to use SQL within BigQuery. Pcap files are not currently in BigQuery.  We parse all NDT results into a series of BigQuery tables, and further do some data cleaning and schema standardization across all NDT datatypes (ndt5, ndt7, web100), and finally provide the result in a set of BigQuery views.  Use BigQuery if you wish to perform your own analyses of individual NDT tests using SQL. Follow our quickstart guide to add your account to our access group to get started NDT Data in BigQuery outlines what datasets, and views to use for querying We also recommend reviewing this blog post for recommendations on conducting your own analyses with NDT data Finally, you could also use pre-aggregated statistics for NDT provided by our statistics pipeline service. Read more about that service and the API it provides here: https://github.com/m-lab/stats-pipeline/#statistics-pipeline-service  I hope this is helpful for your project.  Best regards, Chris - M-Lab Support \ue5d3'}}
67	mlabs-client-script	1618421151.0	2021-04-14 10:25:51	Ankur Khanna	Hi I need to write a script in python for consecutive mLabs test for bandwidth measurement, has it been done before? Any help would be appreciated.	{0: {'username': 'Chris Ritzo', 'response_date': 'Apr 21, 2021, 5:19:21 AM', 'response_content': 'Thanks for asking this question. Yes, this has been done before.  You might take a look at one of our community tools, Murakami, to either use directly or derive examples.  We also encourage anyone using command line clients, Murakami, or custom clients that use M-Lab tests to review our Developer Guidelines, which outline our general requirements and policies, as well as best practices for scheduled tests and the frequency of tests.  Perhaps you might say more what you mean by consecutive tests. You may also reach out directly to sup...@measurementlab.net for individual assistance.  Best regards, Chris - M-Lab Support \ue5d3'}}
68	invitation:-strategy-for-m-lab’s-long-term-data-calibration---discussion-on-april-28	1619007036.0	2021-04-21 05:10:36	Chris Ritzo	Want to hear more about M-Lab’s plans to calibrate our data? Join us next Wednesday, April 28, 2021 from 11am-12pm Eastern for a presentation and follow up discussion with Matt Mathis, Research Scientist at Google and open-source contributor to M-Lab, who is considering ways to improve M-Lab tools for long-term use by Internet researchers. An introduction from Matt:   My vision for improving the calibration of longitudinal MLab data, is to reprocess historical data using new insights drawn from recent observations.   Since this process has the potential to affect the reproducibility of previously published results, we need to be careful to fully disclose and justify our changes and enable researchers to examine how our processing changes might affect their results.  Basic experience or familiarity with M-Lab will be assumed but questions will be encouraged. As always, we ask participants to review and respect our community guidelines.   If you plan on attending please RSVP to our 2021 community calls and indicate that you’d like to be attended to the “Internet Research” meetings. You’ll be sent a Zoom link shortly after. If you previously RSVP'd, you should have already received a link, if not, please reply to this email directly.  If you have any questions at all, please feel free to reply to this email directly or write to sup...@measurementlab.net.  -- Chris Ritzo (he/him) Program Management & Community Lead, Measurement Lab	{}
69	spanish-instructions/interface-for-speed-test	1615923594.0	2021-03-16 12:39:54	Rich Stalzer	Good day, I chair a Broadband Access committee in my rural NY State town, and am about to launch a survey on local broadband availability and affordability.  I plan to link to the m-labs speed test but would like to offer the survey in Spanish as well as English.  Is there a Spanish language instruction or landing page that uses the m-labs infrastructure in the US?  Thanks, Rich Stalzer Town of North East, NY Broadband Access Committee	"{0: {'username': 'Chris Ritzo', 'response_date': 'Mar 29, 2021, 9:59:06 AM', 'response_content': 'Hello Rich, With apologies for the delayed reply, yes, you can direct Spanish speaking users to this URL for our speed test: https://speed.measurementlab.net/es/#/  We had an issue with a recent update to that site where the available translations were not working, but this is now fixed.  Best regards, Chris - M-Lab Support \ue5d3'}, 1: {'username': 'Rich Stalzer', 'response_date': 'Apr 4, 2021, 10:23:38 AM', 'response_content': 'Thank you.    Virus-free. www.avg.com  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/5c3e87bc-ee48-474a-a4fa-e027180ec38dn%40measurementlab.net.'}}"
70	running-ndt-on-ipad-mini-4-test-scores-lower-than-my-regular-ipad	1617557011.0	2021-04-04 10:23:31	George Fratus	Hi, I like this NDT test by M-Lab this test has helped me confirm a problem with my cable TV with San Diego cox cable, a problem which they have after 4 tech visits can't find but a problem shared by over five different homes. That is another story.  My ipad mini 4 shows a slower speed result than my laptop does. Both are wireless while the laptop and my other regular ipad scores higher each time the ipad mini 4 scores lower. Any suggestions on why and how if I can fix it would be greatly acknowledged. GF   	{}
71	mlab-ns-returning-a-404-error-for-mobiperf	1616765768.0	2021-03-26 06:36:08	Taveesh Sharma	Hi,  I am using MobiPerf to run a few tests using an Android emulator. I am getting the following error in application logs while it tries to find an M-Lab server for checking IP compatibility:  I/Mobiperf: MLAB-NS URL http://mlab-ns.appspot.com/mobiperf?format=json&address_family=ipv6 E/Mobiperf: InvalidParameterException in checkIPCompatibility(). Received status 404 from mlab-ns  The application also uses mlab-ns for finding an m-lab server for running speed tests. I wish to alternate between M-Lab servers and a custom server to run speed tests from android phones and compare the results. The custom server setup does work for me but I cannot get MobiPerf to find the nearest m-lab servers. Is there any way I can achieve this?  Kind regards, Taveesh	"{0: {'username': 'Chris Ritzo', 'response_date': 'Mar 26, 2021, 6:44:06 AM', 'response_content': 'Hello Taveesh, Thanks for posting. Unfortunately, MobiPerf is no longer hosted on the M-Lab platform. If you or others reading this are maintainers or contributors to MobiPerf, we would be happy to discuss supporting the experiment again. If that is of interest, please reach out at sup...@measurementlab.net.  Best, Chris \ue5d3'}, 1: {'username': 'Josiah Chavula', 'response_date': 'Mar 29, 2021, 4:51:59 AM', 'response_content': 'Hi Chris,  Just to clarify: we understand that Mobiperf is no longer hosted on M-Lab, but does that mean a custom ndt Mobiperf-based client that uses mlab-ns will not be able to find and test against M-Lab servers?  Thanks, Josiah \ue5d3'}, 2: {'username': 'Chris Ritzo', 'response_date': 'Mar 29, 2021, 4:56:13 AM', 'response_content': 'Hi Josiah,  Yes, you are correct. mlab-ns, now called our ""locate service"", no longer supports Mobiperf clients. This support was removed when Mobiperf was decommissioned from our servers.  Best, Chris \ue5d3'}, 3: {'username': 'Nathan Kinkade', 'response_date': 'Mar 31, 2021, 8:56:35 AM', 'response_content': 'Just to add to what Chris said, while you can no longer query the M-Lab Locate Service for Mobiperf services, if it\'s an NDT test of some sort that you want to run, and you can control the URL that gets queried (which I gather you can), then you can query the locate service for NDT servers instead:  http://locate.measurementlab.net/v2/nearest/ndt/ndt5 http://locate.measurementlab.net/v2/nearest/ndt/ndt7  Best,  Nathan  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/6d4da292-9dd2-4ca9-a40d-c685235058e9n%40measurementlab.net.'}}"
72	too-slow-conection-to-your-server.	1616416547.0	2021-03-22 05:35:47	Ernest	Hi, Why are your tests showing such poor results? The same happens at the stadia where the game is still breaking me, I tested the speed on the stadia page and the same too low speed, the game cuts out after a few minutes. I run Geforce Now and play without any connection problems...	"{0: {'username': 'Chris Ritzo', 'response_date': 'Mar 26, 2021, 6:55:33 AM', 'response_content': 'Hello and thanks for posting.  The NDT test is a different measurement instrument than many other tests like Fast. You can learn more about the differences and our position on Internet ""speed"" in general in this blog post. Our servers are also outside of last mile networks, so your measurement with NDT also includes the impact of your provider\'s peering with upstream networks on your connection\'s performance beyond the last mile networks that they maintain.  Since you mentioned Stadia, please know the we have informed them about how the use of our test results may be misleading, as shown in your screenshot. Because our code is open source, Stadia and others may instrument our test in their site or software without coordination with M-Lab, as long as their integration follows our policies. I would recommend complaining to Stadia support about this, and please feel free to reference this message.  Best, Chris - M-Lab Support \ue5d3'}}"
73	request-for-addition-of-latitude-and-longitude-to-location-in-locate-v2	1616765771.0	2021-03-26 06:36:11	Kristofer Spinka	Hi, I think it would be very beneficial to add the latitude and longitude of the host datacenter to the Location in Locate v2.  While GCP does a good job localizing the client, identifying where the NDT node itself is would be extremely helpful at the point of test.  For example, in a dense metropolitan region, say NYC, NDT target hostnames with the LGA IATA (New York, US) often mean anything from 111 8th Ave., NY all the way to Secaucus, NJ and beyond.  I do fear that some cleaning of the NDT node registrations is going to be required as well because when I look in ndt/tcpinfo on BQ, I see quite a few Server.Geo.{latitude,longitude} records that are not right, also IATA's that don't match Server.Geo.region.  So at least worth a review there too.  Thank you,    -Kris	{}
74	use-m-lab-open-source-tools-in-your-research---rsvp-for-discussion-*next-wednesday*-march-24	1616089561.0	2021-03-18 10:46:01	Lai Yi Ohlsen	Want to get ideas for how to use M-Lab’s open source community tools in your research? Join us next Wednesday, March 27, 2021 from 11am-12pm Eastern for a conversation with researchers who are using M-Lab tools to better understand the Internet in their area of interest. Speakers will include:   Kevin Chege, Director, Internet Development at the Internet Society and Amreesh Phokeer, Research Manager at AFRINIC who are currently researching the resilience of the African Internet. Chris Ritzo, Program Management and Community lead at Measurement Lab and Colin Rhinesmith, Associate Professor and Director, Community Informatics Lab at Simmons University who recently finished the Measuring Libraries Broadband Networks project, which studied the broadband performance of public libraries across the US.   Our casual conversation will cover everything from the technical details of their research to the high level successes and lessons learned. Any M-Lab user who is interested in learning more about how M-Lab’s open source tools can enhance their research is encouraged to join. No level of experience or familiarity with M-Lab is required; all we ask is that participants review and respect our community guidelines.   If you plan on attending please RSVP to our 2021 community calls and indicate that you’d like to be attended to the “General” meetings. You’ll be sent a Zoom link shortly after. If you have any questions, please feel free to reply to this email directly or write to la...@measurementlab.net.   -- Lai Yi Ohlsen Project Director, Measurement Lab www.measurementlab.net	{0: {'username': 'Lai Yi Ohlsen', 'response_date': 'Mar 18, 2021, 10:54:09 AM', 'response_content': 'CORRECTION: next Wednesday, March 24 at 11am Eastern.  \ue5d3'}, 1: {'username': 'Lai Yi Ohlsen', 'response_date': 'Mar 24, 2021, 6:14:01 AM', 'response_content': 'Hi everyone,   Quick reminder that this conversation will happen in a little under 2 hours at 11am Eastern. Please RSVP here for M-Lab Community Calls if you would like to attend and feel free to email me directly if you have any questions or issues accessing the meeting.  \ue5d3'}}
75	withering-connectivity	1615212011.0	2021-03-08 07:00:11	Starr Gilmartin	Over a considerable period of time, my connectivity has decreased.  My download is between 60 and 25.  I have employed various fixes all to no avail.  I have plugged an Ethernet cable directly into the modem and that produces a much more robust signal.    I have had Spectrum out here numerous times and each time, they say they have fixed it. Very disappointed, Starr	{}
76	m-lab-newsletter---march-2021	1614967196.0	2021-03-05 10:59:56	Lai Yi Ohlsen	Hello! I hope this finds you well. Today I’m writing with the first of many newsletters that you’ll receive on this mailing list. In each monthly edition, we’ll provide updates about M-Lab such as changes to our platform and pipeline, data schemas, community tools, best practice analyses, community case studies, documentation and guides, and more. Ultimately, our goal is to communicate with you on a more regular basis, so we encourage you to reply with any questions or comments that come to mind. Additionally, as part of our efforts to communicate more effectively, we’ve established a lightweight set of community guidelines that we ask participants to keep in mind as you engage here and on any other M-Lab hosted forum. If there is anything you’d like to see in these newsletters, please do let me know. And without further ado! We recently published two new blog posts. Using M-Lab data in Broadband Advocacy and Policy was written as a guide for researchers, policy makers, governing bodies, advocacy groups, or anyone who wants to understand M-Lab data and how it compares to other internet measurement data sets. We plan to continue to develop these recommendations for appropriate use of our data in analyses and reports. Requiring access tokens for ndt7 announces the requirement for NDT client integrations to use access tokens that are issued by the Locate v2 API. These requirements are relevant to anyone supporting an NDT integration. The latest versions of the ndt7-js, ndt7-client-go, and ndt7-client-android already support the Locate v2 API natively. Update to the latest version and you’re done! Upcoming updates In our December 2020 community calls, we announced the development of a pipeline to ease the use of aggregate NDT statistics into third party applications. We have soft launched the pipeline to a group of early testers and plan to release to the public in the next quarter. If you are interested in early testing, please let us know. Contract opportunities We currently have two projects that we are looking for a Javascript developer to complete. You can read more about them here. Please reach out to la...@measurementlab.net if you are interested. Recent events Project Director Lai Yi Ohlsen recently presented at NTIA’s February 2021 Webinar: Data as the Foundation for Broadband Planning, alongside Karen Perry, Senior Policy Analyst for BroadbandUSA and Bryan Darr, Vice President of Smart Communities at Ookla. The recording, presentation slides, and webinar transcript are available and are good resources for folks who want to learn or educate others more about the use of data in Broadband Planning. Community Call Schedule In 2020, we began hosting regular community calls where we discussed topics related to the M-Lab project and its related research topics. Here is the schedule for this year’s calls and the form to RSVP. -- Lai Yi Ohlsen Project Director, Measurement Lab www.measurementlab.net	{}
77	understanding-of-overview-of-the-test-and-statements.	1614692387.0	2021-03-02 06:39:47	Vijay Ahire	Hi  i want to understand if subscriber in United states subscribe for a broadband plan of 100Mbps and he is trying to do speedtest using servers located in INDIA.  so will he get the 100Mbps speed ?? according to Mlab they trying to do tests on OFFnets, how can i check on which country or location they trying to perform tests ? i did not find any conclusive information like which servers or ip address being used to perform tests on . Regards Vijay A	"{0: {'username': 'margaret agbo', 'response_date': 'Mar 3, 2021, 5:41:33 AM', 'response_content': 'Hello Vijay     I am using the M-Lab plugin on the chrome browser so I think I can attempt to give a reply to this challenge. Having studied a portion of the data set I got, there are some features that give an idea about the country details such as ClientInfoCountry, ClientInfoLatitute, ClientInforLongitude, ClientInfoRegion, ClientInforTimezone . Also features such as ServerInfo City, ServerInfoCountry, ServerInfoLavel will give destination country details.  Features such as ServerInfoIPV4, ServerInfoIPV, ServerInfoFDQN will give the address used for the test.  In summary, any feature with ""Client..."" is referring to the terminal the test is generated from, and any feature with ""...Server..."" is is refered to the destination point.  I hope that helps.  IZZYLYF    \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/4dedbba8-b418-46ae-8959-3caec68e809fn%40measurementlab.net.'}, 1: {'username': 'Vijay Ahire', 'response_date': 'Mar 3, 2021, 5:41:41 AM', 'response_content': ""Hi Margaret, Thanks for getting back to me so quickly. I can't find any plugins for Chrome named M-lab. Can you share a link here.   Regards Vijay A. \ue5d3""}, 2: {'username': 'Chris Ritzo', 'response_date': 'Mar 3, 2021, 5:45:27 AM', 'response_content': 'Hello all, As a reference for tools like the Chrome extension, our Data / Tools page provides links to several official and community tools, and third-party software and websites that use M-Lab test clients or data. The M-Lab Measure Chrome Extension is the first listed there.  Best, Chris - M-Lab Support \ue5d3'}, 3: {'username': 'Vijay Ahire', 'response_date': 'Mar 4, 2021, 6:13:40 AM', 'response_content': 'Hi Chris, Thanks for responding. one thing I want to highlight here is that there should be an option to select remote servers to do the measurement test. as many normal broadband users simply go to google.com and search speedtest and google chrome browser present on page speedtest widget without any more information as to on what destination servers these tests are performed on.  you understand that we cannot have the same speed all across the globe from point A to point B,  broadband customers argue that isp not giving them committed bandwidth showing results which has no more information as to what destination servers these tests are performed.  I hope you understand my point of view.  Regards Vijay A.   \ue5d3 -- Regards Vijay A CTO | Sevenstar dot com pvt ltd. +91 9930804010 vi...@my7star.com skype :- aspiremac'}, 4: {'username': 'Chris Ritzo', 'response_date': 'Mar 4, 2021, 6:48:55 AM', 'response_content': 'Hi Vijay, Thank you for offering your initial comment in support of the community. We appreciate it!  We understand the need to test to both the closest server (the default), and to locations in other parts of the world. You are right that speeds to a server closer to you will not be the same as to a server elsewhere. We do have support to select different servers than the closest or nearest: the Chrome Extension is one.  In the Chrome extension settings there is an option to select a server in another part of the world, not the default ""nearest"" server. It should be noted that the Chrome extension uses the NDT5 protocol test, and the (now deprecated) Locate v1 API. Our Locate API service is what all clients will eventually use to obtain a list of servers through which a test may be conducted. The Locate v2 service supports ISO3166-2 Country and Region parameters, which effectively allow a client to select servers in another country or region. If/when the Chrome extension is updated, it will move to NDT7 and Locate v2. Supporting this feature might look like a list of countries and/or regions, instead of the current list of server locations. One other note about targeting specific servers-- M-Lab is moving toward not allowing this, but instead focusing on selecting servers by regional availability as described here.  From the perspective of Internet Service Providers, their contracted speeds are typically intended to be the speeds within their network. In contrast, the NDT test measures something different- speeds from your location to a server outside the ISP network. So our measurements are not intended to demonstrate that you are or are not getting guaranteed speeds, but to measure your experience uploading or downloading content to points on the Internet.  All this to say, that when clients are upgraded, they could make use of the Country and Region selectors. As our team has capacity, we are upgrading all clients we maintain to ndt7 and the Locate API service. Our code is also open source, and we welcome the contributions of developers in the community.  I hope this provides some useful context. If you\'re a developer reading this and wish to learn more about contributing to M-Lab, please reach out here or at sup...@measurementlab.net  Best, Chris \ue5d3'}, 5: {'username': 'margaret agbo', 'response_date': 'Mar 5, 2021, 6:55:20 AM', 'response_content': 'Hello Vijay Sure of course. I got the extension here or here  Mlab. There are other choices too to suit your need.  Enjoy!!      IZZYLYF    On Fri, 5 Mar 2021 at 06:21, Vijay Ahire <vi...@my7star.com> wrote: Hi Chris, Thank you for your response.  Do you support hosting speedtest servers in internet exchange point in country or ISP datacenter.  Also I would like to know how can I have access to test data.  Regards Vijay A. \ue5d3'}, 6: {'username': 'Vijay Ahire', 'response_date': 'Mar 5, 2021, 6:55:21 AM', 'response_content': 'Hi Chris, Thank you for your response.  Do you support hosting speedtest servers in internet exchange point in country or ISP datacenter.  Also I would like to know how can I have access to test data.  Regards Vijay A.   On Thu, Mar 4, 2021, 19:18 Chris Ritzo <cri...@measurementlab.net> wrote: \ue5d3'}, 7: {'username': 'Chris Ritzo', 'response_date': 'Mar 5, 2021, 8:45:48 AM', 'response_content': 'Hi Vijay, You can find a map of our servers, and more information about them here: https://www.measurementlab.net/status/ Some of our servers are hosted in Internet Exchanges or Research and Education networks, but most are in commercial datacenters where ISPs peer. Each set of servers at each location has the requirements listed on our Contribute page. To access the data produced by M-Lab tests, you can learn more about all the datasets we host on the Data Overview page, and to access our public datasets, please review and follow our BigQuery Quickstart guide.  Best, Chris \ue5d3'}}"
78	ndt7-to-require-access-tokens-after-feb-1st	1607099863.0	2020-12-04 09:37:43	Stephen Soltesz	Hi, you may remember me from such announcements about required access tokens such as Oct 7th and Nov 4th.  We briefly required access tokens from Nov 4th to Nov 9th, before discovering community maintained clients that had not yet migrated to the Locate v2 API (ndt7-client-android and ndt7-client-ios) and un-requiring access tokens again.  There are now complete or pending changes to add Locate v2 support to these clients. And we will again require access tokens after Feb 1st. For real this time.  Thank you, Stephen	"{0: {'username': 'Stephen Soltesz', 'response_date': 'Feb 1, 2021, 12:44:46 PM', 'response_content': 'Hello, the change to require access tokens for ndt7 clients will roll out soon. Clients may add region= or country= parameters to the Locate API URL to select servers from a different geographic region than the ""nearest"" default. For example, using the ndt7-client-go: ndt7-client \'-locate.url=https://locate.measurementlab.net/v2/nearest/?country=JP\' ndt7-client \'-locate.url=https://locate.measurementlab.net/v2/nearest/?region=GB-LND\' See the API sources for a complete list of all countries and regions recognized.  Best, Stephen \ue5d3'}}"
79	reverse-traceroute	1611345170.0	2021-01-22 12:52:50	Colin McCann	Hi all, We are hoping to work with CIRA to expand on their internet performance testing tools (https://performance.cira.ca/), and had a couple of questions about your traceroute offerings. What we hope to do is have users do reverse traceroutes (eg from target server to user IP), and then provide the user with direct feedback based on the results. Is this something that is achievable? Or do we need to wait for the results to be updated in That traceroute results would be returned is somewhat implied here: https://support.measurementlab.net/help/en-us/9-platform/1-what-is-m-lab. However, I'm not totally sure I'm parsing it correctly (eg is the traceroute offering a subcomponent of the NDT offering? The data structures seem to imply that...)  A couple other quick questions: - where can I look at the source code for the reverse TR? - I've been looking at the data in BigQuery / measurement-lab / ndt / traceroute. Is this the correct place to be looking? Are there other places in addition? - is there a delay between when results are created and when they are available for query?  Thanks in advance! Colin	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jan 22, 2021, 2:51:12 PM', 'response_content': 'Hi Colin, Thanks for posting these questions. I\'ll reply here since you had two very similar threads, and this is the most current.  First, we should distinguish Traceroute from Reverse Traceroute. On our tests page, we distinguish Reverse Traceroute - a test (aka ""measurement service"") from the Traceroute ""M-Lab Core Service"".  The Traceroute M-Lab core service uses the Scamper traceroute tool provided by the Center for Applied Internet Data Analysis, CAIDA. For every TCP connection made to an M-Lab server, the traceroute service gathers a trace from our server back to the originating IP address. These traces are collected on a per server basis and parsed into BigQuery.   Traces are associated with each measurement service like NDT and others, and are also available for TCP connections not associated with any M-Lab measurement service as well.  All traces for all connections are available in measurement-lab.aggregate.traceroute. Traces relevant to specific measurement services like NDT are provided within the dataset for supported services. For example, measurement-lab.ndt.traceroute contains the traces associated with NDT tests. You can obtain the traceroutes for specific NDT tests by joining or matching on the UUID field.  Where Traceroute provides path information from M-Lab server to client, Reverse Traceroute is a tool intended to provide the reverse path information -- client to server-- which would normally only be possible by running traceroute from the client side to the server. You can find more information about Reverse Traceroute on their project page. However, as noted on our landing page for Reverse Traceroute, this data is not currently parsed into BigQuery. However, our team is actively working with the developers of Reverse Traceroute make that a possibility. As for running Reverse Traceroute to gather new reverse traces, we will need to inquire with their team to document client usage once the team reaches their re-launch milestone for this test. It is in the process of being updated to be supported on our Kubernetes based server platform.  Our Reverse Traceroute page provides links to the source code and currently available data.  Regarding our data publication process, expect that there will be an ~2 business day delay between the point when a test like NDT is run, and the data for that test being available in BigQuery. I expect the same would be true for traceroute. So in terms of real time access, this isn\'t really possible now, but can be provided after the fact. For example for CIRA\'s IPT tool, this could be something you provide to users who create an account perhaps.  I hope this response is helpful. Please let us know if you have additional questions.  Best, Chris - M-Lab Support \ue5d3'}}"
80	traceroute-generation-real-time-results	1611345166.0	2021-01-22 12:52:46	Colin McCann	Hi all,  We are working with CIRA on enhancing some of their tools. These tools use MLAB tests under the surface (https://performance.cira.ca/). One thing we are particularly interested in is being able to run reverse traceroutes and display the results to users in (semi) real time. Is this a possibility? Or is only the pattern [create traceroute - submit traceroute to mlab DB - query mlab DB for traceroute]? This is implied here (https://support.measurementlab.net/help/en-us/9-platform/1-what-is-m-lab), but I'm not sure I'm parsing it correctly.  Other quick questions: - I have been looking through the data in BigQuery / measurement-lab / ndt / traceroute. Is that the correct place to be looking for results? Does this cover both traceroutes and reverse traceroutes? Are there other tables of interest for these? - is there a time gap between when a traceroute is created and when it is queryable? - is reverse traceroute considered a subset of the NDT toolset? I wouldn't have assumed that, but the way the data is organized seems to imply it  Thanks in advance Colin	{}
81	mlab--measure-varaible-defination	1611152617.0	2021-01-20 07:23:37	margaret agbo	Good day support Team,   With hope this mail meets you well. I am Mrs. Margaret Oluwadare from Nigeria. I am research student in the University of Ibadan. I came across the M-Lab measures plug-in for google chrome online and it was indeed a perfect tool for my proposed research work. Thank you for developing such tool. But I have a challenge currently and it does require urgent attention.   I have been reading my network connectivity, and exported it as a CSV file. I can understand what some of the variable measures are but bulk of it I don’t have a clue to it.  I wish to request if I can have a link to where I can have a full definition of the variables listed.  I have here attached an except of the data.   Thank you with great expectation of prompt reply.	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jan 20, 2021, 8:04:34 AM', 'response_content': ""Good day & thanks for writing to us about the M-Lab Measure Chrome browser app.  The fields saved are the result of the NDT 5 test, which are documented on this page: https://www.measurementlab.net/tests/ndt/ndt5/  Note that there are field names on that page that may not be present in the Chrome browser app's output. Many of these fields are the TCP statistics collected during the test by our server-side TCP INFO service.  I would recommend searching for the field names in the CSV export on the page above to find the relevant field description.  For your immediate need, fields relevant to most users like Download, Upload, and Latency, the units as saved in the CSV file are kilobits per second (Download & Upload), and milliseconds (Latency).  Also, thank you for reporting this need. I've filed an issue to add this information to our public documentation.  If you have additional questions please let us know.  Best regards, Chris - M-Lab Support \ue5d3""}}"
82	tcp-packet-capture	1608641247.0	2020-12-22 05:47:27	Danilo Janković	Dear all,  Can you please provide me info where I can find TCP packet capture for performed tests? On website I can see that there is link: https://console.developers.google.com/storage/browser/archive-measurement-lab/  But I don't know which folder to use.  Looking forward to hearing from you soon.  Kind regards, Danilo. 	"{0: {'username': 'Matt Mathis', 'response_date': 'Dec 23, 2020, 7:18:00 AM', 'response_content': 'We are not indexing .pcap files (yet).  To find a .pcap look at the parser.Filename to find raw measurement data, and use it as a hint to find the tar files that might contain the .pcap  For example the .pcap for ndt/ndt5/2020/06/03/20200603T200936.305465Z-ndt5-mlab2-lga06-ndt is most likely in gs://archive-measurement-lab/ndt/pcap/2020/06/03/20200603T201319.748088Z-pcap-mlab2-lga06-ndt.tgz  gs://archive-measurement-lab/ndt/pcap/ - prefix for all ndt pcaps 2020/06/03/20200603 - date twice T201319.748088Z - timestamp close to the test time pcap-mlab2-lga06-ndt - the right type, server name  Note that the pcap packing is asynchronous, and in principle there can be arbitrary skew between the NDT and the pcap tar file timestamp, but in experience they are normally pretty close.  The offset can be either sign and there is some weirdness near 00:00:00Z.    The tar files can contain many traces, and the filenames within the tar include the test id (UUID)  Some day (not very soon) we will index all pcap files in BQ.   \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CALkOHCrG_V2Jx%2BOWXM2Pp8Syy%3DRk%3DHkNkduO99Mr3qpuBZs_gA%40mail.gmail.com.   -- Thanks, --MM--'}, 1: {'username': 'Peter Boothe ¶', 'response_date': 'Dec 23, 2020, 7:18:00 AM', 'response_content': 'Some third party services (e,g, ipinfo.io ) claim to be able to know such things. There are no known open sources of data for this, and M-Lab only publishes open data.    -Peter  On Tue, Dec 22, 2020 at 7:46 PM Danilo Janković <danilo.j...@gmail.com> wrote: Hi Peter,  First of all, thank you for answering.  You are right, I meant on NDT. So there is no way to find out if tests are perormed either on 2g/3g or 4g? Because we want to examine network behaviour only on 4G.  Kind regards, Danilo.  On Tue, 22 Dec 2020, 16:26 Peter Boothe ¶, <pbo...@google.com> wrote: For NDT tests (which are probably the tests you mean), the directory is ndt/ and for the packet captures, the directory is ndt/pcap/  NDT results are not annotated by the subscriber\'s connection method, because that is only known to the ISP of the tester, and not to the test server.  Hope that helps!    -Peter  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CALkOHCrG_V2Jx%2BOWXM2Pp8Syy%3DRk%3DHkNkduO99Mr3qpuBZs_gA%40mail.gmail.com.   --  Software Engineer at Google, writing open source software in support of M-Lab ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful, always with the goal of making the Internet better for the people who use it.   -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful, always with the goal of making the Internet better for the people who use it.'}, 2: {'username': 'Peter Boothe ¶', 'response_date': 'Dec 23, 2020, 7:18:00 AM', 'response_content': 'For NDT tests (which are probably the tests you mean), the directory is ndt/ and for the packet captures, the directory is ndt/pcap/  NDT results are not annotated by the subscriber\'s connection method, because that is only known to the ISP of the tester, and not to the test server.  Hope that helps!    -Peter  On Tue, Dec 22, 2020 at 1:47 PM Danilo Janković <danilo.j...@gmail.com> wrote: \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CALkOHCrG_V2Jx%2BOWXM2Pp8Syy%3DRk%3DHkNkduO99Mr3qpuBZs_gA%40mail.gmail.com. \ue5d3'}, 3: {'username': 'Danilo Janković', 'response_date': 'Dec 25, 2020, 10:24:18 AM', 'response_content': 'Dear Matt,  This way for finding pcap files is not much convenient since as can be seen from your example time offset between measurement and pcap file is almost 4 min, and there can be a lot of files in between. Is there an easier way to find a pcap file for a specified test since I need to search them for about 24 tests?  Kind regards, Danilo. \ue5d3'}, 4: {'username': 'Danilo Janković', 'response_date': 'Dec 25, 2020, 10:24:18 AM', 'response_content': ""Hi Matt,  But in some cases, there are more upload measurements that download.  During one test,  is upload first performed than download, or reverse?  Kind regards, Danilo.  On Thu, 24 Dec 2020 at 16:53, Matt Mathis <mattm...@google.com> wrote: Mostly impatient users who don't bother to wait for the upload test to finish.  On Thu, Dec 24, 2020, 2:53 AM Danilo Janković <danilo.j...@gmail.com> wrote: Hi Matt,  Thank you for your detailed explanation.  I have additional question. In NDT upload and download databases, when I collected  all measurements  for one operator for this year, number of upload and download measurements are not equal. It should be since when we perform test, both databases should be updated. Can you provide me explanation for this?  Kind regards, Danilo.    On Wed, 23 Dec 2020 at 08:08, Matt Mathis <mattm...@measurementlab.net> wrote: \ue5d3""}, 5: {'username': 'Matt Mathis', 'response_date': 'Dec 25, 2020, 10:24:18 AM', 'response_content': ""Mostly impatient users who don't bother to wait for the upload test to finish.  On Thu, Dec 24, 2020, 2:53 AM Danilo Janković <danilo.j...@gmail.com> wrote: Hi Matt,  Thank you for your detailed explanation.  I have additional question. In NDT upload and download databases, when I collected  all measurements  for one operator for this year, number of upload and download measurements are not equal. It should be since when we perform test, both databases should be updated. Can you provide me explanation for this?  Kind regards, Danilo.    On Wed, 23 Dec 2020 at 08:08, Matt Mathis <mattm...@measurementlab.net> wrote: \ue5d3""}, 6: {'username': 'Danilo Janković', 'response_date': 'Dec 25, 2020, 10:24:18 AM', 'response_content': 'Hi Matt,  Thank you for your detailed explanation.  I have additional question. In NDT upload and download databases, when I collected  all measurements  for one operator for this year, number of upload and download measurements are not equal. It should be since when we perform test, both databases should be updated. Can you provide me explanation for this?  Kind regards, Danilo.    On Wed, 23 Dec 2020 at 08:08, Matt Mathis <mattm...@measurementlab.net> wrote: \ue5d3'}, 7: {'username': 'Matt Mathis', 'response_date': 'Dec 26, 2020, 1:16:36 PM', 'response_content': 'In the early years the upload test always ran first.   At the request of some integrators we decoupled the tests and as the clients evolved they gradually shifted to download first.  It is also possible for people to build a custom NDT client for upload monitoring, and run repeated tests w/o any corresponding downloads.  Thanks, --MM-- Evil is defined by mortals who think they know ""The Truth"" and use force to apply it to others.  ------------------------------------------- Matt Mathis  (Email is best) Home & mobile: 412-654-7529 please leave a message if you must call.    \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CALkOHCrhHJALBXjtRh-urhWGfENiEdFa4ouVc64ama%2BYRgKGGQ%40mail.gmail.com.'}, 8: {'username': 'Matt Mathis', 'response_date': 'Dec 28, 2020, 1:22:43 PM', 'response_content': 'How are you finding the data now?  If querying unified views, node._instrument gives the tool (this will be deprecated when we have a better solution).   We will include the archive URL in the future.  \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CA%2Bs1KQFymm-Sb54Ujp%2Bzd%3DCccNe39e2zuXUBb_sv1_241wvBfA%40mail.gmail.com.   -- Thanks, --MM--'}, 9: {'username': 'Danilo Janković', 'response_date': 'Dec 28, 2020, 1:22:49 PM', 'response_content': 'Dear Matt,  Thank you for you response.  Regarding TCP capture, how to know if test record is in nd5 or ndt7 folder? We performed tests using https://speed.measurementlab.net/#/  KR, Danilo. \ue5d3'}, 10: {'username': 'Matt Mathis', 'response_date': 'Dec 29, 2020, 2:43:00 PM', 'response_content': ""Would it be ok for me to use extracting your trace for an example for how to do this for public documentation?  On Mon, Dec 28, 2020 at 11:25 PM Danilo Janković <danilo.j...@gmail.com> wrote: I am collecting data from measurement-lab.ndt.unified_downloads and measurement-lab.ndt.unified_downloads. I am trying to find this test for example: UUID: ndt-9nm6g_1596683030_000000000077F48B log_time: 2020-12-18 12:24:08.010343 UTC node._instrument:  tcpinfo  But I can't find it in archive-measurement-lab/ndt/tcpinfo when searching by log time. Can you please help?  Thank you in advance.  KR, Danilo.  \ue5d3   -- Thanks, --MM--""}, 11: {'username': 'Peter Boothe ¶', 'response_date': 'Dec 31, 2020, 7:33:55 AM', 'response_content': 'Currently, speed.measurementlab.net uses the ndt5 protocol  \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CALkOHCpyFSVFGKU2aDLUnBBfDsQKPZiXJXda4Fr6DDNUWZCRTg%40mail.gmail.com.   -- \ue5d3'}, 12: {'username': 'Danilo Janković', 'response_date': 'Dec 31, 2020, 7:34:00 AM', 'response_content': ""I am collecting data from measurement-lab.ndt.unified_downloads and measurement-lab.ndt.unified_downloads. I am trying to find this test for example: UUID: ndt-9nm6g_1596683030_000000000077F48B log_time: 2020-12-18 12:24:08.010343 UTC node._instrument:  tcpinfo  But I can't find it in archive-measurement-lab/ndt/tcpinfo when searching by log time. Can you please help?  Thank you in advance.  KR, Danilo.   On Mon, 28 Dec 2020 at 19:14, Matt Mathis <mattm...@measurementlab.net> wrote: \ue5d3""}}"
83	rat-type-for-tests	1608641247.0	2020-12-22 05:47:27	Danilo Janković	Dear all,  Can you provide me info where I can find info about RAT technology on which test was performed (2g,3g or 4g)? Is there some kind of parameter for that?  Kind regards, Danilo.	{}
84	rsvp-for-nov-dec-m-lab-community-calls	1603747799.0	2020-10-26 14:29:59	Lai Yi Ohlsen	Hi all,   I hope you're all doing the 2020 version of well :) I am writing to invite you to Measurement Lab's upcoming Community Calls. Similar to what we did in May, we'll hold 3 different calls throughout November/December, each one focused on a different level of expertise and area of focus.   Please RSVP HERE to receive information about the call(s).   Wednesday, Nov 18 11am-12pm EST - M-Lab Community Call Updates and discussion related to the use of M-Lab's platform, data, and community tools.  Wednesday, Dec 2 11am-12pm EST - Internet Measurement Research Deep dives into topics related to Internet measurement methodology. Technical expertise encouraged but not required.  Wednesday, Dec 9 11am-12pm EST - Broadband Policy/Advocacy Discussion and presentations related to the use of M-Lab data in digital inclusion and broadband research. Policy/advocacy expertise welcome but not required.   If you've been following along with our blog, you'll know that we've been quite busy and have a lot to discuss, but if you can't make it, no worries. Throughout 2021 we'll start hosting each call in a regular rotation, so there will be plenty of times to chat.    Again, please RSVP HERE to receive information for the call(s). Feel free to respond directly or to sup...@measurementlab.net with any questions.   -- Lai Yi Ohlsen Project Director, Measurement Lab www.measurementlab.net	"{0: {'username': 'Lai Yi Ohlsen', 'response_date': 'Nov 16, 2020, 1:04:49 PM', 'response_content': ""Hi everyone,   Writing to remind you of the General Community Call happening this Wednesday, November 18 at 11:00a Eastern.   If you have already RSVP'd, you should have received a calendar invite with the call information.  If you have already RSVP'd, but have not received the calendar invite, please let me know directly.  If you have not RSVP'd and you would like to, you can still do so here and we'll send you the call info asap.   The agenda and slides for our call can be found in the calendar invite and here. Topics will include items of interest to: - Developers who have integrated NDT into their application  - Anyone analyzing NDT data across August 2020 (see our blog posts on NDT's evolution for background information) - Researchers and developers interested in ingesting M-Lab data into their application using an API  We will also be giving a roadmap update and discussing our plans for the next 6 months, as shared in this blog post. Topics related to Internet Research and Broadband Advocacy/Policy will be discussed on December 2 and 9, respectively.    As always, feel free to reach out with questions or comments. Looking forward to connecting!   \ue5d3""}, 1: {'username': 'Romain Fontugne', 'response_date': 'Nov 17, 2020, 7:09:00 AM', 'response_content': 'Hi,  I won\'t be able to attend the call, so I will ask questions here.  Is there any plan to make the \'statistics pipeline\' with different aggregates? I\'d be very interested in having these statistics per ASN.  Thanks, Romain  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcM%2B4Tt%2BcUMNcaj8Jw%2Bu%2BYp537Moh7LTaz6UMjfoBpA_Nw%40mail.gmail.com.'}, 2: {'username': 'Lai Yi Ohlsen', 'response_date': 'Dec 1, 2020, 11:52:28 AM', 'response_content': ""Hi everyone,   Writing to remind you of the Internet Research Community Call happening this Wednesday (tomorrow), December 2 at 11:00a Eastern.   If you have already RSVP'd, you should have received a calendar invite with the call information. If you have not received the calendar invite, please let me know directly.   If you have not RSVP'd and you would like to, you can still do so here and we'll send you the call info asap.   The agenda and slides for our call can be found in the calendar invite and here. Topics will include: - M-Lab’s vision for collaboration with Internet Researchers in 2021 and beyond  - An overview of the data/tools Internet researchers have access to, including Multi-Track views and M-Lab's own self-monitoring  - An introduction to our current open research questions including: Factoring out Data Influences, the Influence of Platform Engineering, IP Anonymization, ndt7 Early Exit, Analysis Pitfalls, and Test Labeling  We look forward to a casual, collaborative discussion during and after the content we've prepared.   If you are interested in topics related to Broadband Advocacy/Policy, we'll be discussing them next week Wednesday, December 9 at 11:00a Eastern. As always, feel free to reach out with questions or comments.   Talk soon!  \ue5d3""}, 3: {'username': 'Lai Yi Ohlsen', 'response_date': 'Dec 1, 2020, 11:56:47 AM', 'response_content': ""Hi Romain,   Apologies for delayed response here. We are currently in design discussions around adding aggregations to ASN in the stats pipeline. There are some performance tradeoffs to consider before promising its feasibility. But it's helpful to know this would be useful to your research. We will keep you and the list updated.   \ue5d3""}, 4: {'username': 'Romain Fontugne', 'response_date': 'Dec 2, 2020, 5:55:15 AM', 'response_content': 'Hi Lai,  Thanks for the response. I will play with the current aggregates and report here if I find any problems.  Romain \ue5d3'}, 5: {'username': 'Lai Yi Ohlsen', 'response_date': 'Dec 2, 2020, 2:48:38 PM', 'response_content': ""Hi all,  Thanks to those of you who joined today. Here is a summary of the topics we covered:    Collaboration Through 2021 and beyond, M-Lab would like to pursue more collaboration with the Internet Research community. We invite the insight of others to point our blindspots and help us find solutions to our unique challenges. Towards this end, look out for the 2021 Community Call schedule coming soon.   Data Multi-track views are available, which allow for the separation of your research question from data selection and grooming. You can see example queries in the slides. A blog post is coming soon.  We have many data types available other than NDT: pcap, tcpinfo, switch, traceroute, data-annotations.   Open Research Questions There are many influences on Internet measurement  data including the platform and the endpoint environment. We invite the insight and expertise of the Internet Research community as we consider how each of the following research questions are affected by one or more of these factors.   Platform Engineering: The effect of the design decisions made within Locate API, Geo Annotations and Switch Discards are currently tracked but unquantified and open for exploration.  IP Anonymization: IP Anonymization in radically open data is a “wicked” problem. Test users want it, researchers don't, and regardless, the world is moving towards it. We are currently considering our options for how to preserve user privacy, remain open and maintain data validity. We imagine using client pseudonyms, issued by the locate service but are still in the design process.  Analysis Pitfalls: We have started to observe some common Analysis Pitfalls including: failing to compensate for client bias, dividing data too finely, and using medians (or averages) to summarize multi-modal data. We welcome community researchers' insight as other pitfalls are discovered.  Test Labeling: At least two factors significantly complicate data analysis and interpretation:  Client bias, and in-home bottlenecks, (or poor cellular SNR). We are considering approaches for labeling tests that appear to demonstrate these characteristics.  ndt7 Early Exit: We are pursuing an implementation of ndt7 that uses BBR to decide when to stop a download measurement. The goal is to do so without degrading measurement quality.   The slides from the meeting can be found here. They include some useful information, though were meant to be shared through the context of the presentation. If you have questions about how it was meant to be understood, please feel free to reach out.   Have a great week!  \ue5d3""}, 6: {'username': 'rjmcmahon', 'response_date': 'Dec 3, 2020, 6:43:34 AM', 'response_content': 'Hi All,  I\'m not sure if this is helpful but we\'re releasing iperf 2.0.14. We have found that measuring RTT isn\'t really enough. We\'ve added end/end write to read latencies for both TCP writes and isochronous (video traffic) as useful. It does require clock sync. man page is here  https://iperf2.sourceforge.io/iperf-manpage.html  Also, we\'ve been clustering are latency distributions, which are non-parametric, using the kolmogorov smirnov distances (and distance matrices)  https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test https://www.statisticshowto.com/parametric-and-non-parametric-data/  Then mostly monitoring the tails of the latendy PDFs/CDFs as latency means aren\'t very useful, rather the tail is driving customer experience.  An advert: If you volunteer to test with iperf 2.0.14 then will give you a shirt.  Bob  > Hi all, > Thanks to those of you who joined today. Here is a summary of the > topics we covered: > Collaboration > > * > > Through 2021 and beyond, M-Lab would like to pursue more collaboration > with the Internet Research community. We invite the insight of others > to point our blindspots and help us find solutions to our unique > challenges. Towards this end, look out for the 2021 Community Call > schedule coming soon. > > Data > > * > > Multi-track views are available, which allow for the separation of > your research question from data selection and grooming. You can see > example queries in the slides. A blog post is coming soon. > * > > We have many data types available other than NDT: pcap, tcpinfo, > switch, traceroute, data-annotations. > > Open Research Questions > > There are many influences on Internet measurement data including the > platform and the endpoint environment. We invite the insight and > expertise of the Internet Research community as we consider how each > of the following research questions are affected by one or more of > these factors. > > * > > Platform Engineering: The effect of the design decisions made within > Locate API, Geo Annotations and Switch Discards are currently tracked > but unquantified and open for exploration. > * > > IP Anonymization: IP Anonymization in radically open data is a > “wicked” problem. Test users want it, researchers don\'t, and > regardless, the world is moving towards it. We are currently > considering our options for how to preserve user privacy, remain open > and maintain data validity. We imagine using client pseudonyms, issued > by the locate service but are still in the design process. > * > > Analysis Pitfalls: We have started to observe some common Analysis > Pitfalls including: failing to compensate for client bias, dividing > data too finely, and using medians (or averages) to summarize > multi-modal data. We welcome community researchers\' insight as other > pitfalls are discovered. > * > > Test Labeling: At least two factors significantly complicate data > analysis and interpretation: Client bias, and in-home bottlenecks, > (or poor cellular SNR). We are considering approaches for labeling > tests that appear to demonstrate these characteristics. > * > > ndt7 Early Exit: We are pursuing an implementation of ndt7 that uses > BBR to decide when to stop a download measurement. The goal is to do > so without degrading measurement quality. > > The slides from the meeting can be found here [2]. They include some > useful information, though were meant to be shared through the context > of the presentation. If you have questions about how it was meant to > be understood, please feel free to reach out. > > Have a great week! > > On Tue, Dec 1, 2020 at 1:52 PM Lai Yi Ohlsen > <la...@measurementlab.net> wrote: > >> Hi everyone, >> >> Writing to remind you of the Internet Research Community Call >> happening this Wednesday (tomorrow), December 2 at 11:00a Eastern. >> >> If you have already RSVP\'d, you should have received a calendar >> invite with the call information. If you have not received the >> calendar invite, please let me know directly. >> If you have not RSVP\'d and you would like to, you can still do so >> here [1] and we\'ll send you the call info asap. >> >> The agenda and slides for our call can be found in the calendar >> invite and here [2]. Topics will include: \ue5d3 >> here [3] and we\'ll send you the call info asap. >> >> The agenda and slides for our call can be found in the calendar >> invite and here [2]. Topics will include items of interest to: >> - Developers who have integrated NDT into their application >> - Anyone analyzing NDT data across August 2020 (see our blog posts >> [4] on NDT\'s evolution for background information) >> - Researchers and developers interested in ingesting M-Lab data into >> their application using an API >> >> We will also be giving a roadmap update and discussing our plans for >> the next 6 months, as shared in this blog post [5]. Topics related >> to Internet Research and Broadband Advocacy/Policy will be discussed >> on December 2 and 9, respectively. >> >> As always, feel free to reach out with questions or comments. >> Looking forward to connecting! >> >> On Mon, Oct 26, 2020 at 5:29 PM Lai Yi Ohlsen >> <la...@measurementlab.net> wrote: >> >> Hi all, >> >> I hope you\'re all doing the 2020 version of well :) I am writing to >> invite you to Measurement Lab\'s upcoming Community Calls. Similar to >> what we did in May, we\'ll hold 3 different calls throughout >> November/December, each one focused on a different level of >> expertise and area of focus. >> >> PLEASE RSVP HERE [1] TO RECEIVE INFORMATION ABOUT THE CALL(S). >> >> Wednesday, Nov 18 11am-12pm EST - M-LAB COMMUNITY CALL >> Updates and discussion related to the use of M-Lab\'s platform, data, >> and community tools. >> >> Wednesday, Dec 2 11am-12pm EST - INTERNET MEASUREMENT RESEARCH >> Deep dives into topics related to Internet measurement methodology. >> Technical expertise encouraged but not required. >> >> Wednesday, Dec 9 11am-12pm EST - BROADBAND POLICY/ADVOCACY >> Discussion and presentations related to the use of M-Lab data in >> digital inclusion and broadband research. Policy/advocacy expertise >> welcome but not required. >> >> If you\'ve been following along with our blog, you\'ll know that we\'ve >> been quite busy and have a lot to discuss, but if you can\'t make it, >> no worries. Throughout 2021 we\'ll start hosting each call in a >> regular rotation, so there will be plenty of times to chat. >> >> AGAIN, PLEASE RSVP HERE [1] TO RECEIVE INFORMATION FOR THE CALL(S). >> Feel free to respond directly or to sup...@measurementlab.net with >> any questions. >> >> -- >> >> LAI YI OHLSEN >> Project Director, Measurement Lab >> www.measurementlab.net [6] >> >> -- >> >> LAI YI OHLSEN >> Project Director, Measurement Lab >> www.measurementlab.net [6] > > -- > > LAI YI OHLSEN > Project Director, Measurement Lab > www.measurementlab.net [6] > > -- > > LAI YI OHLSEN > Project Director, Measurement Lab > www.measurementlab.net [6] > > -- > You received this message because you are subscribed to the Google > Groups ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, send > an email to discuss+u...@measurementlab.net. > To view this discussion on the web visit > https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcM0g9OyLD3%3DdGUbXxTLag-U3myiMdro_bzrM%2BnSGq%3DLXQ%40mail.gmail.com > [7]. > > > Links: > ------ > [1] > https://docs.google.com/forms/d/e/1FAIpQLSfjMN4f_QHPEH6-2oPutKCDCyXeh-iHyfb8LBhO0Jv9K0H82A/viewform?usp=sf_link > [2] https://bit.ly/3kzQsJd > [3] https://forms.gle/a385i1vMFd9mAiPr8 > [4] https://www.measurementlab.net/blog/category/ndt7/ > [5] > https://www.measurementlab.net/blog/roadmap-update/#m-lab-roadmap-update---q4-2020 > [6] http://www.measurementlab.net > [7] > https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcM0g9OyLD3%3DdGUbXxTLag-U3myiMdro_bzrM%2BnSGq%3DLXQ%40mail.gmail.com?utm_medium=email&utm_source=footer'}, 7: {'username': 'Lai Yi Ohlsen', 'response_date': 'Dec 8, 2020, 9:57:51 AM', 'response_content': ""Hi everyone,   Writing to remind you of the Broadband Advocacy/Policy call happening this Wednesday, December 9 at 11:00a Eastern, our last community call of the year.    If you have already RSVP'd, you should have received a calendar invite with the call information. If you have not received the calendar invite, please let me know directly.  If you have not RSVP'd and you would like to, you can still do so here and we'll send you the call info asap.   This meeting's agenda focuses upon what you might consider when using speed measurement data in your advocacy/policy work, specifically M-Lab's NDT. Topics include:  - Useful terms to understand such as bandwidth and latency, off-net and on-net, link capacity and path capacity, and single-stream and multi-stream - Notable differences between M-Lab NDT, 3rd Party M-Lab NDT Integrations, Form 477 Fixed, Ookla’s Speedtest - An introduction to the factors that influence M-Lab data - Common analysis pitfalls, with guided examples on how to avoid them  We look forward to a casual, collaborative discussion during and after the content we've prepared. As always, feel free to reach out with questions or comments.   Talk soon!  \ue5d3""}, 8: {'username': 'Lai Yi Ohlsen', 'response_date': 'Dec 11, 2020, 12:58:19 PM', 'response_content': ""Hi all,  Thanks to those of you who joined our Broadband Advocacy/Policy call on 12/9. Here is a summary of the call:   Defined broadband measurement terms: Bandwidth and latency, on-net and off-net, interconnect, access link capacity, end to end path capacity, single stream and multi-stream, and bulk transport capacity are all useful terms for you to know and use in your broadband advocacy/policy work.  They are specifically useful when looking at the different broadband data sources that are often referenced, including M-Lab’s NDT data, 3rd party client integrations of M-Lab’s, Form 477 data and Ookla’s Speedtest. Talking points from these definitions and comparisons are in the slides.  We plan to follow up with a blog post for reference to document in more detail but please feel free  to reach out if you have any questions or would like to cite these definitions elsewhere.  Factoring Data Influences There are many influences on Internet measurement data including the platform and the endpoint environment. Our recommendations for factoring them in your analysis include:  Acknowledging that a number of things can cause the data to swing 10-30% in any direction. The data changing, by say, 90% is likely a real change. But considering context when deciding upon a threshold is important, and so we recommend not having a hard threshold, and if you do, we recommend it not be below 30%.  We strongly recommend distributions e.g. bucketing data into 1,2,5,10,20,50,100 Mbps buckets and looking at the fraction of tests in each bucket.  The best choice is always to compare the data to itself. Examples of this include: Compare competing ISPs in the same region Compare an ISP's performance to its performance last year When you do this, you are much more likely to be comparing apples to apples.  Common Analysis Pitfalls and Recommendations We also reviewed a number of common analysis pitfalls we’ve started to recognize in the past few years including:  Excluding invalid data e.g. monitoring data, errored tests Failing to compensate for client bias M-Lab NDT data is a mix of infrequent manually triggered tests and beacons that test frequently. Without de-biasing, beacons often dominate the stats. Dividing data too finely; segmenting until there are too few samples in a segment to be meaningful e.g. rural zip-codes and census tracts may have only 1 or 2 tests per month. Oversimplifying e.g. using medians (or averages) to summarize multi-modal data.  We recommend avoiding linear scales and linear averages. We recommend digging deeper into multimodal distributions by examining the influence of ASNumber, of socio-economic and rural/urban influences, and exclude tests to very distant servers.  Our team’s understanding of our data is always evolving alongside the community’s; we invite you to share your insights as we share ours.  The slides from the meeting can be found here. Standard reminder that the slides and the summary are artifacts of a larger conversation. If you have questions about how the information was meant to be understood or would like to cite it elsewhere, please feel free to reach out.   Thanks to all who have joined us for the last round of community calls. Please look out for our 2021 schedule, coming soon. If we don't speak before, have a safe and happy holiday and we look forward to working with you next year.  \ue5d3""}}"
85	rtt-data---urgent	1607622872.0	2020-12-10 10:54:32	Danilo Janković	Dear Colleagues,  I need data for RTT (Round Trip Time) for all mobile operators in Montenegro for last year by day and by month. Also I need data for RTT daily and monthly  for specified countries.  Could you possibly help me? I need this data as soon as possible.  Thank you in advance.   Kind regards, Danilo Janković.	"{0: {'username': 'Danilo Janković', 'response_date': 'Dec 11, 2020, 5:45:25 AM', 'response_content': 'Dear Colleagues,  Can you please assist regarding below issue? Thank you in advance.  Kind regards, Danilo Janković. \ue5d3'}, 1: {'username': 'Chris Ritzo', 'response_date': 'Dec 11, 2020, 7:52:18 AM', 'response_content': ""Hello Danilo. Thanks for inquiring about how to search the M-Lab datasets for per-country Round Trip Time statistics by mobile provider. This forum is intended to enable M-Lab community members to support one another in their analysis and research.  If you have attempted to search our datasets already and are running into issues or questions, it's best to post those details here if you need help. However, if you are new to querying our data, I'll share a few pointers to help get you started.  M-Lab provides the data for each of our measurement services (tests) and core services in BigQuery, and membership in this group provides you access to query M-Lab's datasets freely.  Here are some notes on the specific things you are interested in: Minimum Round Trip Time is available in the NDT dataset (see the BigQuery Views: unified_downloads  and unified_uploads) in the field a.MinRTT Many geographic fields in this dataset allow identification of results by country, city, region, etc. For example the fields client.Geo.CountryCode or client.Geo.CountryName could be selected and used as aggregation fields in your query. The fields date or a.TestTime can be used to aggregate by various date & time values. All datetime or timestamp fields are saved in GMT.  Identifying only tests from mobile operators may require you to use some inference if using the NDT test results alone. The originating IP address is provided in the field, client.IP, and the Autonomous System Number (ASN) of the network operator associated with that IP address is provided in the field, client.Network.ASNumber. We will also soon be adding values to client.Network.ASName, but this information can also be looked up online. For example, I often use the service, ipinfo.io, to lookup details about an IP address or ASNumber. You could identify all of the ASNs from tests in our dataset within your countries of interest in a given time period, and pick only the ones that are mobile networks to use in your analysis.  The ipinfo.io API service (with appropriate subscription) can also be used to lookup IPs and includes detail about whether the IP was from a mobile provider or not. Others on this group may also have suggestions for alternative means of identifying mobile or other access media.  I hope this is a helpful starting point for you to begin researching with our datasets.  Best,  Chris - M-Lab Support \ue5d3""}}"
86	updated-ndt-unified-views,-monday-2020-11-21	1605832001.0	2020-11-19 17:26:41	Matt Mathis	"On Monday Nov 21 we will be updating NDT unified views as a next step in the migration to our new parser and data gardner, as described in past announcements and our community call last Wednesday, Nov. 19, 2020.  These changes will make it easier for researchers to explore the data in ways we did not anticipate.   Most of the changes will not require changes to your current queries, but do bring new capabilities.  Changes that potentially affect current queries:  Publish temporary views that provide the current schemas for a short time, to enable users to continue using them while updating queries and applications.   For example, `unified_downloads_20201026x` and `unified_uploads_20201026x`, will provide the schemas for unified views as of 2020-10-26 (the current schemas).  Please let us know if this is useful, otherwise we may discontinue this service in the future.  Measurement annotations (geo and network information for the client and server) are now stored with the measurement data in materialized* BigQuery tables for most of our newest data (from NDT7).  These new tables avoid query time joins, and are vastly faster than the old tables for all location based queries.  Older tools and data will be converted to materialized joins in future updates;  The new geographical labels use CamelCase column names: ContinentCode, CountryCode, CountryCode3, CountryName, MetroCode, AreaCode, PostalCode, AccuracyRadiusKm, etc.   Queries using old column names containing underscores will need to be updated;  BigQuery now enforces that all queries contain a WHERE clause on date to prevent people from accidentally accessing the entire data set.   This update also removes the column `test_date` to complete the transition announced earlier - use column `date`;  Publish new extended views in the intermediate_ndt dataset: these are strict supersets of the raw data augmented with non-standard columns carrying interim results, provenance labeling and other internal information.    The additional columns are not standardized and are subject to future breaking changes or removal.   Since they are not uniform between measurement tools or tool versions, these tables can not be combined (UNIONed) without filtering columns.   An upcoming blog post will describe how to efficiently use the extended views;  Note that we are gradually deprecating all older tables and views.  If the last row in a table is older than 2020, assume that it has been (or will be) migrated into the new unified view framework.   Please retire all code that uses older tables.  *The output from a slow or complicated query can be stored or ""materialized"" as a table to provide faster access to common intermediate results.  Thank you for your time and attention, --MM--"	{0: {'username': 'Matt Mathis', 'response_date': 'Nov 30, 2020, 10:02:26 AM', 'response_content': 'Sorry this missed the Monday window and slipped across Thanksgiving (US) to today.  We will be updating NDT unified views as a next step in the migration to our new parser and data gardner, as described in past announcements and our community call last Wednesday, Nov. 19, 2020. \ue5d3 \ue5d3'}}
87	interval-of-tcp_info-measurements?	1601388456.0	2020-09-29 07:07:36	Ralf Lübben	Hello,  I just have looked into the tcp_info measurements and I'm wondering how often the tcp_info reports are stored.  From the description and the code of tcp_info (https://github.com/m-lab/tcp-info/blob/master/collector/collector_linux.go), I expect an interval 10 milli seconds but the entries in the bigquery database and also in the related archive file shows less reports, also I cannot deduce the measurement interval from the file. The intervals seem be irregular.  For example the entry  SELECT * from ndt.tcpinfo WHERE UUID='ndt-sk6z6_1589402225_0000000000160252'  returns 4 entries for the tcp_info and the related archive  gs://archive-measurement-lab/ndt/tcpinfo/2020/06/07/20200607T011902.513578Z-tcpinfo-mlab2-lax06-ndt.tgz  including the tcp_info messages contains about 29 records (including the header) for a measurement of multiple seconds.  Is my expection wrong that tcp_info records are stored each 10 milli seconds or do I look at the wrong place for the raw data?  Thank you very much.	"{0: {'username': 'Stephen Soltesz', 'response_date': 'Oct 23, 2020, 5:55:22 AM', 'response_content': 'Ah, another factor that effects the number of snapshots in BQ is that to save on parsing and query costs, initially we are ""thinning"" the samples by 10 to 1.  This would have a more profound impact on traces with few changes over the life of the connection. We should consider only ""thinning"" snapshots over a certain threshold length.  \ue5d3'}, 1: {'username': 'Stephen Soltesz', 'response_date': 'Oct 23, 2020, 5:55:52 AM', 'response_content': 'Hello! Good question.  tcp_info polls the socket stats roughly every 10ms for all open tcp connections. However, stat snapshots are archived only when we detect ""major differences"" between samples. For NDT measurements, you\'ll see many snapshots over the life of the measurement. For other operational connections, random connections from the Internet (e.g. connect without any data sent), tcp_info would record only when the stats changed, which could be very few. The tcpinfo table contains all TCP connections.  To filter out only those that are also ndt7 measurements, you could build on a query like:  select id, ARRAY_LENGTH(tcpinfo.Snapshots), tcpinfo.Snapshots from `measurement-lab.ndt.ndt7` as ndt  join `measurement-lab.ndt.tcpinfo` as tcpinfo  on (ndt.id = tcpinfo.uuid) where ndt.date = date(\'2020-10-01\') and   tcpinfo.partition_date = date(\'2020-10-01\') and   raw.Download is not null and   TIMESTAMP_DIFF(raw.Download.EndTime, raw.Download.StartTime, SECOND) BETWEEN 8 AND 12 limit 1  On Tuesday, September 29, 2020 at 10:07:36 AM UTC-4 ralf.l...@gmail.com wrote: \ue5d3'}, 2: {'username': 'Ralf Lübben', 'response_date': 'Nov 23, 2020, 5:55:11 AM', 'response_content': ""Hi Stephen,  thank you very much, that clarified my observations.  Filtering on NDT measurements returns the results I expected.  Due to frequent changes in TCP's stack, the results also contain frequent updates in the measurements, at least in the raw data files.  Ralf \ue5d3""}}"
88	this-data-is-not-even-close-to-being-accurate	1605542799.0	2020-11-16 09:06:39	Bruce Kushnick	#2. Jersey Jersey is the first juris diction in the world to make pure fibre (FTTP) available to every broadband user. Jersey's shift from third to second shows that uptake has been healthy -- https://kushnickbruce.medium.com/americas-digital-divide-made-easy-7-states-7-maps-7-broadband-failures-a73c0e68c362   These are maps of 7 US states, the one on the top left with the squiggly lines is New Jersey-- it is less than 50% covered -- and the rest is COPPER-based -- the speeds your giving out are not surveys of New Jersey but a subset and they aren't close when you realize that the other areas could be getting DSL speeds of less than 15mbps. or dial up speeds, or wireless at 10mbps down 1 up.  And this goes for every state listed. Verizon New Jersey never completed the fiber build outs. -I Included some details and links in the article. The problem is -- policies are being created based on your data-- which is wildly overstating the speeds and coverage. --These caveats should be right up front.  In fact, all of the speed tests are quoted and all of them are skewing public policies in the US -- making it appear that the telcos are doing a good job... when, as you can see from the maps, they let the entire state utilities deteriorate as the copper should have been replaced starting in the 1990s-- as we documented. 	"{0: {'username': 'Livingood, Jason', 'response_date': 'Nov 20, 2020, 1:17:44 PM', 'response_content': 'FWIW I get a 404 error trying to access that URL, Bruce.   Related to mapping and M-Lab data, this recent Ookla blog post and paper will interest folks here: Blog @ https://www.speedtest.net/insights/blog/better-funding-decisions-accurate-broadband-network-data/ Paper @ https://resources.ookla.com/hubfs/Ookla%20-%20Make%20Better%20Funding%20Decisions%20with%20Accurate%20Broadband%20Network%20Data.pdf   Regards Jason \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/7ef2c7d5-36d0-428d-8d52-649d8bf090efn%40measurementlab.net.'}}"
89	question-re-returning-results	1604960974.0	2020-11-09 15:29:34	Glenn Fishbine	Is there a way to return the results of the current NDT test to either a javascript or PHP environment.  My general idea is embed the test in an Iframe, and pick off the download, upload, jitter, and ping averages.  The intent is to store these results in my own environment.  I would run either https://speed.measurementlab.net/#/  OR https://www.measurementlab.net/p/ndt-ws.html and would simply like to scrape those 4 numbers.	{0: {'username': 'frog...@gmail.com', 'response_date': 'Nov 17, 2020, 7:09:06 AM', 'response_content': 'you can implement a javascript page to run tests using the ndt javascript class. https://github.com/m-lab/ndt7-js \ue5d3'}}
90	modify-old-query-to-new-data	1604667845.0	2020-11-06 06:04:05	Arika Bennett	Hi,   I have this old query I was using to pull the average minimum ping and the average maximum ping by City/State.  How can I change the query so it successfully runs?   Thank you for your help!  select  avg(web100_log_entry.snap.MaxRTT) as maxRTT,   avg(web100_log_entry.snap.MinRTT) as minRTT  from `measurement-lab.ndt.recommended`  where connection_spec.client_geolocation.city = 'Salt Lake City' and connection_spec.client_geolocation.region = 'UT' and web100_log_entry.snap.MaxRTT > 0 and web100_log_entry.snap.MinRTT > 0  -- Arika Bennett Sr. Data Coordinator T +1 801.424.0018 | e-mail: arika....@clearlink.com  Clearlink, a SYKES company 5202 West Douglas Corrigan Way | Salt Lake City, UT 84116, USA www.clearlink.com | like us on Facebook | follow us on Twitter    This email and any files transmitted with it are confidential and intended solely for use of the intended recipient(s). If you received this email in error, please notify the sender and delete it.	{}
91	"requiring-""access-tokens""-for-ndt7-starting-oct-7th"	1599827330.0	2020-09-11 05:28:50	Stephen Soltesz	As part of the ndt7 client migration, we will require access tokens for ndt7 clients starting Oct 7th. Today, about 98% of all ndt7 measurements are already using access tokens. For those clients, no changes are necessary.  Our two reference clients (ndt7-js and ndt7-client-go) have open PRs that include support for access tokens. We will be completing those changes in the coming two weeks. If you use these clients, please let us know if you need more time to update.  You can read the full post here: https://www.measurementlab.net/blog/ndt7-access-tokens/  As always, if you have questions, please let us know! Stephen	"{0: {'username': 'Stephen Soltesz', 'response_date': 'Oct 15, 2020, 7:30:37 AM', 'response_content': ""Due to ongoing migration efforts by some current users and M-Lab staff capacity, we've deferred requiring access tokens until Nov 4th.  Best, Stephen  \ue5d3""}, 1: {'username': 'Stephen Soltesz', 'response_date': 'Oct 23, 2020, 5:56:12 AM', 'response_content': 'Over the last two weeks, ~98.5% of all ndt7 measurements used access tokens. ~1.4% report using the ndt7-client-go command with a client_os of ""windows"".  If you\'ve not already planned to do so, please rebuild using the latest version https://github.com/m-lab/ndt7-client-go/releases/tag/v0.4.1 to begin using access tokens automatically.  Best, Stephen \ue5d3'}, 2: {'username': 'Samuel Amico', 'response_date': 'Oct 28, 2020, 11:25:28 AM', 'response_content': 'Stephen, I have a question about access, as I use bq sdk for my python. I can already do it through CLI, but I am facing this problem:  google.api_core.exceptions.Forbidden: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/plenary-caster-211314/jobs?prettyPrint=false: Access Denied: Project plenary-caster-211314: User does not have bigquery.jobs.create permission in project plenary-caster-211314.  How can I use the python lib google.cloud.bigquery? Thanks, Best, Sam \ue5d3'}, 3: {'username': 'Stephen Soltesz', 'response_date': 'Nov 3, 2020, 10:17:22 AM', 'response_content': 'The change to make ndt7 access tokens required is scheduled tomorrow, Nov 4th. \ue5d3'}}"
92	two-questions-🙏🏻	1602505198.0	2020-10-12 05:19:58	Tyler Servais	1. Is there any table/data source that shows if the speed test was run on a wired or cellular connection?  2. What is the best way to make sense of the Network.ASNumber? For example, does each provider (Comcast) have a unique number? Is there a reference table anywhere for these codes?  Appreciate any help this group can provide!	"{0: {'username': 'Prem Sylvester', 'response_date': 'Oct 13, 2020, 5:06:59 AM', 'response_content': 'Unsure about the first query, but this: https://asrank.caida.org/ might help with the ASNs \ue5d3'}, 1: {'username': 'David Belson', 'response_date': 'Oct 13, 2020, 6:08:58 AM', 'response_content': 'Tools like bgpview.io also provide more information about who the ASN is owned by, and who it is connected to. For example: https://bgpview.io/asn/13335   \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/1f76c170-0b0e-4cd2-b440-e2c4f6f6d2dan%40measurementlab.net.'}, 2: {'username': 'Ben Dowling', 'response_date': 'Oct 21, 2020, 6:01:37 AM', 'response_content': 'You can lookup details on IPinfo.io too - eg. https://ipinfo.io/AS13335 or also through our API - see https://ipinfo.io/developers    On Tue, Oct 13, 2020 at 5:40 AM, David Belson <dbe...@gmail.com> wrote: Tools like bgpview.io also provide more information about who the ASN is owned by, and who it is connected to. For example: https://bgpview.io/asn/13335   On Tue, Oct 13, 2020 at 8:06 AM Prem Sylvester <prem.xsylvester@gmail.com> wrote: Unsure about the first query, but this: https://asrank.caida.org/ might help with the ASNs  On Monday, October 12, 2020 at 5:49:58 PM UTC+5:30 tylers...@gmail.com wrote: 1. Is there any table/data source that shows if the speed test was run on a wired or cellular connection?  2. What is the best way to make sense of the Network.ASNumber? For example, does each provider (Comcast) have a unique number? Is there a reference table anywhere for these codes?  Appreciate any help this group can provide! -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/1f76c170-0b0e-4cd2-b440-e2c4f6f6d2dan%40measurementlab.net. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAL3%2BC_6ipxh48OCe3XC1Uw1aUcOQdL-fO5JP5mhf-m4kK%3D_tcw%40mail.gmail.com.'}}"
93	iperf-2.0.14	1602850552.0	2020-10-16 05:15:52	Robert McMahon	Hi All,  I don't know if this is relevant to you or not and, if not, sorry for the spam. We're in an early field test EFT phase for iperf 2.0.14.  One of the new aspects is support for end to end read to write latencies, i.e. speed and capacity, which is a direct measurement of both.  More here  Thanks and my apologies if this seems like spam to you, Bob McMahon	"{0: {'username': 'Chris Ritzo', 'response_date': 'Oct 19, 2020, 10:24:55 AM', 'response_content': 'Hi Bob, Thanks for writing to share about the testing for iperf 2.0.14. We have considered the possibility of hosting iperf 2 or 3. I wonder if this is an appropriate thread to discuss the nuances of each and whether one or both would be useful to M-Lab users.  Thanks again, Chris \ue5d3'}, 1: {'username': 'Robert McMahon', 'response_date': 'Oct 19, 2020, 10:53:35 AM', 'response_content': ""Fine by me.  I do talk with the iperf 3 team and have some idea of their goals.   The number of 2 vs 3 might be confusing as people think a larger number suggests the same but better.  In this context, 2 vs 3 are completely different code bases.   One technical thing that's been missing by my judgment is direct measurements of both capacity (peak average throughput) and speed (latency.)  Some use throughput/latency or network power as the metric to optimize.  Ping and packet latencies aren't necessarily good proxies for actual use experience.  I think the write-start to read-complete latency is much better.  Also things like connect times (TCP 3WHS) are a big deal too and should be measured.  We've added a lot to 2.0.14 per our semi-conductor customers.  We supply NICs, WiFi chips, switch fabric chips, etc. for all types of device and network equipment and this broad customer base has provided some inputs to the features implemented.  Bob \ue5d3""}}"
94	modify-old-query-to-new-data	1600779049.0	2020-09-22 05:50:49	Tao Fineberg	Hello   I have this old query that was used to get ISP specific speed data for a location   How would I modify it to work with the current data?    Thanks in advance for the assistance   Tao   -----  SELECT  mm.asn_name AS isp, 8 * (ndt.web100_log_entry.snap.HCThruOctetsAcked / (ndt.web100_log_entry.snap.SndLimTimeRwin +  ndt.web100_log_entry.snap.SndLimTimeCwnd +  ndt.web100_log_entry.snap.SndLimTimeSnd)) as download_speed, (ndt.web100_log_entry.snap.SegsRetrans / ndt.web100_log_entry.snap.DataSegsOut) AS packet_retransmission_rate, ndt.web100_log_entry.snap.SumRTT/ndt.web100_log_entry.snap.CountRTT as rtt FROM    `measurement-lab.release.ndt_downloads` as ndt,   `measurement-lab.maxmind_historical.2018_07` as mm WHERE ndt.partition_date BETWEEN '2018-01-01' AND '2018-12-31' AND ndt.connection_spec.client_geolocation.country_code = 'US' AND (ndt.connection_spec.client_geolocation.region = 'TN' OR ndt.connection_spec.client_geolocation.region = 'Tennessee') AND ndt.connection_spec.client_geolocation.city = 'Chattanooga' AND  TO_BASE64(NET.IP_FROM_STRING(ndt.connection_spec.client_ip))   BETWEEN    TO_BASE64(NET.IP_FROM_STRING(mm.min_ip)) AND   TO_BASE64(NET.IP_FROM_STRING(mm.max_ip))	"{0: {'username': 'Chris Ritzo', 'response_date': 'Sep 22, 2020, 6:01:37 AM', 'response_content': 'Hi Tao, Thanks for writing with this question. We\'ve made some significant changes to the NDT schemas and this query is actually a lot simpler now. Here is an updated version. Note that the field ""ISP"" is the Autonomous System Number of the client ISP in this query, where your previous query used a copy of Maxmind data from July 2018. We no longer make Maxmind data available in that table after they changed their terms of use. However, you can lookup the AS Name using that number for free using sites like https://ipinfo.io In upcoming schema updates to our data, we will soon publish the AS Name as well as the AS Number.  Hope this is helpful. -Chris  SELECT   client.Network.ASNumber AS isp,   a.MeanThroughputMbps AS download_speed,   a.LossRate AS packet_retransmission_rate,   a.MinRTT AS rtt FROM   `measurement-lab.ndt.unified_downloads` as ndt WHERE    date BETWEEN \'2018-01-01\' AND \'2018-12-31\'   AND client.Geo.country_code = \'US\'   AND ( client.Geo.region = \'TN\' OR client.Geo.region = \'Tennessee\')   AND client.Geo.city = \'Chattanooga\'  \ue5d3'}, 1: {'username': 'Tao Fineberg', 'response_date': 'Sep 22, 2020, 12:24:25 PM', 'response_content': 'Thank you very much.  \ue5d3 -- Regards  Tao Fineberg Tel +268 4045504 Fax +268 4045258 Cell +268 6051239  Computronics Systems Swaziland'}, 2: {'username': 'Concinnity Risks', 'response_date': 'Sep 30, 2020, 12:54:45 PM', 'response_content': ""I'm in the same boat with this old beast from 2018:  What can I do to resurrect it?  SELECT connection_spec.client_geolocation.country_code AS country, NTH(1, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/ (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadMin, NTH(26, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/ (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadLower, NTH(51, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/ (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadMedian, NTH(76, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/ (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadUpper, NTH(101, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/ (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadMax, FROM release.ndt_downloads_legacysql WHERE web100_log_entry.log_time >= PARSE_UTC_USEC('2017-01-01 00:00:00') / POW(10, 6) AND web100_log_entry.log_time < PARSE_UTC_USEC('2018-01-01 00:00:00') / POW(10, 6) AND (connection_spec.client_geolocation.country_code = 'AD' OR connection_spec.client_geolocation.country_code = 'AE' OR connection_spec.client_geolocation.country_code = 'AF' OR connection_spec.client_geolocation.country_code = 'AG' OR connection_spec.client_geolocation.country_code = 'AI' OR connection_spec.client_geolocation.country_code = 'AL' OR connection_spec.client_geolocation.country_code = 'AM' OR connection_spec.client_geolocation.country_code = 'AO' OR connection_spec.client_geolocation.country_code = 'AQ' OR connection_spec.client_geolocation.country_code = 'AR' OR connection_spec.client_geolocation.country_code = 'AS' OR connection_spec.client_geolocation.country_code = 'AT' OR connection_spec.client_geolocation.country_code = 'AU' OR connection_spec.client_geolocation.country_code = 'AW' OR connection_spec.client_geolocation.country_code = 'AX' OR connection_spec.client_geolocation.country_code = 'AZ' OR connection_spec.client_geolocation.country_code = 'BA' OR connection_spec.client_geolocation.country_code = 'BB' OR connection_spec.client_geolocation.country_code = 'BD' OR connection_spec.client_geolocation.country_code = 'BE' OR connection_spec.client_geolocation.country_code = 'BF' OR connection_spec.client_geolocation.country_code = 'BG' OR connection_spec.client_geolocation.country_code = 'BH' OR connection_spec.client_geolocation.country_code = 'BI' OR connection_spec.client_geolocation.country_code = 'BJ' OR connection_spec.client_geolocation.country_code = 'BL' OR connection_spec.client_geolocation.country_code = 'BM' OR connection_spec.client_geolocation.country_code = 'BN' OR connection_spec.client_geolocation.country_code = 'BO' OR connection_spec.client_geolocation.country_code = 'BQ' OR connection_spec.client_geolocation.country_code = 'BR' OR connection_spec.client_geolocation.country_code = 'BS' OR connection_spec.client_geolocation.country_code = 'BT' OR connection_spec.client_geolocation.country_code = 'BW' OR connection_spec.client_geolocation.country_code = 'BY' OR connection_spec.client_geolocation.country_code = 'BZ' OR connection_spec.client_geolocation.country_code = 'CA' OR connection_spec.client_geolocation.country_code = 'CD' OR connection_spec.client_geolocation.country_code = 'CF' OR connection_spec.client_geolocation.country_code = 'CG' OR connection_spec.client_geolocation.country_code = 'CH' OR connection_spec.client_geolocation.country_code = 'CI' OR connection_spec.client_geolocation.country_code = 'CK' OR connection_spec.client_geolocation.country_code = 'CL' OR connection_spec.client_geolocation.country_code = 'CM' OR connection_spec.client_geolocation.country_code = 'CN' OR connection_spec.client_geolocation.country_code = 'CO' OR connection_spec.client_geolocation.country_code = 'CR' OR connection_spec.client_geolocation.country_code = 'CU' OR connection_spec.client_geolocation.country_code = 'CV' OR connection_spec.client_geolocation.country_code = 'CW' OR connection_spec.client_geolocation.country_code = 'CY' OR connection_spec.client_geolocation.country_code = 'CZ' OR connection_spec.client_geolocation.country_code = 'DE' OR connection_spec.client_geolocation.country_code = 'DJ' OR connection_spec.client_geolocation.country_code = 'DK' OR connection_spec.client_geolocation.country_code = 'DM' OR connection_spec.client_geolocation.country_code = 'DO' OR connection_spec.client_geolocation.country_code = 'DZ' OR connection_spec.client_geolocation.country_code = 'EC' OR connection_spec.client_geolocation.country_code = 'EE' OR connection_spec.client_geolocation.country_code = 'EG' OR connection_spec.client_geolocation.country_code = 'ER' OR connection_spec.client_geolocation.country_code = 'ES' OR connection_spec.client_geolocation.country_code = 'ET' OR connection_spec.client_geolocation.country_code = 'FI' OR connection_spec.client_geolocation.country_code = 'FJ' OR connection_spec.client_geolocation.country_code = 'FK' OR connection_spec.client_geolocation.country_code = 'FM' OR connection_spec.client_geolocation.country_code = 'FO' OR connection_spec.client_geolocation.country_code = 'FR' OR connection_spec.client_geolocation.country_code = 'GA' OR connection_spec.client_geolocation.country_code = 'GB' OR connection_spec.client_geolocation.country_code = 'GD' OR connection_spec.client_geolocation.country_code = 'GE' OR connection_spec.client_geolocation.country_code = 'GF' OR connection_spec.client_geolocation.country_code = 'GG' OR connection_spec.client_geolocation.country_code = 'GH' OR connection_spec.client_geolocation.country_code = 'GI' OR connection_spec.client_geolocation.country_code = 'GL' OR connection_spec.client_geolocation.country_code = 'GM' OR connection_spec.client_geolocation.country_code = 'GN' OR connection_spec.client_geolocation.country_code = 'GP' OR connection_spec.client_geolocation.country_code = 'GQ' OR connection_spec.client_geolocation.country_code = 'GR' OR connection_spec.client_geolocation.country_code = 'GS' OR connection_spec.client_geolocation.country_code = 'GT' OR connection_spec.client_geolocation.country_code = 'GU' OR connection_spec.client_geolocation.country_code = 'GW' OR connection_spec.client_geolocation.country_code = 'GY' OR connection_spec.client_geolocation.country_code = 'HK' OR connection_spec.client_geolocation.country_code = 'HN' OR connection_spec.client_geolocation.country_code = 'HR' OR connection_spec.client_geolocation.country_code = 'HT' OR connection_spec.client_geolocation.country_code = 'HU' OR connection_spec.client_geolocation.country_code = 'ID' OR connection_spec.client_geolocation.country_code = 'IE' OR connection_spec.client_geolocation.country_code = 'IL' OR connection_spec.client_geolocation.country_code = 'IM' OR connection_spec.client_geolocation.country_code = 'IN' OR connection_spec.client_geolocation.country_code = 'IO' OR connection_spec.client_geolocation.country_code = 'IQ' OR connection_spec.client_geolocation.country_code = 'IR' OR connection_spec.client_geolocation.country_code = 'IS' OR connection_spec.client_geolocation.country_code = 'IT' OR connection_spec.client_geolocation.country_code = 'JE' OR connection_spec.client_geolocation.country_code = 'JM' OR connection_spec.client_geolocation.country_code = 'JO' OR connection_spec.client_geolocation.country_code = 'JP' OR connection_spec.client_geolocation.country_code = 'KE' OR connection_spec.client_geolocation.country_code = 'KG' OR connection_spec.client_geolocation.country_code = 'KH' OR connection_spec.client_geolocation.country_code = 'KI' OR connection_spec.client_geolocation.country_code = 'KM' OR connection_spec.client_geolocation.country_code = 'KN' OR connection_spec.client_geolocation.country_code = 'KP' OR connection_spec.client_geolocation.country_code = 'KR' OR connection_spec.client_geolocation.country_code = 'KW' OR connection_spec.client_geolocation.country_code = 'KY' OR connection_spec.client_geolocation.country_code = 'KZ' OR connection_spec.client_geolocation.country_code = 'LA' OR connection_spec.client_geolocation.country_code = 'LB' OR connection_spec.client_geolocation.country_code = 'LC' OR connection_spec.client_geolocation.country_code = 'LI' OR connection_spec.client_geolocation.country_code = 'LK' OR connection_spec.client_geolocation.country_code = 'LR' OR connection_spec.client_geolocation.country_code = 'LS' OR connection_spec.client_geolocation.country_code = 'LT' OR connection_spec.client_geolocation.country_code = 'LU' OR connection_spec.client_geolocation.country_code = 'LV' OR connection_spec.client_geolocation.country_code = 'LY' OR connection_spec.client_geolocation.country_code = 'MA' OR connection_spec.client_geolocation.country_code = 'MC' OR connection_spec.client_geolocation.country_code = 'MD' OR connection_spec.client_geolocation.country_code = 'ME' OR connection_spec.client_geolocation.country_code = 'MF' OR connection_spec.client_geolocation.country_code = 'MG' OR connection_spec.client_geolocation.country_code = 'MH' OR connection_spec.client_geolocation.country_code = 'MK' OR connection_spec.client_geolocation.country_code = 'ML' OR connection_spec.client_geolocation.country_code = 'MM' OR connection_spec.client_geolocation.country_code = 'MN' OR connection_spec.client_geolocation.country_code = 'MO' OR connection_spec.client_geolocation.country_code = 'MP' OR connection_spec.client_geolocation.country_code = 'MQ' OR connection_spec.client_geolocation.country_code = 'MR' OR connection_spec.client_geolocation.country_code = 'MS' OR connection_spec.client_geolocation.country_code = 'MT' OR connection_spec.client_geolocation.country_code = 'MU' OR connection_spec.client_geolocation.country_code = 'MV' OR connection_spec.client_geolocation.country_code = 'MW' OR connection_spec.client_geolocation.country_code = 'MX' OR connection_spec.client_geolocation.country_code = 'MY' OR connection_spec.client_geolocation.country_code = 'MZ' OR connection_spec.client_geolocation.country_code = 'NA' OR connection_spec.client_geolocation.country_code = 'NC' OR connection_spec.client_geolocation.country_code = 'NE' OR connection_spec.client_geolocation.country_code = 'NF' OR connection_spec.client_geolocation.country_code = 'NG' OR connection_spec.client_geolocation.country_code = 'NI' OR connection_spec.client_geolocation.country_code = 'NL' OR connection_spec.client_geolocation.country_code = 'NO' OR connection_spec.client_geolocation.country_code = 'NP' OR connection_spec.client_geolocation.country_code = 'NR' OR connection_spec.client_geolocation.country_code = 'NU' OR connection_spec.client_geolocation.country_code = 'NZ' OR connection_spec.client_geolocation.country_code = 'OM' OR connection_spec.client_geolocation.country_code = 'PA' OR connection_spec.client_geolocation.country_code = 'PE' OR connection_spec.client_geolocation.country_code = 'PF' OR connection_spec.client_geolocation.country_code = 'PG' OR connection_spec.client_geolocation.country_code = 'PH' OR connection_spec.client_geolocation.country_code = 'PK' OR connection_spec.client_geolocation.country_code = 'PL' OR connection_spec.client_geolocation.country_code = 'PM' OR connection_spec.client_geolocation.country_code = 'PR' OR connection_spec.client_geolocation.country_code = 'PS' OR connection_spec.client_geolocation.country_code = 'PT' OR connection_spec.client_geolocation.country_code = 'PW' OR connection_spec.client_geolocation.country_code = 'PY' OR connection_spec.client_geolocation.country_code = 'QA' OR connection_spec.client_geolocation.country_code = 'RE' OR connection_spec.client_geolocation.country_code = 'RO' OR connection_spec.client_geolocation.country_code = 'RS' OR connection_spec.client_geolocation.country_code = 'RU' OR connection_spec.client_geolocation.country_code = 'RW' OR connection_spec.client_geolocation.country_code = 'SA' OR connection_spec.client_geolocation.country_code = 'SB' OR connection_spec.client_geolocation.country_code = 'SC' OR connection_spec.client_geolocation.country_code = 'SD' OR connection_spec.client_geolocation.country_code = 'SE' OR connection_spec.client_geolocation.country_code = 'SG' OR connection_spec.client_geolocation.country_code = 'SI' OR connection_spec.client_geolocation.country_code = 'SK' OR connection_spec.client_geolocation.country_code = 'SL' OR connection_spec.client_geolocation.country_code = 'SM' OR connection_spec.client_geolocation.country_code = 'SN' OR connection_spec.client_geolocation.country_code = 'SO' OR connection_spec.client_geolocation.country_code = 'SR' OR connection_spec.client_geolocation.country_code = 'SS' OR connection_spec.client_geolocation.country_code = 'ST' OR connection_spec.client_geolocation.country_code = 'SV' OR connection_spec.client_geolocation.country_code = 'SX' OR connection_spec.client_geolocation.country_code = 'SY' OR connection_spec.client_geolocation.country_code = 'SZ' OR connection_spec.client_geolocation.country_code = 'TC' OR connection_spec.client_geolocation.country_code = 'TD' OR connection_spec.client_geolocation.country_code = 'TG' OR connection_spec.client_geolocation.country_code = 'TH' OR connection_spec.client_geolocation.country_code = 'TJ' OR connection_spec.client_geolocation.country_code = 'TK' OR connection_spec.client_geolocation.country_code = 'TL' OR connection_spec.client_geolocation.country_code = 'TM' OR connection_spec.client_geolocation.country_code = 'TN' OR connection_spec.client_geolocation.country_code = 'TO' OR connection_spec.client_geolocation.country_code = 'TR' OR connection_spec.client_geolocation.country_code = 'TT' OR connection_spec.client_geolocation.country_code = 'TV' OR connection_spec.client_geolocation.country_code = 'TW' OR connection_spec.client_geolocation.country_code = 'TZ' OR connection_spec.client_geolocation.country_code = 'UA' OR connection_spec.client_geolocation.country_code = 'UG' OR connection_spec.client_geolocation.country_code = 'US' OR connection_spec.client_geolocation.country_code = 'UY' OR connection_spec.client_geolocation.country_code = 'UZ' OR connection_spec.client_geolocation.country_code = 'VA' OR connection_spec.client_geolocation.country_code = 'VC' OR connection_spec.client_geolocation.country_code = 'VE' OR connection_spec.client_geolocation.country_code = 'VG' OR connection_spec.client_geolocation.country_code = 'VI' OR connection_spec.client_geolocation.country_code = 'VN' OR connection_spec.client_geolocation.country_code = 'VU' OR connection_spec.client_geolocation.country_code = 'WF' OR connection_spec.client_geolocation.country_code = 'WS' OR connection_spec.client_geolocation.country_code = 'XY' OR connection_spec.client_geolocation.country_code = 'YE' OR connection_spec.client_geolocation.country_code = 'YT' OR connection_spec.client_geolocation.country_code = 'ZA' OR connection_spec.client_geolocation.country_code = 'ZM' OR connection_spec.client_geolocation.country_code = 'ZW') AND IS_EXPLICITLY_DEFINED(web100_log_entry.connection_spec.remote_ip) AND IS_EXPLICITLY_DEFINED(web100_log_entry.connection_spec.local_ip) AND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.HCThruOctetsAcked) AND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.SndLimTimeRwin) AND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.SndLimTimeCwnd) AND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.SndLimTimeSnd) AND IS_EXPLICITLY_DEFINED(connection_spec.data_direction) AND connection_spec.data_direction = 1 AND web100_log_entry.snap.HCThruOctetsAcked >= 8192 AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000 AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd +  web100_log_entry.snap.SndLimTimeSnd) < 3600000000 AND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.CongSignals) AND web100_log_entry.snap.CongSignals > 0 AND (web100_log_entry.snap.State == 1 OR (web100_log_entry.snap.State >= 5 AND web100_log_entry.snap.State <= 11)) GROUP BY country ORDER BY country ASC;   \ue5d3""}, 3: {'username': 'Chris Ritzo', 'response_date': 'Sep 30, 2020, 2:23:37 PM', 'response_content': 'Hi all,  We\'re not able to update all queries for you-- the previous one in this thread was very easy to do. I\'m sorry if I gave the impression that we will do this work for you. We encourage all members of this group who wish to query M-Lab datasets to subscribe to our blog posts, and track changes to our tables and views. We are working to better communicate changes to our platform and datasets publicly so that researchers may self serve and update past queries. This reply will be a first draft of a more comprehensive post and update to our website documentation this fall.  First, since this query appears to be in LegacySQL, I should note that our tables and views now only support StandardSQL. BigQuery\'s documentation includes this guide to migrating to StandardSQL. The quantiles aggregation in your query for example, can now be accomplished with the APPROX_QUANTILES function, or other aggregate functions. BigQuery\'s docs are really good.  There have been many changes to our platform and table/view schemas since 2018, and the upshot is that to query NDT data for tests that meet our team\'s current, best understanding of test completeness and research quality. In addition to working on new documentation and tutorial content, our team has re-engineered how we publish data so that we can present views and tables that meet the needs of researchers in our community who have a wide range of expertise and needs.  In July we published a blog post that describes our work to standardize the columns provided in our BigQuery datasets, to better enable Long Term Support of stable schemas. The post discusses the first recognizable outcome of that work to our community: ""unified"" views of NDT data that span the entire archive with a standardized schema. Additionally, this blog post provides more details about the NDT unified views.  We now publish two series of BigQuery Views for NDT data: ""Faithful"" and ""Helpful"". As described on the NDT page:  Faithful Views: Faithful Views are the base tables/views for each NDT data type, providing direct access to the unfiltered NDT data and the TCP INFO and Traceroute data associated with NDT tests. In BigQuery, Faithful Views are provided in datasets prepended with raw_ Faithful views will be of interest mostly to researchers interested in all testing conditions and results. Helpful Views: A set of tables/views derived from “Faithful Views” that are pre-filtered to only provide the most commonly used fields, and which only show tests that meet our current, best understanding of test completeness and research quality. More details on what constitutes “research quality” is listed on the NDT page linked above. In BigQuery, Helpful Views are provided in datasets labelled for each experiment. Helpful views should be the starting point for most people. There are now three NDT protocol types in our dataset: web100, ndt5, & ndt7 . We have schemas with field descriptions for each protocol on their respective pages on our website, and hope to soon mirror those descriptions in the BigQuery website.  All NDT data prior to ~ November 2019 will be of the web100 protocol, derived from the web100 Linux kernel TCP statistics engine we used before our platform upgrade. In that upgrade, we began using TCPINFO to gather TCP statistics. One of the outcomes of this change is that some fields that you may have used in the web100 protocol NDT data may not be available in TCPINFO.  You can use sub-queries to pull data and metadata from the different protocols, by using the node._Instruments field in the unified views, which indicates the test protocol version: ndt5, ndt7, or web100.   If you are updating past queries, please begin by querying the appropriate ""Helpful Views"" for upload or download test results: `measurement-lab.ndt.unified_downloads` `measurement-lab.ndt.unified_uploads` Instead of having to calculate measurements from component fields as is the case in the query posted here, we now provide fields that are named more logically. Below are a series of fields from old tables/views, and their equivalents in unified_uploads and unified_downloads: log_time = a.TestTime  connection_spec.client_ip = client.IP download_Mbps = unified_downloads.a.MeanThroughputMbps  upload_Mbps = unified_uploads.a.MeanThroughputMbps connection_spec.client_geolocation.latitude  = client.Geo.latitude connection_spec.client_geolocation.longitude = client.Geo.longitude connection_spec.client_geolocation.postal_code = client.Geo.postal_code connection_spec.client_geolocation.region = client.Geo.region  connection_spec.client_geolocation.country_code  = client.Geo.country_code You can review the schema column names in the unified views in BigQuery for a complete list of available fields, for example: unified_downloads If you don\'t see a field that you need in the unified views, the next step is to see if the field is available in the Faithful view for the test protocol. For example, Min and Max RTT have equivalent fields for the download (S2C) test in ndt5 and ndt7 tables: web100_log_entry.snap.MaxRTT web100_log_entry.snap.MinRTT ndt.ndt5.result.S2C.MinRTT ndt.ndt5.result.S2C.MaxRTT ndt.ndt7.result.S2C.MinRTT ndt.ndt7.result.S2C.MaxRTT These can be pulled into your unified views query by matching on the test UUID, for example: WHERE ndt.unified_downloads.a.UUID = ndt.ndt5.test_id  The UUID field is a unique ID for each TCP connection to any of our servers, and is very useful for matching and joining generally.  One last thing to note is that interactions like this are helpful input for our engineering team for future releases of the unified views\' schemas. They included the most often used fields at first, and will add others as feedback comes in from the community where it makes sense to do so. We\'re looking for your input, so please let us know your thoughts.  Best, Chris \ue5d3'}}"
95	ndt-server-for-community-network-monitoring	1598875513.0	2020-08-31 05:05:13	Taveesh Sharma	Hi,  I had posted previously on this same topic stating our requirement but I do not seem to find my past post on the forum for editing. So I'm starting a new conversation for the purpose of adding a clarification to my previous post.  A little bit of background in case the previous post could not be found:  We are developing a monitoring system for a community network in South Africa. There's going to be a central server against which certain network measurements will be taken, and a bunch of Raspberry Pis will be there for collecting the network data. So far I've been able to run tests locally on my laptop using the dockerized golang application ndt-server, provided by M-Lab (https://github.com/m-lab/ndt-server), and the test data was stored in JSON format locally. The question goes as under:  We would like to alternate the measurements against M-LAB servers and our own servers. Is it possible for us to keep a copy of the measurement data that would normally be going to MLab servers?  Also, in case if it is not possible for us to keep a copy of the data, is it possible to have the data returned to the NDT clients (Raspberry Pis in our case) so that it can be further modified and sent to the server of our choice?  Regards, Taveesh	"{0: {'username': 'Chris Ritzo', 'response_date': 'Aug 31, 2020, 5:44:37 AM', 'response_content': ""Hi Taveesh, Sorry about your initial post, we moderate the group posts so I've released this one. Thanks for sharing about your project.  You can certainly alternate measurements against M-Lab servers and your own, as well as keep a copy of each test in addition to having the results of tests to M-Lab servers go to our dataset.  In the ndt7-client-go client, there is a `-hostname` flag that can be used to direct a test to your self-hosted ndt-server. You can also use the `-format` flag to save output in JSON and redirect the output to a local file.  You might consider looking at our Murakami code repository for this purpose, or examining the code for ideas to use in your own solution. Murakami uses Docker to manage a Docker measurement container on Raspberry Pi and other platforms. The container can be configured to run one or more M-Lab (and non-M-Lab) tests, to our servers or others, on a randomized schedule. Test result data for each device can be saved on-disk, or uploaded to a central archive in either Google Cloud Storage or to your own SCP service.  I hope this is helpful, and please let us know if you have more questions.  Chris Ritzo - M-Lab Support \ue5d3""}, 1: {'username': 'Taveesh Sharma', 'response_date': 'Aug 31, 2020, 7:32:24 AM', 'response_content': ""Thanks for sharing the info, Chris. This is super helpful! I'll definitely have a look at the code and come up with questions.  Regards, Taveesh \ue5d3""}}"
96	ndt7-client-questions	1595852202.0	2020-07-27 05:16:42	stt9000	I'm setting up test devices with the ndt7 client installed on them.  I am testing several devices before deployment.   However, they periodically produce the following error: download (or upload) failed:  No available M-Lab servers  Any idea on what may be causing this?  Also, is there a way to use the M-Lab servers to get a udp latency result?  Thanks,  Shawn Thompson	{0: {'username': 'Chris Ritzo', 'response_date': 'Aug 31, 2020, 5:26:01 AM', 'response_content': 'Hi Shawn, If your devices are conducting scheduled tests, and it is possible that they are receiving HTTP response code 204 for no content because of a limit we impose on the number of tests per day, per IP address, per M-Lab server, as described in our Developer Guide. If you are using the ndt7 Golang client there is a flag `-hostname` which you could use to test against a specific ndt-server (including a self-hosted one). Self hosting might be ideal if you are testing a large number of devices. You may also be interested in our Murakami code repository, which provides a means for running regular M-Lab and non-M-Lab tests from any machine that supports Docker,.  Regarding UDP latency, unfortunately we do not currently host a measurement service that provides this.  Chris Ritzo - M-Lab Support \ue5d3'}}
97	ndt7-blog-posts	1597182120.0	2020-08-11 14:42:00	Lai Yi Ohlsen	Hi M-Lab Discuss,   I’m writing to share the blog posts we recently published regarding the release of our new protocol, ndt7. It is recommended reading for users of the NDT dataset.   Introducing ndt7 Migrating NDT clients to ndt7 Evolution of NDT  We are available to answer any questions you might have after reading via reply to this email or by contacting sup...@measruementlab.net   Additionally, the Evolution of NDT introduces a list of open questions that we intend to investigate as transparently as possible and we invite the M-Lab community to help us do so collaboratively. You can read more about our initial ideas and provide feedback on them here. You can also reach out to us directly at sup...@measurementlab.net or to me directly at la...@measurementlab.net.   Our next blog post will be published when we migrate the majority of NDT clients to ndt7 and will include updates to the deliverables introduced in “Migrating NDT clients to ndt7”. We'll update the list when it is published.   Hope you’re all staying safe! Talk soon.    -- Lai Yi Ohlsen Project Director, Measurement Lab www.measurementlab.net	{}
98	google-account	1596130600.0	2020-07-30 10:36:40	berkat cellcomm	Why i got different speed test result when i switch to another account on a same device?	{}
99	update-to-m-lab-privacy-policy-&-minor-updates-to-experimenter-mou-document	1594906256.0	2020-07-16 06:30:56	Chris Ritzo	Good day, M-Lab Discuss subscribers,  Today we have published updates to our Privacy Policy and Memorandum of Understanding with Experiment Developers. Per our policies, we notify this list when changes to our policies occur. For your reference, all M-Lab published policies are available on our website: https://www.measurementlab.net/policies/  In summary, the changes reflect the results of a third party legal review with focus on GDPR and similar legal frameworks. The exact changes made in this update can be reviewed in the release notes and this comparison to the previous release.  Best regards,  -- Chris Ritzo (he/him) Program Management & Community Lead, Measurement Lab Schedule a meeting with me! https://calendly.com/critzo/30min	{}
100	advice-on-why-collected-median-speeds-seem-so-much-lower-than-reality.	1589824708.0	2020-05-18 10:58:28	Daniel Thomas	Hi There,  I've written up some code in Python to go out and gather internet speeds in 500 major global cities as a part of a benchmarking effort. The data is pulled through BigQuery, within a Jupyter Notebook  I've tweaked the standard Common Metrics queries, and combined them with a bounding box of longitude and latitudes to gather metrics for each city. I pull the big query results into a pandas data frame from where I perform a whole bunch of aggregation.  My issue is that the results I pull for many Chinese/Asian cities seems to be substantially lower what we would expect, and substantially lower than is recorded in Measurement labs own visualisations. I am wondering if I need to filter out more tests or something along these lines.   For example, 3 Mbs - Median speeds for Hong Kong based on the common metrics query. 19 Mbs - Median speeds for Hong Kong based on the Mlab visualisation   My BigQuery query to  the collect download data is as follows:    SELECT       `connection_spec`.`client_geolocation`.city AS city,       partition_date,       8 * (web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration) AS mbps,       `connection_spec`.`client_geolocation`.`country_code` AS country_code,       `connection_spec`.`client_geolocation`.`country_name` AS country_name,       `connection_spec`.`client_geolocation`.latitude AS latitude,       `connection_spec`.`client_geolocation`.longitude AS longiude,       `connection_spec`.`client_geolocation`.`metro_code` AS metro_code,       `connection_spec`.`client_geolocation`.region AS region    FROM     `measurement-lab.ndt.recommended`   WHERE      `connection_spec`.`client_geolocation`.latitude 22.09912108658368 AND 22.4600543490944     AND `connection_spec`.`client_geolocation`.longitude BETWEEN 113.99481156645193 AND 114.38262545045124     AND partition_date BETWEEN '2019-08-01' AND '2019-10-30'      # Default queries here     AND connection_spec.data_direction = 0     AND web100_log_entry.snap.HCThruOctetsReceived >= 8192     AND web100_log_entry.snap.Duration >= 9000000     AND web100_log_entry.snap.Duration < 600000000     AND (web100_log_entry.snap.State = 1         OR (web100_log_entry.snap.State >= 5         AND web100_log_entry.snap.State <= 11))      LIMIT 30000  To calculate medians in Python, I simply perform a .median() function on the 'mbps' column in a pandas data frame (returned from the query above)	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jun 12, 2020, 8:30:19 AM', 'response_content': ""Hi Daniel, Thanks for posting your question and the query you're using. Awesome!  On first glance, not related to the measurement difference you identified, a couple of things to note. - The Visualization website is in the process of being upgraded, so your second link will result in an error- wanted to mention in case others clicked on it. - The table/view you are querying,     `measurement-lab.ndt.recommended`   , has been recently replaced with a new set of NDT views that will simplify the query. `measurement-lab.ndt.unified_uploads` and `.unified_downloads` provide most of the core fields people are interested in, and allow querying NDT across our platform upgrade in November 2019. For data beyond November, you will need to use the new views. This blog post discusses the unified views in more detail. - Hong Kong is considered a country in our dataset. We use the ISO 3166-2 standard for the country code and country name fields, and the first level ISO 3166-2 subdivision for region. Soon we will also add the second level subdivision region codes and names for both to the schema.  When we do analyses like the one you are doing, we typically will use a multi-step query that first computes the median per IP address, per day, over the desired date range, and within the geography of interest. Then we will compute the median of those daily medians. This is one way to reduce potential skew that could be introduced by many tests run from the same IP. Other methods might be to take one value per IP per day, like the Max value, and use those in the final aggregate.  Lastly, if you desire you could also do aggregation in your query. Below is an example rewrite of your query given some of the suggestions above, which also aggregates by country and combines both upload and download into a final set of descriptive statistics. The second query does the same, but also groups by country and city.  I hope this helps. Please let us know if you have additional questions.  Best, Chris Ritzo - M-Lab Support  WITH country_dl AS (   SELECT     test_date,     client.geo.country_name AS country,     NET.SAFE_IP_FROM_STRING(client.IP) AS ip,     a.MeanThroughputMbps as mbps,     a.MinRTT AS MinRTT   FROM `measurement-lab.ndt.unified_downloads`   WHERE     client.geo.latitude BETWEEN 22.09912108658368 AND 22.4600543490944     AND client.geo.longitude BETWEEN 113.99481156645193 AND 114.38262545045124     AND test_date BETWEEN '2019-08-01' AND '2019-10-30'     AND client.IP IS NOT NULL     AND client.geo.country_name IS NOT NULL AND client.geo.country_name != '' ), country_dl_sample AS (   SELECT     COUNT(*) AS dl_sample_size,     country   FROM country_dl   GROUP BY country ), country_daily_per_ip_stats_dl AS (   SELECT     test_date, country, ip,     MIN(mbps) AS MIN_download_Mbps,     APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_download_Mbps,     APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(50)] AS MED_download_Mbps,     AVG(mbps) AS MEAN_download_Mbps,     APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_download_Mbps,     MAX(mbps) AS MAX_download_Mbps,     APPROX_QUANTILES(CAST(MinRTT AS FLOAT64), 100) [ORDINAL(50)] as MED_DL_min_rtt   FROM country_dl   GROUP BY test_date, ip, country ), country_ul AS (   SELECT     test_date,     client.geo.country_name AS country,     NET.SAFE_IP_FROM_STRING(client.IP) AS ip,     a.MeanThroughputMbps as mbps,     a.MinRTT AS MinRTT   FROM `measurement-lab.ndt.unified_uploads`   WHERE     client.geo.latitude BETWEEN 22.09912108658368 AND 22.4600543490944     AND client.geo.longitude BETWEEN 113.99481156645193 AND 114.38262545045124     AND test_date BETWEEN '2019-08-01' AND '2019-10-30'     AND client.IP IS NOT NULL     AND client.geo.country_name IS NOT NULL AND client.geo.country_name != '' ), country_ul_sample AS (   SELECT     COUNT(*) AS ul_sample_size,     country   FROM country_ul   GROUP BY country ), country_daily_per_ip_stats_ul AS (   SELECT test_date, country, ip,     MIN(mbps) AS MIN_upload_Mbps,     APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_upload_Mbps,     APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(50)] AS MED_upload_Mbps,     AVG(mbps) AS MEAN_upload_Mbps,     APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_upload_Mbps,     MAX(mbps) AS MAX_upload_Mbps   FROM country_ul   GROUP BY test_date, ip, country ), country_stats_dl AS (   SELECT     country,     MIN(MIN_download_Mbps) AS MIN_download_Mbps,     APPROX_QUANTILES(LOWER_QUART_download_Mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_download_Mbps,     APPROX_QUANTILES(MED_download_Mbps, 100) [SAFE_ORDINAL(50)] AS MED_download_Mbps,     AVG(MEAN_download_Mbps) AS MEAN_download_Mbps,     APPROX_QUANTILES(UPPER_QUART_download_Mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_download_Mbps,     MAX(MAX_download_Mbps) AS MAX_download_Mbps,     APPROX_QUANTILES(CAST(MED_DL_min_rtt AS FLOAT64), 100) [ORDINAL(50)] as MED_DL_min_rtt   FROM country_daily_per_ip_stats_dl   GROUP BY country ), country_stats_ul AS (   SELECT     country,     MIN(MIN_upload_Mbps) AS MIN_upload_Mbps,     APPROX_QUANTILES(LOWER_QUART_upload_Mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_upload_Mbps,     APPROX_QUANTILES(MED_upload_Mbps, 100) [SAFE_ORDINAL(50)] AS MED_upload_Mbps,     AVG(MEAN_upload_Mbps) AS MEAN_upload_Mbps,     APPROX_QUANTILES(UPPER_QUART_upload_Mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_upload_Mbps,     MAX(MAX_upload_Mbps) AS MAX_upload_Mbps   FROM country_daily_per_ip_stats_ul   GROUP BY country ) SELECT * FROM country_stats_dl JOIN country_stats_ul USING (country) JOIN country_dl_sample USING (country) JOIN country_ul_sample USING (country)   WITH country_dl AS (   SELECT     test_date,     client.geo.country_name AS country,     client.Geo.city AS city,     NET.SAFE_IP_FROM_STRING(client.IP) AS ip,     a.MeanThroughputMbps as mbps,     a.MinRTT AS MinRTT   FROM `measurement-lab.ndt.unified_downloads`   WHERE     client.geo.latitude BETWEEN 22.09912108658368 AND 22.4600543490944     AND client.geo.longitude BETWEEN 113.99481156645193 AND 114.38262545045124     AND test_date BETWEEN '2019-08-01' AND '2019-10-30'     AND client.IP IS NOT NULL     AND client.geo.country_name IS NOT NULL AND client.geo.country_name != ''     AND client.geo.city IS NOT NULL AND client.geo.city != '' ), country_dl_sample AS (   SELECT     COUNT(*) AS dl_sample_size,     country,     city   FROM country_dl   GROUP BY country, city ), country_daily_per_ip_stats_dl AS (   SELECT     test_date, country, city, ip,     MIN(mbps) AS MIN_download_Mbps,     APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_download_Mbps,     APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(50)] AS MED_download_Mbps,     AVG(mbps) AS MEAN_download_Mbps,     APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_download_Mbps,     MAX(mbps) AS MAX_download_Mbps,     APPROX_QUANTILES(CAST(MinRTT AS FLOAT64), 100) [ORDINAL(50)] as MED_DL_min_rtt   FROM country_dl   GROUP BY test_date, ip, country, city ), country_ul AS (   SELECT     test_date,     client.geo.country_name AS country,     client.Geo.city AS city,     NET.SAFE_IP_FROM_STRING(client.IP) AS ip,     a.MeanThroughputMbps as mbps,     a.MinRTT AS MinRTT   FROM `measurement-lab.ndt.unified_uploads`   WHERE     client.geo.latitude BETWEEN 22.09912108658368 AND 22.4600543490944     AND client.geo.longitude BETWEEN 113.99481156645193 AND 114.38262545045124     AND test_date BETWEEN '2019-08-01' AND '2019-10-30'     AND client.IP IS NOT NULL     AND client.geo.country_name IS NOT NULL AND client.geo.country_name != ''     AND client.geo.city IS NOT NULL AND client.geo.city != '' ), country_ul_sample AS (   SELECT     COUNT(*) AS ul_sample_size,     country,     city   FROM country_ul   GROUP BY country, city ), country_daily_per_ip_stats_ul AS (   SELECT test_date, country, city, ip,     MIN(mbps) AS MIN_upload_Mbps,     APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_upload_Mbps,     APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(50)] AS MED_upload_Mbps,     AVG(mbps) AS MEAN_upload_Mbps,     APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_upload_Mbps,     MAX(mbps) AS MAX_upload_Mbps   FROM country_ul   GROUP BY test_date, ip, country, city ), country_stats_dl AS (   SELECT     country, city,     MIN(MIN_download_Mbps) AS MIN_download_Mbps,     APPROX_QUANTILES(LOWER_QUART_download_Mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_download_Mbps,     APPROX_QUANTILES(MED_download_Mbps, 100) [SAFE_ORDINAL(50)] AS MED_download_Mbps,     AVG(MEAN_download_Mbps) AS MEAN_download_Mbps,     APPROX_QUANTILES(UPPER_QUART_download_Mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_download_Mbps,     MAX(MAX_download_Mbps) AS MAX_download_Mbps,     APPROX_QUANTILES(CAST(MED_DL_min_rtt AS FLOAT64), 100) [ORDINAL(50)] as MED_DL_min_rtt   FROM country_daily_per_ip_stats_dl   GROUP BY country, city ), country_stats_ul AS (   SELECT     country,     city,     MIN(MIN_upload_Mbps) AS MIN_upload_Mbps,     APPROX_QUANTILES(LOWER_QUART_upload_Mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_upload_Mbps,     APPROX_QUANTILES(MED_upload_Mbps, 100) [SAFE_ORDINAL(50)] AS MED_upload_Mbps,     AVG(MEAN_upload_Mbps) AS MEAN_upload_Mbps,     APPROX_QUANTILES(UPPER_QUART_upload_Mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_upload_Mbps,     MAX(MAX_upload_Mbps) AS MAX_upload_Mbps   FROM country_daily_per_ip_stats_ul   GROUP BY country, city ) SELECT * FROM country_stats_dl JOIN country_stats_ul USING (country, city) JOIN country_dl_sample USING (country, city) JOIN country_ul_sample USING (country, city)   \ue5d3 \ue5d3""}, 1: {'username': 'David Farias-llerenas', 'response_date': 'Jul 13, 2020, 8:39:46 AM', 'response_content': 'Hello,  I\'m having some trouble getting authorization to perform queries from BigQuery into Pandas under \'measurement-lab\' and was curious to know how you went about doing so. I\'ve created a service account and have performed the code below before querying:    os.environ[""GOOGLE_APPLICATION_CREDENTIALS""]=""../../google_auth_credentials.json""  credentials, your_project_id = google.auth.default(     scopes=[""https://www.googleapis.com/auth/cloud-platform""] ) your_project_id = \'measurement-lab\' bqclient = bigquery.Client(     credentials=credentials,     project=your_project_id, ) bqstorageclient = bigquery_storage_v1beta1.BigQueryStorageClient(     credentials=credentials ) query_string = """"""         ... """"""  dataframe = (     bqclient.query(query_string)     .result()     .to_dataframe(bqstorage_client=bqstorageclient) )     The error message I receive is as follows: ""403 request failed: the user does not have \'bigquery.readsessions.create\' permission for \'projects/measurement-lab\' "". I\'ve confirmed that I am allowed to query with my service account (it works when querying with ""bq"" on the command line). Any help or input on the process you took would be much appreciated. Thank you! \ue5d3'}}"
101	i-just-pushed-minor-updates-to-the-bigquery-unified-views-for-ndt	1594297106.0	2020-07-09 05:18:26	Matt Mathis	None of these updates should affect user results, but add columns to bring the schemas into better alignment with NDT7, which will be incorporated into the unified views.  We plan to retire the column 'test_date'.  If you use test_date, please update your queries to use column 'date' instead.  Thanks, --MM-- The best way to predict the future is to create it.  - Alan Kay  We must not tolerate intolerance;        however our response must be carefully measured:              too strong would be hypocritical and risks spiraling out of control;             too weak risks being mistaken for tacit approval.	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jul 9, 2020, 6:36:07 AM', 'response_content': 'Thanks for posting this update, Matt.  A point of clarification - the new field ""date"" appears to be aliased or something, so ""test_date"" still works when querying ""ndt.unified_uploads"" and ""ndt.unified_downloads"".  Any existing queries using ""test_date"" will still work. \ue5d3'}}"
102	fwd:-[measurement-wg]-fwd:-open-positions-for-fully-funded-phd-students-at-imdea-networks	1593266842.0	2020-06-27 07:07:22	Georgia Bullen	Might be of interest to some folks!  ---------- Forwarded message --------- From: roderick <rode...@caida.org> Date: Thu, Jun 25, 2020 at 12:42 PM Subject: [Measurement-wg] Fwd: Open positions for fully funded PhD Students at IMDEA Networks To: <measure...@afrinic.net>   Dear all,   I hope this find you well.   IMDEA Networks Institute is hiring for the positions below. Please feel free to let me know if you are interested in any of them.   Best,   Roderick Fanou https://www.caida.org/~roderick/   Begin forwarded message:  From: Joerg Widmer <joerg....@imdea.org> Subject: Open positions for fully funded PhD Students at IMDEA Networks Date: 25 June 2020 at 08:43:01 GMT-7  Dear all, We wanted to call your attention to our call for PhD students. The call text is attached below. Please help us spread the word by sending this to colleagues and suitable candidates.  Thanks a lot and best regards,  Joerg  -----------------  APPLY NOW THROUGH OUR ONLINE FORM AT https://careers.networks.imdea.org/  IMDEA Networks (http://www.networks.imdea.org) is a networking research institute whose multinational team is engaged in cutting edge fundamental science. As a growing, English-speaking institute located in Madrid, Spain, IMDEA Networks offers a unique opportunity for pioneering scientists to develop their ideas across many research areas (http://www.networks.imdea.org/research/research-areas). IMDEA Networks has established itself internationally at the forefront of the development of future network technologies thanks to highly-reputed faculty members (http://www.networks.imdea.org/people).  We have a generic PhD call (topic open) as well as specific calls for the following PhD positions:  - Mobile Data Traffic Analysis - Supervisor: Dr. Marco FIORE - AI for mobile networks - Supervisor: Dr. Marco FIORE - Mobile Networks – Supervisor: Dr. Arturo AZCORRA - Mobile Network Communications – Supervisor: Dr. Albert BANCHS - Distributed Ledger Systems – Supervisor: Dr. Antonio FERNÁNDEZ ANTA  The total combined value of the financial package is more than 135,000 Euros over a minimum of four years, including company social security costs, public healthcare coverage, unemployment benefits, etc. For more information see http://www.networks.imdea.org/careers/phd-student  IMDEA Networks is an equal opportunity employer, and explicitly encourages qualified female applicants to apply.  Applications composed of a CV, a brief research statement, and the contact details of two referees shall be submitted by *July 31, 2020 (14:00 CEST)* through the IMDEA Networks Institute hiring portal (https://careers.networks.imdea.org/).   Joerg Widmer (Research Professor, IMDEA Networks Institute)   _______________________________________________ Measurement-wg mailing list Measure...@afrinic.net https://lists.afrinic.net/mailman/listinfo/measurement-wg   -- Georgia Bullen M-Lab Advisory Committee Chair	{}
103	anonymize-ip	1592923258.0	2020-06-23 07:40:58	Ma Uttaram	Is there a way to anonymize IP when speed test is run. Some clients of ours have static IP and their company info can be found using https://ipinfo.io/. Thus, entities could deduce the speed test data against the ipinfo.io data and point to a specific customer and location. Do we have any options to anonymize Ips?	"{0: {'username': 'Jim Warner', 'response_date': 'Jun 24, 2020, 4:45:22 AM', 'response_content': 'I think what you are asking is: ""Can a client run a test against a public server without disclosing its assigned static IP to the server?"" Or -- ""Is it  possible for the client to hide its identity when running a test against a public server?""  I think the answer is ""no."" You might consider setting up your own server(s) so you can be certain that test results will not escape to the world of unwanted correlations. Otherwise, I don\'t see an option but to trust the public servers not to be bad guys.    On Tue, Jun 23, 2020 at 7:40 AM Ma Uttaram <maut...@gmail.com> wrote: Is there a way to anonymize IP when speed test is run. Some clients of ours have static IP and their company info can be found using https://ipinfo.io/. Thus, entities could deduce the speed test data against the ipinfo.io data and point to a specific customer and location. Do we have any options to anonymize Ips?   -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/d9936920-41ff-4943-bf94-9b1f34c35ba3o%40measurementlab.net.'}}"
104	percentages-reported-by-the-visualization-tool	1592429494.0	2020-06-17 14:31:34	Ron Dallmeier	This is easy to spot if you use a smaller remote region. In this case I used Yukon Territories in northern Canada.  3419 samples of upload tests with median results of 2.54mbps The number of samples that resulted <3mbps is 1783 (a little more than half which makes sense) Why is the percentage of upload <3 = 12.63? I would expect this to be 1783/3419*100=52% Either I am misunderstanding something or there is a common error in the formula for calculating all the percentages.  ...Ron	{0: {'username': 'Chris Ritzo', 'response_date': 'Jun 18, 2020, 5:38:20 AM', 'response_content': 'Hi Ron, thanks for reporting this issue.  You have identified an error in the percentage calculation that we will correct.  -Chris \ue5d3'}}
105	unable-to-find-results-in-bigquery	1592229919.0	2020-06-15 07:05:19	Avneesh Jain	"I ran a speed test on June 12th using ndt7 go client and I was expecting to see the results in BigQuery the next day, but I do not see the results when I run this query:  SELECT * FROM `measurement-lab.ndt.ndt5` where result.Control.UUID='ndt-nhlrk_1589233788_0000000000518FE3'   Here is the output sinppet from the test, from which I found the UUID ============================ avneesh@avneesh-ThinkPad-X220:~/projects/opensource_repos/ndt7-client-go/cmd/ndt7-client$ ./ndt7-client --format json {""Key"":""starting"",""Value"":{""Test"":""download""}} {""Key"":""connected"",""Value"":{""Test"":""download"",""Server"":""ndt-iupui-mlab2-maa01.mlab-oti.measurement-lab.org""}} {""Key"":""measurement"",""Value"":{""AppInfo"":{""NumBytes"":65536,""ElapsedTime"":339408},""Origin"":""client"",""Test"":""download""}} {""Key"":""measurement"",""Value"":{""AppInfo"":{""NumBytes"":122880,""ElapsedTime"":615181},""Origin"":""client"",""Test"":""download""}} {""Key"":""measurement"",""Value"":{""AppInfo"":{""NumBytes"":196608,""ElapsedTime"":903576},""Origin"":""client"",""Test"":""download""}} {""Key"":""measurement"",""Value"":{""BBRInfo"":{""BW"":300557,""MinRTT"":29998,""PacingGain"":256,""CwndGain"":512,""ElapsedTime"":499458},""ConnectionInfo"":{""Client"":""106.197.224.127:24192"",""Server"":""121.242.229.88:443"",""UUID"":""ndt-q78l5_1589309573_000000000052839D""},""Origin"":""server"",""Test"":""download"",""TCPInfo"":{""State"":1,""CAState"":0,""Retransmits"":0,""Probes"":0,""Backoff"":0,""Options"":7,""WScale"":119,""AppLimited"":0,""RTO"":287000,""ATO"":40000,""SndMSS"":1288,""RcvMSS"":536,""Unacked"":17,""Sacked"":0,""Lost"":0,""Retrans"":0,""Fackets"":0,""LastDataSent"":9,""LastAckSent"":0,""LastDataRecv"":516,""LastAckRecv"":25,""PMTU"":1500,""RcvSsThresh"":64076,""RTT"":69388,""RTTVar"":4757,""SndSsThresh"":14,""SndCwnd"":24,""AdvMSS"":1448,""Reordering"":3,""RcvRTT"":0,""RcvSpace"":14600,""TotalRetrans"":0,""PacingRate"":312691,""MaxPacingRate"":-1,""BytesAcked"":122366,""BytesReceived"":852,""SegsOut"":116,""SegsIn"":71,""NotsentBytes"":104328,""MinRTT"":29998,""DataSegsIn"":3,""DataSegsOut"":114,""DeliveryRate"":300580,""BusyTime"":552000,""RWndLimited"":0,""SndBufLimited"":0,""Delivered"":98,""DeliveredCE"":0,""BytesSent"":144262,""BytesRetrans"":0,""DSackDups"":0,""ReordSeen"":0,""ElapsedTime"":499458}}} =================================================  Is the above query correct? Are ndt7 test results stored in some other tables? Even looking by IP address didnt return the results for my test (it showed results from some other days):  SELECT * FROM `measurement-lab.ndt.ndt5` where result.ClientIP='106.197.224.127'  Thanks Avneesh"	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jun 15, 2020, 7:11:20 AM', 'response_content': 'Hello Avneesh,  The table `measurement-lab.ndt.ndt5` contains results from the ndt5 test. Since you are using an ndt7 client, and ndt7 is still in public beta, M-Lab has not yet begun parsing ndt7 test data to a separate table/view. When we do, it will be `measurement-lab.ndt.ndt7`.  Until that time, you can however find ndt7 test data in the table `measurement-lab.ndt.tcpinfo`, using a query like this:  SELECT * FROM `measurement-lab.ndt.tcpinfo` WHERE UUID = ""ndt-q78l5_1589309573_000000000052839D""  Best regards, Chris - M-Lab Support'}, 1: {'username': 'Avneesh Jain', 'response_date': 'Jun 16, 2020, 5:25:06 AM', 'response_content': 'Thanks Chris, for pointing me to the right table.  -Avneesh  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/5a9481d9-f231-4eb0-9442-72fc20a13119o%40measurementlab.net.'}}"
106	where-did-the-data-studio-dashboards-go?	1592233277.0	2020-06-15 08:01:17	Marina Levy	Hi everyone,  The dashboards here: https://www.measurementlab.net/blog/covid-19-response-dashboards/ seem to be gone.  I was hoping to look at the methodology page to get a sense of how US counties are handled in SQL queries. Did anyone save those queries and if so, could you share them with me?  Thanks,  Marina	{0: {'username': 'Chris Ritzo', 'response_date': 'Jun 15, 2020, 8:04:30 AM', 'response_content': 'Hi Marina,  My apologies- on Friday we updated those dashboards and linked to them on this page: https://www.measurementlab.net/visualizations/ I will update the blog post as well.  I hope you will find these versions much faster.  Best regards, Chris - M-Lab Support \ue5d3'}, 1: {'username': 'Marina Levy', 'response_date': 'Jun 15, 2020, 8:19:43 AM', 'response_content': 'Aha! Thank you Chris.  And apologies, I think I posted twice about this. \ue5d3'}}
107	can't-select-measurement-lab-project-in-bigquery-ui	1591970424.0	2020-06-12 07:00:24	Sergey Batalov	Hello.  BigQuery quickstart documentation https://www.measurementlab.net/data/docs/bq/quickstart/ says that one should select measurement-lab project in BQ UI for queries to be free of charge. Previously I was able to select the project and run the queries. For some reason, now measurement-lab can not be selected via 'Select a project' popup (it is not listed). The data is still available and I'm able to query it, but I'm not sure if it's still free of charge or not. I'd appreciate any help in resolving this.  Thanks, Sergey.	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jun 12, 2020, 8:58:29 AM', 'response_content': ""Hello Sergey,  Thanks for posting this question. The issue you're encountering relates to a recent change to the BigQuery access to our datasets in the project `measurement-lab`. Previously, many datasets and tables were visible to all Discuss group users, which wasn't a problem, but made it confusing to many users assessing which datasets were relevant to their inquiry. In doing so, selecting the project as identified in the Quickstart Guide is no longer relevant. I've opened a new issue for this if you wish to track it: https://github.com/m-lab/website/issues/575  To your question about charges, I can confirm that you will not be charged. We maintain a test account subscribed to this group only, and I have confirmed that this account can make queries as you can, and is not billed for them. In fact, the test account has no billing enabled.  I hope this helps, and please let us know if you find other inconsistencies in documentation. If you are a Github user, we also welcome your issue submissions directly.  Thanks, Chris - M-Lab Support \ue5d3""}, 1: {'username': 'Ben Dowling', 'response_date': 'Jun 12, 2020, 9:57:48 AM', 'response_content': 'Hi Chris,  In the past we\'ve always been billed for queries made against m-lab tables unless we selected the measurement-lab account in the billing UI. Did that change?  Thanks, Ben  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/dd2d2008-9784-4d26-9a4b-3486f2cb1e50o%40measurementlab.net.'}, 2: {'username': 'Chris Ritzo', 'response_date': 'Jun 12, 2020, 10:03:17 AM', 'response_content': ""Hi Ben,  Though you cannot select the project in the BigQuery website's drop down menu anymore, I have confirmed that queries will be billed to the M-Lab account.  If anyone finds that they are charged for a query, please document that and get in touch with sup...@measurementlab.net  -Chris \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3""}, 3: {'username': 'Sergey Batalov', 'response_date': 'Jun 13, 2020, 9:49:34 AM', 'response_content': 'Hi Chris,  thanks for the quick and detailed reply!  Sergey \ue5d3'}}"
108	daily-test-limits	1591878911.0	2020-06-11 05:35:11	Avneesh Jain	On MLAB website, there is a limit of 40 tests per day. Is this limit per type of test or across all tests? Is the limit enforced per server or across all servers?  Can I get around this limit by choosing a different server to run the test against (for ndt7 test)?   -Avneesh	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jun 12, 2020, 8:51:36 AM', 'response_content': ""Hello Avneesh,  The 40 test per day limit is based on IP address. Per IP address, after 40 tests in a 24 hour period your client will receive an error. I believe this is for all ndt5 tests, and if I'm incorrect perhaps one of my dev team colleagues will correct me.  For ndt7 specifically, which is available in public beta but not yet fully deployed by us, the same limits will apply, and I believe there will be an enforced API key requirement as well. Again, my colleagues may have more to add.  We encourage you to follow the Developer Guidelines, and not try to find workarounds. We impose these limits to ensure that every M-Lab server location has sufficient capacity to provide quality measurement services for all who wish to run tests.  Best regards, Chris - M-Lab Support \ue5d3""}, 1: {'username': 'Nathan Kinkade', 'response_date': 'Jun 12, 2020, 9:12:43 AM', 'response_content': 'Adding to what Chris said, I believe the client ""signature"" is based on a little more than just IP address:  https://github.com/m-lab/mlab-ns/blob/master/server/mlabns/util/lookup_query.py#L318  That said, as Chris mentioned, trying to work around the rate limiter should be unnecessary. There really should be no need to run more than 40 tests per day (nearly 2 per hour). Indeed, even 40 tests per day is excessive, and if you\'re wanting/needing that many or more I think it would be worth rethinking the reasons for wanting to run so many tests.  Nathan     \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/6719d30e-68b0-429c-940f-a34a70b4eed3o%40measurementlab.net.'}}"
109	firewall-palo-alto	1591888099.0	2020-06-11 08:08:19	Dan Davis	Hi,  I'm looking for information on how to create a firewall rule on a Palo Alto firewall that will allow access to the NDT5 server.   I have been told that they do not support wildcards like this: “*.measurement-lab.org  I'm not sure if that's a Palo Alto thing of a security policy.   Thanks Dan 	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jun 12, 2020, 9:08:45 AM', 'response_content': ""Hi Dan, Thanks for posting this question. I'm not familiar with Palo Alto firewalls, but if they do not support wildcards, you could attempt using the specific FQDNs for our servers' NDT service, or their IP address blocks. We have recently begun publishing information about our sites and servers in a JSON API called `siteinfo`. More details on GitHub: https://github.com/m-lab/siteinfo  The link above is an index containing several files, site hostnames, site (GCP) projects, and sites. It also includes extracts of our DNS zone files.  If you are looking for IP address blocks, I would recommend examining sites.json  I hope this helps. Please let us know if you need additional information.  Best, Chris - M-Lab Support \ue5d3""}}"
110	5g-speed-test	1587570209.0	2020-04-22 08:43:29	Ma Uttaram	I plan to use ndt client  web100clt on my device to run speed test using the m-lab hosted ndt servers. However would like to check if m-lab speed test will work to report 5G speed tests.	"{0: {'username': 'Chris Ritzo', 'response_date': 'Apr 22, 2020, 8:57:23 AM', 'response_content': 'Hello,  M-Lab does not recommend using the web100clt client. Please use one of our other reference clients referenced in my previous reply.  As to the question of whether NDT will work to report 5G speeds, NDT will measure the bulk transport capacity of any network to which the client is connected. \ue5d3'}, 1: {'username': 'Ma Uttaram', 'response_date': 'Apr 23, 2020, 5:13:41 AM', 'response_content': 'Is there way we could  limit or explicitly specify the data limits when running the test?  Could you provide references as developer who plans to write a client , how that could be achieved? \ue5d3'}, 2: {'username': 'Chris Ritzo', 'response_date': 'Apr 23, 2020, 5:52:28 AM', 'response_content': 'Depending on the client code used, some have the option to throttle or limit the data exchanged during the test. Our engineering team does this as a part of their monitoring of our platform. Perhaps one of them on this list will have more to share.  I have confirmed, but not used this feature in the client ndt5-client-go. Here is the help output of that client as an example. -throttle is the relevant flag:  bash-5.0# ndt5-client --help Usage of ndt5-client:   -format value         Output format: ""human"" or ""json"" (default human)   -hostname string         Measurement server hostname   -protocol value         Protocol to use: ""ndt5"" or ""ndt5+wss"" (default ndt5)   -quiet         emit summary and errors only   -throttle         Throttle connections for testing   -timeout duration         time after which the test is aborted (default 55s)   -verbose         Log ndt5 messages  If you are considering a mobile client, you should also review the community developed client code in these repos: https://github.com/m-lab/ndt7-client-ios https://github.com/m-lab/ndt7-client-android These clients are supported by their developers, so questions about their use should be logged as issues or comments in the respective repos.  \ue5d3'}, 3: {'username': 'Avneesh Jain', 'response_date': 'Jun 11, 2020, 5:35:11 AM', 'response_content': 'I dont see --throttle option in ndt7-client-go, was this option removed for a reason in ndt7 client? Is there a way to thrttle the test in ndt7 client?  Thanks Avneesh \ue5d3'}, 4: {'username': 'Chris Ritzo', 'response_date': 'Jun 12, 2020, 8:39:52 AM', 'response_content': ""Hi Avneesh, The --throttle option is not available in ndt7-client-go. If you'd like to have that option, please feel free to file an issue request in the repo.  Thanks, Chris \ue5d3""}}"
111	m-lab-may-2020-community-calls-(plural!)	1587505365.0	2020-04-21 14:42:45	Lai Yi Ohlsen	Hello!   After a successful first Community Call in Q1, Measurement Lab is hosting 3 community calls in May. Each call will be on a Wednesday from 11am-12pm EST.   As the largest collection of open Internet performance data on the planet, M-Lab has a large, diverse community made up of experts in multiple disciplines including Internet infrastructure and measurement, Broadband advocacy and policy, federal and state government, regional/community networks, digital rights, and more. While this speaks to the universal usefulness of open Internet data, it poses unique questions around how to best meet our community where they're at. By breaking up our engagement into focused conversations, we hope to better address topics that are specific to each of your use cases. Our ultimate goal with each of these is to engage with our users and facilitate your support of one another.   Wednesday, May 6 11a-12p EST - Internet Measurement Research Deep dives into topics related to Internet measurement methodology. Technical expertise encouraged but not required.   Wednesday, May 13 11a-12p EST - Broadband Policy/Advocacy Discussion and presentations related to the use of M-Lab data in digital inclusion and broadband research. Policy/advocacy expertise welcome but not required.   Wednesday, May 20 11a-12p EST - M-Lab Community Call Tutorials and discussion related to the general use of M-Lab's platform, data, and community tools including Piecewise and Murakami. First-time users welcome.   We welcome any and all to each of the above, but if you are not sure which call will best fit your needs, please feel free to reach out. To RSVP: https://forms.gle/Ur1FYe8cjW6mo5qU7.  You will receive a calendar invite after submission.   Please reach out with any questions, the M-Lab team is looking forward to connecting. Sending health, stay safe!   -- Lai Yi Ohlsen Project Director, Measurement Lab www.measurementlab.net	"{0: {'username': 'Dieudonne Munganga', 'response_date': 'May 18, 2020, 4:44:43 AM', 'response_content': ""Good day,  I missed this call, but I get it's not too late to ask a few questions!  I intend to do my Masters in Internet Measurements in under-developed countries like DR Congo. I want to be sure it's worth a field to focus on? Is the field advisable in terms of job market? What techniques and principles required to have such a two years study turn into a success?  How do I get started with M-lab in context where the study is such regions with no MLab servers? and limited if none previous research done in the country? \ue5d3""}}"
112	broadband-usage-map-?	1588879963.0	2020-05-07 12:32:43	David Sandel	Hi,  Is there something out on MLabs that will let me see the broadband usage in any particular American City ? By City, County or Zip Code ?  Thanks,  Dave	"{0: {'username': 'Glenn Fishbine', 'response_date': 'May 8, 2020, 6:44:26 AM', 'response_content': 'Here is an example for the U.S. & Canada using a 12 month extract of MLab data.  It\'s more or less at the city level.  Pick your state or province, then zoom around to areas of interest.  Where possible, cities are matched with city boundaries.  http://expressoptimizer.net/projects/Demos/USMLAB.php    If you need higher granularity, here\'s a live example using a heavily modified github version of MLab source from a few years ago.  You can zoom into a particular city on the map.  The address locations have been randomly drifted from the actual locations to preserve privacy.  It is not running on MLab servers.  The data collection is ongoing for the last 4 weeks or so.  https://broadband.ramsmn.org/2020/04/13/st-louis-county-broadband-speed-test/     \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/81072f78-d0d1-4a66-b537-9132c07b5ce6%40measurementlab.net.'}, 1: {'username': 'Brian Rathbone', 'response_date': 'May 8, 2020, 6:44:26 AM', 'response_content': ""Dave,  I don't know of any broadband utilization data set on Mlabs. You could potentially infer usage based on the number of MLabs speed tests per capita in a given area, but that does become a bit challenging when dealing with geolocated by IP address rather than actual end user location.  The American Community Survey is the only data set I know of with nationwide broadband adoption data, and it's limited to a yes or no question on whether there is a broadband connection in the household. I recall the data being at the census block group level. I don't know of an online interactive map at the granularity you need, but you could potentially download the data and map it locally. I've been working on a few things of this nature recently using QGIS.  Online map: https://www.census.gov/library/visualizations/interactive/acs-datamap.html  You can see how North Carolina used the ACS and FCC Form 477 data to created broadband indices.  https://bi.nc.gov/t/DIT-Broadband/views/2017CountyIndices/BBADPStory?:isGuestRedirectFromVizportal=y&:embed=y  https://www.ncbroadband.gov/indices/  I hope that's helpful. Regards, Brian \ue5d3""}, 2: {'username': 'David Sandel', 'response_date': 'May 8, 2020, 7:54:28 AM', 'response_content': 'Hi Glen,  Thanks for sending this along. So if I understand this correctly, the target residents enter their location data  and then the MLab test is run at that moment ? How is the latitude and longitude calculated? After this initial test has been run, does MLab continue to run the test in the background on an interval basis ?  Back to you ,  Dave \ue5d3 -- David Sandel Office 314-628-0688 iPhone 314-435-3658 Fax 800-640-8643 Twitter @dsandel @ iNeighborhoods    Founder iiNeighborhoods Co-Founder STL-RIX 6900 Delmar St. Louis, MO. 63130 My LinkedIn Profile'}, 3: {'username': 'Walter', 'response_date': 'May 8, 2020, 9:10:46 AM', 'response_content': 'You are likely aware, but the FCC publishes broadband deployment data derived from the 477 forms at  https://www.fcc.gov/reports-research/reports/broadband-progress-reports/2019-broadband-deployment-report   \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/af9ef4d9-81d5-4efa-8f85-81a687843822%40measurementlab.net.'}, 4: {'username': 'ball...@internet-is-infrastructure.org', 'response_date': 'May 8, 2020, 9:33:07 AM', 'response_content': 'The I3 Connectivity Explorer (https://i3connect.org) brings together the FCC, MLab, Census ACS 5, the National Center for Educational Statistics,  and other data sets and localizes the data to the places we live (counties, school districts, legislative districts, named towns, and tribal areas among others). There’s an overview at https://internet-is-infrastructure.org. But again, it doesn’t have usage data.   Best regards,  . . . Bob  Robert A. Ballance, Ph.D. Principal, The Center for Internet as Infrastructure, LLC https://internet-is-infrastructure.org  \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CADeGG%3D7Kp%3Dip%3DKXkWOs_p7m6GNyG3dqztbzdsAjUgmpQiHw26w%40mail.gmail.com.'}, 5: {'username': 'btnoreen', 'response_date': 'May 11, 2020, 5:39:59 AM', 'response_content': 'Hey Brian and Bob,   I am working on the metrics of Messaging A2P, P2P and various uses of services, example, security, authentication, branding, chat, bot, etc.  Would you know of any working structure to capture this information in an ongoing manner?  (Like ACS or 477?)   Thanks,  Noreen     \ue5d3 \ue5d3 To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CADeGG%3D7Kp%3Dip%3DKXkWOs_p7m6GNyG3dqztbzdsAjUgmpQiHw26w%40mail.gmail.com.'}, 6: {'username': 'James Miller', 'response_date': 'May 12, 2020, 5:21:32 AM', 'response_content': 'David  What do you mean by usage?    In FCC parlance, the number of folks that subscribe to a service in a given area is termed \'adoption\', and differentiated from \'deployment\' data that describes what\'s available.(Walt mentioned on this thread and should be easier to search on FCC tprc or other sources   The volume of traffic, or how much data is used by a typical user, is available in very aggregated stats from akamai and others but I\'m not aware of anything geocoded at zip code, city level.  Beyond the temporal stratification the time period you would like may also be hard.  Diurnal, day of weekly, monthly are often also hard to find.  Calculating usage as total traffic volumes can be tricky with active measurements but especially with a client server model that measures using connectivity shared with other traffic sources.     \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/81072f78-d0d1-4a66-b537-9132c07b5ce6%40measurementlab.net.'}}"
113	using-meaurement-lab-data	1588945466.0	2020-05-08 06:44:26	Ma Uttaram	I would be using custom NDT client than m-lab supported client for m-lab tests.  However I would like to use M-Lab data, I assume one must upload data to m-lab to use the same.  Is there a way to query data by client? Any option to add custom tags when uploading data?	"{0: {'username': 'Chris Ritzo', 'response_date': 'May 8, 2020, 9:10:20 AM', 'response_content': ""Yes, data from all tests conducted to the M-Lab platform are saved in the M-Lab datasets. If you would like private data, M-Lab is not the platform for you to use.  You can query by client, if the client sets optional metadata fields. As an example, here is how the Speedupamerica.com JavaScript integration does this: https://github.com/Hack4Eugene/SpeedUpAmerica/blob/9cbb0d4625bf3a304d8a0e719e5f2f57d1e845b5/vendor/assets/javascripts/ndt.js#L441-L450  Querying data is accomplished via BigQuery, though if you're writing a custom client you could also send a copy of the test result anywhere else you wanted. \ue5d3""}, 1: {'username': 'Ma Uttaram', 'response_date': 'May 8, 2020, 9:10:46 AM', 'response_content': 'On Friday, May 8, 2020 at 6:44:26 AM UTC-7, Ma Uttaram wrote: I would be using custom NDT client than m-lab supported client for m-lab tests.  Is there a way to analyze historical test results that corresponds to only my tests? '}, 2: {'username': 'Chris Ritzo', 'response_date': 'May 8, 2020, 9:35:11 AM', 'response_content': ""Yes, you can use BigQuery to search for your tests. If you are looking for specific tests that are not tagged with a particular client metadata field, you'll need to know some other piece of metadata like the IP address used during your past tests. \ue5d3""}}"
114	contract-opportunities-w/-m-lab	1588880959.0	2020-05-07 12:49:19	Lai Yi Ohlsen	Hi all,   Measurement Lab has two contract opportunities available. More information is available here: https://www.measurementlab.net/jobs/  We are looking to fill each of these asap. Please feel free to reach out directly if you have any questions.   Thanks, stay safe!  -- Lai Yi Ohlsen Project Director, Measurement Lab www.measurementlab.net	{}
115	looking-for-the-owner-of-a-problematic-ndt7-client-deployment	1588182057.0	2020-04-29 10:40:57	Peter Boothe ¶	We are seeing a usage spike from a problematic NDT7 client.  Have you deployed an NDT7 client that tests only to mlab3 machines? If so, please get back to us ( sup...@measurementlab.net ) ASAP, as your usage is pretty extreme (and growing!) and we will have to soon start blocking it to preserve the data integrity of other clients' measurements.    -Peter  -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful. Coder at Google, writing open-source code in support of M-Lab	{}
116	data-access-as-a-collaborator	1587735444.0	2020-04-24 06:37:24	Harry Crissy	Hi, I'm new to the group.  I'm working on a broadband mapping project for Penn State University.  I'm trying to find power line data and power station data for Pennsylvania to include in a public service map for bidders serving census blocks with poor or no broadband access.  Any access to data that I can convert to map features would be greatly appreciated.  I was referred to this group by Penn State faculty.  My PSU contact info is hjc...@psu.edu and my office phone is 814 802 1024.  thanks,  Harry Crissy	"{0: {'username': 'Chris Ritzo', 'response_date': 'Apr 24, 2020, 7:05:04 AM', 'response_content': ""Hello, Thanks for joining the group and posting. By joining this group, you now have the ability to query M-Lab data at no cost to you. Our tests collect a users' IP address, which is then geolocated to provide fields such as latitude and longitude. This location data is accurate to the extent its source data is accurate. The source data is Maxmind.  You can review our documentation on how to get started with querying our data, and reach out for help either in this forum or by emailing sup...@measurementlab.net  Best regards, Chris - M-Lab Support \ue5d3""}}"
117	ndt-query-server-returns-empty-list-[]-in-the-response	1558408871.0	2019-05-20 20:21:11	David Tang	Hi,  I wrote a Python script as a NDT client. My script will connect to the query server (http://mlab-ns.appspot.com/ndt?format=json) to ask for the closest NDT server. Recently, the query server returns empty list[] in 8 out of 10 requests. Is there anyone seeing the same situation? Any suggestion to solve this issue?  Thank you, David	"{0: {'username': 'Chris Ritzo', 'response_date': 'May 27, 2019, 8:33:27 AM', 'response_content': 'Hi David,  I wanted to follow up on this post with a public reply, since the the feedback our team provided on your separate email to sup...@measurementlab.net may be of interest to others on this group.  The mlab-ns service which provides the closest available NDT server, limits clients that run far too frequently, i.e. more than 40 times a day. In cases like this, mlab-ns returns a ""no capacity"" signal. Prior to early May 2019, this was the empty list ""[]"", but now simply returns HTTP status 204.   The M-Lab team recommends that developers maintaining clients that schedule tests not use cron-style scheduling, but instead use a poisson-distributed in time to take advantage of the PASTA property.  Best, Chris - M-Lab Support \ue5d3'}, 1: {'username': 'Ma Uttaram', 'response_date': 'Apr 22, 2020, 8:58:12 AM', 'response_content': 'Chris,  We have a large network behind public IP, in such a does this mean the all devices together can run max of 40 tests?  \ue5d3'}, 2: {'username': 'Chris Ritzo', 'response_date': 'Apr 22, 2020, 9:02:52 AM', 'response_content': 'That is correct. However, we are working on an API key addition to the mlab-ns / locate service that will allow more tests to be run. This feature will be announced on the M-Lab blog when it is available. \ue5d3'}, 3: {'username': 'Ma Uttaram', 'response_date': 'Apr 23, 2020, 5:13:35 AM', 'response_content': 'Since we plan to incorporate m-lab speed test as part of our product, do we have any rough tentative time lines for API key being added to the locate service?  In the current scenario, if we plan to scale , is there a possibility of us choosing different servers ""in near by locations"" for performing the test? Hoping the limit is defined at the server level due to capacity threshholds.  \ue5d3'}, 4: {'username': 'Chris Ritzo', 'response_date': 'Apr 23, 2020, 5:36:42 AM', 'response_content': ""I'm sorry, but I don't have a tentative timeline for the API key addition at this time. You are correct, the limit is defined to ensure measurement capacity is reserved so that tests are conducted without impact to measurement quality.  M-Lab provides a server locate service that your client code can query to select an available server. There are a number of ways you could use this service, from the default -- requesting the closest server available to you-- to something more complex like selecting a set of servers in a metro area, choosing one of them randomly, and falling back to the others depending on the server response to test initiation. More information on using the locate service is provided on our Developer resources page. \ue5d3""}, 5: {'username': 'Peter Boothe ¶', 'response_date': 'Apr 23, 2020, 7:40:03 AM', 'response_content': 'We have no time lines we are willing to publicly commit to - being in the middle of a pandemic has added too much uncertainty for us to feel confident in our ability to make good on any new commitments. We can however say that it is being actively worked on in the https://github.com/m-lab/locate repository, and that the service in that repo is right now successfully running in our pre-production environment. So the situation is not quite as dire as you might initially assume from the response ""no tentative timeline"".  Multiple stakeholders want this functionality, we are interested in providing it, and it is under active development.   Were it not for the pandemic, we would probably have a timeline for you.  Everything is slowed and strange recently - hope you (and everyone else reading this on the discuss list) are well.    -Peter  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/06ca224f-5133-49ff-8f58-dcdc85e701cc%40measurementlab.net.   -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful, always with the goal of making the Internet better for the people who use it.'}}"
118	possible-to-run-'speed-test'-from-*nix?	1587560833.0	2020-04-22 06:07:13	Ron	"Our office is Linux based (CentOS/RedHat). I'd like to run the M-Lab 'speed test' from crontab, so I could collect historical data. Is there an easy way to get the results of 'speed test' from the Linux shell?  The output of running `curl https://www.google.com/search?q=speed+test` is not helpful:  $ curl https://www.google.com/search?q=speed+test <!DOCTYPE html><html lang=en><meta charset=utf-8><meta name=viewport content=""initial-scale=1, minimum-scale=1, width=device-width""><title>Error 403 (Forbidden)!!1</title><style>*{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}</style><a href=//www.google.com/><span id=logo aria-label=Google></span></a><p><b>403.</b> <ins>That’s an error.</ins><p>Your client does not have permission to get URL <code>/search?q=speed+test</code> from this server.  (Client IP address: 34.217.127.158)<br><br> Please see Google's Terms of Service posted at http://www.google.com/terms_of_service.html <BR><BR><P>If you believe that you have received this response in error, please <A HREF=""https://www.google.com/support/contact/user?hl=en"">report</A> your problem. However, please make sure to take a look at our Terms of Service (http://www.google.com/terms_of_service.html). In your email, please send us the <b>entire</b> code displayed below.  Please also send us any information you may know about how you are performing your Google searches-- for example, ""I'm using the Opera browser on Linux to do searches from home.  My Internet access is through a dial-up account I have with the FooCorp ISP."" or ""I'm using the Konqueror browser on Linux to search from my job at myFoo.com.  My machine's IP address is 10.20.30.40, but all of myFoo's web traffic goes through some kind of proxy server whose IP address is 10.11.12.13.""  (If you don't know any information like this, that's OK.  But this kind of information can help us track down problems, so please tell us what you can.)</P><P>We will use all this information to diagnose the problem, and we'll hopefully have you back up and searching with Google again quickly!</P> <P>Please note that although we read all the email we receive, we are not always able to send a personal response to each and every email.  So don't despair if you don't hear back from us!</P> <P>Also note that if you do not send us the <b>entire</b> code below, <i>we will not be able to help you</i>.</P><P>Best wishes,<BR>The Google Team</BR></P><BLOCKQUOTE>/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/<BR> BbhA56ElLRZQWf6A2LgJbhBezOY_HmMu-BVJjqD5xefSfI-vp<BR> tP8NGNLFWccVKnYDJ0nRqzezdAQfWQjneZLW9-JNL85ZmthYc<BR> yXqI8W6CbyrpGBR1XW0sgGAVYLLGiWqkom1e5IaIQZ7FFUVWa<BR> gC8CHtpQ-qXXXCgZJMiNCXvh_lQlGOv8Loi9oMJZh2Rz9qFjC<BR> 92ZRoFC-ggGzGxZs1d7uofaUwsNYVm897QtVYH1UswXO0EJ6d<BR> L64ZGOi56wC1_eKCu2K5pWyl_uSpqcobCO2lt3WuUbe9hH38V<BR> wRgsocwu3rdqzCt04agIGvnfdqnAiix5tiFpno4ngQ4pLS6kA<BR> Dz7r5p6edsdlXEjHVNhzMI_EhOLhUH3KmJu5M0ZJ4Ug4ZEVkp<BR> P5U18v3Z1rWSI-XuAY-m5KdjNSxaGL19_jXGtnMbrlKtWkOBZ<BR> INL7C4ILyBpxPHbMpq8atR2q9GHXmKIxHrQleJ4MhKC3XqiH1<BR> QY5gZptdqCAbCsQ2lAJRROPu_iwwYrJexO4ekk4jIdchSMjyY<BR> dl_2a9go_K2PK-c436XxgDVJ1tyE7VhKM1PVP_Lkf7ncRIOUj<BR> qCnwhWPKxj-ro8eED-LFAlV5EJ7hUt_xS2XS1jjpwB1HXHIO-<BR> 7klo2mShLDD-wVBk7ZBZKSXI1rl9MKqZwNS8DS3FWU8lhDxPA<BR> Usvgf7zcu-XJY6draNwGGl4Rzt_jEr7D1PPRlg2wvxV7OhPdd<BR> Z68-ytEQYOK8C4iOaQe4qCXaUdYMa1viaYS1QGfRC3gC37Iu3<BR> 3O-M34RfnHPj2wICVfrhBzpUCLCj2BeKolxtN1YpWYq4Y5e-1<BR> U_pIg2LSH14fZruLNdjy9qAhsf8JXivAOkou04Awt8-xNMJOM<BR> NafEmIAE7GrHyzOC4xyOhDSOm24DhrDAsHnGISDLJ2e7eT-pd<BR> [...]"	{0: {'username': 'Chris Ritzo', 'response_date': 'Apr 22, 2020, 8:49:39 AM', 'response_content': 'Hello Ron, You can certainly run the M-Lab test, NDT, from the Linux command line and schedule it using crontab.  We recommend that you use one or both of the NDT golang clients: https://github.com/m-lab/ndt5-client-go https://github.com/m-lab/ndt7-client-go These clients output test results in JSON format. Per our developer recommendations, tests that are scheduled to run automatically should run no more than four times per day with all test times randomized.  Hope this is helpful. \ue5d3'}}
119	fyi:-measurement-kit-is-deprecated-and-will-be-discontinued-on-2021-03-14	1587386639.0	2020-04-20 05:43:59	Simone Basso	Dear all,  The OONI team has been using the Measurement Kit (MK) library since 2017 as its network measurement engine. Because every measurement run using MK by default also submits measurements to the OONI collector, we know that there are several people who have also integrated MK into their network measurement tools and apps.  If you are one of those folks using MK, we’d like to thank you for using it and inform you that it is now deprecated. At OONI, we are now switching to a new engine written in Go which will be easier for us to maintain in the long-term. We encourage you to consider adoption of the new Go probe-engine for your tools.   We will keep maintaining MK for roughly one year and we will stop producing builds and applying fixes after March 14, 2021.  We articulated an upgrade path in the new README of the Measurement Kit repo for all the MK use cases that we know of. If you have questions, comments, suggestions, or use cases that we didn’t consider, please let us know, either here or on GitHub.  Thank you, best,  Simone & the OONI team	{}
120	fwd:-[measurement-wg]-africomm-2020,-3-4-dec-2020,-mauritius---call-for-papers/workshop-proposals	1584796617.0	2020-03-21 06:16:57	Georgia Bullen	---------- Forwarded message --------- From: Amreesh Phokeer <amr...@afrinic.net> Date: Fri, Mar 20, 2020, 08:43 Subject: [Measurement-wg] AFRICOMM 2020, 3-4 Dec 2020, Mauritius - Call for papers/workshop proposals To: <measure...@afrinic.net>   Dear Colleagues,  AFRICOMM brings together researchers and engineers interested in the practical and theoretical problems in Internet technologies. It aims at addressing issues pertinent to the African region with vast diversities of socio-economic and networking conditions while inviting high quality and recent research results from the global international research community to be presented. AFRICOMM 2020 will be held in Mauritius on December 3-4 and will be hosted by the African Network Information Centre (AFRINIC) and the Middlesex University, Mauritius.  AFRICOMM 2020 solicits high-quality papers reporting research results and/or experimental results on e-Infrastructures and e-Services for developing countries. Submissions will be judged on their originality, significance, clarity, relevance, and technical correctness.  We welcome contributions from the following fields of networking (but not limited to):         • Future Internet architectures and technologies         • Networking technologies for developing regions         • Internet measurement, analysis and modeling         • Wireless, mobile and ad hoc networks         • Delay and disruption tolerant networks         • Content delivery with P2P, CDN or ICN         • Network operations and management         • Social networks         • Network and cybersecurity         • Cloud Computing and Services         • Internet of Things         • Blockchain Technology and Applications         • Machine Learning and AI applications in networks  http://africommconference.org/call-for-papers/ http://africommconference.org/call-workshop-proposals/  =======Important dates======= Full Paper Submission deadline 8 June 2020  Notification deadline 27 July 2020  Camera-ready deadline 3 September 2020  Conference Dates 3-4 December 2020 ==========================   COVID-19 Note: The local organizing committee is closely following the evolution of the global pandemic and a decision to host either a physical or a virtual conference will be taken in due course. AFRICOMM will continue to accept submissions and all matters related to publication and indexing remain unchanged.   Regards, -- Amreesh D. Phokeer General Chair AFRICOMM 2020 _______________________________________________ Measurement-wg mailing list Measure...@afrinic.net https://lists.afrinic.net/mailman/listinfo/measurement-wg	{}
121	mlab-speed-test-is-incorrect?	1485447437.0	2017-01-26 09:17:17	David Radin	I'm on my office network, which is not heavily utilized and has a 75/75 fiber connection to the internet. On speedtest.net or dslreports.com speed test, I get results that are in the neighborhood of 70/65, which is what I'd expect when an office of 40ish people are using the internet.  MLab's test consistently shows speeds in the 12/6 range. Why would its results be so much slower?	"{0: {'username': 'Ron Dallmeier', 'response_date': 'Jan 26, 2017, 1:54:42 PM', 'response_content': 'Latency. The mlab server you are testing against is likely not nearby from a network perspective, while the speedtest sites are hosted in many places and quite likely your ISP is even hosting one.  ...Ron  On Thu, Jan 26, 2017 at 10:17 AM, David Radin <david...@gmail.com> wrote: I\'m on my office network, which is not heavily utilized and has a 75/75 fiber connection to the internet. On speedtest.net or dslreports.com speed test, I get results that are in the neighborhood of 70/65, which is what I\'d expect when an office of 40ish people are using the internet.  MLab\'s test consistently shows speeds in the 12/6 range. Why would its results be so much slower? -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': 'Kim Prince', 'response_date': 'Jan 27, 2017, 6:39:04 PM', 'response_content': ""It seems to me that the usual speed testing sites are well suited to testing the user's 'last mile', and perhaps other 'reasonably local' elements of their connection.  By contrast, the M-Lab tests are designed to help the user understand their overall internet performance, i.e. what performance they can expect when downloading/uploading to a 'representative' location on the internet.  By testing with the usual sites, you can confirm that your ISP is living up to their promised connection speed.  To understand how well that ISP is 'interconnected' to the rest of the web however, you need to consider the M-Lab results.  I picked this up from reading the M-Lab page at http://www.measurementlab.net/observatory/#tab=help&, particularly under the heading 'The Internet'.  Am I on the right track?   \ue5d3""}, 2: {'username': '☕Peter Boothe', 'response_date': 'Jan 27, 2017, 7:28:51 PM', 'response_content': 'The intent of the Measurement Lab speed test is to test your Internet speed from your location to places where content lives. This is why Measurement Lab test servers are hosted in data centers that also contain major content providers.  On the other hand, as Kim Prince mentioned, many other speed tests attempt to measure only your last-mile performance, and as such are frequently hosted within the ISP they are testing.  Unless you are getting geographically mis-routed to a cluster that is unreasonably far away from you (possible, but hopefully unlikely) then it sounds like you are connected at high speeds to your local ISP, but your connection through that ISP to content on the Internet may not be as good due to latency (more likely) or congestion along the path (less likely, but also possible)*.  * - There are of course more than two opportunities, and network people are often pedantic, so let me note here that there are other things that could cause the slowdown. But latency and congestion are the two most likely culprits.    -Peter \ue5d3 ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.'}, 3: {'username': 'Ron Dallmeier', 'response_date': 'Jan 28, 2017, 4:27:42 PM', 'response_content': 'From the FAQ:  Why are my M-Lab results different from other speed tests? Internet performance tests may provide different results for a lot of reasons. Three of the main reasons for different results among tests are listed below: 1. Differences in the location of testing servers Every performance test has two parts: client: This is the software that runs on the user’s machine and shows the user their speed results. server: This is the computer on the Internet to which the client connects to complete the test. A test generates data between the client and the server, and measures performance between these two points. The location of these two points is important in terms of understanding the results of a given test. If the server is located within your Internet Service Provider’s (ISP’s) own network (also known as the “last mile”), this is referred to as an “on-net” measurement. This approach lets you know about how your Internet connection is performing intra-network within your ISP, but it does not necessarily reflect the full experience of using the Internet, which almost always involves using inter-network connections (connections between networks) to access content and services that are hosted somewhere outside of your ISP. Results from on-net testing are often higher than those achieved by using other methods, since the “distance” traveled is generally shorter, and the network is entirely controlled by one provider (your ISP). “Off-net” measurements occur between your computer and a server located outside of your ISP’s network. This means that traffic crosses inter-network borders and often travels longer distances. Off-net testing frequently produces results that are lower than those produced from on-net testing. M-Lab’s measurements are always conducted off-net. This way, M-Lab is able to measure performance from testers’ computers to locations where popular Internet content is often hosted. By having inter-network connections included in the test, test users get a real sense of the performance they could expect when using the Internet. 2. Differences in testing methods Different Internet performance tests measure different things in different ways. M-Lab’s NDT test tries to transfer as much data as it can in ten seconds (both up and down), using a single connection to an M-Lab server. Other popular tests try to transfer as much data as possible at once across multiple connections to their server. Neither method is “right” or “wrong,” but using a single stream is more likely to help diagnose problems in the network than multiple streams would. Learn more about M-Lab’s NDT methodology. I would suggest a couple of things. When you run the m-lab test, note which server it is running the test against. It shows you as the test is running. It would be something like: NDT.IUPUI.MLAB1.ORD02.MEASUREMENT-LAB.ORG  ORD is the airport code for Chicago O\'Hare in this example. It is certainly important to note, which server it used.  Another suggestion would be to select the ""Details"" from the results page. In here you will get a summary of the test results. This can shed some light as to whether the test observed any potential causes for bad results. Two big factors for TCP based throughput are Packet Loss and Latency. Here is an example: Your system: - Plugin version: - (-)  TCP receive window: 893408 current, 894848 maximum 0.00 % of packets lost during test Round trip time: 21 msec (minimum), 68 msec (maximum), 33 msec (average) Jitter: - 0.00 seconds spend waiting following a timeout TCP time-out counter: 232 473 selective acknowledgement packets received  No duplex mismatch condition was detected. The test did not detect a cable fault. No network congestion was detected.  0.9633 % of the time was not spent in a receiver limited or sender limited state. 0.0000 % of the time the connection is limited by the client machine\'s receive buffer. Optimal receive buffer: - bytes Bottleneck link: - 469 duplicate ACKs set ...Ron   \ue5d3'}, 4: {'username': 'David Radin', 'response_date': 'Feb 16, 2017, 2:00:35 PM', 'response_content': 'Thanks, all.  \ue5d3'}, 5: {'username': 'ma...@hoppes.us', 'response_date': 'Jul 31, 2017, 8:53:29 AM', 'response_content': ""Sorry, but I don't buy this for one second.  While it's true any number of factors can affect your Internet service speeds - I can run a speedtest.net speedtest to a server well outside my local geographic area and get the expected speeds.  Same with openspeedtest.com  Neither of these are local to the network.  Run an MLab and the results are 3-4megabits while on a 65megabit connection.  Someone at MLab needs to fix their servers.""}, 6: {'username': 'ma...@hoppes.us', 'response_date': 'Jul 31, 2017, 8:55:11 AM', 'response_content': 'Running a second test I got 3megabits the first time and 60 the second to Washington D.C.  Explain please?'}, 7: {'username': 'Collin Anderson', 'response_date': 'Aug 9, 2017, 10:57:32 AM', 'response_content': 'Hello Discuss List,  My apologies for not following up on this thread publicly. We had received a couple of similar emails at the same time to our support address and replied directly rather than publicly. However, since this is a public list I wanted to provide a bit more clarity in a way that I hope may be broadly useful, rather than address one particular network.   While there are a number of speed tests that are available, they all have differences related to measurement methods and server placement that lead to divergent numbers. There are a number of papers out there that attempt to account for these differences, and we have tried to surface some of those themes in the FAQ in a manner that is comprehendible to the lay reader. M-Lab has always taken the position that \'more is better,\' even where M-Lab isn\'t used, and that the critical factor is understanding why those differences exist and how they tell different stories about accessibility and performance.  On occasion we receive inquiries from Internet service providers, typically small-to-medium networks that are interested in why their numbers are different from other tests. What we often find is that the issue is related to peering and topology between those providers and the networks that we are located in. M-Lab chooses prominent transit and content providers as neutral places for our sites that should reflect user experience – the names well known among this community, and not arcane locations. It\'s difficult to remotely diagnose particular networks from the other side, however, we generally find that in those cases where there are lower-than-expected numbers, some intermediary provider is experiencing degraded conditions, e.g. packet loss and higher latency. In one of the recent cases, we found that there were two or three networks between us and the provider, and there appeared to be substantial loss on that ISP\'s upstream – neither a failure with M-Lab nor within their network, but a real issue facing users.   In the past three years, we have expanded our presence in each market to include multiple sites, covering different providers for each location. This was meant to be a diagnostic resource for the community. I realize that the ""Washington, D.C."" label in some of the integrations of NDT is not so descriptive of these variables in a way that would better enable accounting of differences for those who know – especially when for each refresh of the page, D.C. might mean Level 3, Tata, X.O, etc. As I understand some other tests select servers based on latency, whereas most integrations of M-Lab and NDT randomly select a server within the same geographic location. Sometimes this sole difference is the most significant factor in the result, but both tests are correct within their context. This topology and selection factor seems like a more prevalent matter for smaller ISPs that are reliant on one or two networks for transit – in those cases, one directly-connected network will perform well, whereas others where there are additional intermediaries in the path do not perform as expected.   So, rather than platform issues, we tend to find those differences result from the more common infrastructure challenges that all operators contend with, which does have the impact on consumers reflected in the measurement. When questions arise, we encourage networks to check their peering between them and our sites in BGP, run traceroutes (check reverse traceroutes in M-Lab\'s BigQuery dataset), and conduct comparative tests across all sites in the region to see how they perform differently.   We have long meant to expose more technical information about our platform for those who are interested in metadata and documentation. As we update our documentation, we will aim to also have a ""FAQs for Operators"" that more clearly lays out how methodological and topological difference lead to different-than-expected results, and how to use M-Lab as a diagnostic resource. In the interim, we take such questions quite seriously and try to provide support to operators where we can.   Please feel free to reach out directly to me and our support address (support@) in the future.   Cordially, Collin Anderson'}, 8: {'username': 'dominic...@yarris.com', 'response_date': 'Nov 1, 2017, 3:15:04 PM', 'response_content': ""I'm getting unexpected results from the test. My upload speed is twice that of my download speed. I don't believe that is correct.  \ue5d3""}, 9: {'username': 'xgma...@gmail.com', 'response_date': 'Jan 18, 2018, 8:59:34 AM', 'response_content': ""Modern modems are run with multiple channels now. You're one internet connection can be a 2 or 3 separate connections or data channels tied together in a bundle to give you speeds faster than the technology alone. An example of this is WOW's Docsis modems. With a Docsis 2 modem you have 2 channels and speeds up to 60mbps. Docsis 3 modem 3 channels are now used and speeds can be upwards of 100mbps.   Measurement Labs does not support this technology which I think is a crock because all the major ISPs have shifted to this methodology for high-speed connections. I have stopped using their testing platform because it only runs on one channel and only effectively tests 1 third of my connection capabilities. I believe that Measurement Labs is an obsolete service and no longer offers valuable real-time information. This information is available on their own website if you read through their FAQ. If you're still using a 2-20mbps connection it may still be a valid test but in this day in age, it's just obsolete.   On Thursday, January 26, 2017 at 11:17:17 AM UTC-5, David Radin wrote: \ue5d3""}, 10: {'username': 'Livingood, Jason', 'response_date': 'Jan 18, 2018, 10:43:35 AM', 'response_content': 'On 1/18/18, 10:59 AM, ""xgma...@gmail.com"" <xgma...@gmail.com> wrote:   > Modern modems are run with multiple channels now. You\'re one internet connection can be a 2 or 3 separate connections or data channels tied together in a bundle to give you speeds faster than the technology alone. An example of this is WOW\'s Docsis modems. With a Docsis 2 modem you have 2 channels and speeds up to 60mbps. Docsis 3 modem 3 channels are now used and speeds can be upwards of 100mbps.    [JL] FWIW, according to a 2016 Arris report (https://www.arris.com/globalassets/resources/white-papers/scte-future-directions-for-fiber-deep-hfc-deployments.pdf) in the near future most DOCSIS 3.0 networks will move to 32 bonded 3.0 channels and 4 DOCSIS 3.1 OFDM channels. This enables 1 Gbps services, which Comcast and other ISP networks are providing over DOCSIS networks (obviously also over fiber, and there are many other fiber-based ISPs). I don’t think there are many measurement tools that can adequately measure those speeds at scale (such as the scale at which Ookla operates).   > Measurement Labs does not support this technology which I think is a crock because all the major ISPs have shifted to this methodology for high-speed connections. I have stopped using their testing platform because it only runs on one channel and only effectively tests 1 third of my connection capabilities. I believe that Measurement Labs is an obsolete service and no longer offers valuable real-time information. This information is available on their own website if you read through their FAQ. If you\'re still using a 2-20mbps connection it may still be a valid test but in this day in age, it\'s just obsolete.   [JL] Steve Bauer from MIT has done some thinking about this. See his section on the M-Labs test in https://www.measurementlab.net/publications/understanding-broadband-speed-measurements.pdf (Section 4.2.5) and his presentation on testing in the gigabit era at https://www.caida.org/workshops/aims/1602/slides/aims1602_sbauer.pdf.  On Thursday, January 26, 2017 at 11:17:17 AM UTC-5, David Radin wrote: I\'m on my office network, which is not heavily utilized and has a 75/75 fiber connection to the internet. On speedtest.net or dslreports.com speed test, I get results that are in the neighborhood of 70/65, which is what I\'d expect when an office of 40ish people are using the internet.   MLab\'s test consistently shows speeds in the 12/6 range. Why would its results be so much slower? -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}, 11: {'username': 'xgma...@gmail.com', 'response_date': 'Jan 18, 2018, 12:09:12 PM', 'response_content': ""All of that is assuming the ISP has a gigabit capable network in the area which ours does not. I was told specifically that ours runs on three channels. I have the same ISP at home with the same modem and I get exactly the same results at almost exactly 1/3rd of my capacity. I'm just trying to offer this as an explanation for the results the other user posted. I have seen the exact same thing and found an explanation for it. Also I wouldn't focus on speed and latency out on the web as much as I would good house keeping on my own router. I've found the most impact I've had on my networks with all my testing and tweaking has been to get my buffer-bloat under control which has made noticeable differences in our speeds and reduces connection timeouts to nearly non-existent. My point is Measurement Labs played no part in our improvements other than to throw us off and confuse us making us think there were issues when according to EVERY other speed/network check, we were right on the money. I measure RESULTS, not fanboyism for an outdated service. Thousandeyes helped me verify the bull%$@ that is ML.  \ue5d3""}, 12: {'username': 'David Radin', 'response_date': 'Jan 18, 2018, 12:15:39 PM', 'response_content': 'ML measures the ""real world"" throughput, where peering connections between ISPs can become a bottleneck.  DSLReports and Ookla tend to measure the ""last mile"" throughput of the connection between customer premises and the ISP\'s headend.  Both are valid approaches. It just depends what you\'re trying to determine.  \ue5d3 \ue5d3 -- You received this message because you are subscribed to a topic in the Google Groups ""discuss"" group. To unsubscribe from this topic, visit https://groups.google.com/a/measurementlab.net/d/topic/discuss/vOTs3rcbp38/unsubscribe. To unsubscribe from this group and all its topics, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3'}, 13: {'username': 'Srikanth S', 'response_date': 'Jan 18, 2018, 12:28:33 PM', 'response_content': 'On Thu, Jan 18, 2018 at 11:15 AM, David Radin <david...@gmail.com> wrote: ML measures the ""real world"" throughput, where peering connections between ISPs can become a bottleneck.   This is debatable, due to the ML infrastructure. We looked at interconnects between access ISPs and ML targets and access ISPs and Alexa 500 sites, and found there isn\'t much overlap. It\'s not a given that ML is measuring real-world throughput.  See 5.3 here: https://conferences.sigcomm.org/imc/2017/papers/imc17-final100.pdf  '}, 14: {'username': 'Woundy, Richard', 'response_date': 'Jan 22, 2018, 2:48:43 PM', 'response_content': ""> An example of this is WOW's Docsis modems. With a Docsis 2 modem you have 2 channels and speeds up to 60mbps. Docsis 3 modem 3 channels are now used and speeds can be upwards of 100mbps.   For this thread, are we talking about performance testing over DOCSIS 2, or over DOCSIS 3?   DOCSIS 2 uses load balancing to distribute traffic among multiple channels, whereas DOCSIS 3 uses channel bonding.   As I understand, ML’s NDT performance test uses a single TCP connection. (Also confirmed in section 4.2.5.1 of the MIT paper cited below.)   DOCSIS 2 uses load balancing, so the NDT TCP connection packets will be transmitted over only one of the DOCSIS channels (to keep packets in order), and that channel may be more or less congested than other channels.   DOCSIS 3 is more likely to use channel bonding than load balancing, so the NDT TCP connection packets would be striped (ie inverse-multiplexed) across all available channels for transmission.   This is less of an issue for Speedtest/Ookla because that performance test uses multiple HTTP threads (aka parallel TCP connections), and they can be load balanced across multiple channels. (see section 4.2.2.1 of the MIT paper). \ue5d3""}, 15: {'username': 'Nick Feamster', 'response_date': 'Jan 22, 2018, 4:44:11 PM', 'response_content': '> On Jan 22, 2018, at 4:48 PM, Woundy, Richard <Richard...@comcast.com> wrote: > > This is less of an issue for Speedtest/Ookla because that performance test uses multiple HTTP threads (aka parallel TCP connections), and they can be load balanced across multiple channels. (see section 4.2.2.1 of the MIT paper).  I’ll also add that the BISmark test has used multiple TCP threads since 2010, as well.  Even with channel bonding, a single-threaded test would have trouble filling a link to capacity. We saw this in experiments that are detailed in our SIGCOMM 2011 paper.  The inability of a single-threaded TCP connection to fill the link to capacity seems (1) independent of the underlying physical medium (i.e., cable, DSL, fiber); (2) to be present even for access links _well_ below Gigabit speeds.  -Nick'}, 16: {'username': 'trump...@gmail.com', 'response_date': 'Jan 23, 2018, 3:11:02 PM', 'response_content': 'I just use 3 services for reliability http://www.speedtest.net/, https://speedof.me/ and http://internet-speed-test.online  четверг, 26 января 2017 г., 18:17:17 UTC+2 пользователь David Radin написал: \ue5d3'}, 17: {'username': 'James Miller', 'response_date': 'Jan 23, 2018, 3:38:06 PM', 'response_content': 'The suite of tests run on Measuring Broadband America Program supported by Samknows are also multithreaded.  May be also worth noting that the number of threads are really import for understanding limits of TCP based tests but for UDP tests, for latency for example, the total number of datagrams exchanged has implications for accuracy and precision that can be attained by a given test.    A well documented, public methodology for tests is critical to understanding measurement results.     -- James Miller, Esq.  ""Japanese is so Eighties..."" Anonymous FCC Colleague  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3'}, 18: {'username': 'Julian Johnston Jr.', 'response_date': 'Mar 11, 2020, 10:39:05 AM', 'response_content': 'I know this post  is old, but every time i use mlab, the measurement is too distant from what I have, just used the service, got 41mb from a 400mb speed but upload was correct, using other test I have seen 480mb, mlab has never been past 41mb.   On Thursday, January 26, 2017 at 11:17:17 AM UTC-5, David Radin wrote: \ue5d3'}, 19: {'username': 'Chris Ritzo', 'response_date': 'Mar 11, 2020, 10:41:35 AM', 'response_content': 'There are multiple reasons why our test returns measurements that are slower than other tests. We outline a few of them in this FAQ article. You might also be interested in this blog post about speed tests, accuracy, and our primary performance measurement test, NDT.  One reason for the differences is that our servers are hosted outside last mile access networks, in data centers where networks ""peer"" or interconnect with one another. When providers are well peered, we see closer parity with other speed tests which often host servers at the edge of their last mile networks. The other major difference is that the architecture of our test itself differs from other tests. Our test is a single TCP stream test where others use multiple TCP streams. The use of multiple TCP streams emulates how web browsers typically operate when downloading resources you request from the Internet. Our NDT test\'s measurement using a single stream conforms more closely to accepted standards for performance measurement.  I hope this provides some more context for the differences in measurements from our test versus others. \ue5d3'}}"
122	acm-mmsys'20---calls-for-contributions	1583948345.0	2020-03-11 10:39:05	Cise Midoglu	Dear all,  please find below a joint call for contributions to multiple events co-located with the ACM Multimedia Systems Conference (MMSys).  Travel and Childcare Grants have also been announced, feel free to check: https://2020.acmmmsys.org/grants.php for more details.  Best regards, Cise Midoglu  *  (This email is also available online at https://tinyurl.com/mmsys20-calls)  Dear Colleagues,   There are multiple calls for the events co-located with ACM MMSys 2020 that will take place in Istanbul on June 8-11.  All accepted papers will be published as part of the MMSys’20 proceedings in the ACM Digital Library. Also note that MMSys’20 will offer a large number of travel grants to students as well as attendees from minority groups and less fortunate countries. All details regarding the calls, submission formats and travel grants are available at https://2020.acmmmsys.org.   [1] Demo and Industry Track [2] Open Dataset and Software Track [3] NOSSDAV’20 (30th Anniversary) [4] Packet Video 2020 (25th Anniversary) [5] MMVE 2020  [6] Grand Challenge on Open-Source HEVC Encoding ($7,500) [7] Grand Challenge on Adaptation Algorithms for Near-Second Latency ($7,500)  Supporters Adobe, Ozyegin University, Turkish Airlines, Twitch, YouTube, Comcast, Medianova, MulticoreWare, AMD, Argela, Bigdata Teknoloji, Bitmovin, DASH-IF, Dolby, Mux, Nokia, Pixery, SSIMWAVE, Streaming Video Alliance, Tencent, Unified Streaming, Vispera, Ericsson, Interdigital, Sky  Follow Us https://twitter.com/acmmmsys  https://www.facebook.com/acmmmsys/  https://www.instagram.com/acmmmsys/     Demo and Industry Track Submissions due: February 29 https://2020.acmmmsys.org/calls.php#demo-industry  The goal of the Demo and Industry Track is to bridge the gap between research and industry by showcasing demonstrations of innovative multimedia concepts. Submissions are encouraged in all areas related to multimedia. Researchers are also encouraged to submit demo proposals that concretize their accepted research papers and have a chance to showcase technical aspects of their work.  Open Dataset and Software Track Submissions due: February 29 https://2020.acmmmsys.org/calls.php#ods   Those who have created a new dataset or open-source software package that is relevant to the multimedia community should consider submitting it to this track. This includes, but is not limited to, software and datasets relevant to both traditional and emerging areas, traces reflecting network, user or application behavior and performance, both real or synthetic, as well as software from all aspects of production, coding, transmission, use or analysis of multimedia systems. Together with the dataset or source code, authors are asked to also provide a short paper describing the motivation and design, and discussing the way it can be useful to the community.  NOSSDAV’20 (30th Anniversary) Submissions due: March 27  As in previous years, NOSSDAV will continue to focus on both established and emerging research topics, high-risk high-return ideas and proposals, and future research directions in multimedia systems. In a single-track format the encourages active participation and discussions among academic and industry researchers and practitioners. Out-of-the-box ideas are particularly welcome.  The workshop seeks papers in all areas of multimedia systems with an emphasis on the systems aspects. Authors are especially encouraged to submit papers with real-world experimental results and datasets. Topics of interest include (but are not limited to):  Virtual reality (VR), augmented reality (AR) and immersive systems Cloud architectures for multimedia coding and processing Wireless, mobile, IoT, and embedded systems for multimedia applications Medical multimedia systems Multi-core and many-core systems, distribution and storage components Network-distributed video coding and network-based media processing Multimedia systems for autonomous driving Multimedia systems support in mobile networks, such as 5G Networked GPUs, graphics, and virtual environments Systems for computer vision applications Security in multimedia systems  Packet Video 2020 (25th Anniversary) Submissions due: March 27  The 25th Packet Video Workshop (PV’20) is devoted to presenting technological advancements and innovations in video and multimedia transmission over packet networks. The workshop provides a unique venue for people from the multimedia and networking fields to meet, interact and exchange ideas. Its charter is to promote the research and development in both established and emerging areas of video streaming and multimedia networking.   PV’20 seeks submission of original work in all areas of multimedia networking, including cutting-edge research and novel applications. Authors are especially encouraged to submit papers with real-world experimental results and datasets. Topics of interest include (but are not limited to):  Adaptive media streaming, content storage and content delivery Novel technologies for interactive audiovisual communications Next-generation/future video coding, point cloud compression Cloud and P2P based multimedia Video streaming over software-defined networks Multimedia communications over future networks, such as information-centric networks, next-generation 802.11ax networks and 5G wireless Coding and streaming of immersive media, including VR, AR, 360° video and multi-sensory systems Machine learning in media coding and streaming systems Protocols and standards for real-time multimedia communication (e.g., MPEG, 3GPP, IETF and others) Performance evaluation of proof-of-concept systems for video transmission Low-delay transmission of conversational multimedia Emerging applications: social media, game streaming, personal broadcast, healthcare, industry 4.0, multi-camera surveillance, smart transportation, social VR, 6DoF video, etc.  MMVE’20 - Virtual, Augmented and Immersive Media Submissions due: March 27  In its 12th year, MMVE welcomes all prior and new contributors to a workshop devoted to virtual, augmented and immersive media. Today’s market offers a wide selection of user technology, from head mounted displays and smart glasses to wearable sensors and mobile applications. Yet many domains remain unexplored, and novel technologies need to tackle both new and old challenges and constraints. Innovation in the design and development of these technologies require the combined expertise from several domains.  MMVE is an interdisciplinary forum where academic researchers, industry developers and other professionals can exchange ideas, present findings, initiate collaborations, and move the state of the art forward. The workshop will focus on novel research and new ideas in a wide range of topics related to immersive and virtual media systems and architectures:  Visualization 3D virtual environments 3D graphics and meshes Light fields and point clouds Applied contexts Health, games, education Storytelling, social communities Immersive media Psychological and physiological effects Experience and perception Multisensory processes Learning and memory Social interactions and human-computer interactions Quality and performance Interactivity, media synchronization Quality of experience Security and privacy Scalability, consistency and throughput Systems Immersive and interactive multimedia systems Sensor and vision systems Wearable, operating and distributed systems Middleware, mobile and embedded systems Extended reality systems Cinematic virtual reality  Grand Challenge on Open-Source HEVC Encoding Sponsored by: Comcast, MulticoreWare, SSIMWAVE Submissions due: March 27 https://2020.acmmmsys.org/x265_challenge.php  High-quality and efficient compression of this content is a challenge for the industry due to the high bitrates required for its transmission. HEVC is the codec of choice for UltraHD content, and the open-source x265 project is currently the most widely used HEVC encoder. The goal of this challenge is to produce algorithmic improvements to HEVC encoding, and make them available to the open-source community.  Awards: The winner will be awarded $5,000 and the runner-up will be awarded $2,500.  Grand Challenge on Adaptation Algorithms for Near-Second Latency Sponsored by: Twitch Submissions due: March 27 https://2020.acmmmsys.org/lll_challenge.php  The purpose of this challenge is to design an adaptation algorithm tailored towards HTTP chunked transfer streaming in the near-second (1-2s) latency range. It should minimize rebuffering while maximizing bandwidth utilization given the considerations above. The algorithm must also be fair to other clients viewing the same stream - its performance should not come at the expense of another. The proposed algorithm must be implementable on the web and within an HTML5-based player.  Awards: The winner will be awarded $5,000 and the runner-up will be awarded $2,500.  -- Cise Midoglu Simula Research Laboratory https://www.simula.no	{}
123	[deadline-in-one-week]-acm-mmsys’20---demo-and-industry-&-open-dataset-and-software-tracks	1582292150.0	2020-02-21 06:35:50	Cise Midoglu	Dear all,  a kind reminder that you can consider submitting demos, open datasets and software to the ACM Multimedia Systems Conference (MMSys) tracks outlined below. Areas of interest also include network modeling and measurement (tools), which can aide multimedia research.  Best, Cise  *  ACM MMSys’20 Call for Contributions Demo and Industry Track Open Dataset and Software Track  June 8-11, 2020, Istanbul, Turkey https://2020.acmmmsys.org  Submission Deadline February 29, 2020  ==> Demo and Industry Track <==  The goal of the Demo and Industry Track is to bridge the gap between research and industry by showcasing demonstrations of innovative multimedia concepts. Submissions are encouraged in all areas related to multimedia. Researchers are also encouraged to submit demo proposals that concretize their accepted research papers and have a chance to showcase technical aspects of their work.  Format: Up to 4 pages (PDF), plus a demo requirements checklist More information: https://2020.acmmmsys.org/calls.php#demo-industry   Accepted papers will be published in ACM Digital Library.  ==> Open Dataset and Software Track <==  Those who have created a new dataset or open-source software package that is relevant to the multimedia community should consider submitting it to this track. This includes, but is not limited to, software and datasets relevant to both traditional and emerging areas, traces reflecting network, user or application behavior and performance, both real or synthetic, as well as software from all aspects of production, coding, transmission, use or analysis of multimedia systems. Together with the dataset or source code, authors are asked to also provide a short paper describing the motivation and design, and discussing the way it can be useful to the community.  Format: Up to 6 pages (PDF), including the URL to the public repository for the dataset, source code or VM image/container file with installation instructions More information: https://2020.acmmmsys.org/calls.php#ods   Accepted papers will be published in ACM Digital Library.  Travel Grants for Students and Minorities  MMSys’20 will offer a large number of travel grants to students as well as attendees from minority groups and less fortunate countries.  Supporters Adobe, Ozyegin University, Turkish Airlines, Twitch, YouTube, Comcast, Medianova, MulticoreWare, AMD, Argela, Bigdata Teknoloji, Bitmovin, DASH-IF, Dolby, Mux, Nokia, Pixery, SSIMWAVE, Streaming Video Alliance, Tencent, Unified Streaming, Vispera, Ericsson, Interdigital, Sky  Follow Us https://twitter.com/acmmmsys https://www.facebook.com/acmmmsys/ https://www.instagram.com/acmmmsys/  -- Cise Midoglu Simula Research Laboratory https://www.simula.no	{}
124	best-way-to-keep-a-current-testing-environment?	1581350775.0	2020-02-10 09:06:15	Glenn Fishbine	A couple of years ago I downloaded a javascript library that you created that permits me to do the speed tests from my own server.  As new features come about, I realized that your current distributions are always better than mine, and you take into account location when assigning a server, which I do not.  Further it has a really sick headache with Safari.  The key difference between what you do by default and what I do, is I have the latitude and longitude of the actual location, and I don't mean HTML5 geolocation.  What I'd really like to do is run your most current test, and somehow get the jitter, ping, up and download speeds returned to my calling application so I can merge with my latitude longitude results.  Is there a browser independent way to call your test, let you do the testing, and somehow get a return value for jitter, ping, up and down?	"{0: {'username': 'Chris Ritzo', 'response_date': 'Feb 18, 2020, 2:25:07 PM', 'response_content': 'Hi Glenn, Thanks for posting this question and apologies for the delayed reply.  There is a reference JavaScript client for the new ndt7 protocol which is in the final stages of development. You can track that work here: https://github.com/m-lab/ndt-server/issues/237  The current JavaScript client code that M-Lab maintains for the ndt5 protocol, I would recommend borrowing from this repository: https://github.com/m-lab/mlab-speedtest - specifically: https://github.com/m-lab/mlab-speedtest/tree/master/app/assets/js  If you are interested in a browser independent way of testing, I would recommend: - https://github.com/m-lab/ndt7-client-go - https://github.com/m-lab/ndt5-client-go  I hope this helps in your work.  Best, Chris \ue5d3'}, 1: {'username': 'Glenn Fishbine', 'response_date': 'Feb 19, 2020, 6:31:35 AM', 'response_content': 'Thank you Chris.  I\'ll check them out. :-)  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/8a8786ba-8f13-4ca2-8809-c4d6081518ee%40measurementlab.net.'}}"
125	save-the-date-m-lab-community-call-january-29,-2020	1576530309.0	2019-12-16 14:05:09	Lai Yi Ohlsen	Hi all!  If we have not met yet, my name is Lai Yi Ohlsen, I am the new Project Director of Measurement Lab as of July.   I am writing to invite you to save the date for our first Measurement Lab Community Call on January 29, 2020 at 11am EST.   At a high level, our goal is to connect with our users and perhaps more importantly, connect our users with each other. More specifically, for the first call, we will focus on questions and feedback from data users. A request for RSVP and contributions to an agenda will be sent out in early January, but in the meantime please save the date and forward to others who might be interested. We hope to have a full group for the first call, but we do plan to host one on a regular basis -- so if you can't make it, there will be a next time.   Let myself or Chris Ritzo (Program Manager & Community Lead) know if you have any questions or suggestions. Warm wishes to the rest of your decade!   -- Lai Yi (Lie-Yee) Ohlsen  Project Director @ Measurement Lab	"{0: {'username': 'Lai Yi Ohlsen', 'response_date': 'Jan 22, 2020, 10:01:30 AM', 'response_content': ""Hello and Happy New Year,   Our first Measurement Lab Community Call is happening next week!  Date/Time: Wednesday, January 29, 2020 11:00am Eastern Time Zone  Agenda: The call will include:  - community introductions (who is working on what) - a data demo - a Q&A (see below to submit a question) - an update on M-Lab tool development  - and most importantly, a chance for us to get feedback from you, on both our data and community  All levels of familiarity with the data are welcome!   To RSVP:  https://forms.gle/JyAucMpWR3SuReFP6 Please fill out the above form and you will receive a calendar invite.   If you've already contacted us: You should have already received a calendar invite -- if you haven't let me know.    If you can't make it: There will be others! Reply to this email if you'd like to be informed of the next date/time.   The M-Lab team is really looking forward to the chance to talk! The call is as much for us as it is for you; we are extremely curious about our users and how we can be most useful to you. If you have any questions/comments/concerns, please feel free to reach out. Have a great week! \ue5d3""}}"
126	acm-mmsys-2020-research-track---one-week-until-deadline	1578317086.0	2020-01-06 06:24:46	Cise Midoglu	Dear colleagues,  a kind reminder about the ACM Multimedia Systems (MMSys) Conference, which will take place in Istanbul, Turkey between June 8-11th.  Submission deadline for the research track is January 10th.  Best regards, Cise Midoglu  *  We apologize if you receive multiple copies of this call.  ACM MMSys 2020 Research Track - Call for Papers  “Bridging Deep Media and Communications” June 8-11, 2020, Istanbul, Turkey https://2020.acmmmsys.org   Scope and Topics of Interest -----------------------------------------  The ACM Multimedia Systems Conference (MMSys) provides a forum for researchers to present and share their latest research findings in multimedia systems. While research about specific aspects of multimedia systems are regularly published in the various proceedings and transactions of the networking, operating systems, real-time systems, databases, mobile computing, distributed systems, computer vision, and middleware communities, MMSys aims to cut across these domains in the context of multimedia data types. This provides a unique opportunity to investigate the intersections and the interplay of the various approaches and solutions developed across these domains to deal with multimedia data types.  MMSys is a venue for researchers who explore: Complete multimedia systems that provide a new kind of multimedia experience or system whose overall performance improves the state-of-the-art through new research results in more than one component, or Enhancements to one or more system components that provide a documented improvement over the state-of-the-art for handling continuous media or time-dependent services.  Such individual system components include: Operating systems Distributed architectures and protocols Domain languages, development tools and abstraction layers Using new architectures or computing resources for multimedia New or improved I/O architectures or I/O devices, innovative uses, and algorithms for their operation Representation of continuous or time-dependent media Metrics and measurement tools to assess performance  This touches aspects of many hot topics including but not limited to: content preparation and (adaptive) delivery systems, high dynamic range (HDR), games, virtual/augmented/mixed reality, 3D video, immersive systems, plenoptics, 360-degree video, volumetric video delivery, multimedia Internet of Things (IoT), multi and many-core, GPGPUs, mobile multimedia and 5G, wearable multimedia, peer-to-peer (P2P), cloud-based multimedia, cyber-physical systems, multi-sensory experiences, smart cities, quality of experience (QoE).  We especially encourage submissions in the following Focus Areas: Machine learning and statistical modeling for video streaming Volumetric media: from capture to consumption Fake media and tools for preventing illegal broadcasts   Important Dates ----------------------------------------- Submission deadline: January 10, 2020 (firm deadline) Acceptance notification: March 16, 2020 Camera-ready deadline: April 17, 2020   Submission Instructions ----------------------------------------- Online submission: https://mmsys2020.hotcrp.com/  Papers must be up to 12 pages long (in PDF format) prepared in the ACM style and written in English. MMSys papers enable authors to present entire multimedia systems or research work that builds on considerable amounts of earlier work in a self-contained manner. MMSys papers are published in the ACM Digital Library. The papers are double-blind reviewed.  MMSys 2020 will continue to support scientific reproducibility, by implementing the ACM reproducibility badge system. Refer to the website for more details on the review process and the reproducibility badge system.   Travel Grants for Students and Minorities  ----------------------------------------- MMSys’20 will offer a large number of travel grants to students as well as attendees from minority groups and less fortunate countries. For more details, visit https://2020.acmmmsys.org/participation.php.   General Chairs ----------------------------------------- Ali C. Begen (Ozyegin University and Networked Media, Turkey) Laura Toni (University College London, UK)   TPC Chairs ----------------------------------------- Özgü Alay (Simula Metropolitan and University of Oslo, Norway) Christian Timmerer (Alpen-Adria-Universität Klagenfurt and Bitmovin, Austria)   Supporters ----------------------------------------- Adobe, Ozyegin University, Twitch, YouTube, Comcast, Medianova, MulticoreWare, Argela, Bigdata Teknoloji, Bitmovin, DASH-IF, Dolby, Mux, Nokia, Pixery, SSIMWAVE, Tencent, Unified Streaming, Vispera, Ericsson, Interdigital, Sky   Follow Us ----------------------------------------- https://twitter.com/acmmmsys https://www.facebook.com/acmmmsys/ https://www.instagram.com/acmmmsys/  This call for papers in PDF: https://2020.acmmmsys.org/files/cfp_mmsys20.pdf  -- Cise Midoglu Simula Research Laboratory https://www.simula.no	{}
127	ndt-upload-speed-calculation-issue	1575581742.0	2019-12-05 14:35:42	WestNGN Broadband	Hello,   I seem to have encountered an issue concerning the calculation of upload throughput while accessing the Measurement Labs NDT database through an SQL query.  The calculation and query is this as per https://www.measurementlab.net/data/docs/bq/ndtmetrics/: #standardSQL       8 * (web100_log_entry.snap.HCThruOctetsReceived /           web100_log_entry.snap.Duration) AS upload_Mbps  The issue is that when I perform this calculation the upload speed always shows less than 1 Mbps, whereas the reported calculation is usually around 10 or 11 Mbps. Is there some piece of the calculation that I am missing, or is there an issue with my syntax that I'm not seeing?   Thanks for all of your help in the past, and I hope you can help here as well.   Regards, Matthew Wilson from WestNGN 	"{0: {'username': 'WestNGN Broadband', 'response_date': 'Dec 5, 2019, 3:29:03 PM', 'response_content': 'Just to clarify, here\'s the complete SELECT statement     SELECT       8 * (web100_log_entry.snap.HCThruOctetsAcked /         (web100_log_entry.snap.SndLimTimeRwin +         web100_log_entry.snap.SndLimTimeCwnd +         web100_log_entry.snap.SndLimTimeSnd)) AS download_Mbps,       8 * (web100_log_entry.snap.HCThruOctetsReceived /           web100_log_entry.snap.Duration) AS upload_Mbps,          connection_spec.client_geolocation.latitude AS client_lat,          connection_spec.client_geolocation.longitude AS client_lon,         connection_spec.client_ip AS client_ip,         log_time,         FORMAT_DATETIME(""%F %X"", DATETIME(log_time, ""UTC"")) AS client_test_time,         test_id      FROM       `measurement-lab.ndt.web100`     WHERE       partition_date BETWEEN \'2019-10-01\' AND \\now\\       AND connection_spec.data_direction = 1       AND web100_log_entry.snap.HCThruOctetsAcked >= 8192       AND (web100_log_entry.snap.SndLimTimeRwin +         web100_log_entry.snap.SndLimTimeCwnd +         web100_log_entry.snap.SndLimTimeSnd) >= 9000000       AND (web100_log_entry.snap.SndLimTimeRwin +         web100_log_entry.snap.SndLimTimeCwnd +         web100_log_entry.snap.SndLimTimeSnd) < 600000000       AND web100_log_entry.snap.CongSignals > 0       AND (web100_log_entry.snap.State = 1 OR         (web100_log_entry.snap.State >= 5 AND         web100_log_entry.snap.State <= 11))    '}}"
128	acm-mmsys-2020-research-track---call-for-papers	1571756073.0	2019-10-22 07:54:33	Cise Midoglu	Dear colleagues, a kind reminder about the ACM Multimedia Systems (MMSys) Conference, which will take place in Istanbul between June 8-11th next year. Deadline for submissions is: January 10th 2020. Best regards, Cise Midoglu  *  We apologize if you receive multiple copies of this call.  ACM MMSys 2020 Research Track - Call for Papers  “Bridging Deep Media and Communications” June 8-11, 2020, Istanbul, Turkey https://2020.acmmmsys.org   Scope and Topics of Interest -----------------------------------------  The ACM Multimedia Systems Conference (MMSys) provides a forum for researchers to present and share their latest research findings in multimedia systems. While research about specific aspects of multimedia systems are regularly published in the various proceedings and transactions of the networking, operating systems, real-time systems, databases, mobile computing, distributed systems, computer vision, and middleware communities, MMSys aims to cut across these domains in the context of multimedia data types. This provides a unique opportunity to investigate the intersections and the interplay of the various approaches and solutions developed across these domains to deal with multimedia data types.  MMSys is a venue for researchers who explore: Complete multimedia systems that provide a new kind of multimedia experience or system whose overall performance improves the state-of-the-art through new research results in more than one component, or Enhancements to one or more system components that provide a documented improvement over the state-of-the-art for handling continuous media or time-dependent services.  Such individual system components include: Operating systems Distributed architectures and protocols Domain languages, development tools and abstraction layers Using new architectures or computing resources for multimedia New or improved I/O architectures or I/O devices, innovative uses, and algorithms for their operation Representation of continuous or time-dependent media Metrics and measurement tools to assess performance  This touches aspects of many hot topics including but not limited to: content preparation and (adaptive) delivery systems, high dynamic range (HDR), games, virtual/augmented/mixed reality, 3D video, immersive systems, plenoptics, 360-degree video, volumetric video delivery, multimedia Internet of Things (IoT), multi and many-core, GPGPUs, mobile multimedia and 5G, wearable multimedia, peer-to-peer (P2P), cloud-based multimedia, cyber-physical systems, multi-sensory experiences, smart cities, quality of experience (QoE).  We especially encourage submissions in the following Focus Areas: Machine learning and statistical modeling for video streaming Volumetric media: from capture to consumption Fake media and tools for preventing illegal broadcasts   Important Dates ----------------------------------------- Submission deadline: January 10, 2020 (firm deadline) Acceptance notification: March 16, 2020 Camera-ready deadline: April 17, 2020   Submission Instructions ----------------------------------------- Online submission: https://mmsys2020.hotcrp.com/  Papers must be up to 12 pages long (in PDF format) prepared in the ACM style and written in English. MMSys papers enable authors to present entire multimedia systems or research work that builds on considerable amounts of earlier work in a self-contained manner. MMSys papers are published in the ACM Digital Library. The papers are double-blind reviewed.  MMSys 2020 will continue to support scientific reproducibility, by implementing the ACM reproducibility badge system. Refer to the website for more details on the review process and the reproducibility badge system.   General Chairs ----------------------------------------- Ali C. Begen (Ozyegin University and Networked Media, Turkey) Laura Toni (University College London, UK)   TPC Chairs ----------------------------------------- Özgü Alay (Simula Metropolitan and University of Oslo, Norway) Christian Timmerer (Alpen-Adria-Universität Klagenfurt and Bitmovin, Austria)   Supporters ----------------------------------------- Adobe, Ozyegin University, Twitch, YouTube, Comcast, Medianova, Multicoreware, Argela, Bigdata Teknoloji, Bitmovin, DASH-IF, Dolby, Mux, Nokia, Pixery, SSIMWAVE, Unified Streaming, Vispera, Ericsson, Interdigital, Sky   Follow Us ----------------------------------------- https://twitter.com/acmmmsys https://www.facebook.com/acmmmsys/ https://www.instagram.com/acmmmsys/  This call for papers in PDF: https://2020.acmmmsys.org/files/cfp_mmsys20.pdf  -- Cise Midoglu Simula Research Laboratory https://www.simula.no	{0: {'username': 'Cise Midoglu', 'response_date': 'Nov 28, 2019, 7:44:24 AM', 'response_content': 'Dear all,  a kind reminder about the ACM Multimedia Systems (MMSys) Conference, which will take place in Istanbul, Turkey between June 8-11th.  Network modeling and measurement is an important aspect of multimedia research, and it is possible that a session will be organized around network measurement (tools) and their relevance to multimedia research if there are enough papers. Please consider submitting your relevant work.  Deadline for submissions: January 10th. \ue5d3 \ue5d3'}}
129	huge-drop-in-number-of-tests-since-6th-november	1573572466.0	2019-11-12 08:27:46	Thomas Buck	Hi all,  I'm worried that I'm querying BigQuery data in the wrong way. Running the following SQL goes from a count of 20,000-40,000 tests per day down to double figures - e.g. 35 _total_ - since the 6th of November:  SELECT partition_date, COUNT(*) FROM `measurement-lab.ndt.downloads` M WHERE partition_date BETWEEN '2019-10-15' AND '2019-11-11'  AND connection_spec.client_geolocation.country_name = 'Germany' GROUP BY partition_date ORDER BY partition_date  Am I looking at the wrong column? I haven't had a chance to test other countries in more detail, it holds up for Germany, France, and the United Kingdom.  Thanks! Tom.	"{0: {'username': 'Peter Boothe™', 'response_date': 'Nov 12, 2019, 12:31:32 PM', 'response_content': 'C2S is for client to server (aka upload) tests.  S2C is for server to client (aka download) tests.  S2C result data is inside the result.S2C struct. You likely only care about mean throughput and min RTT, which can be selected like: SELECT result.S2C.MeanThroughputMbps, result.S2C.MinRTT FROM `measurement-lab.ndt.ndt5` WHERE result.S2C IS NOT NULL C2S result data is inside the result.C2S struct. The relevant query for you is probably: SELECT result.C2S.MeanThroughputMbps FROM `measurement-lab.ndt.ndt5` WHERE result.C2S IS NOT NULL  One of the nice features of the new schema is how little calculation is required to get the data you want :)  -Peter    On Tue, Nov 12, 2019 at 2:19 PM Thomas Buck <t...@moounlimited.com> wrote: Hi Peter,  This is amazing, thank you for your quick and comprehensive reply. Can you point me in the right direction for pulling out speed measurements from the new schema?   I’m fine without the geolocation stuff, it’s download / upload mbps and min RTT that I’m most interested in.   Exploring at `measurement-lab.ndt.ndt5`, I’m not seeing any populated values:  SELECT partition_date,    COUNT(*) AS total_rows,   SUM(CASE WHEN result.C2S IS NULL THEN 1 ELSE 0 END) AS null_c2s,   SUM(CASE WHEN result.Download IS NULL THEN 1 ELSE 0 END) AS null_downloads,   SUM(CASE WHEN result.Upload IS NULL THEN 1 ELSE 0 END) AS null_uploads FROM `measurement-lab.ndt.ndt5` WHERE partition_date BETWEEN \'2019-10-15\' AND \'2019-11-11\'   GROUP BY partition_date ORDER BY partition_date   Row partition_date total_rows null_c2s null_downloads null_uploads 1 2019-10-15 1580639 979435 1580639 1580639 2 2019-10-16 1548101 956595 1548101 1548101 3 2019-10-17 1515766 938295 1515766 1515766 4 2019-10-18 1543635 954888 1543635 1543635 5 2019-10-19 1570913 973059 1570913 1570913 6 2019-10-20 1529246 950606 1529246 1529246 7 2019-10-21 1521549 943600 1521549 1521549 8 2019-10-22 1580653 974895 1580653 1580653 9 2019-10-23 1655781 1015297 1655781 1655781 10 2019-10-24 1881269 1142739 1881269 1881269 11 2019-10-25 2231778 1349355 2231778 2231778 12 2019-10-26 2202261 1338717 2202261 2202261 13 2019-10-27 2198697 1344825 2198697 2198697 14 2019-10-28 2251075 1374445 2251075 2251075 15 2019-10-29 2430001 1466670 2430001 2430001 16 2019-10-30 2563155 1541106 2563155 2563155 17 2019-10-31 2455425 1486344 2455425 2455425 18 2019-11-01 2490693 1515257 2490693 2490693 19 2019-11-02 2515799 1533997 2515799 2515799 20 2019-11-03 2485304 1522871 2485304 2485304 21 2019-11-04 2468385 1509086 2468385 2468385 22 2019-11-05 2869215 1734356 2869215 2869215 23 2019-11-06 3187630 1938870 3187630 3187630 24 2019-11-07 3203866 1953382 3203866 3203866 25 2019-11-08 3321079 2044216 3321079 3321079 26 2019-11-09 3357889 2073160 3357889 3357889 27 2019-11-10 2082386 1316249 2082386 2082386 28 2019-11-11 1852342 1152755 1852342 1852342  I’ve taken a brief look at the tcpinfo schema; should I be calculating metrics based on that?  Many thanks, Tom.  On 12 Nov 2019, at 17:51, Peter Boothe ¶ <pbo...@google.com> wrote:  Hello!  We are in the process of migrating our infrastructure to what we have called MLab2.0.  The new NDT server implementation produces results in a different schema stored in the `measurement-lab.ndt.ndt5` table.  SELECT partition_date, COUNT(*) FROM `measurement-lab.ndt.ndt5` WHERE partition_date BETWEEN \'2019-10-15\' AND \'2019-11-11\'   GROUP BY partition_date ORDER BY partition_date  Returns many results:   Row partition_date f0_ 1 2019-10-15 1580639 2 2019-10-16 1548101 3 2019-10-17 1515766 4 2019-10-18 1543635 5 2019-10-19 1570913 6 2019-10-20 1529246 7 2019-10-21 1521549 8 2019-10-22 1580653  ...  The NDT5 table is not currently geolocated, but the associated tcpinfo table is.  (Nota bene: The NDT5 table will get geolocation data added, the migration just has a lot of moving parts) For now, to query the geolocation information, join the ndt table with the tcpinfo table, like:  SELECT ndt5.partition_date, COUNT(*) FROM `measurement-lab.ndt.ndt5` as ndt5 INNER JOIN  `measurement-lab.ndt.tcpinfo` as tcpinfo ON (ndt5.result.S2C.UUID = tcpinfo.UUID) WHERE ndt5.partition_date BETWEEN \'2019-10-15\' AND \'2019-11-11\'     AND ndt5.result.S2C.UUID IS NOT NULL AND ndt5.result.S2C.UUID != """"   AND tcpinfo.Client.Geo.country_name = \'Germany\' GROUP BY ndt5.partition_date ORDER BY ndt5.partition_date  And then you can see that Germany has lots of data: Row partition_date f0_ 1 2019-10-15 35361 2 2019-10-16 32341 3 2019-10-17 33809 4 2019-10-18 34078 5 2019-10-19 35931 6 2019-10-20 36907 7 2019-10-21 32207 8 2019-10-22 34505 ... Although our parsing has apparently fallen a bit behind.  Again, this ""you need to join to query geo information""  feature is a bug, and it is a bug we are actively working on.  In the future (meaning early next year) everything should have geo information and querying should be more straightforward.  For now, this is a note to say: the data is still there. You can query it right now if you want to.    -Peter  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/f40ab949-e27b-4885-b393-f057c694d6ee%40measurementlab.net.   -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful, always with the goal of making the Internet better for the people who use it.    -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful. Peter Boothe - Coder at Google, working in support of M-Lab'}}"
130	speed-test-results	1573234795.0	2019-11-08 10:39:55	Hope Calvin	im concerned about the results of my speed test results and need some troubleshooting tips 	{}
131	re:-[support:11739]-web100,-ndt-5-&-ndt-7-server-deployment-plans	1572620039.0	2019-11-01 07:53:59	Peter Boothe ¶	On Wed, Oct 30, 2019 at 12:26 PM 'Alok Swain (aloswain)' via Support / Contact / Privacy <sup...@measurementlab.net> wrote: Hi,   We have a few questions.   Based on the link below it says - “The web100 version of server will be decommissioned on M-Lab once ndt-server has been tested and launched.” Does that mean the Public web100 NDT Server will go away at the end of 2019. https://www.measurementlab.net/tests/ndt/ Yes, but not the way it looks like you are thinking. Every web100 ndt client is already an NDT5 client, so no existing clients should lose the ability to run NDT tests.               After that I suppose, are you going to support both NDT-5 and NDT-7 servers? Do you have any ideas as to how many servers do you plan to have for each protocol type? Could you please share your deployment plans for these Server types?  Yes. NDT5 and NDT7 will be supported on every server, just like today.  No clients should lose their ability to run tests. The two protocols will be served from different ports on the server.    I see that you have NDT-7 clients implemented in Go and C++11. Do you have any NDT-7 client implementationavailable in Python? Not that I know of.  A high-quality javascript client is coming soon, but that's not the python you are looking for.  NDT7 is *much* easier to implement a client for, though.    -Peter    Thanks   Alok      -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful, always with the goal of making the Internet better for the people who use it.	{}
132	convincing-my-isp-that-there-is-a-problem	1572005826.0	2019-10-25 05:17:06	Michael Petty	I use the internet to watch tv and this fails at around 9-10pm. I have a 30Mbs adsl connection and if I use any number of test sites in the daytime they return results of around 23-25Mbs DL. When the tv service fails ookla and ovh.net who my isp recommend still report 20mbs but M-Labs figures are around 2Mbs.  I am in Spain and with my Spanish not being fluent I am having trouble convincing them there is a problem.  Any thoughts on what the problem may be.  Thanks for reading.	"{0: {'username': 'keith dawson', 'response_date': 'Oct 25, 2019, 6:42:17 AM', 'response_content': 'You can try qualoo.net they are good at solving issues like this,  the problem maybe where your iptv service servers are held, if they are in another country then maybe the way your isp routes to that service is congested,  most probably they have poor quality on their international links and do not know, which service provider do you use?    \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/e6184d3d-10c6-4da6-bafa-272d22bb2d35%40measurementlab.net.'}}"
133	m-lab-seeking-contract-developer-for-web-application	1571144115.0	2019-10-15 05:55:15	Chris Ritzo	Greetings M-Lab Discuss members,  I'm writing to share an opportunity to do some contract web development for M-Lab.  We are seeking a contract developer to improve and build new features for a web application called Piecewise. This application is a public engagement portal, providing a web-based survey, M-Lab NDT test, and asks the user to consent to share their location to enable fine grained spatial aggregation of the data. Deployments of this application have enabled communities to gather their own data to support policy advocacy at the local level. Most recently, the MERIT network in Michigan used Piecewise in a pilot to study the homework gap in their state (https://mi.broadbandtest.us/).  We now have funding to support taking Piecewise from a prototype application to a containerized or Software as Service product. This will enable more communities to easily deploy and use M-Lab tools and data for their advocacy, research, or public engagement.  The attached work scope describes the current application state, roadmap, timeline, as well as the budget we have to support this work.  If you are interested in learning more, please reach out to myself (cri...@measurementlab.net), or M-Lab Director, Lai Yi Ohlsen (la...@measurementlab.net).  -- Chris Ritzo (he/him) Program Management & Community Lead, Measurement Lab sup...@measurementlab.net	{}
134	what-exact-algorithm-is-being-used-when-running-a-test-on-https://speed.measurementlab.net/#/?	1568890392.0	2019-09-19 03:53:12	Jakub Sławiński	Hi,  what exact algorithm is being used when running a test on https://speed.measurementlab.net/#/? How to check that?  Is it possible that https://github.com/m-lab/ndt-server/issues/171 affects the download results? Sometimes (especially on the first run, when all the name resolution magic is being done) the speeds achieved are surprisingly small.   Regards,   Jakub.  -- Jakub Sławiński Chief Technical Officer jslaw...@soldevelo.com / +48 514 780 384   SolDevelo Sp. z o.o. [LLC] / www.soldevelo.com Al. Zwycięstwa 96/98, 81-451, Gdynia, Poland Phone: +48 58 782 45 40 / Fax: +48 58 782 45 41	"{0: {'username': 'Chris Ritzo', 'response_date': 'Sep 19, 2019, 4:45:34 AM', 'response_content': 'Hello Jakub,  The code for the website https://speed.measurementlab.net can be reviewed in this repository: https://github.com/m-lab/mlab-speedtest The test used is the Network Diagnostic Tool (NDT), using JavaScript. The test code within that repo can be found here: https://github.com/m-lab/mlab-speedtest/blob/master/app/services/mlabService.js  Regarding the ndt-server issue you referenced, this refers to ongoing work on the new ndt-server, currently in global pilot on the M-Lab platform, in parallel to the web100 version of NDT server. The new server is running on 1/3 of our fleet for production testing and final QA before it is scheduled for launch later this year.   If you have seen issues with tests using servers that have been upgraded as part of the global pilot, please report them here or as issues in https://github.com/m-lab/ndt-server  Best regards, Chris - M-Lab Support \ue5d3'}, 1: {'username': 'Peter Boothe ¶', 'response_date': 'Sep 19, 2019, 4:19:49 PM', 'response_content': 'It is worrying and strange to me that you would be getting slow speeds on speed.measurementlab.net  If you keep track of the server to which you are getting slow speeds (or happen to know your public-facing IP - both IPv4 and, if relevant, IPv6) then I can investigate further.    -Peter  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAFa%2B0sSRqwqS-omjWaRZvw9qP%3D_RRO07VSTUzQ%2BoQW%3Dbto2JTQ%40mail.gmail.com.   -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful, always with the goal of making the Internet better for the people who use it.'}, 2: {'username': 'Jakub Sławiński', 'response_date': 'Sep 20, 2019, 6:31:53 AM', 'response_content': ""Hi Peter,  sure, my public IP is 213.192.95.26.  I tried the tests several times, but couldn't reproduce extremely small numbers (i.e. < 1 Mb/s, which I achieved earlier). Also I had in the past the situation that the tests freezes completely.  Is there any way to enable debugging on the browser to see more info from NDT?  When using m-lab, I achieved the download speeds in the range of 18.08 Mb/s - 41.30 Mb/s, which is quite comparable with the Ookla single thread download speeds: 18.68 Mb/s - 25.08Mb/s.  Regarding the upload, the distribution when using m-lab is a little larger: 8.51 Mb/s - 74.79 Mb/s vs. 44.78 Mb/s - 70.71 Mb/s from Ookla.  I tested the same path with both tools, i.e. from my computer to a server in Hamburg.   Regards,   Jakub. \ue5d3""}}"
135	dataset-measurement-lab:base_tables-was-not-found-in-location-us-error	1568890280.0	2019-09-19 03:51:20	Matthew Wilson	"I am attempting to query M-Labs data using  https://www.measurementlab.net/data/docs/bq/ndtmetrics/ and https://www.measurementlab.net/blog/bq-datasets/  as guides. I am getting the error ""Not found: Dataset measurement-lab:base_tables was not found in location US"" when running this query through the Google BigQuery SDK.  SELECT       8 * (web100_log_entry.snap.HCThruOctetsAcked /     (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd)) AS download_Mbps FROM   `measurement-lab.release.ndt_downloads` WHERE   partition_date BETWEEN '2019-08-01' AND '2019-08-31'   AND connection_spec.data_direction = 1   AND web100_log_entry.snap.HCThruOctetsAcked >= 8192   AND (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd) >= 9000000   AND (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd) < 600000000   AND web100_log_entry.snap.CongSignals > 0   AND (web100_log_entry.snap.State = 1 OR     (web100_log_entry.snap.State >= 5 AND     web100_log_entry.snap.State <= 11))   LIMIT 100   Can one of the team, or any others help me with this?   Thanks -Matthew Wilson"	"{0: {'username': 'Chris Ritzo', 'response_date': 'Sep 19, 2019, 4:33:58 AM', 'response_content': ""Hi Matt,  Thanks for contacting M-Lab. Our discuss group messages are moderated, which is why your posts didn't appear right away.   In the query you sent, the issue appears to be the table name. You should use the tables/views in `measurement-lab.ndt.* ` now instead of `measurement-lab.release.*`  I hope this resolves the issue and please let us know if you have other questions.  Best regards, Chris - M-Lab Support \ue5d3""}}"
136	permission-denied-for-table:-mlab-oti:base_tables.traceroute	1568636816.0	2019-09-16 05:26:56	Sergey Batalov	I tried to run some queries from https://www.measurementlab.net/blog/traceroute-bq-newdata-available/ and got this error:  > Access Denied: BigQuery BigQuery: Permission denied for table: mlab-oti:base_tables.traceroute  I am subscribed to the M-Lab discussion group and was able to query the data before. Any idea what am I doing wrong?	"{0: {'username': 'Chris Ritzo', 'response_date': 'Sep 16, 2019, 5:37:11 AM', 'response_content': ""Hello,  Thanks for posting. Perhaps the wording of that blog post could be clearer-- I believe the error is due to querying the previous traceroute table instead of the new one.   If you change your queries to use `measurement-lab.aggregate.traceroute` instead of `measurement-lab.base_tables.traceroute` I think the error should go away.  Please post if that doesn't solve the issue.  Best, Chris - M-Lab Support \ue5d3""}, 1: {'username': 'Sergey Batalov', 'response_date': 'Sep 16, 2019, 6:01:26 AM', 'response_content': 'Hey Chris,  Thank you for reply! Here is the query that caused the error, copied as-is from the blog post:  SELECT   ts,   COUNT(*) AS num FROM (   SELECT     DATE(TestTime) as ts   FROM `measurement-lab.aggregate.traceroute`   WHERE   DATE(TestTime) BETWEEN DATE(""2016-01-01"") AND DATE(""2018-06-30"") ) GROUP BY ts ORDER BY ts DESC  It queries correct table \'measurement-lab.aggregate.traceroute\', which is actually a view, defined as follows:  #standardSQL -- This is the traceroute root view for historical traceroute data. SELECT CAST(_PARTITIONTIME AS DATE) AS partition_date, * FROM `mlab-oti.base_tables.traceroute`  Apparently, I\'m not allowed to read the underlying table \'mlab-oti.base_tables.traceroute\'. Is this an old view definition or something else?  Thanks, Sergey \ue5d3'}, 2: {'username': 'Chris Ritzo', 'response_date': 'Sep 16, 2019, 7:28:20 AM', 'response_content': ""Hi Sergey,  Thank you for clarifying. This appears to be a permissions issue on our end. We've reported it to the staff person who manages the traceroute table to investigate and fix.  Our apologies for the inconvenience. I will report back when the issue is resolved.  Best, Chris \ue5d3""}, 3: {'username': 'Chris Ritzo', 'response_date': 'Sep 16, 2019, 10:00:05 AM', 'response_content': 'Hello Sergey,  We believe the permissions issue is now resolved. Could you please re-try your query when you have a moment to confirm?  Thanks, Chris \ue5d3'}, 4: {'username': 'Sergey Batalov', 'response_date': 'Sep 17, 2019, 5:01:28 AM', 'response_content': 'Hello guys, thank you very much for quick responses! Yes, the issue is resolved now!  Thanks again, Sergey \ue5d3'}}"
137	canada-ontario-visualizations-location-data-not-updated-since-june-11-2019	1568636816.0	2019-09-16 05:26:56	D Clarke	Good morning. It looks like Ontario Canada Data from performance tests have not been updated since June 11, 2019. Below is a daily sample for Caledon, but same is for Ontario as well. How do we get the data updates restarted ? David  Canada nacaoncaledon North America Ontario CA Caledon NA ON city nacaoncaledon 4 0.087 1.345 0.351 6/8/2019 90.971 Canada nacaoncaledon North America Ontario CA Caledon NA ON city nacaoncaledon 9 0.026 13.971 0.902 6/9/2019 31.898 Canada nacaoncaledon North America Ontario CA Caledon NA ON city nacaoncaledon 3 0.005 9.934 1.624 6/10/2019 19.917 Canada nacaoncaledon North America Ontario CA Caledon NA ON city nacaoncaledon 2 0.078 2.054 1.709 6/11/2019 38.448 Canada nacaoncaledon North America Ontario CA Caledon NA ON city nacaoncaledon 6/12/2019 Canada nacaoncaledon North America Ontario CA Caledon NA ON city nacaoncaledon 6/13/2019 Canada nacaoncaledon North America Ontario CA Caledon NA ON city nacaoncaledon 6/14/2019	{0: {'username': 'Chris Ritzo', 'response_date': 'Sep 16, 2019, 5:33:47 AM', 'response_content': 'Hello David, Apologies for the delay posting your message.   Our data visualization site is updated approximately on a monthly schedule currently, and we are working on automating updates to it. The site derives its aggregate data from our BigQuery datasets, which are continuously updated. So the most current data will always be in BigQuery, where the visualization site received periodic updates.  The site has been updated with aggregate data through August 2019 now, so you should find newer aggregate data for your locations of interest there now.  Best, Chris - M-Lab Support \ue5d3'}}
138	acm-mmsys-2020-research-track---call-for-papers	1568636816.0	2019-09-16 05:26:56	Cise Midoglu	Dear colleagues, please find below the CfP for the ACM Multimedia Systems Conference (MMSys 2020). Some of the topics of interest might be relevant for the measurement community as well. Best regards, Cise Midoglu  *   ACM MMSys 2020 Research Track - Call for Papers  “Bridging Deep Media and Communications”  June 8-11, 2020, Istanbul, Turkey https://2020.acmmmsys.org   Scope and Topics of Interest -----------------------------------------  The ACM Multimedia Systems Conference (MMSys) provides a forum for researchers to present and share their latest research findings in multimedia systems. While research about specific aspects of multimedia systems are regularly published in the various proceedings and transactions of the networking, operating systems, real-time systems, databases, mobile computing, distributed systems, computer vision, and middleware communities, MMSys aims to cut across these domains in the context of multimedia data types. This provides a unique opportunity to investigate the intersections and the interplay of the various approaches and solutions developed across these domains to deal with multimedia data types.  MMSys is a venue for researchers who explore: Complete multimedia systems that provide a new kind of multimedia experience or system whose overall performance improves the state-of-the-art through new research results in more than one component, or Enhancements to one or more system components that provide a documented improvement over the state-of-the-art for handling continuous media or time-dependent services.  Such individual system components include: Operating systems Distributed architectures and protocols Domain languages, development tools and abstraction layers Using new architectures or computing resources for multimedia New or improved I/O architectures or I/O devices, innovative uses, and algorithms for their operation Representation of continuous or time-dependent media Metrics and measurement tools to assess performance  This touches aspects of many hot topics including but not limited to: content preparation and (adaptive) delivery systems, high dynamic range (HDR), games, virtual/augmented/mixed reality, 3D video, immersive systems, plenoptics, 360-degree video, volumetric video delivery, multimedia Internet of Things (IoT), multi and many-core, GPGPUs, mobile multimedia and 5G, wearable multimedia, peer-to-peer (P2P), cloud-based multimedia, cyber-physical systems, multi-sensory experiences, smart cities, quality of experience (QoE).  We especially encourage submissions in the following Focus Areas: Machine learning and statistical modeling for video streaming Volumetric media: from capture to consumption Fake media and tools for preventing illegal broadcasts  Important Dates ----------------------------------------- Submission deadline: January 10, 2020 (firm deadline) Acceptance notification: March 16, 2020 Camera-ready deadline: April 17, 2020  Submission Instructions ----------------------------------------- Online submission: https://mmsys2020.hotcrp.com/  Papers must be up to 12 pages long (in PDF format) prepared in the ACM style and written in English. MMSys papers enable authors to present entire multimedia systems or research work that builds on considerable amounts of earlier work in a self-contained manner. MMSys papers are published in the ACM Digital Library. The papers are double-blind reviewed.  MMSys 2020 will continue to support scientific reproducibility, by implementing the ACM reproducibility badge system. Refer to the website for more details on the review process and the reproducibility badge system.  General Chairs ----------------------------------------- Ali C. Begen (Ozyegin University and Networked Media, Turkey) Laura Toni (University College London, UK)   TPC Chairs ----------------------------------------- Özgü Alay (Simula Metropolitan and University of Oslo, Norway) Christian Timmerer (Alpen-Adria-Universität Klagenfurt and Bitmovin, Austria)  Supporters ----------------------------------------- Adobe, Ozyegin University, Medianova, Multicoreware, Argela, Bigdata Teknoloji, Bitmovin, DASH-IF, Dolby, Mux, Nokia, Pixery, SSIMWAVE, Twitch, Unified Streaming, Vispera, Ericsson, Interdigital  Follow Us ----------------------------------------- https://twitter.com/acmmmsys https://www.facebook.com/acmmmsys/ https://www.instagram.com/acmmmsys/  This call for papers in PDF: https://2020.acmmmsys.org/files/cfp_mmsys20.pdf  -- Cise Midoglu Simula Research Laboratory https://www.simula.no	{}
139	getting-error-while-running-example-query-on-bigquery-(ds101-exercise)	1564609179.0	2019-07-31 14:39:39	Ekele Shaibu	"Is anyone else getting this error when they run a query on BigQuery?  ""Not found: Dataset measurement-lab:base_tables was not found in location US"""	{0: {'username': 'Chris Ritzo', 'response_date': 'Jul 31, 2019, 2:47:42 PM', 'response_content': 'Hello!   Earlier this summer M-Lab updated our tables to have more consistent naming. You can read the complete details in this blog post. Instead of the former dataset `measurement-lab.base_tables` you can use the tables in `measurement-lab.ndt. ` for NDT results.  I hope this helps.   Best regards, Chris - M-Lab Support \ue5d3'}, 1: {'username': 'Ekele Shaibu', 'response_date': 'Jul 31, 2019, 3:00:12 PM', 'response_content': 'Thanks a lot Chris.  This fixed the issue. \ue5d3'}}
140	"204-""no-content""-when-using-""mlabns/address_family"":""ipv4""-and-""mlabns/policy"":""geo"""	1564609179.0	2019-07-31 14:39:39	Alex N	"In the last few weeks, we started getting errors from ""http://mlab-ns.appspot.com/ndt?policy=geo&address_family=ipv4"" We get 204 ""No Content"" in most of the cases. Any changes for this API have been made?"	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jul 31, 2019, 2:56:34 PM', 'response_content': 'Hello,  In early May, M-Lab implemented a change to the mlab-ns service that returns the status 204 ""No Content"" code, when the response to retrieve servers is empty. Previously, mlab-ns would return status 200 and an empty results if there were no servers to report in response to a query. The status 204 code is now returned in the same situation.  More detail can be found here: https://github.com/m-lab/mlab-ns/pull/190  I hope this is helpful. If you need help with the specific situation, please email sup...@measurementlab.net  Best regards, Chris - M-Lab Support \ue5d3'}}"
141	re:-ipv6-speed-test-is-failed/couldn't-be-start	1564498088.0	2019-07-30 07:48:08	Simone Basso	I have no IPv6, therefore I cannot be much of help here. I would recommend to perhaps use the developer tools to see if the console provides useful information that can help us diagnose more precisely the issue. Can you also check running the official speed test website and see whether it's working for you: https://speed.measurementlab.net/#/?  Thanks,  -sbs   Il giorno mar 9 lug 2019 alle ore 00:18 Yanxin Na (yanxna) <yan...@cisco.com> ha scritto: Hi, Google support team,   When I did the ipv6 test with the webpage http://ndt.iupui.mlab1.lax04.measurement-lab.org:7123 as the following: http://[2001:1900:2100:15::11]:7123   it could show the page that could start the speed test, but after started the speed test, the test was terminated immediately with “NAN” invalid result value. I attached the photos of results in the email. Seems the ipv6 speed test was failed or couldn’t be started.   I also tested another ipv6 google ndt server:   http://[2001:2030:0:1f::165]:7123   It showed same result “NAN”.   Would you please check the issue and tell us how to do the ipv6 speed test successfully?   Thanks a lot, Yanxin      	{}
142	nat-queries.	1563372578.0	2019-07-17 07:09:38	Jay P	I am trying to run a query to get a dataset which has a Local IP address (IP of a client) and IP which the client uses to connect to the internet. The result should specifically correspond,  to African countries, and I should get the corresponding ASN.   Any help? Thanks	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jul 17, 2019, 7:17:46 AM', 'response_content': ""Hello Jay, The IP address is saved in the field `connection_spec.client_ip`. However, private IPs (NAT'ed) are not stored, only the public facing IP address provided to a premise device by the ISP. For example a cable modem. ASN should be in the field `connection_spec.client.network.asn`  Hope this helps.   --Chris / M-Lab Support \ue5d3""}}"
143	upload-calculations???	1561379994.0	2019-06-24 05:39:54	Glenn Fishbine	"I think I'm doing something wrong?  Are these the wrong upload fields?  I'm trying to extract average upload speeds as follows  SELECT  avg( 8 * (web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration)) AS upload_Mbps FROM `measurement-lab.ndt.web100`   and the MAXIMUM value from the run is 0.001915,  so obviously I'm doing something wrong.   full query:  CREATE TEMP FUNCTION MEDIAN(a_num ARRAY<FLOAT64>)     RETURNS FLOAT64 AS ((        SELECT           AVG(num)         FROM (           SELECT             row_number() OVER (ORDER BY num) -1 as rn             , num           FROM UNNEST(a_num) num         )         WHERE           rn = TRUNC(ARRAY_LENGTH(a_num)/2)             OR (              MOD(ARRAY_LENGTH(a_num), 2) = 0 AND               rn = TRUNC(ARRAY_LENGTH(a_num)/2)-1 )     ));  SELECT  avg(8 * (web100_log_entry.snap.HCThruOctetsAcked /     (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd))) AS download_Mbps, MEDIAN(ARRAY_AGG(8 * (web100_log_entry.snap.HCThruOctetsAcked /     (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd)))) AS median_download_Mbps, avg( 8 * (web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration)) AS upload_Mbps, MEDIAN(ARRAY_AGG( 8 * (web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration))) AS upload_median_Mbps,     count(*),         connection_spec.client.network.asn,  avg(    connection_spec.client_geolocation.latitude), avg(    connection_spec.client_geolocation.longitude),     connection_spec.client_geolocation.city,     connection_spec.client_geolocation.region FROM `measurement-lab.ndt.web100`  WHERE ((connection_spec.client_geolocation.country_name='United States')    OR (connection_spec.client_geolocation.country_name='Canada')) AND connection_spec.client.network.asn IS NOT NULL  AND  log_time > ""2018-06-01""  AND connection_spec.client_geolocation.city IS NOT NULL AND ((web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd) >0)  AND web100_log_entry.snap.HCThruOctetsAcked >= 0 AND connection_spec.data_direction = 1 AND web100_log_entry.snap.HCThruOctetsAcked >= 8192 AND (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd) >= 9000000 AND (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd) < 600000000 AND web100_log_entry.snap.CongSignals > 0 AND (web100_log_entry.snap.State = 1 OR     (web100_log_entry.snap.State >= 5 AND     web100_log_entry.snap.State <= 11))  group by      connection_spec.client.network.asn,connection_spec.client_geolocation.city,     connection_spec.client_geolocation.region   order by connection_spec.client_geolocation.region,connection_spec.client_geolocation.city"	{}
144	how-to-calculate-a-median	1561289300.0	2019-06-23 04:28:20	Glenn Fishbine	"Given this query structure, I can't figure out how to do a MEDIAN calculation in place of the Average for download speeds.  I've googled my brains out and suspect it's a variation on PERCENTILE_DISC, but I can't get the query editor to accept any variation I try.  What I'm trying to do is have both Average and Median in the same query so I can compare them.  Failing that I could do two queries and merge the results.  Bigquery docs say I can use QUANTILES but it seems to be not recognized as a valid function.  :)  SELECT  connection_spec.client.network.asn,  avg(8 * (web100_log_entry.snap.HCThruOctetsAcked /     (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd)))  AS average,  avg(connection_spec.client_geolocation.latitude) AS latitude,  avg(connection_spec.client_geolocation.longitude) AS longitude  FROM `measurement-lab.ndt.web100`   WHERE connection_spec.client_geolocation.country_name='Canada'  AND connection_spec.client.network.asn IS NOT NULL  AND  log_time > ""2018-06-01"" AND connection_spec.client_geolocation.city IS NOT NULL AND ((web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd) >0)  AND web100_log_entry.snap.HCThruOctetsAcked >= 0  GROUP BY  connection_spec.client.network.asn, connection_spec.client_geolocation.city, connection_spec.client_geolocation.region   ORDER BY connection_spec.client_geolocation.region,connection_spec.client_geolocation.city"	"{0: {'username': 'Glenn Fishbine', 'response_date': 'Jun 23, 2019, 11:03:03 AM', 'response_content': 'I think this works.   CREATE TEMP FUNCTION MEDIAN(a_num ARRAY<FLOAT64>)     RETURNS FLOAT64 AS ((        SELECT           AVG(num)         FROM (           SELECT             row_number() OVER (ORDER BY num) -1 as rn             , num           FROM UNNEST(a_num) num         )         WHERE           rn = TRUNC(ARRAY_LENGTH(a_num)/2)             OR (              MOD(ARRAY_LENGTH(a_num), 2) = 0 AND               rn = TRUNC(ARRAY_LENGTH(a_num)/2)-1 )     )); \ue5d3'}, 1: {'username': 'Chris Ritzo', 'response_date': 'Jun 23, 2019, 11:12:57 AM', 'response_content': ""Thanks for posting this, Glenn. We also have used BigQuery's function, APPROX_QUANTILES, to calculate median. For example:  APPROX_QUANTILES(8 * SAFE_DIVIDE(web100_log_entry.snap.HCThruOctetsAcked,       (web100_log_entry.snap.SndLimTimeRwin +         web100_log_entry.snap.SndLimTimeCwnd +         web100_log_entry.snap.SndLimTimeSnd)), 101)[SAFE_ORDINAL(51)] AS download_Mbps \ue5d3""}}"
145	"""buffer-is-undefined""-issue-caused-by-possible-dns-problem"	1561289300.0	2019-06-23 04:28:20	Ryan Olds	"Greetings,   I noticed an error in our Sentry.io logs:  ""Cannot read property 'slice' of undefined""  NDTjs.prototype.parseNdtMessage = function (buffer) {   var i,     response = [],     bufferArray = new Uint8Array(buffer),     message =  String.fromCharCode.apply(null,                                          new Uint8Array(buffer.slice(3)));   for (i = 0; i < 3; i += 1) {     response[i] = bufferArray[i];   }   response.push(message);   return response;  Ignore the line numbers, it's from a concatenated JS file. It's the line at https://github.com/ndt-project/ndt/blob/master/HTML5-frontend/ndt-browser-client.js#L152.   When this happens, I see a request error followed by the error about buffer being undefined.  Error: #1 application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19257 WebSocket connection to 'wss://ndt-iupui-mlab1-sea01.measurement-lab.org:3010/ndt_protocol' failed: Error in connection establishment: net::ERR_NAME_NOT_RESOLVED   Error: #2 NDTjs.createWebsocket @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19257 NDTjs.startTest @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19505 (anonymous) @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:21142 dispatch @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:5227 elemData.handle @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:4879 trigger @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:5131 (anonymous) @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:5861 each @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:371 each @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:138 trigger @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:5860 jQuery.fn.<computed> @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:8984 (anonymous) @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19748 sentryWrapped @ helpers.ts:85 application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19208 Uncaught TypeError: Cannot read property 'slice' of undefined     at NDTjs.parseNdtMessage (application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19208)     at WebSocket.ndtSocket.onerror (application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19615)  Error #1 looks like a DNS error.   I've run dig on two servers we get. The first one is the one we are getting the DNS error, the 2nd work works:  $ dig ndt-iupui-mlab1-sea01.measurement-lab.org  ; <<>> DiG 9.11.3-1ubuntu1.1-Ubuntu <<>> ndt-iupui-mlab1-sea01.measurement-lab.org ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 47026 ;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1   ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 512 ;; QUESTION SECTION: ;ndt-iupui-mlab1-sea01.measurement-lab.org. IN A   ;; AUTHORITY SECTION: measurement-lab.org.    300     IN      SOA     sns-pb.isc.org. support.measurementlab.net. 2019061000 3600 600 604800 300   ;; Query time: 31 msec ;; SERVER: 192.168.1.1#53(192.168.1.1) ;; WHEN: Sat Jun 22 23:05:39 DST 2019 ;; MSG SIZE  rcvd: 143   ryan@DESKTOP-I28ILK0:~$ dig ndt-iupui-mlab1-sea02.measurement-lab.org   ; <<>> DiG 9.11.3-1ubuntu1.1-Ubuntu <<>> ndt-iupui-mlab1-sea02.measurement-lab.org ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 22803 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1   ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 512 ;; QUESTION SECTION: ;ndt-iupui-mlab1-sea02.measurement-lab.org. IN A   ;; ANSWER SECTION: ndt-iupui-mlab1-sea02.measurement-lab.org. 300 IN A 63.243.224.11   ;; Query time: 31 msec ;; SERVER: 192.168.1.1#53(192.168.1.1) ;; WHEN: Sat Jun 22 23:06:18 DST 2019 ;; MSG SIZE  rcvd: 86   It looks like DNS record for dig ndt-iupui-mlab1-sea01.measurement-lab.org isn't set and is causing NDT.js clients to fail when it's used.  Thank you for taking the time to look at this,  Ryan"	{0: {'username': 'Chris Ritzo', 'response_date': 'Jun 23, 2019, 11:07:19 AM', 'response_content': 'Thanks for posting this Ryan. This issue is related to some recent sites being renamed (e.g. sea01 became sea08) to standardize the mapping of IPs to virtual servers across all locations. Currently mlab-ns can sometimes still return FQDNs with the old site name. We are going to fix this soon, likely by EOD tomorrow.  Best, Chris \ue5d3'}}
146	what-we're-doing-with-the-m-lab-data	1561289300.0	2019-06-23 04:28:20	Glenn Fishbine	for the U.S. and Canada:  http://expressoptimizer.net/projects/Demos/USMLAB.php  for Europe:    http://expressoptimizer.net/projects/Demos/EUMLAB.php  just a FYI	{}
147	negative-average-download-speeds?	1560356102.0	2019-06-12 09:15:02	Glenn Fishbine	"Using this query:  SELECT  count(*), connection_spec.client.network.asn, avg(8 * (web100_log_entry.snap.HCThruOctetsAcked /     (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd))) AS download_Mbps,     connection_spec.client_geolocation.city,     connection_spec.client_geolocation.region,     avg(connection_spec.client_geolocation.latitude) AS latitude,     avg(connection_spec.client_geolocation.longitude) AS longitude FROM `measurement-lab.ndt.web100`  WHERE connection_spec.client_geolocation.country_name='United States' AND  log_time > ""2019-01-01"" AND connection_spec.client_geolocation.city IS NOT NULL AND ((web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd) >0) group by      connection_spec.client.network.asn,connection_spec.client_geolocation.city,     connection_spec.client_geolocation.region order by connection_spec.client_geolocation.region,connection_spec.client_geolocation.city  I get some negative download values, perhaps a floating point overflow?  Specific values that are negative ASN=7019    for Emeryville CA - average is -1420655         Atlanta GA - average is -33789         La Grange GA - average is -8035560  ASN=1239  for Houston TX - average is -257023   Any thoughts or suggestions?"	"{0: {'username': 'Peter Boothe™', 'response_date': 'Jun 12, 2019, 11:42:31 AM', 'response_content': 'Whoah! That is certainly surprising.  I do not know why that is happening. Whether it is an artifact of the raw data or a parsing artifact is also unknown. I have filed a bug in our ETL pipeline to track this issue.    https://github.com/m-lab/etl/issues/682  Unfortunately, we are pretty swamped for the next 2 weeks and so unlikely to do a deep dive right now, but this is potentially an important issue, so by filing and triaging the bug we can make sure it doesn\'t get swept under the rug.  That said, there are only 33 (out of 2,265,022,904) records which have web100_log_entry.snap.HCThruOctetsAcked < 0, in our 10-year dataset so one fix is to change your query to:  SELECT count(*), connection_spec.client.network.asn, avg(8 * (web100_log_entry.snap.HCThruOctetsAcked /     (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd))) AS download_Mbps,     connection_spec.client_geolocation.city,     connection_spec.client_geolocation.region,     avg(connection_spec.client_geolocation.latitude) AS latitude,     avg(connection_spec.client_geolocation.longitude) AS longitude FROM `measurement-lab.ndt.web100` WHERE connection_spec.client_geolocation.country_name=\'United States\' AND  log_time > ""2019-01-01"" AND connection_spec.client_geolocation.city IS NOT NULL AND ((web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd) >0) AND web100_log_entry.snap.HCThruOctetsAcked >= 0 group by      connection_spec.client.network.asn,connection_spec.client_geolocation.city,     connection_spec.client_geolocation.region order by connection_spec.client_geolocation.region,connection_spec.client_geolocation.city  Then your query will not contain these 33 funky records. Why those 33 records are the way they are remains an open question.    -Peter    \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.   -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful. Peter Boothe - Coder at Google, working in support of M-Lab'}, 1: {'username': 'Glenn Fishbine', 'response_date': 'Jun 12, 2019, 12:34:41 PM', 'response_content': ""I'm good with trashing bad data. :)  Just a hint for your team, while I didn't search for all 33 records, of the 5 that I extracted, 3 of them are with the same ASN.  7018 AT&T Services, Inc.  2 in Georgia, and 1 in California.  This may be a rabbit hole, but the commonality is interesting. \ue5d3 -- Glenn Fishbine C:  612 387 7536 w:  http://www.breakingpointsolutions.com""}}"
148	multiple-goecoordinates-for-same-city/region	1560093748.0	2019-06-09 08:22:28	Glenn Fishbine	Just an observation and a question.  I noticed in a June 2018-June 2019 extract that the latitude longitude coordinates for a specific city were different between records.  Often different ASNs showed at different geocodes for the same city.  Typical displacements were usually +-1 a mile or so.  This is not a problem for me, but I'm curious to understand why that would be?	"{0: {'username': 'Ben Dowling', 'response_date': 'Jun 9, 2019, 9:48:04 AM', 'response_content': 'Was the postalcode the same? The lat/lng are usually the centroid of the zip or the city, if there is not zip, in my experience.  ᐧ  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': 'Chris Ritzo', 'response_date': 'Jun 9, 2019, 9:53:56 AM', 'response_content': 'Client lat/lon, as well as other client geolocation fields are annotated from the client IP address, using Maxmind geolite 2. So the lat/lon represents the location of ISP infrastructure that hands out IP addresses to customer premise equipment, not the service address. It would be expected that ISPs have different locations throughout a city or metro region.  I hope this helps.  - Chris @M-Lab Support \ue5d3'}, 2: {'username': 'Glenn Fishbine', 'response_date': 'Jun 9, 2019, 2:08:16 PM', 'response_content': 'Chris,  Yes that helps and is easy to understand and makes sense.  A triple play. :-)    \ue5d3 \ue5d3 \ue5d3'}}"
149	re:-[support:10416]-re:-ndt-c2s-test-failing---advice-solicited	1559681741.0	2019-06-04 13:55:41	Chris Ritzo	"All: note that M-Lab discuss posts are now moderated, so in addition to joining the list to post, a moderator must approve and post the message.  Best, Chris M-Lab support  On Tue, Jun 4, 2019, 1:24 PM 'Stephen Soltesz' via Support / Contact / Privacy <sup...@measurementlab.net> wrote: Hi, Alok,  How about, 12pm or 2pm ET Wednesday, or 3pm ET Thurday?  And, ah, yes; messages to discuss@ appear to require that you join that group. support@ messages allow anyone to send a message.  Best, Stephen  On Mon, Jun 3, 2019 at 2:55 PM 'Alok Swain (aloswain)' via Support / Contact / Privacy <sup...@measurementlab.net> wrote: Hi,   I got a mail from the Mail-Server saying that previous mail may-not have gone through to the sup...@measurementlab.net. Hence re-forwarding it.   Thanks   Alok   From: ""Alok Swain (aloswain)"" <alos...@cisco.com> Date: Monday, June 3, 2019 at 1:48 PM To: Stephen Soltesz <sol...@google.com>, ""<sup...@measurementlab.net>"" <sup...@measurementlab.net>, ""dis...@measurementlab.net"" <dis...@measurementlab.net>, Peter Boothe <pbo...@google.com>, Simone Basso <basso...@gmail.com> Cc: ""Asha Mohan (ashmohan)"" <ashm...@cisco.com>, ""David Tang (datang2)"" <dat...@cisco.com>, ""Richard D'Silva (ricdsilv)"" <ricd...@cisco.com>, ""Weiguo Xie (weiguxie)"" <weig...@cisco.com> Subject: Re: NDT C2S test failing - Advice Solicited   Hi Stephen,   Thanks for getting back.   We would love to talk to you guys. We are based in Richardson, TX (CST). Where are you based.   Please give us a few time slots that is convenient to you, so that I can ensure that our Architect and our Manager can also attend the meeting. We are available tomorrow or the day after.   Thanks,   Alok   From: Stephen Soltesz <sol...@google.com> Date: Monday, June 3, 2019 at 1:01 PM To: ""Alok Swain (aloswain)"" <alos...@cisco.com> Cc: Peter Boothe <pbo...@google.com>, Simone Basso <basso...@gmail.com>, ""Asha Mohan (ashmohan)"" <ashm...@cisco.com>, ""David Tang (datang2)"" <dat...@cisco.com>, ""Richard D'Silva (ricdsilv)"" <ricd...@cisco.com>, ""<sup...@measurementlab.net>"" <sup...@measurementlab.net> Subject: Re: NDT C2S test failing - Advice Solicited   Alok, please take advantage of our sup...@measurementlab.net or dis...@measurementlab.net aliases. These will always get the best visibility and response from our whole team. I've CC'd support@.   The short answer it's hard to say. There are currently two versions of the NDT server: a legacy C implementation with known issues, and a rewrite in Go that we are rolling out at the same time as we are upgrading our platform software stack during the next few months, which we believe resolves many issues with the C implementation - greatest of which is that we can easily fix issues once discovered.   What is the timeline that you're hoping to release this feature? We also have a new protocol NDT7 that will likely be easier to develop and deploy a client for your use-case. However, it is still maturing. An alpha version is available on our staging infrastructure. As well, the Go version of the NDT server is also on our staging infrastructure. Do you see the same upload behavior from mlab4 servers returned by our staging location service? https://locate-dot-mlab-staging.appspot.com/ndt_ssl ** Would you be willing to talk with us so we can get a better sense of Cisco's deployment plans for NDT for our capacity planning? Would you be willing to consider adopting NDT7 instead? Best, Stephen     ** Note this is staging infrastructure suitable only for testing. Do not use it for anything other than testing - there is no guarantee of availability in general.   On Thu, May 30, 2019 at 8:25 PM Alok Swain (aloswain) <alos...@cisco.com> wrote: Hi Peter, Stephen, Simone,   In a successful test case the NDT Server sends us 28305 Mbps.   (TEST_MSG) body = {u'msg': u'28305'}   which matches somewhat the throughput that we measure in the Client side 25759 Mbps.   2019-05-25 21:18:02,637 - AGENT - DEBUG - C2S rate calculated in local: 25759.339397                                                                                                               2019-05-25 21:18:02,639 - AGENT - DEBUG - C2S rate calculated by server: 28305     Thanks   Alok   From: ""Alok Swain (aloswain)"" <alos...@cisco.com> Date: Thursday, May 30, 2019 at 7:17 PM To: Peter Boothe <pbo...@google.com>, Stephen Soltesz <sol...@google.com>, Simone Basso <basso...@gmail.com> Cc: ""Asha Mohan (ashmohan)"" <ashm...@cisco.com>, ""David Tang (datang2)"" <dat...@cisco.com>, ""Richard D'Silva (ricdsilv)"" <ricd...@cisco.com> Subject: NDT C2S test failing - Advice Solicited   Hi Peter, Stephen, Simone,   My name is Alok Swain. I work in Cisco. We are working on including NDT Client in one of our products. We are testing it against publicly available NDT Servers.   I am having some issues with the c2s test. It works fine most of the times but fails sometimes.   I have included the failure case (highlighted in yellow) where we don’t receive the TEST_MSG from the NDT Server, and eventually the websocket connection times out. I also have included the case where it works fine shown in green below as well.   Could you please shed some light on why is the Server not sending TEST_MSG sometimes?   Any help will be greatly appreciated.   Thanks   Alok   Failure   2019-05-25 21:21:25,385 - AGENT - DEBUG - Test started.  Waiting for connection to server...                                                                                                                2019-05-25 21:21:25,387 - AGENT - DEBUG - ws://175.45.79.24:3001/ndt_protocol ndt                                                                                                                                 2019-05-25 21:21:25,388 - AGENT - DEBUG - Opened connection on port 3001                                                                                                                                          2019-05-25 21:21:25,390 - AGENT - DEBUG - state = LOGIN_SENT type = 1 (SRV_QUEUE) body = {u'msg': u'0'}                                                                                                           2019-05-25 21:21:25,392 - AGENT - DEBUG - SRV_QUEUE 0: Ignoring & Waiting for MSG_LOGIN.                                                                                                                           2019-05-25 21:21:25,393 - AGENT - DEBUG - state = LOGIN_SENT type = 2 (MSG_LOGIN) body = {u'msg': u'v4.0.0.1-Web100'}                                                                                              2019-05-25 21:21:25,395 - AGENT - DEBUG - Server Version v4.0.0.1-Web100                                                                                                                                           2019-05-25 21:21:25,396 - AGENT - DEBUG - state = WAIT_FOR_TEST_IDS type = 2 (MSG_LOGIN) body = {u'msg': u'2 4 32'}                                                                                               2019-05-25 21:21:25,398 - AGENT - DEBUG - state = WAIT_FOR_MSG_RESULTS type = 3 (TEST_PREPARE) body = {u'msg': u'43074'}                                                                                          2019-05-25 21:21:25,400 - AGENT - DEBUG - ws://175.45.79.24:43074/ndt_protocol c2s                                                                                                                                2019-05-25 21:21:25,401 - AGENT - DEBUG - state = WAIT_FOR_TEST_START type = 4 (TEST_START) body = {u'msg': u''}                                                                                                   2019-05-25 21:21:25,403 - AGENT - DEBUG - NDT websocket error:[Errno 110] Connection timed out                                                                                                                     2019-05-25 21:21:25,836 - AGENT - INFO - Run auto test: Speed done, run time: 0:01:08.000708                             Success   2019-05-25 21:18:02,612 - AGENT - DEBUG - Test started.  Waiting for connection to server...                                                                                                                       2019-05-25 21:18:02,616 - AGENT - DEBUG - ws://175.45.79.24:3001/ndt_protocol ndt                                                                                                                                 2019-05-25 21:18:02,618 - AGENT - DEBUG - Opened connection on port 3001                                                                 2019-05-25 21:18:02,620 - AGENT - DEBUG - state = LOGIN_SENT type = 1 (SRV_QUEUE) body = {u'msg': u'0'}                                                                                                            2019-05-25 21:18:02,622 - AGENT - DEBUG - SRV_QUEUE 0: Ignoring & Waiting for MSG_LOGIN.                                                                                                                    2019-05-25 21:18:02,623 - AGENT - DEBUG - state = LOGIN_SENT type = 2 (MSG_LOGIN) body = {u'msg': u'v4.0.0.1-Web100'}                                                                                             2019-05-25 21:18:02,625 - AGENT - DEBUG - Server Version v4.0.0.1-Web100                                                                                                                                          2019-05-25 21:18:02,626 - AGENT - DEBUG - state = WAIT_FOR_TEST_IDS type = 2 (MSG_LOGIN) body = {u'msg': u'2 4 32'}                                                                                               2019-05-25 21:18:02,628 - AGENT - DEBUG - state = WAIT_FOR_MSG_RESULTS type = 3 (TEST_PREPARE) body = {u'msg': u'42916'}                                                                                        2019-05-25 21:18:02,630 - AGENT - DEBUG - ws://175.45.79.24:42916/ndt_protocol c2s                                                                               2019-05-25 21:18:02,631 - AGENT - DEBUG - state = WAIT_FOR_TEST_START type = 4 (TEST_START) body = {u'msg': u''}                                                                                                  2019-05-25 21:18:02,633 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG type = 5 (TEST_MSG) body = {u'msg': u'28305'}                          2019-05-25 21:18:02,634 - AGENT - DEBUG - NDT uplink test success                                                                                                                               2019-05-25 21:18:02,636 - AGENT - DEBUG - NDT uplink test success                                                                                    2019-05-25 21:18:02,637 - AGENT - DEBUG - C2S rate calculated in local: 25759.339397                                                                             2019-05-25 21:18:02,639 - AGENT - DEBUG - C2S rate calculated by server: 28305                                                                                                                                   2019-05-25 21:18:02,640 - AGENT - DEBUG - state = WAIT_FOR_TEST_FINALIZE type = 6 (TEST_FINALIZE) body = {u'msg': u''}                                   2019-05-25 21:18:02,642 - AGENT - DEBUG - state = DONE type = 3 (TEST_PREPARE) body = {u'msg': u'45646'}                                    2019-05-25 21:18:02,644 - AGENT - DEBUG - ws://175.45.79.24:45646/ndt_protocol s2c                                                                                                                                 2019-05-25 21:18:02,645 - AGENT - DEBUG - state = WAIT_FOR_TEST_START type = 4 (TEST_START) body = {u'msg': u''}                                    2019-05-25 21:18:02,647 - AGENT - DEBUG - state = WAIT_FOR_FIRST_TEST_MSG type = 5 (TEST_MSG) body = {u'TotalSentByte': u'54124544', u'UnsentDataAmount': u'431518', u'ThroughputValue': u'43220'}                2019-05-25 21:18:02,649 - AGENT - DEBUG - S2C rate calculated by client: 42820.4416554                                                                                                                             2019-05-25 21:18:02,650 - AGENT - DEBUG - S2C rate calculated by server: 43220                                                                   2019-05-25 21:18:02,652 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'CurMSS: 1238\n'}                 2019-05-25 21:18:02,654 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'X_Rcvbuf: 87380\n'}         2019-05-25 21:18:02,656 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'X_Sndbuf: 891996\n'}                   2019-05-25 21:18:02,657 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'AckPktsIn: 8898\n'}          2019-05-25 21:18:02,659 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'AckPktsOut: 0\n'}                                                                  2019-05-25 21:18:02,660 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'BytesRetrans: 4952\n'}                                                                    2019-05-25 21:18:02,661 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'CongAvoid: 5976\n'}                                                                      2019-05-25 21:18:02,663 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'CongestionOverCount: 9\n'}                                                               2019-05-25 21:18:02,665 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'CongestionSignals: 4\n'}                                                                 2019-05-25 21:18:02,666 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'CountRTT: 8594\n'}                                                                       2019-05-25 21:18:02,668 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'CurCwnd: 101516\n'}                                                                      2019-05-25 21:18:02,669 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'CurRTO: 219\n'}                                                                           2019-05-25 21:18:02,671 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'CurRwinRcvd: 545920\n'}                                                                  2019-05-25 21:18:02,672 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'CurRwinSent: 15616\n'}                                                                   2019-05-25 21:18:02,674 - AGENT - DEBUG - s2c on_error: Connection is already closed.                                                                                                                             2019-05-25 21:18:02,676 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'CurSsthresh: 42092\n'}                                                                   2019-05-25 21:18:02,677 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'DSACKDups: 0\n'}                                                                          2019-05-25 21:18:02,679 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'DataBytesIn: 233\n'}                                                                      2019-05-25 21:18:02,680 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'DataBytesOut: 55233616\n'}                                                               2019-05-25 21:18:02,682 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'DataPktsIn: 1\n'}                                                                        2019-05-25 21:18:02,683 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'DataPktsOut: 43496\n'}                                                                   2019-05-25 21:18:02,685 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'DupAcksIn: 305\n'}                                                                       2019-05-25 21:18:02,687 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'ECNEnabled: 0\n'}                                                                         2019-05-25 21:18:02,688 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'FastRetran: 4\n'}                                                                         2019-05-25 21:18:02,690 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'MaxCwnd: 320642\n'}                                                                      2019-05-25 21:18:02,691 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'MaxMSS: 1238\n'}                                                                         2019-05-25 21:18:02,693 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'MaxRTO: 274\n'}                                                                          2019-05-25 21:18:02,694 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'MaxRTT: 92\n'} 2019-05-25 21:18:02,696 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'MaxRwinRcvd: 570752\n'}                                                           2019-05-25 21:18:02,697 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'MaxRwinSent: 15616\n'}                                                                   2019-05-25 21:18:02,699 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'MaxSsthresh: 79232\n'} 2019-05-25 21:18:02,700 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'MinMSS: 1238\n'}                                                                   2019-05-25 21:18:02,702 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'MinRTO: 207\n'}                                                                          2019-05-25 21:18:02,704 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'MinRTT: 6\n'}                                                                            2019-05-25 21:18:02,705 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'MinRwinRcvd: 29312\n'}                                                                   2019-05-25 21:18:02,707 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'MinRwinSent: 14480\n'}                                                                 2019-05-25 21:18:02,708 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'NagleEnabled: 1\n'}                                                       2019-05-25 21:18:02,710 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'OtherReductions: 4\n'}                                                                   2019-05-25 21:18:02,711 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'PktsIn: 8899\n'}                                                         2019-05-25 21:18:02,713 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'PktsOut: 43496\n'}                                                       2019-05-25 21:18:02,714 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'PktsRetrans: 4\n'}                                                       2019-05-25 21:18:02,716 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'RcvWinScale: 7\n'}                                                        2019-05-25 21:18:02,717 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SACKEnabled: 3\n'}                                                                     2019-05-25 21:18:02,719 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SACKsRcvd: 314\n'}                                                       2019-05-25 21:18:02,720 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SendStall: 0\n'}                                                         2019-05-25 21:18:02,722 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SlowStart: 256\n'}                                                                        2019-05-25 21:18:02,724 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SampleRTT: 19\n'}                                                        2019-05-25 21:18:02,725 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SmoothedRTT: 19\n'}                                                                      2019-05-25 21:18:02,727 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SndWinScale: 7\n'}                                                                       2019-05-25 21:18:02,728 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SndLimTimeRwin: 3927604\n'} 2019-05-25 21:18:02,730 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SndLimTimeCwnd: 6091449\n'}      2019-05-25 21:18:02,731 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SndLimTimeSender: 24203\n'} 2019-05-25 21:18:02,733 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SndLimTransRwin: 12\n'}                 2019-05-25 21:18:02,735 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SndLimTransCwnd: 24\n'}      2019-05-25 21:18:02,736 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SndLimTransSender: 12\n'}                                                         2019-05-25 21:18:02,738 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SndLimBytesRwin: 25431750\n'}                                                             2019-05-25 21:18:02,739 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SndLimBytesCwnd: 29701490\n'}                                                             2019-05-25 21:18:02,740 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SndLimBytesSender: 100376\n'}                                                            2019-05-25 21:18:02,742 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SubsequentTimeouts: 0\n'}                                                                2019-05-25 21:18:02,744 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'SumRTT: 154525\n'}                                                                       2019-05-25 21:18:02,745 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'Timeouts: 0\n'}                                                                          2019-05-25 21:18:02,747 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'TimestampsEnabled: 1\n'}                                                                  2019-05-25 21:18:02,748 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'WinScaleRcvd: 7\n'}                                                                      2019-05-25 21:18:02,750 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'WinScaleSent: 7\n'}                                                                      2019-05-25 21:18:02,751 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'DupAcksOut: 0\n'}                                                                        2019-05-25 21:18:02,753 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'StartTimeUsec: 912688\n'}                                                                2019-05-25 21:18:02,754 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 5 (TEST_MSG) body = {u'msg': u'Duration: 10043341\n'}                                                                   2019-05-25 21:18:02,756 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 6 (TEST_FINALIZE) body = {u'msg': u''}                                                                                  2019-05-25 21:18:02,757 - AGENT - DEBUG - state = WAIT_FOR_TEST_MSG_OR_TEST_FINISH type = 3 (TEST_PREPARE) body = {u'msg': u''}                                                                                   2019-05-25 21:18:02,759 - AGENT - DEBUG - state = WAIT_FOR_TEST_START type = 4 (TEST_START) body = {u'msg': u''}                                                                                                   2019-05-25 21:18:02,760 - AGENT - DEBUG - state = WAIT_FOR_TEST_FINALIZE type = 6 (TEST_FINALIZE) body = {u'msg': u''}                                                                                             2019-05-25 21:18:02,762 - AGENT - DEBUG - state = WAIT_FOR_TEST_FINALIZE type = 8 (MSG_RESULTS) body = {u'msg': u'c2sData: 6\nc2sAck: 6\ns2cData: 0\ns2cAck: 0\n'}                                                2019-05-25 21:18:02,764 - AGENT - DEBUG - state = WAIT_FOR_TEST_FINALIZE type = 8 (MSG_RESULTS) body = {u'msg': u'half_duplex: 0\nlink: 100\ncongestion: 1\nbad_cable: 0\nmismatch: 0\nspd: 44.00\n'}             2019-05-25 21:18:02,765 - AGENT - DEBUG - state = WAIT_FOR_TEST_FINALIZE type = 8 (MSG_RESULTS) body = {u'msg': u'bw: 54.78\nloss: 0.000091962\navgrtt: 17.98\nwaitsec: 0.00\ntimesec: 10.00\norder: 0.0343\n'}   2019-05-25 21:18:02,767 - AGENT - DEBUG - state = WAIT_FOR_TEST_FINALIZE type = 8 (MSG_RESULTS) body = {u'msg': u'rwintime: 0.3911\nsendtime: 0.0024\ncwndtime: 0.6065\nrwin: 4.3545\nswin: 6.8054\n'}            2019-05-25 21:18:02,768 - AGENT - DEBUG - state = WAIT_FOR_TEST_FINALIZE type = 8 (MSG_RESULTS) body = {u'msg': u'cwin: 2.4463\nrttsec: 0.017981\nSndbuf: 891996\naspd: 0.00000\nCWND-Limited: 0.00\n'}           2019-05-25 21:18:02,770 - AGENT - DEBUG - state = WAIT_FOR_TEST_FINALIZE type = 8 (MSG_RESULTS) body = {u'msg': u'minCWNDpeak: 43330\nmaxCWNDpeak: 320642\nCWNDpeaks: 3\n'}                                        2019-05-25 21:18:02,771 - AGENT - DEBUG - state = WAIT_FOR_TEST_FINALIZE type = 9 (MSG_LOGOUT) body = {u'msg': u''}                                                                                            2019-05-25 21:18:02,773 - AGENT - DEBUG - All tests successfully completed.                                                     -- You received this message because you are subscribed to the Google Groups ""Support / Contact / Privacy"" group. To unsubscribe from this group and stop receiving emails from it, send an email to support+u...@measurementlab.net."	{}
150	fwd:-huge-inconsistency-between-google-speed-test-and-ndt7-client	1559216192.0	2019-05-30 04:36:32	roger peppe	"Hi,  I've been seeing very low bandwidth from Google's ""speed test"" results. As they say they're partnering with M-Lab, I built the ndt7-client program (trivial - yay for Go!) and ran that to try to find out a bit more about what's happening.  ndt7-client program consistently reports about 60Mbps down, 17Mbps up. Google speed test was reporting 2.7Mbps down, 17Mbps up.  The Google speed test is using the ""Dublin"" server (193.1.12.203), and ndt7-client reports that it's using ndt-iupui-mlab4-dub01.measurement-lab.org. The ""dub01"" makes me think that it might be an a similar location; it's also using IPv4. My ISP is TalkTalk.  Sorry if this is inappropriate for this list, but I wondered if someone might have some useful input here, especially as these results might be being recorded and taken as somehow representative.  Thanks very much for any thoughts you might have,     Roger Peppe."	"{0: {'username': 'Chris Ritzo', 'response_date': 'May 30, 2019, 4:54:39 AM', 'response_content': 'Hi Roger,  This type of question is absolutely appropriate and thanks for taking time to send it.   The Google search team did build an integration of our NDT test, so in this respect they are using M-Lab as a service to provide that test. Once we have completed our internal testing and roll-out of the new NDT server, we\'ll circle back to the search team to update their integration. Side note- if you\'re on this group and currently integrate NDT, and want to learn more about NDT7, please contact us.  Great to hear you are trying out ndt7-client! Both the Google test and the ndt7 client are being directed to use our servers in Dublin. M-Lab names our server pods by the nearest IATA airport code to the location, in this case DUB for Dublin. If there are more than one pod, they are numbered as well (i.e. dub01). Whether the test is conducted over IPv4 or IPv6 first depends on the network you are running from-- if you have an IPv6 address and our servers have IPv6 addresses, then the test will be over IPv6. In the server name you referred to, ndt-iupui-mlab4-dub01.measurement-lab.org, the ""mlab4"" part refers to the last of four servers in the pod, which are generally used for testing. Since NDT7 is still in testing, your ndt7-client is being directed there.   Thanks for testing ndt7-client! Other M-Lab team members may have more to share in this thread, or may be interested in the tests you\'re conducting with ndt7 under real world conditions. We\'re pleased to hear that it\'s measuring consistently for you!   Best regards, Chris - M-Lab Support \ue5d3'}, 1: {'username': 'roger peppe', 'response_date': 'May 30, 2019, 5:21:26 AM', 'response_content': 'Thanks very much for your swift reply. A bit more specific information in case it helps. I just ran ndt7-client, then ran a google speed test, then ran ndt7-client again. I\'ve attached the results of those two runs (min speed 57.4Mbps). In between the two runs, I got a google speed test result of 5.7Mbps down. After the second run, I ran google speed test again and got 12Mbps; then I just ran it again a moment ago and got 0.13Mbps.  Out of curiosity, I just started a google speed test, and then started ndt7-client while that was in progress. The google speed test started at about 0.5Mbps and continued at that level, but the ndt7-client results were showing at least 27Mbps (running at the same time!).  So it seems that google speed test is wildly inconsistent betwen runs, which I guess might equate to some throttling somewhere in the network, or... I\'ve no idea :)  Yesterday, I was seeing very low speeds to other providers such as Amazon EC2 us-east-1 region too, but I\'m not sure how much I can trust the measurement tool I was using (https://cloudharmony.com/speedtest-for-aws).  The slow speeds did seem to correspond with low speeds to other sites (I was struggling to run a Zoom video call, and other pages seemed slow to load), but I can\'t say for sure if there\'s any causal relation there.  I\'d be very interested to hear if there\'s anything more I can do to find out if there\'s a real issue here.    cheers,     rog.  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 2: {'username': 'Chris Ritzo', 'response_date': 'May 30, 2019, 5:47:58 AM', 'response_content': 'The google test is a javascript test, so depending on your browser and its handling of javascript, websockets, etc. this could explain the results you\'re seeing with that version. I know that the search team at Google has tested it extensively with Chrome, but perhaps less with other browsers.  In general, with respect to comparing speed tests (M-Lab\'s versus other platforms) I should also mention this recent blog post about NDT, speeds, and accuracy.  In any case, the second thing you mentioned was NDT7\'s measurement during the web-based test. It illustrates an important feature of the NDT7 client-- it uses BBR-based TCP flows to improve measurement performance in high-latency, high-bandwidth cases, and effectively implements a Model Based Metrics (MBM) approach to measurement. Quoting from the RFC: ""Model-Based Metrics rely on mathematical models to specify a Targeted IP Diagnostic Suite, a set of IP diagnostic tests designed to assess whether common transport protocols can be expected to meet a predetermined Target Transport Performance over an Internet path."" -- in other words, NDT7 uses MBM to effectively estimate the capacity of the entire end to end path, without having to flood the connection to congestion in order to do so.  Thanks again for testing it! --Chris \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3'}, 3: {'username': 'Livingood, Jason', 'response_date': 'May 30, 2019, 6:32:10 AM', 'response_content': 'Roger -- It’s also worth reading this recent paper: https://arxiv.org/abs/1905.02334   Chris – Is NDT7 still using a single TCP connection? The prior limitation to a single connection seemed to be one of the key issues that didn’t make it useful for contemporary throughput testing.   Jason \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}, 4: {'username': 'Chris Ritzo', 'response_date': 'May 30, 2019, 6:47:41 AM', 'response_content': 'Thanks for sharing a link to the paper, Jason. It certainly presents fair points about the current NDT version, though our own testing does show that the current version is useful for measuring bulk transport capacity using a single stream for connections with advertised links above 100Mbps. I\'ve seen measurements up to 800-900Mbps personally.  In any case, I enjoyed reading the paper as well.   NDT7 is using a single TCP connection, but as I understand it the measurements using BBR and MBM will measure more accurately than a multi-stream test. Most, if not all of the issues that you reference in the paper above are no longer issues with NDT7.  I can\'t speak to the detailed internals of NDT 7, so I think others on the team will add more information.   Best, Chris \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3'}, 5: {'username': 'Nick Feamster', 'response_date': 'May 30, 2019, 6:51:42 AM', 'response_content': 'I second Jason’s thoughts here.  The paper referenced below highlights the limitations not only of measuring with a single TCP connection, but also general limitations of any client-based speed test. Common limiting factors of such tests include home wireless connections, device hardware (e.g., the WiFi radio in your mobile device or tablet), and so forth. Another thing to watch out for is browser-based testing. Above several hundred Mbps, browser-based tests tend to be unreliable and inaccurate. Best-of-breed client-based tests such as Ookla have been steadily moving to native clients for this very reason. It’s unfortunate to see these outmoded tests still being used and promoted.  I’d recommend baselining using a router-based test, such as the BISmark one that we have developed (some modern routers, such as the Orbi, also incorporate the Ookla test directly into the router device; SamKnows is another example).  Unfortunately, NDT doesn’t account for any of these limitations, and I certainly would not rely on it as an accurate measure of access ISP capacity, especially for modern access networks. It would be great to see M-Lab adopt a more reliable, standard measurement method; hopefully NDT7 addresses some of these concerns, but rather than re-inventing the wheel, it would be nice to see the designers of NDT join the academic and industry conversations on this topic from Ookla, SamKnows, BISmark, and other groups. We’d make more progress by working together here.  If you’d like to learn more about device-based testing, I’d be happy to follow-up off-list. We’ve been designing such tests for nearly a decade now and would be happy to help you get more reliable and accurate measurements.    -Nick \ue5d3'}, 6: {'username': 'Chris Ritzo', 'response_date': 'May 30, 2019, 7:26:07 AM', 'response_content': 'Thank you, Nick. Great to have participation in our group from one of M-Lab\'s experiment review committee members!  As I mentioned in my reply to Jason, NDT7 does address all of the concerns addressed in your and Jason\'s paper. If you\'d like to test and confirm that yourself, the code repositories are all open and available. It would be great to see an update from you if you do decide to do that. I\'m not an engineer, so I\'ll again defer to my colleagues to respond to technical internals of NDT7 client and server. I\'ve asked at least one colleague to reply on this thread.  Thanks also for mentioning all the other speed tests out there, including BISmark, another M-Lab hosted test! I\'ve personally used BISmark in the past Nick, but can\'t seem to find the data it produces? Where can I find BISmark\'s raw data?  M-Lab encourages people to use as many tests as they think make sense for them. It\'s important to note their differences as well, and you paper outlines some of those differences. On the subject of Ookla and SamKnows, one thing I wonder about is their test methods and internals. Since both are closed source code and commercial products, perhaps, Nick, you have deeper insight into how their tests work and why you recommend them? I have tried both and agree they are quality products.   I also agree that using a standardized device connected to an ethernet port or running tests from the router itself eliminate many of the inconsistencies introduced by testing over WiFi as you mentioned. M-Lab is also doing this in smaller scale pilots, using similar low cost single board computers to automate tests.   To respond to your comment about engaging with the Internet Measurement Community, we actually do! Last year we invited all of our current test developers and the broader M-Lab community to our 10th anniversary event. Attendees included at least one of your peers in the academic community, and the original developer of NDT, with whom our team consulted before the rewrite of NDT server & client. We also regularly attend the TPRC conference, where many academics in the Internet measurement community present their research. It was my pleasure to attend last year and meet several of your peers and hear more about their work. Last year we were also sponsors of the annual Internet Measurement Conference, and coordinated a pre-conference workshop on mobile measurement specifically. We were also invited to attend CAIDA\'s 2018 AIMS workshop, but could not attend due to scheduling reasons. We\'ll be there this year though!   If you\'d like us to be involved in other conversations as you are with the FCC, FTC, and industry partners, we\'d be pleased to be there. As an M-Lab experiment review committee member, perhaps you could help ensure that an M-Lab representative is invited to be a part of those conversations and events. We\'d love to talk with you more about that off list.  Best regards, Chris     \ue5d3 \ue5d3 >>> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. >>> To post to this group, send email to dis...@measurementlab.net. >>> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. > -- > You received this message because you are subscribed to the Google Groups ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. > To post to this group, send email to dis...@measurementlab.net. > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. > > > -- > You received this message because you are subscribed to the Google Groups ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3'}, 7: {'username': 'Livingood, Jason', 'response_date': 'May 30, 2019, 7:26:35 AM', 'response_content': 'Thanks, Chris. What seems interesting is to consider further is whether BBR eliminates some of the TCP slow start and congestion control issues. It will be worth looking at that further. \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}, 8: {'username': 'Nick Feamster', 'response_date': 'May 30, 2019, 7:27:14 AM', 'response_content': ""> On May 30, 2019, at 9:47 AM, Chris Ritzo <cri...@measurementlab.net> wrote: > > Thanks for sharing a link to the paper, Jason. It certainly presents fair points about the current NDT version, though our own testing does show that the current version is useful for measuring bulk transport capacity using a single stream for connections with advertised links above 100Mbps. I've seen measurements up to 800-900Mbps personally. In any case, I enjoyed reading the paper as well. >  Is the test browser-based?  In any case, if the test is client based, then I suspect that the test will still face pretty much all of the limitations that we outline in the paper.  > NDT7 is using a single TCP connection, but as I understand it the measurements using BBR and MBM will measure more accurately than a multi-stream test.  Is there a paper on the method or experiments comparing the accuracy? I’d be curious to see the results, because this is certainly an unorthodox approach, and in my experience, a router-based test that uses multiple TCP connections is pretty darn accurate.  Out of curiosity: Why not simply adopt the industry and research-community accepted approaches? Why re-invent the wheel? It would presumably be more efficient to build on past experience and work with the community to adopt a standard. The rest of us are likely open to that.  Thanks! -Nick""}, 9: {'username': 'Matt Mathis', 'response_date': 'May 30, 2019, 7:30:23 AM', 'response_content': 'Jason, have you been following the BBR work?   As a transport protocol (real applications moving real data), single stream BBR is capable of filling huge pipes without creating large standing queues.  e.g. ""controlling to the knee"" at 10Gb/s * 100mS.  In these environments multistream BBR is less stable, because it needs large queues to signal between the flows in order to balance the bandwidth.  BBR TCP is different in that it constructs an explicit model for the network, which includes accurate estimates of the available capacity and min RTT, as well as measures queue memory size (only when small) and ACK compression/decimation.  One of the things on my queue is demonstrating that single stream BBR is more accurate than multi-stream CUBIC or Reno.  Jason & Nick do you remember my work on ""UCP unfriendly"" a decade ago?   The underlying root problem is that the algorithms traditionally used by TCP are out of scale and unstable in modern networks.  This adversely affects all applications, including measurement.   Multi-stream is a workaround for this scale problem.  BTW, BBR is Van\'s redo of Jacobson88, and everything we think we know about transport behavior is probably wrong, because all of our assumptions were derived from Jacobson88, which has some serious bugs.  We still have a lot of work to do, for one thing BBR is still a moving target, and our distro is pinned to a version of BBR that is slightly older than I would prefer.  Thanks, --MM-- The best way to predict the future is to create it.  - Alan Kay  We must not tolerate intolerance;        however our response must be carefully measured:              too strong would be hypocritical and risks spiraling out of control;             too weak risks being mistaken for tacit approval.  \ue5d3'}, 10: {'username': 'Nick Feamster', 'response_date': 'May 30, 2019, 7:43:16 AM', 'response_content': 'Hi Chris,  Unless I’m misunderstanding something, NDT7 still appears to be a client-based test, I don’t think NDT7 “addresses all of the concerns”, as most of them are fundamental limitations of client-based speed tests. In particular, how does the test cope for: (1) cross-traffic on the local network; (2) device limitations (including, but not limited to the limitations of the hardware radio of the device performing the tests); (3) WiFi interference and cross-fading; etc. ? I’m pretty sure all of these are going to remain concerns unless you intend to deploy the client in CPE.  I believe that M-Lab still hosts all of the BISmark data (thank you!), and it’s also on AWS and locally on our servers. Info at projectbismark.net. Let us know if you can’t find it and we’ll help you out. All of the code is also public on Github. In addition, we’ve now augmented the suite with application performance monitoring, as well as passive tests that infer application quality for many streaming video applications. Ultimately, as access network speeds increase, simply “maxing out the pipe” isn’t really a relevant metric anyhow. You’re most likely just measuring performance to M-Lab servers, in the best case scenario, and in other scenarios you may be measuring bottlenecks of the client software/hardware, home network, etc.  Indeed, I’m quite familiar with the Ookla speed test implementation and design and am certainly willing to vouch for their methods, subject to the limitations of client-based testing, of course. (Note that Ookla also recognizes these limitations has embedded their tests in commercial APs and home routers, which is the way to go.) Ookla has a description of their methods on their website which you can read... SamKnows, as you know, has also been quite open in the design of their methods, and in the early stages we provided a lot of input on their tests. Both of these tests, I will add, use multiple TCP connections to measure throughput. BISmark does, too. So does our mobile measurement test. Ours are open-source, as well. I think Comcast also has a test, although I know less about that one (although I do believe it also uses multiple TCP connection).  If you haven’t done any validation of NDT7 vs. Ookla, SamKnows, BISmark, etc. then I agree this is something to do. Might be careful about making claims about “more accurate” in the meantime, though…  -Nick \ue5d3 > >>> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. > >>> To post to this group, send email to dis...@measurementlab.net. > >>> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. > > -- > > You received this message because you are subscribed to the Google Groups ""discuss"" group. > > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. > > To post to this group, send email to dis...@measurementlab.net. > > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. > > > > > > -- > > You received this message because you are subscribed to the Google Groups ""discuss"" group. > > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. > > To post to this group, send email to dis...@measurementlab.net. > > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. > > > -- > You received this message because you are subscribed to the Google Groups ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}, 11: {'username': 'Livingood, Jason', 'response_date': 'May 30, 2019, 7:43:44 AM', 'response_content': ""> As I mentioned in my reply to Jason, NDT7 does address all of the concerns addressed in your and Jason's paper.   (as Nick said) Technically it may just address the issues with a single TCP stream, so performance relative to other web-based sorts of tests as well as native client tests. But all of those sorts of tests are still burdened with self-selection bias, low sampling rates, no knowledge of concurrent uses of the network, and are affected by WiFi and other client limitations.   In any case, I look forward to kicking the tires on the new NDT7 test! Thanks for the info.   Jason  ""}, 12: {'username': 'Nick Feamster', 'response_date': 'May 30, 2019, 7:43:49 AM', 'response_content': 'Hi Matt,  This is interesting; I read the paper and taught BBR in my course this year, although I cannot really claim deep experience (yet).  If there is a good way to experiment with BBR, I’d like to follow up offline. It sounds like perhaps the NDT7 client is the way to do that? Perhaps we can follow up offline in more detail. I think it is worth doing some detailed experiments and comparisons and I’d be glad to engage on that with you and others.  -Nick \ue5d3'}, 13: {'username': 'Chris Ritzo', 'response_date': 'May 30, 2019, 7:47:33 AM', 'response_content': 'Hi Nick, I\'ll have to defer to Matt and others on the team with these questions, and happy to arrange a time with you to meet with the team on this as well. The team is QA testing now and we\'ve discussed comparisons with Speedtest and potentially others, but perhaps this is something to collaborate on with you?   On the BISmark data, I\'ll follow up with you on another thread. I think that the data is not yet in GCS with our other test data.  Best, Chris \ue5d3 \ue5d3 > >>> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. > >>> To post to this group, send email to dis...@measurementlab.net. > >>> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. > > -- > > You received this message because you are subscribed to the Google Groups ""discuss"" group. > > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. > > To post to this group, send email to dis...@measurementlab.net. > > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. > > > > > > -- > > You received this message because you are subscribed to the Google Groups ""discuss"" group. > > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. > > To post to this group, send email to dis...@measurementlab.net. > > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. > > > -- > You received this message because you are subscribed to the Google Groups ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3'}, 14: {'username': 'Nick Feamster', 'response_date': 'May 30, 2019, 7:59:01 AM', 'response_content': 'I should add that as our paper is a draft, once we learn more, we can certainly update the paper to discuss NDT7...  -Nick  > On May 30, 2019, at 10:56 AM, Nick Feamster <feam...@CS.Princeton.EDU> wrote: > > Yes, I’d enthusiastically collaborate with you folks on this. For me, it will be a learning experience about BBR, which would be welcome! > > BISmark: yes, let’s follow up offline. We can fix. > > -Nick \ue5d3 >>>>>> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. >>>>>> To post to this group, send email to dis...@measurementlab.net. >>>>>> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. >>>> -- >>>> You received this message because you are subscribed to the Google Groups ""discuss"" group. >>>> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. >>>> To post to this group, send email to dis...@measurementlab.net. >>>> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. >>>> >>>> >>>> -- >>>> You received this message because you are subscribed to the Google Groups ""discuss"" group. >>>> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. >>>> To post to this group, send email to dis...@measurementlab.net. >>>> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. >>> >>> >>> -- >>> You received this message because you are subscribed to the Google Groups ""discuss"" group. >>> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. >>> To post to this group, send email to dis...@measurementlab.net. >>> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. >> >> >> -- >> You received this message because you are subscribed to the Google Groups ""discuss"" group. >> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}, 15: {'username': 'Nick Feamster', 'response_date': 'May 30, 2019, 7:59:01 AM', 'response_content': 'Yes, I’d enthusiastically collaborate with you folks on this. For me, it will be a learning experience about BBR, which would be welcome!  BISmark: yes, let’s follow up offline. We can fix.  -Nick \ue5d3 > > >>> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. > > >>> To post to this group, send email to dis...@measurementlab.net. > > >>> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. > > > -- > > > You received this message because you are subscribed to the Google Groups ""discuss"" group. > > > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. > > > To post to this group, send email to dis...@measurementlab.net. > > > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. > > > > > > > > > -- > > > You received this message because you are subscribed to the Google Groups ""discuss"" group. > > > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. > > > To post to this group, send email to dis...@measurementlab.net. > > > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. > > > > > > -- > > You received this message because you are subscribed to the Google Groups ""discuss"" group. > > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. > > To post to this group, send email to dis...@measurementlab.net. > > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. > > > -- > You received this message because you are subscribed to the Google Groups ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}, 16: {'username': 'Matt Mathis', 'response_date': 'May 30, 2019, 4:47:14 PM', 'response_content': ""One of the cool things about ndt7 is that the main client version was Dockerized from the very beginning.   Thus it is a no brainer to create an ndt7 autotest image that will run on any CPE running a modern OS.  (Getting global load regulation right requires some engineering that we have not done yet, but it is on our roadmap).  The really powerful thing about Docker is that it completely decouples measurement SW version management from platform SW and HW version management.   This scales way better than integrating measurement tools into other peoples stacks and build environments.  A cool idea (that is NOT on our roadmap) would be a meta tool to compare CPE, prefix neighbors and client device performance measurements.    This might be the ultimate tool to re-educate people who blame their ISP because they are expecting too much from their home WiFi swamps.  I am already talking to Steve Bauer about reconstructing some of his experiments using NDT7.  We will not make any claims that we can't document.  I will provide pointers once we have resolved some of the things that obviously don't look right.  What is the timeline for your paper?   Thanks, --MM-- The best way to predict the future is to create it.  - Alan Kay  We must not tolerate intolerance;        however our response must be carefully measured:              too strong would be hypocritical and risks spiraling out of control;             too weak risks being mistaken for tacit approval.  \ue5d3""}}"
151	proper-mlab-citation	1559075326.0	2019-05-28 13:28:46	Glenn Fishbine	In putting MLAB data in the public domain, what is the appropriate citation to credit MLAB with the data?	"{0: {'username': 'Chris Ritzo', 'response_date': 'May 28, 2019, 1:32:31 PM', 'response_content': 'Hi Glenn,  We generally leave the citation format up to you (MLA, APA, etc.), but also have recommended citation formats on the page for each test we host. For example, on the NDT page we suggest: ""Please cite this data set as follows: The M-Lab NDT Data Set, <date range used> https://measurementlab.net/tests/ndt""  Best, Chris - M-Lab Support \ue5d3'}}"
152	asn-information-in-base_tables.ndt	1558970521.0	2019-05-27 08:22:01	John Parks	"Hey there!  Trying to figure out what is going on with ASN data in base_tables.ndt table in the measurements-lab NDT data. Still pretty new with Big Query but I'm confused at what I'm seeing:    ^ screenshot of the base_tables.ndt schema, looks like the ASN is there.   ^ disabled columns with no data when querying the most recent data from table.  Looks like you guys either pushed this out, or are in the process: https://www.measurementlab.net/blog/visualization-site-update/ - Last section of the blog post covers ASNs - ""will be able to get that with a single query to our dataset"" https://github.com/m-lab/annotation-service/issues/223 - Looks like it's been added to the annotation-service https://github.com/m-lab/etl-schema/pull/17 - Looks like the column has been added to the schema I think I may be jumping the gun and it's just not out there yet.  Thanks for any help clearing up the confusion =)  - John"	"{0: {'username': 'Chris Ritzo', 'response_date': 'May 27, 2019, 1:58:37 PM', 'response_content': 'Hello John, Thanks for emailing the group with this question.   Yes, as of early May 2019, ASN is now a field in the NDT dataset. The annotation service now adds this field for newly collected test data and our gardener service reprocesses historical data. Two ASNs are now annotated for each test row: client and server ASN. For client, the field is `connection_spec.client.network.asn` and identifies the client source ASN based on the client IP address. The other ASN field is `connection_spec.server.network.asn` which is the ASN that our server is connected to.  We now recommend using the views in the NDT dataset, such as: `measurement-lab.ndt.recommended`. You can read more about recent table and schema changes in this blog post: https://www.measurementlab.net/blog/bq-datasets/  I hope this helps.  Best, Chris - M-Lab Support \ue5d3'}, 1: {'username': 'John Parks', 'response_date': 'May 27, 2019, 2:09:31 PM', 'response_content': ""Bingo!  Looking at the right view/dataset was it - thanks for clearing that up.  Thanks for everything you guys do! This is an amazing public service, and I can't express how excited I was to find M-Lab in regards to my research =)  Cheers! - John \ue5d3""}}"
153	asns-in-bigquery	1558970521.0	2019-05-27 08:22:01	Glenn Fishbine	I'm probably looking at the wrong reference documents.  I can find client and server IP, but I can't seem to find the ASN field.  Am I blind, am I looking in the wrong place, or is it simply not there?  I can do a lookup, but it would be nice to add a group by ASN in the initial query.  Thank you	"{0: {'username': 'Chris Ritzo', 'response_date': 'May 27, 2019, 2:02:17 PM', 'response_content': ""Hi Glenn, Thanks for emailing the group with this question. One reason it's difficult to find in the documentation at the moment is that we're due to update some of our docs after recently enabling new fields and parts of the schema as described in this blog post: https://www.measurementlab.net/blog/bq-datasets/   As of early May 2019, ASN is now a field in the NDT dataset. The annotation service now adds this field for newly collected test data and our gardener service reprocesses historical data. Two ASNs are now annotated for each test row: client and server ASN. For client, the field is `connection_spec.client.network.asn` and identifies the client source ASN based on the client IP address. The other ASN field is `connection_spec.server.network.asn` which is the ASN that our server is connected to.  I hope this helps.  Best, Chris - M-Lab Support \ue5d3""}}"
154	open-internet-engineering-fellowship	1558883020.0	2019-05-26 08:03:40	Georgia Bullen	Hi M-Lab discuss!  Mozilla, ISOC, and NSRC are launching a new fellowship program: https://medium.com/read-write-participate/fellowships-were-seeking-open-internet-engineers-66eed422cc28  More info: https://foundation.mozilla.org/en/fellowships/open-internet-engineers/  Application: https://mozilla.fluxx.io/apply/fellowship  LOI Deadline: Thursday, May 30, 2019 3 pm EDT Full App Deadline: Monday, June 10, 2019, 3 pm EDT  Open Internet Engineering fellows will undertake transformative infrastructure-building projects in countries with low internet penetration. These engineers will work with technical organizations to ensure efficient and affordable internet transit based on open standards and software.  Apply if you are interested, share with your networks  -Georgia	{}
155	dramatic-download-variance-between-test-sites	1558731020.0	2019-05-24 13:50:20	David Petty	I am consistently seeing the following results between two testing sites:  Mlabs-   Download - .65-.75 Mbps  Upload - 8-9 Mbps  Ookla-  Download - 25-27 Mbps  Upload - 10-11 Mbps  I can understand the slight difference between the upload speeds based on previous threads, but the download speeds don't make any sense to me. Does anyone have an explanation. Thank you in advance.	"{0: {'username': 'Chris Ritzo', 'response_date': 'May 24, 2019, 1:55:00 PM', 'response_content': ""Hello David,  The reason you're seeing the difference is that though M-Lab returns the same metrics as Ookla, our platform and test architectures are different. This FAQ describes those differences: https://www.measurementlab.net/faq/#why-are-my-m-lab-results-different-from-other-speed-tests  M-Lab considers both to be valid results and useful for understanding your connection performance to both the edge of your ISP's networks where Ookla servers are typically located, and its performance beyond the ISP edge into the peering points where ISPs connect their networks to one another.   We've also written a recent blog post that describes the issues of measuring speed more generally, with some specifics as well: https://www.measurementlab.net/blog/speed-tests-accuracy/  I hope this helps answer your question.  Best regards, Chris - M-Lab Support \ue5d3""}}"
156	mlab-city-names	1558479400.0	2019-05-21 15:56:40	Glenn Fishbine	I'm working with U.S. and Canadian Census data and find that about 1/4 f the U.S.  and 1/2 of the Canadian city names simply do not match between the Mlab city and the corresponding Census city (U.S. & Canada).  I can work with partial data sets, and I can grab the latitude/longitude and make a good guess as to which city it really belongs to, but I can't believe Mlab's data is created by a random name generator.  Surely there is a list of cities out there that maybe can be cross referenced to the real city names?  Any hints please?  Also, for places like Quebec, I see that none of the french accent marks are in the bigquery data content.  I was kinda hoping there's be some language considerations, and I can work around that as well.  So recap questions: 1.  Where does the Mlab city list come from?  If I discover that, I may be able to create a concordance once I now how they define cities. 2.  What are the language types used to store fields in bigquery?  i.e.  I suggest they be updated to a UTF type.  Hoping for answers before I build a two-map side by side manual exception correction system.  :)  By the way, fantastic content and wonderful that it's so easily accessible.	"{0: {'username': 'Peter Boothe™', 'response_date': 'May 22, 2019, 7:37:01 AM', 'response_content': 'It is definitely not created by a random name generator :). The city names come from our IP geolocation system, which is based on MaxMind. To your questions specifically: M-Lab\'s city names come from MaxMind - https://dev.maxmind.com/geoip/geoip2/geolite2/  The datatype used to store place names in BigQuery is the bq STRING type, which is UTF-8, so if MaxMind has accents, then so should M-Lab\'s data. So that\'s M-Lab\'s geographic source of truth. Hopefully now that you know about it, it will be easier to get the names into the form that works best for you.    -Peter  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.   -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful. Peter Boothe - Coder at Google, working in support of M-Lab'}, 1: {'username': 'Glenn Fishbine', 'response_date': 'May 24, 2019, 1:49:52 PM', 'response_content': 'Excellent!   thank you!!! \ue5d3 -- Glenn Fishbine C:  612 387 7536 w:  http://www.breakingpointsolutions.com'}}"
157	naming-bq-datasets-after-m-lab-measurement-services-&-data-types	1557931273.0	2019-05-15 07:41:13	Chris Ritzo	Greetings M-Lab community members:  We recently published a blog post outlining our work to unify the naming of M-Lab datasets in BigQuery to match the measurement services and data types for each dataset.  These changes will require you to update any queries you use or that are used within applications or services you produce. Please read on for a brief summary or refer to the blog post for complete details.   Going forward, datasets in the measurement-lab project will be named for each measurement service, and views within each dataset will contain data relevant to that service.  Below is a summary of upcoming changes: For each measurement service (ndt, traceroute, sidestream, utilization), we will create a corresponding BigQuery dataset and view in the measurement-lab project that are managed by our data reprocessing service (a.k.a. Gardener). The current views for release candidates, versioned intermediate tables, and releases will remain unchanged as we migrate them to the per-measurement service dataset. LegacySQL support will be deprecated. We may keep a single LegacySQL view of the legacy data, but only support StandardSQL in any new views of the comprehensive reprocessed data. We will no longer offer any views that combine legacy tables and recently parsed data. The current release convention supports a hierarchy of releases, release candidates “rc”, versioned release candidates, and versioned intermediate views. For now, these will remain unchanged until June 1, 2019. However, they will cease being updated with new data starting May 6, 2019. As we validate the output from Gardener, and retire the contents of legacy tables, new releases and release candidates views will be migrated to the corresponding dataset.  If you have any questions please contact us at sup...@measurementlab.net  -- Chris Ritzo Measurement Lab Support sup...@measurementlab.net	{}
158	neubot	1519182645.0	2018-02-20 20:10:45	kinga Farkas	Is M-Lab still collecting Neubot data?  I cannot seem to find any Neubot data after 06/2017.   Thanks,  Kinga	"{0: {'username': 'Simone Basso', 'response_date': 'Feb 21, 2018, 1:46:21 AM', 'response_content': 'I think you are using the old bucket. You should now use:      https://console.cloud.google.com/storage/browser/archive-mlab-oti/?pli=1  Simone  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': 'Amreesh Phokeer', 'response_date': 'Apr 3, 2019, 10:54:48 AM', 'response_content': 'Hello Simone,  I saw on the Neubot client retirement blog post, that there is an intention to continue the DASH measurement project on the new M-Lab platform. <http://www.neubot.org/2019/01/retiring-neubot-client.html>  I\'m currently looking into running video performance measurement from end-user devices and thought I should ask you, if you know of any project tool that could help.  Thanks, --  Amreesh Phokeer  On Wed, Feb 21, 2018 at 12:46 PM Simone Basso <basso...@gmail.com> wrote: I think you are using the old bucket. You should now use:      https://console.cloud.google.com/storage/browser/archive-mlab-oti/?pli=1  Simone Il 21 Feb 2018 4:10 AM, ""kinga Farkas"" <kinga....@gmail.com> ha scritto: Is M-Lab still collecting Neubot data?  I cannot seem to find any Neubot data after 06/2017.   Thanks,  Kinga -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.   -- Amreesh Phokeer'}}"
159	bq-fails-to-filter-by-longitude?	1553644907.0	2019-03-26 17:01:47	e...@ucsb.edu	Hi group, I expected to be able to pull out a rectangle of basic network measurements around Los Angeles with the following query:  SELECT  8 * (web100_log_entry.snap.HCThruOctetsAcked /     (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd)) AS download_Mbps,     8 * (web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration) AS upload_Mbps,     web100_log_entry.connection_spec.remote_ip  AS remote_ip,     web100_log_entry.log_time AS time,     connection_spec.client_geolocation.latitude AS latitude,     connection_spec.server_geolocation.longitude AS longitude FROM `measurement-lab.release.ndt_downloads` WHERE connection_spec.client_geolocation.longitude < -116.28 AND connection_spec.client_geolocation.longitude > -118.58 AND connection_spec.client_geolocation.latitude > 33.68 AND connection_spec.client_geolocation.latitude < 34.47  But the returned points include longitudes from all around the world. The result is a long strip of points bounded by the correct latitudes but reaching worldwide.  I can filter out the points I need in QGIS, but I'd rather get the query right and not download thousands of extra entries. What's wrong with my query? Or does BQ somehow count longitudes as wrapping around, so that positive longitudes are considered less than negative longitudes? What is going on?  Regards, Esther	"{0: {'username': 'Chris Ritzo', 'response_date': 'Mar 26, 2019, 5:11:55 PM', 'response_content': 'Hi Esther,  Thanks for posting to the list. The reason you\'re getting some results that shouldn\'t be within your bounding box query has to do with inaccuracies in the geolocation of some IP addresses. M-Lab uses IP based geolocation to annotate test records with latitude, longitude, and other client geolocation fields, but the method has some limitations and inaccuracies. I\'ve found that the best bet is to remove these entries in your data cleaning process. You might also try a location base query using client_geolocation.city = ""Los Angeles"" or a combination of country = US, region = CA, and city = Los Angeles. This will return fewer records but will likely have fewer incorrectly geolocated results.  Hope this helps.  Best, Chris - M-Lab Support'}, 1: {'username': 'Esther Showalter', 'response_date': 'Apr 3, 2019, 5:16:03 AM', 'response_content': 'Thank you! So the query was right but my label was showing the server longitude. I\'m actually amazed that there are so many clients querying servers along their same latitude strip.   Regards, Esther  On Tue, 26 Mar 2019, 17:55 Peter Boothe ¶, <pbo...@google.com> wrote: On Tue, Mar 26, 2019, 8:01 PM <e...@ucsb.edu> wrote: Hi group, I expected to be able to pull out a rectangle of basic network measurements around Los Angeles with the following query:  SELECT  8 * (web100_log_entry.snap.HCThruOctetsAcked /     (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd)) AS download_Mbps,     8 * (web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration) AS upload_Mbps,     web100_log_entry.connection_spec.remote_ip  AS remote_ip,     web100_log_entry.log_time AS time,     connection_spec.client_geolocation.latitude AS latitude,     connection_spec.server_geolocation.longitude AS longitude FROM `measurement-lab.release.ndt_downloads` WHERE connection_spec.client_geolocation.longitude < -116.28 AND connection_spec.client_geolocation.longitude > -118.58 AND connection_spec.client_geolocation.latitude > 33.68 AND connection_spec.client_geolocation.latitude < 34.47  But the returned points include longitudes from all around the world. The result is a long strip of points bounded by the correct latitudes but reaching worldwide.  You have ""connection_spec.server_geolocation.longitude AS longitude"" in your query, but it sounds like you want it to be ""connection_spec.client_geolocation.longitude AS longitude"" instead.     -Peter  I can filter out the points I need in QGIS, but I\'d rather get the query right and not download thousands of extra entries. What\'s wrong with my query? Or does BQ somehow count longitudes as wrapping around, so that positive longitudes are considered less than negative longitudes? What is going on?  Regards, Esther -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 2: {'username': 'Peter Boothe ¶', 'response_date': 'Apr 3, 2019, 5:16:03 AM', 'response_content': 'On Tue, Mar 26, 2019, 8:01 PM <e...@ucsb.edu> wrote: Hi group, I expected to be able to pull out a rectangle of basic network measurements around Los Angeles with the following query:  SELECT  8 * (web100_log_entry.snap.HCThruOctetsAcked /     (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd)) AS download_Mbps,     8 * (web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration) AS upload_Mbps,     web100_log_entry.connection_spec.remote_ip  AS remote_ip,     web100_log_entry.log_time AS time,     connection_spec.client_geolocation.latitude AS latitude,     connection_spec.server_geolocation.longitude AS longitude FROM `measurement-lab.release.ndt_downloads` WHERE connection_spec.client_geolocation.longitude < -116.28 AND connection_spec.client_geolocation.longitude > -118.58 AND connection_spec.client_geolocation.latitude > 33.68 AND connection_spec.client_geolocation.latitude < 34.47  But the returned points include longitudes from all around the world. The result is a long strip of points bounded by the correct latitudes but reaching worldwide. You have ""connection_spec.server_geolocation.longitude AS longitude"" in your query, but it sounds like you want it to be ""connection_spec.client_geolocation.longitude AS longitude"" instead.     -Peter  I can filter out the points I need in QGIS, but I\'d rather get the query right and not download thousands of extra entries. What\'s wrong with my query? Or does BQ somehow count longitudes as wrapping around, so that positive longitudes are considered less than negative longitudes? What is going on?  Regards, Esther -- \ue5d3'}}"
160	m-lab-is-moving!	1551379399.0	2019-02-28 11:43:19	Chris Ritzo	Greetings M-Lab Community!  After a decade of growth at New America’s Open Technology Institute, Measurement Lab will join Code for Science & Society’s Sponsored Projects Program on March 1, 2019. Since our launch in 2008, M-Lab has worked in the public interest to measure internet performance around the world and share measurement data openly. This work will continue at our new institutional home.  Measurement Lab comes to Code for Science & Society after recently celebrating its tenth anniversary at New America’s Open Technology Institute. The M-Lab community and team are thankful for the supportive home that OTI has long provided, but are also excited to join the family of projects at Code for Science & Society, an organization purpose-built for hosting large open source public interest tech projects.   Code for Science & Society, the new host of Measurement Lab’s operations, is a small nonprofit dedicated to advancing open technologies in the public interest. They work with partners across research, civic technologies, and new media to support the growth and sustainability of the public interest tech ecosystem.  M-Lab’s work will continue to be supported by a consortium of research, industry, and public interest partners including OTI, focused on fostering, collecting, and publishing open internet data. M-Lab will also continue to collaborate with organizations all over the world to build out the internet measurement platform, do research and data studies, and inform policy work by regulators, policymakers, and advocacy organizations.   The M-Lab Discuss group has served the dual purposes of providing a community discussion channel and serving as a whitelist for providing free query access to M-Lab data. In the short term that will remain unchanged, but in the coming months we will be working on new ways to support, discuss, and communicate with you, so please look for communications from us about upcoming changes and new resources.   If you have any ideas of things you would like us to do more of, e.g. blog posts, data trainings, regular community calls or individual check-ins, events, let us know — we’d love to hear your ideas!  Thanks for being part of the M-Lab community!  -- Chris Ritzo Measurement Lab Support sup...@measurementlab.net	{}
161	i-think-m-lab-testing-methods-are-poor	1547565146.0	2019-01-15 08:12:26	C W	I have run 11 internet speed tests, and this one from M-Lab is the only one that is consistently an outlier.  Your FAQs indicate that others use different testing methods.  While true, it appears that if you are the only outlier, your testing methods are the ones that are off.  Of the 11 tests I ran, 10 (non M-Lab) tests gave values of download speed between 65 and 70, while the M-Lab test consistently gives results between 1.74 and 8 Mb/s. I checked the other tests to ensure that the same units were being used, all were using megabits per second.  I do not claim to know how all this works, but it seems that running the test through a server halfway across the country may be part of the problem.  I am in central Colorado and the server used was in Los Angeles.  	{}
162	handicapped-by-geographic-location	1545261760.0	2018-12-19 16:22:40	Mark Kneen	Hi, My ISP is in the Isle of Man and its main transit links are based in London. However, the tests i do to mlab are always through Dublin. (MLAB chooses the closest geographic location) This would mean my test traffic is first going to London, then to Dublin. Is there way to ensure the test is done from London, not Dublin so that a more accurate test can be ran? Mark	{}
163	m-lab-hardware-probes?	1544987171.0	2018-12-16 12:06:11	Ron Dallmeier	I am curious if anyone has deployed small inexpensive hardware probes (maybe something like Raspberry Pi, Arduino or similar) that run periodic NDT speed-tests and if there are a significant numbers of these out there? If so, can these be found via connection_spec.client fields, any links to firmware builds, etc?  ...Ron	"{0: {'username': 'Livingood, Jason', 'response_date': 'Dec 19, 2018, 11:22:48 AM', 'response_content': 'If you are interested in a speed test, especially with a hardware probe, you’ll want to look beyond NDT. A few years ago we had challenges using Rasperry Pi or Banana Pi to test 1 Gbps+ speeds, due to NIC, memory, and CPU limitations at that time. We had better luck using ODRIOD and running iperf or on other platforms using some open source speed test software the team wrote (https://github.com/Comcast/Speed-testJS). And of course the SamKnows whiteboxes are pretty reliable – though I think at 1 Gbps and beyond there are some open question.   Jason \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': 'Nick Feamster', 'response_date': 'Dec 19, 2018, 12:29:37 PM', 'response_content': ""Ron,  We have such a deployment and would be happy to help out if you are interested in chatting more.  I second Jason's recommendation on Odroid for hardware. We are currently using Odroid C2 hardware and are doing passive and active measurements up to 1 Gbps.  As far as a speed test, I wholeheartedly agree with the recommendations below. We run this in our deployment, which we developed: https://github.com/projectbismark.  I would absolutely not use NDT for a speed test, especially if you’re interested in testing above 100 Mbps. Approaching gigabit speeds, things are much trickier in terms of both testing and the hardware itself, and we had the same problems with RPi/BPi, and much better luck with the Odroid devices.  Off hand, another thing you may be interested in looking into are metrics beyond “speed tests”, including application quality. To that end, we hav e developed some passive monitoring software to measure the quality of streaming video apps (e.g., Netflix, Facebook, YouTube, Hulu, etc.). We’d be happy to help you with that deployment if you’re interested in application QoE. We haven’t tried the Comcast speed test on our box, but that would be an easy thing to try and/or add to our existing suite of measurements.  -Nick \ue5d3""}}"
164	performance-of-cuba's-new-3g-mobile-network	1544901854.0	2018-12-15 12:24:14	Larry press	Cuba is belatedly rolling out a UMTS 900 900 Mhz 3G mobile network.  Anecdotal reports range between 500 Kbps and 1 Mbps  Assuming no congestion at the base station, what ranges of speed and latencies could they expect?  What would be typical performance?	"{0: {'username': 'Peter Heinzmann', 'response_date': 'Dec 16, 2018, 3:02:13 AM', 'response_content': 'Here are results from people who used the cnlab speedtest https://play.google.com/store/apps/details?id=ch.cnlab.speedtest .  In Switzerland. We do not have many 3G measurements nowadays, most tests are with 4G.  The median speeds i.e. the speed which was reached by 50% of the tests are as follows:  Download: 3G   4Mbit/s,   4G   28Mbit/s Upload:     3G   1Mbit/s,    4G    4Mbit/s  These resulats are from tests for MCC=228 i.e. Switzerland between 16-12-2017 and 16-12-2018: 3G:  16\'942 Measurements by 1\'762 Devices    4G:  202\'500 Measurement by 19\'660 Devices  If we look at the results from the last three months the 4G Upload Data Rate is up to 4 Mbit/s. All other values are more constant over the last year.  Here is the cumulative upload and download speed distribution for 3G:   This gives an idea about ""typical performance"" with 3G. \ue5d3'}}"
165	data-use-as-regional-timeseries	1542908136.0	2018-11-22 10:35:36	Kyle Lillie	I'd like input on how practical it would be to use this data to create a regional time series representing average municipal download and upload speeds? On https://regionaldashboard.alberta.ca/#/explore-an-indicator?i=average-download-speed&d=CalculatedValue we have some old data taken from speedtest.net when it was publicly available and would like to have some updated figures.  If speed isn't a good measure to derive, are the other stats that would work better? Thanks.	"{0: {'username': 'Chris Ritzo', 'response_date': 'Nov 26, 2018, 8:26:36 AM', 'response_content': 'Hello Kyle,  M-Lab\'s data is certainly suitable for what you\'re thinking about. If you need assistance accessing the data, please refer to our documentation, or contact us at sup...@measurementlab.net  Best regards, Chris -- Chris Ritzo Measurement Lab Operations & Support o...@measurementlab.net | sup...@measurementlab.net  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
166	'average-connection-speeds'	1541546761.0	2018-11-06 16:26:01	hanadis...@gmail.com	I looking for the variable related to measuring the 'Average connection speeds' in middle east countries ,and I think you have these data for these countries.  Please advice me as soon as possible.	"{0: {'username': 'Chris Ritzo', 'response_date': 'Nov 7, 2018, 3:38:07 PM', 'response_content': 'Good day,  In the M-Lab NDT dataset, there is not a single variable that makes up ""average connection speed"", or even download speed or upload speed. Instead, you may calculate these using individual fields as described on our page, Calculating Common Metrics.  For example, if you wanted to get Download speed in Mbps, you would use this formula in your query:  #standardSQL SELECT   8 * (web100_log_entry.snap.HCThruOctetsAcked /     (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd)) AS download_Mbps FROM   `measurement-lab.release.ndt_downloads` ...  And if you wanted to get Upload speed in Mbps:   #standardSQL SELECT  8 * (web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration) AS upload_Mbps FROM   `measurement-lab.release.ndt_all` ...  Then to the question of averages, and other mathematical functions. As you construct queries to aggregate data, in averages, medians, quantiles, etc. or group by fields, such as country, please refer to Google\'s BigQuery reference documentation.  In your inquiry, average download and average upload speeds grouped by country require both using the AVG function, and GROUP BY statements in your queries. You will need to run two queries, one for download speeds and one for upload speeds.   Here is a basic example returning average download speeds per country for all M-Lab tests since 2009:  #standardSQL SELECT  connection_spec.client_geolocation.country_name AS country, AVG(8 * (web100_log_entry.snap.HCThruOctetsAcked /    (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd))) AS average_download_mbps FROM `measurement-lab.release.ndt_downloads` GROUP BY country ORDER BY country  And here is the query returning average upload speeds per country for all M-Lab tests since 2009:  #standardSQL SELECT  connection_spec.client_geolocation.country_name AS country, AVG( 8 * (web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration)) AS average_upload_mbps FROM `measurement-lab.release.ndt_uploads` GROUP BY country ORDER BY country  Please note that I\'m querying different BigQuery views for upload and download tests. You may also wish to return additional fields, or apply a WHERE statement limiting your results to specific date ranges.   I hope this helps with your research.  Best regards, Chris  -- Chris Ritzo Measurement Lab Operations & Support o...@measurementlab.net | sup...@measurementlab.net   On Tue, Nov 6, 2018 at 6:26 PM <hanadis...@gmail.com> wrote: I looking for the variable related to measuring the \'Average connection speeds\' in middle east countries ,and I think you have these data for these countries.  Please advice me as soon as possible.   -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
167	recent-traceroutes	1535965557.0	2018-09-03 02:05:57	Lars Prehn	Hi all,  is there any way to query for all traceroutes between the 16th. Mai 2019 and the 19th. Mai 2018 (included)?  I tried the public traceroutes but every query with log_time >= '2018-04-00 00:00:00' returns 0 results :S  Best regards, Lars 	"{0: {'username': 'Chris Ritzo', 'response_date': 'Nov 7, 2018, 3:10:05 PM', 'response_content': 'Hello Lars, We were reviewing recent discuss group posts that had not received replies this week. Sorry that we or others haven\'t replied as yet.  It is certainly possible to query for all traceroutes within a date range. However, our development team is currently working on our service that does quality assurance, re-publication, an re-annotation for historical data for Paris Traceroute. This is affecting access to Paris Traceroute data in our BigQuery tables prior to 2018-07-25. New data for the tool continues to be published in `measurement-lab.base_tables.traceroute`. We also have some additional development happening toward replacing Paris Traceroute, resulting from issues identified earlier this year.  In any case, I apologize for the inconvenience. If you or others need to examine Paris Traceroute data prior to 2018-07-25, we suggest using the archived raw data in GCS.  Best regards, Chris -- Chris Ritzo Measurement Lab Operations & Support o...@measurementlab.net | sup...@measurementlab.net    \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
168	broadband-cooperative---data-deep-dive	1537993702.0	2018-09-26 13:28:22	Jason Weaver	Hello  I am consulting with a newly formed Broadband Cooperative and we are looking to use this data to map out un-served or under-served homes in six counties of South Central Pa.   In the description for the ndt-ws test it indicates that the test pulls geo data. How accurate is the Geo Data being provided? Is the data available as part of the data set that is publicly available? Are there any scripts available that can be deployed an a wordpress site that will assist us in tying the results of a test to a contact with an address?  Thank you advance for your advice.	"{0: {'username': 'Chris Ritzo', 'response_date': 'Nov 7, 2018, 5:51:11 AM', 'response_content': 'Hi Jason,  Thanks for sending this inquiry and our apologies for the delay in replying.   M-Lab uses is from the openly available Maxmind Geolite 2 databases to annotate geographic fields for our NDT client tests. Maxmind includes an accuracy radius for it\'s IP address geo-location database. In short, the geo data is as accurate as the Maxmind dataset. We don\'t have anything like a wordpress plugin at the moment, but if you\'re interested in more accurate Geo Location associated with test results, there are some options. A number of cities [1] and other municipal areas [1] have been using an open source web app called Piecewise to host a survey form, the NDT speed test, and map aggregate statistics for a chosen geographic region. In Pennsylvania, there is currently a broadband testing initiative through the legislature\'s Center for Rural PA. These initiatives submit standard M-Lab tests, which are later annotated as described above, but the website integration separately saves more accurate geo-location using HTML5 in a private, non-M-Lab hosted dataset.  If you have any questions about these initiatives please don\'t hesitate to ask, or email at sup...@measurementlab.net  Best regards, Chris -- Chris Ritzo Measurement Lab Operations & Support o...@measurementlab.net | sup...@measurementlab.net  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
169	distinguishing-between-mobile-and-fixed-connections	1536052594.0	2018-09-04 02:16:34	William Haslam	Are there any datafields that would help me separate out mobile and fixed (wired/wireless) connections?  Specifically I'm pulling data from the `measurement-lab.release.ndt_all` bigquery table and then mapping the IP addresses to ISP's. I can map the IP's fine, but I'm unable to separate out to connection type. I'm aware of 3rd party databases (maxmind/neustar) which claim to map IP addresses to connection type but I was hoping there would be something in the dataset that would allow me to do this? Any suggestions?	"{0: {'username': 'Chris Ritzo', 'response_date': 'Nov 7, 2018, 4:34:35 AM', 'response_content': 'Hello William, We were reviewing recent discuss group posts that had not received replies this week. Sorry that we or others haven\'t replied as yet.  In any case, there are some fields in the NDT dataset which could provide a rough way to distinguish tests conducted from mobile devices from desktops or laptops. This would be based on the device\'s operating system however, and would not be an indicator of connection type (mobile versus fixed). Thse fields would be: connection_spec.client_kernel_version connection_spec.client_os connection_spec.client_browser To properly separate mobile tests from non-mobile tests, you will need to use third party databases, as you mentioned. I have used the Maxmind connection type database for this, as well as the API provided by https://ipinfo.io . I find that the ipinfo.io API is more accurate, and had better global coverage.   Thanks for asking this question, and my apologies for the delayed reply. I hope this helps.  Also, we do hope to add this type of annotation in the future, and with respect to mobile specifically, M-Lab is coordinating with researchers on the issue of mobile measurement generally, most recently sponsoring this year\'s ACM Internet Measurement Conference, where we hosted a pre-conference workshop on mobile measurement.   Best regards, Chris -- Chris Ritzo Measurement Lab Operations & Support o...@measurementlab.net | sup...@measurementlab.net   On Tue, Sep 4, 2018 at 5:16 AM William Haslam <william...@gmail.com> wrote: Are there any datafields that would help me separate out mobile and fixed (wired/wireless) connections?  Specifically I\'m pulling data from the `measurement-lab.release.ndt_all` bigquery table and then mapping the IP addresses to ISP\'s. I can map the IP\'s fine, but I\'m unable to separate out to connection type. I\'m aware of 3rd party databases (maxmind/neustar) which claim to map IP addresses to connection type but I was hoping there would be something in the dataset that would allow me to do this? Any suggestions? -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
170	massive-charge-appearing-on-my-google-cloud-platform-console	1538116284.0	2018-09-27 23:31:24	Zachary Smith	Hi.  I'm looking around the M-Lab data via BigQuery.  Navigating to Billing, I saw a charge for $7000 and immediately got a little nervous! But it looks like that charge is for M-Lab and not related to me.  Am I supposed to be able to see the billing information for the M-Lab project?  Also... Is it definitely correct that this billing account in no way relates to me? :p Just want to be sure...  Best regards, Zach	"{0: {'username': 'Chris Ritzo', 'response_date': 'Sep 28, 2018, 4:26:38 AM', 'response_content': 'Hi Zach,  You should definitely not be seeing M-Labs project billing and should not be being charged for queries when using an Google account subscribed to this group.  Let\'s get into the details on a separate sup...@measurementlab.net thread.    If others on the discuss group have had similar experiences, please email us as well.  Thanks, Chris Ritzo  M-Lab Support    \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': 'in...@researchictafrica.net', 'response_date': 'Oct 16, 2018, 1:05:56 AM', 'response_content': ""Hi Chris.  I'm seeing the same public project (with pricing details) on another GCP account that is associated with this mailing list. In this case I actually had already created a separate GCP project for performing BigQuery queries on the M-Lab data.  Is it better to use the publicly available M-Lab project to perform these queries? Or should I still query the M-Lab data from a separate project to the public M-Lab project?  Best regards, Zach \ue5d3""}, 2: {'username': 'Chris Ritzo', 'response_date': 'Oct 16, 2018, 1:38:34 AM', 'response_content': ""Hi Zach,  I apologize for this issue.  We are investigating the permissions issue that is allowing our discuss group subscribers to see the query charges for M-Lab's GCP account. At least one other person has confirmed they can also see these amounts, but are not being charged on their personal accounts in their GCP projects.   Regarding whether you need to have your own GCP project to query, I will need to confirm. To the best of my knowledge this is a requirement, but as you might expect permissions models and documentation for these products can sometimes change.   Please continue to query from your GCP project as I investigate this issue. If you, or others have concern about being charged for queries, please contact me off list.   I will follow up on list once this issue is resolved.  Best regards, Chris Ritzo \ue5d3""}, 3: {'username': 'Rich Snapp', 'response_date': 'Nov 6, 2018, 2:04:35 PM', 'response_content': 'I also just got a charge of $30 for querying some of this M-Labs data, showed up as ""BigQuery Analysis: 8.302 Tebibytes"".  This also wasn\'t just a charge I\'m seeing to M-Labs, it charged my credit card.  I\'m using the same account in this discussion group as I used to query the data... \ue5d3'}, 4: {'username': 'Chris Ritzo', 'response_date': 'Nov 6, 2018, 2:24:23 PM', 'response_content': ""Hi Rich,  That should not be happening and we'll look into it right away. Could I ask you to email me at sup...@measurementlab.net with a screenshot of what you're seeing in your account? We can carry on the troubleshooting from there.  Thanks, Chris  -- Chris Ritzo Measurement Lab Operations & Support o...@measurementlab.net | sup...@measurementlab.net   \ue5d3 \ue5d3 -- \ue5d3""}}"
171	where's-the-data-after-april-2018?	1540389910.0	2018-10-24 07:05:10	Sam M.	I was recently attempting to search for speed test data for the Raleigh, NC area and all the M-Lab Viz data stops after April 1st, 2018 from what I can tell. Can anyone shed light on what's going on with this?  Thanks, -Sam	"{0: {'username': 'Sam M.', 'response_date': 'Oct 24, 2018, 7:07:08 AM', 'response_content': 'This was the URL BTW - https://viz.measurementlab.net/location/nausncraleigh?isps=AS10796x_AS10774x_AS3651. \ue5d3'}, 1: {'username': 'Chris Ritzo', 'response_date': 'Nov 6, 2018, 1:10:13 PM', 'response_content': 'Hi Sam, Apologies for the delay replying. The visualization website has been getting some updates and is hopefully going to reflect all recent data soon. There were several issues causing this, first our transition to a new ETL pipeline last year and new annotation service. More recently, the version of Google Cloud Dataflow that this application uses needs to be updated. We hope to have it all resolved soon.  In any case, the underlying data we collect that this site uses is still available if you\'d like to query for more recent data.  Best regards, Chris -- Chris Ritzo Measurement Lab Operations & Support o...@measurementlab.net | sup...@measurementlab.net   \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
172	"seemingly-wrong-data-in-""release.ndt_all.connection_spec.client_os""-column"	1540284095.0	2018-10-23 01:41:35	in...@researchictafrica.net	"Hi.  It looks like the ""connection_spec.client_os"" column in the table ""release.ndt_all"" has seemingly incorrect values if I query for data prior to 2018.  The query is in this gist: https://gist.github.com/zachsa/72b7371a73754885d8b1071ac2070a5a. Some of the values for 'client_os' include (along with other strange values): castbusiness.net s.airband.net t.au ginia.net net.ao iamedia.cz--kontakty.viamedia.infoWebClient/3200 ircom.net Is this something that is known about?  (I apologise in advance if I'm missing something obvious)  Best regards, Zach"	"{0: {'username': 'Chris Ritzo', 'response_date': 'Oct 23, 2018, 4:36:56 AM', 'response_content': 'Hi Zach,  Thanks for posting about this issue. I re-ran your query using date bounds, one year at a time and it appears that these and similar values are in the client_os field prior to 2016. For recent data from 2016 forward, there are expected operating system values only. Here is the modified query I used:  select   ifnull(connection_spec.client_os, \'Unknown\') sOS,   count(ifnull(connection_spec.client_os, \'Unknown\')) iCount     from release.ndt_all   where date(log_time) > \'2016-01-01\' AND date(log_time) < \'2017-01-01\'      group by   ifnull(connection_spec.client_os, \'Unknown\')  So for recent data it appears that our ETL pipeline is processing this field correctly. I will bring this issue to our team so that it can be investigated for data prior to 2016. so that it might be addressed in an upcoming reparsing of archival data if that is possible.   Thanks again for reporting this issue.  Best regards, Chris  -- Chris Ritzo Measurement Lab Operations & Support o...@measurementlab.net | sup...@measurementlab.net   \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
173	fair-usage-policy?	1538337485.0	2018-09-30 12:58:05	Zachary Smith	Hi,  I'm wondering if there is some kind of limitation on the amount of queries that can be run on M-Lab via BigQuery per user/session/etc.  Some use cases I can think of:  1. Is it okay to run numerous queries via the UI for several hours/day? 2. Is it okay to setup a client that runs many potentially expensive queries (and possibly in parallel from the client perspective) every 10 minutes or so - indefinitely? etc.  Best regards, Zach	"{0: {'username': 'Chris Ritzo', 'response_date': 'Oct 1, 2018, 5:45:54 AM', 'response_content': 'Hi Zach,  Thanks for asking this question. We currently do not have a policy, technical limits or otherwise, to limit your ability to run queries against the M-Lab dataset. Your only limits will be those imposed by BigQuery itself. Additionally, any resources you need outside of querying are not covered by M-Lab. For example, if you need to store large query results in a BigQuery table, this must be done in your own Google Cloud project.  Best regards., Chris -- Chris Ritzo Measurement Lab Operations & Support o...@measurementlab.net | sup...@measurementlab.net  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
174	are-all-m-lab-tests-guaranteed-to-be-'off-net'?	1538315228.0	2018-09-30 06:47:08	Zachary Smith	"Hi all,  I'm quite new to Google groups threads, so I don't know the appropriate way to engage here yet! Please let me know if I'm off the mark (and especially if I'm just creating spam).  I'm looking for specific ways to evaluate Internet performance in South Africa and am exploring the M-Lab datasets to see what's available. From the M-Lab status page (https://www.measurementlab.net/status/) I see that there is one M-Lab server setup in South Africa. I thought that this might mean that all tests in South Africa are therefore relative to this single server. But from the FAQs (https://www.measurementlab.net/faq/):  ""M-Lab’s measurements are always conducted off-net. This way, M-Lab is able to measure performance from testers’ computers to locations where popular Internet content is often hosted. By having inter-network connections included in the test, test users get a real sense of the performance they could expect when using the Internet.""  I take this to mean that a testing-client will always connect to a server hosted on a separate ISP's network?  For the specific example of South Africa with one M-Lab server in one of the main business districts, could this result in the best internet connections (connections close to the data center where the M-Lab server resides) showing the highest latency/throughput times since there is a 'rule' that will result in NOT using the closest local server that is in the same Access network as the testing client?  In general, how is it ensured that test-client - server connections are all 'off-net'? Alternatively, if this isn't the case, is there a flag somewhere that indicates this?  Best regards, Zach"	"{0: {'username': 'Chris Ritzo', 'response_date': 'Oct 1, 2018, 5:39:31 AM', 'response_content': 'Hello Zach,  Thanks for asking this question, and welcome to the M-Lab Discuss group.   M-Lab servers are always hosted outside of access networks, with direct connections to transit networks. This is how we ensure tests are conducted to off-net servers. Our architecture in this respect is similar to Akamai. To directly answer your question about the FAQ- yes, the testing client will always connect to a server hosted on a transit network.  The vast majority of testing clients normally are routed to the geographically closest M-Lab server. Some clients allow the user to select a specific M-Lab server to conduct an NDT test, for example if you compiled the NDT command line binary or install the M-Lab Measure Chrome Extension.  Happy to answer additional questions, and thanks for posting in the group.  Best regards, Chris -- Chris Ritzo Measurement Lab Operations & Support o...@measurementlab.net | sup...@measurementlab.net   \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
175	new-switch-telemetry-dataset-(disco)	1537376359.0	2018-09-19 09:59:19	Stephen Soltesz	Hello,  Since June 2016, M-Lab has collected high resolution switch telemetry for each M-Lab server and site uplink. We are happy to announce that we are now publishing this data in BigQuery tables.  To learn more, please see: https://www.measurementlab.net/blog/disco-dataset/  Best, Stephen	{}
176	community-wireless-mesh	1537005168.0	2018-09-15 02:52:48	Diane Nek	Just want to say thanks for providing this service which is very helpful for testing various combinations of equipment for our small community wireless mesh internet project. Would like to connect with others who may be involved in similar projects to share ideas.	{}
177	fwd:-2nd-workshop-on-internet-measurements-research-in-africa	1536150207.0	2018-09-05 05:23:27	Amreesh Phokeer	FYI  ---------- Forwarded message --------- From: Amreesh Phokeer <amreesh...@gmail.com> Date: Wed, Sep 5, 2018 at 4:22 PM Subject: 2nd Workshop on Internet Measurements Research in Africa  {apologies for cross-posting} {please circulate}  2nd IMRA WORKSHOP Internet Measurements Research in Africa co-located to AFRICOMM 2018, 29-30 Nov, Dakar, Senegal  Call for Papers/Presentations  Internet measurements provide useful insights into the accessibility of the Internet (e.g. coverage of WiFi and cellular networks), performance (e.g. Internet throughput and latency) and Internet usage. Internet development campaigners, national regulators, and policy makers in the developing regions are recognising  the crucial role that Internet measurement data can play in facilitating evidence-based policy-making and regulation. Given that the Internet ecosystem comprises a diversity of stakeholders and service providers it is difficult for any other single entity to access all of Internet topology data without the cooperation of the Internet community. For this reason, appropriate acquisition of Internet data requires a variety of cooperative research methods, including wide distribution of Internet probes for technical measurements, located in diverse locations and networks, as well as region-specific techniques and demand-side surveys on Internet access and use.  The aim of the workshop is to facilitate discussions around mechanisms and challenges of measuring Africa’s Internet; to evaluate the breadth of Internet measurements research and to formulate strategic directions for such research in Africa; and to initiate and accelerate collaboration among Africa’s Internet measurements researchers.  The workshop is calling for high-quality papers that are focused on Internet measurements research in Africa. Papers are invited on topics related to tools, methods and analysis of:  End-to-end Internet performance metrics Internet topology characteristics, including peering and routing Application-level performance, including DNS, Web, CDNs, Cloud Computing Physical layer performance measurements, including for TVWS, WiFi, and 3G/4G Mobile and Cellular technologies Detection of middleboxes, censorship, and content filtering Data analytics for network monitoring, traffic analysis and network Network topology and performance visualization Internet access, use, and Quality of Experience (QoE) surveys  Committee  General Workshop Chair Amreesh Phokeer – AFRINIC  Technical Programme Committee Ahmed Elmokashfi (TPC Co-chair) – Simula Research Laboratory Josiah Chavula (TPC Co-chair) – University of Cape Town Amreesh Phokeer – AFRINIC Gareth Tyson – Queen Mary University of London Alemnew Asrese – Aalto University Ermias Walelgne – Aalto University Assane Gueye – UADB-Senegal Roderick Fanou – CAIDA/UC San Diego  Publication  Accepted and registered papers will be included in the AFRICOMM conference proceedings.  Submission Instructions  See the instructions for paper submission here: <http://africommconference.org/initial-submission/>  Workshop papers will be selected through a peer-review process.  N.B Previous and already published peer-reviewed work on Internet measurements may also be accepted for presentation only. Presentations should be emailed to the workshop TPC co-chairs.  Important Dates Submission deadline: 28th September 2018 Notification deadline: 15th October 2018 Camera-ready deadline: 30th October 2018  -- Amreesh Phokeer   -- Amreesh Phokeer	{}
178	internet-speed-test-results-are-at-odds-with-other-speed-test-services.	1534813844.0	2018-08-20 18:10:44	Cory Rahman	Results (tested multiple times)  SOURCE / DL mbps / UP mbps   On my home 5Ghz network:  MLAB speed test / 40 / 76 Ookla / 83 / 84 AT&T / 82 / 83 Verizon / 82 / 89   On my home 2.4Ghz network:  MLAB speed test / 45 / 62 Ookla / 82 / 86 AT&T / 82 / 88 Verizon / 81 / 90   Does anyone know why these MLAB speed test results would be so different than the other online speed tests?	"{0: {'username': 'Cory Rahman', 'response_date': 'Aug 20, 2018, 6:15:16 PM', 'response_content': 'I did come across this page:  https://www.measurementlab.net/faq/#why-are-my-m-lab-results-different-from-other-speed-tests  Which seems to claim that the M-Lab tests are more accurate. Is this the case? Are the other 3 speed tests inaccurate?'}, 1: {'username': 'Livingood, Jason', 'response_date': 'Aug 21, 2018, 8:30:44 AM', 'response_content': 'IIRC from prior discussions here, I think it was due to a single connection vs. multiple connections for the other tests.   Jason \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 2: {'username': 'Sascha Meinrath', 'response_date': 'Aug 21, 2018, 8:56:07 AM', 'response_content': 'This may be an artifact of multi-threading; but it may also reflect on- vs. off-network test servers (i.e., are you testing the connection within an ISPs network or to a location that is outside of that single ISPs system).  --Sascha  On 08/21/2018 11:30 AM, Livingood, Jason wrote: > IIRC from prior discussions here, I think it was due to a single connection vs. > multiple connections for the other tests. > >   > > Jason > >   > > *From: *Cory Rahman <cory....@gmail.com> > *Date: *Monday, August 20, 2018 at 9:10 PM > *To: *discuss <dis...@measurementlab.net> > *Subject: *[EXTERNAL] [M-Lab-Discuss] Internet Speed Test results are at odds > with other speed test services. > >   > > Results (tested multiple times) > >   > > SOURCE / DL mbps / UP mbps > >   > >   > > On my home 5Ghz network: > >   > > MLAB speed test / 40 / 76 > > Ookla / 83 / 84 > > AT&T / 82 / 83 > > Verizon / 82 / 89 > >   > >   > > On my home 2.4Ghz network: > >   > > MLAB speed test / 45 / 62 > > Ookla / 82 / 86 > > AT&T / 82 / 88 > > Verizon / 81 / 90 > >   > >   > > Does anyone know why these MLAB speed test results would be so different than > the other online speed tests? > >   > >   > >   > > -- > You received this message because you are subscribed to the Google Groups > ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, send an email > to discuss+u...@measurementlab.net > <mailto:discuss+u...@measurementlab.net>. > To post to this group, send email to dis...@measurementlab.net > <mailto:dis...@measurementlab.net>. > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. > > -- > You received this message because you are subscribed to the Google Groups > ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, send an email > to discuss+u...@measurementlab.net > <mailto:discuss+u...@measurementlab.net>. > To post to this group, send email to dis...@measurementlab.net > <mailto:dis...@measurementlab.net>. \ue5d3'}, 3: {'username': 'Chris Ritzo', 'response_date': 'Aug 21, 2018, 9:31:06 AM', 'response_content': 'Hi Cory,  As others have mentioned, there are a variety of factors which are in play here. The FAQ you reference explains several reasons why the M-Lab test reports lower results than other speed tests, including single versus multi-threaded tests as Jason mentioned, and on-net versus off-net placement of servers as Sascha mentioned. M-Lab doesn\'t claim that our test is more accurate than others, but that it is measuring different network conditions. Different network performance tests use differing methodologies as well, which can account for different measurements. All the tests are as accurate as they can be for what they are measuring, and because they report similar metrics it is often assumed that their results should be equal.  I would characterize them as comparable and each accurate in their own right for what is being measured. The M-Lab NDT test measurements are more in line with Akamai tests, in that the server endpoints are off-net. Whether a single threaded test or a multi-threaded test is more accurate is still a question up for debate in the academic internet measurement community-- the article Jason referenced is one supporting multi-threaded tests, and earlier research points to single-threaded testing to be more precise in assessing overall performance. In any case, whatever the test used, they all provide some sense of a connection and I think that combined the results of each one can help paint a nuanced picture of your quality of access overall.  Best regards, Chris  -- Chris Ritzo Measurement Lab Operations & Support o...@measurementlab.net | sup...@measurementlab.net  Senior Technologist, Open Technology Institute @ New America 740 15th Street NW, Suite 900  Washington, DC 20036        \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. \ue5d3'}, 4: {'username': 'Jim Partridge', 'response_date': 'Aug 21, 2018, 10:23:07 AM', 'response_content': 'This clearly seems to be an issue of multi-threaded tests versus the single-threaded M-Lab NDT test. I would point you to the Comments that Nick Feamster filed with the FCC in the Restoring Internet Freedom docket (link also pasted below) which included the observation that - The M-Lab NDT test consistently underestimates access link throughput. Off-net versus on-net servers aren\'t going to result in performance metrics that are half of actual capacity. It\'s certainly interesting to note how closely aligned the results are from the three other tests, Ookla, AT&T, and Verizon. Of note, Professor Feamster also states that ""As access link speeds continue to increase...the underestimation {of the single-threaded NDT test} is likely to become even more severe.""   https://ecfsapi.fcc.gov/file/1083088362452/fcc-17-108-reply-aug2017.pdf \ue5d3'}, 5: {'username': 'Simone Basso', 'response_date': 'Aug 21, 2018, 10:43:35 AM', 'response_content': 'In the infosec community it often happens that people asking security questions is asked about their threat model. Likewise, I\'d say that perhaps in this community we should help people making questions by consistently asking what they would like to measure.  AFAICT, it\'s non-controversial that parallel streams tests better approximate the last mile speed, however they also fail to reveal losses in the network (or elsewhere) that become obvious with a single stream test. In the same vein, on-net and off-net tests have pros and cons.  Also, speaking of cognitive dissonance, seeing a much lower than expected result from a single stream test can be as surprising as seeing an all-green report from a multi stream test when interactive communication is stuttering, or streaming does not load.  Best,  Simone  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}, 6: {'username': 'Livingood, Jason', 'response_date': 'Aug 21, 2018, 11:11:39 AM', 'response_content': 'I think it was Jim Partridge that cited the research, not me. 😉 But in any case that citation was relatively recent, as is the research from Steve Bauer et. al. on the subject of measurement tests. The citation on single threading you noted (from 1997 on “the macroscopic behavior of the TCP congestion avoidance algorithm”) is probably a bit outdated considering how substantially TCP congestion control and threading has changed in 21 years. But I know one of the co-authors (Matt Mathis) is on this list so he’d know more than anyone how all the recent changes may or may not affect their prior conclusions, since I am pretty sure he’s on the leading edge of congestion control R&D.   In any case, it seems you are right to focus on the right test for the right question; that is the root of it. It seems most folks think NDT is useful for identifying the location of network bottlenecks, rather than aggregate network capacity (speed). But it seems like a lot of people use it for the latter case when another tool may be superior for that question.   JL \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.   -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}, 7: {'username': 'Livingood, Jason', 'response_date': 'Aug 21, 2018, 11:13:39 AM', 'response_content': '+1, Simone. All very good points!   From: Simone Basso <basso...@gmail.com> Date: Tuesday, August 21, 2018 at 1:43 PM To: ""dis...@measurementlab.net"" <dis...@measurementlab.net> Subject: [EXTERNAL] Re: [M-Lab-Discuss] Re: Internet Speed Test results are at odds with other speed test services.   In the infosec community it often happens that people asking security questions is asked about their threat model. Likewise, I\'d say that perhaps in this community we should help people making questions by consistently asking what they would like to measure.   AFAICT, it\'s non-controversial that parallel streams tests better approximate the last mile speed, however they also fail to reveal losses in the network (or elsewhere) that become obvious with a single stream test. In the same vein, on-net and off-net tests have pros and cons.   Also, speaking of cognitive dissonance, seeing a much lower than expected result from a single stream test can be as surprising as seeing an all-green report from a multi stream test when interactive communication is stuttering, or streaming does not load.   Best,   Simone   Il giorno mar 21 ago 2018 alle ore 19:23 Jim Partridge <jpartr...@gmail.com> ha scritto: This clearly seems to be an issue of multi-threaded tests versus the single-threaded M-Lab NDT test. I would point you to the Comments that Nick Feamster filed with the FCC in the Restoring Internet Freedom docket (link also pasted below) which included the observation that - The M-Lab NDT test consistently underestimates access link throughput. Off-net versus on-net servers aren\'t going to result in performance metrics that are half of actual capacity. It\'s certainly interesting to note how closely aligned the results are from the three other tests, Ookla, AT&T, and Verizon. Of note, Professor Feamster also states that ""As access link speeds continue to increase...the underestimation {of the single-threaded NDT test} is likely to become even more severe.""   Error! Filename not specified. \ue5d3 \ue5d3 \ue5d3'}}"
179		1534300344.0	2018-08-14 19:32:24	mariana totpal	Hello, thanks	{}
180	speed-test-data	1534201048.0	2018-08-13 15:57:28	Jenny Abamu	Good Morning,   I am trying to get wifi speed test data for the DC area. I am a reporter and could use some helps with this. 	"{0: {'username': 'thieme', 'response_date': 'Aug 13, 2018, 4:32:23 PM', 'response_content': ""Hey Jenny,  Nice to speak again. I actually just used the D.C. speed test data from 2010 to 2018 for an event we had last week and wrote up a short tutorial on how to do something similar. There are a couple of steps involved in signing up for access to the data that I'd be happy to help with.  If you'd like to go that route, there's another page on the M-Lab GitHub that has some easy-to-use code for getting speed-test data and visualizing it in various ways. Alternatively, since I recently did something similar to what you're looking for, I could use the code I already have to get you the data.  It might be helpful to talk through exactly what you're interested in at some point, as well.  Let me know if I can help,  Nick \ue5d3""}, 1: {'username': 'Livingood, Jason', 'response_date': 'Aug 14, 2018, 8:16:06 AM', 'response_content': 'Worth reading: https://groups.csail.mit.edu/ana/Publications/Understanding_broadband_speed_measurements_bauer_clark_lehr_TPRC_2010.pdf   It’d be cool to see an update of this analysis in the future.   Jason \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 2: {'username': 'Nick Feamster', 'response_date': 'Aug 14, 2018, 8:18:17 AM', 'response_content': 'Jenny,  Good that you’re taking a look at WiFi bottlenecks.  Also worth a look is understanding how WiFi contributes to bottlenecks in these kinds of end-to-end speedtests. In short, you’re better off relying on a router-based test to isolate the effects of home WiFi.  https://smartech.gatech.edu/handle/1853/46991  Happy to talk more.  -Nick \ue5d3'}, 3: {'username': 'Matt Mathis', 'response_date': 'Aug 14, 2018, 12:55:17 PM', 'response_content': 'There was some work done several years ago on fingerprinting* wireless in remote traces.     In our new pipeline I could imagine applying such an annotation to all of the data in BQ...  Does anybody recall the citation?    In a BBR world, I can imagine the tester detecting a wireless bottleneck at the same time as the primary rate measurement.  The real challenge is how to tell the user?   This is the ""meta"" test report problem.  *(The tell is ""lumpy"" or thinned ACKs caused by reversing a shared half duplex channel).  Thanks, --MM-- The best way to predict the future is to create it.  - Alan Kay  We must not tolerate intolerance;        however our response must be carefully measured:              too strong would be hypocritical and risks spiraling out of control;             too weak risks being mistaken for tacit approval.  \ue5d3'}, 4: {'username': 'Nick Feamster', 'response_date': 'Aug 14, 2018, 1:22:18 PM', 'response_content': ""If I understand the reference...The paper referenced below looks at inter packet spacing on the downstream access link to do just that. It was deployed on the SamKnows boxes for a time.  The technique requires observations from the router, though, to observe that timing, and it only works in the downstream direction.  The other feature that works well on the wireless side is looking at RTT between devices and the AP. As with the packet spacing technique, this requires measuring the device-AP part of the segment.  Maybe there's also another technique out there, too. Interesting thought on what this might look like with BBR...  -Nick \ue5d3""}, 5: {'username': 'Matt Mathis', 'response_date': 'Aug 14, 2018, 2:12:24 PM', 'response_content': '""referenced below"" ?  The BBR version can definitely be done at the sender.   Actually BBR has the opposite problem: bad things happen if  the min_rtt or max_rate estimators are confused by batched or thinned ACKs.  There is a lot of logic in BBR to exclude ACKs that seem to have been delayed by the return path.     An ""ACK jitter"" parameter would be a side signal off of these algorithms, and the jitter distribution tells you about any half duplex in the path.  (There could also be congestion on the return path).  I also suspect that some of the signatures appear in Web100 sidestream (TCP exit)  stats, and they are very likely to appear in the Web100 fast polling as well.   Less sure about TCP_INFO.  Thanks, --MM-- The best way to predict the future is to create it.  - Alan Kay  We must not tolerate intolerance;        however our response must be carefully measured:              too strong would be hypocritical and risks spiraling out of control;             too weak risks being mistaken for tacit approval.  \ue5d3'}, 6: {'username': 'Nick Feamster', 'response_date': 'Aug 14, 2018, 2:15:57 PM', 'response_content': 'On August 14, 2018 5:12:10 PM EDT, Matt Mathis <mattm...@google.com> wrote: >""referenced below"" ? >  Yes, see the link below for a pre-BBR method: https://smartech.gatech.edu/handle/1853/46991  -Nick \ue5d3'}}"
181	m-lab-is-turning-10!-&-some-updates	1532126014.0	2018-07-20 15:33:34	Georgia Bullen	Hello Discuss List Community!  M-Lab is turning 10! To celebrate we are having a 2 day convening in DC at New America, which you can register for here: https://www.newamerica.org/oti/events/measurement-lab-10th-anniversary/ There will be great speakers, workshops and lots of interesting research shared, as well as a reception to celebrate! If you have work you'd be interested in sharing or in sponsoring the event, please drop us a note at work...@measurementlab.net.  Updated Privacy Policy We have updated our privacy policy, please review it and reach out to us (pri...@measurementlab.net) if you have any questions or concerns: https://www.measurementlab.net/privacy/  Thanks all!  -Georgia Measurement Lab Team  -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/  Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon	"{0: {'username': 'Georgia Bullen', 'response_date': 'Jul 25, 2018, 8:41:02 AM', 'response_content': ""Oh and I forgot to mention this, but we have an open position at New America to work on M-Lab, in case folks in the community might be interested.  Here's the posting: https://newamerica.jazz.co/apply/eOzq4T1lp7/Technologist-Open-Internet-DevOps  Please share with your networks!  -Georgia \ue5d3""}}"
182	data-after-may-2017?	1528608989.0	2018-06-09 22:36:29	Eireann Leverett	"Hi network nerds,  I returned to some old work today, to update some datasets and found I cannot get data for after May 2017.  I wanted to check if the data isn't there yet for late 2017, or if my old queries have somehow gone out of date because fields or the way we access them has changed.  Can you give me a little feedback?  Thanks in advance!  Eireann  Here's an example query for debugging purposes. I get a ""Query returns zero results"", and you can alter the dates slightly to see it returns data before May.  SELECT connection_spec.client_geolocation.country_code AS country, NTH(1, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/ (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadMin, NTH(26, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/ (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadLower, NTH(51, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/ (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadMedian, NTH(76, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/ (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadUpper, NTH(101, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/ (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadMax, FROM plx.google:m_lab.ndt.all WHERE web100_log_entry.log_time >= PARSE_UTC_USEC('2017-07-01 00:00:00') / POW(10, 6) AND web100_log_entry.log_time < PARSE_UTC_USEC('2017-08-01 00:00:00') / POW(10, 6) AND (connection_spec.client_geolocation.country_code = 'AD' OR connection_spec.client_geolocation.country_code = 'AE' OR connection_spec.client_geolocation.country_code = 'AF' OR connection_spec.client_geolocation.country_code = 'AG' OR connection_spec.client_geolocation.country_code = 'AI' OR connection_spec.client_geolocation.country_code = 'AL' OR connection_spec.client_geolocation.country_code = 'AM' OR connection_spec.client_geolocation.country_code = 'AO' OR connection_spec.client_geolocation.country_code = 'AQ' OR connection_spec.client_geolocation.country_code = 'AR' OR connection_spec.client_geolocation.country_code = 'AS' OR connection_spec.client_geolocation.country_code = 'AT' OR connection_spec.client_geolocation.country_code = 'AU' OR connection_spec.client_geolocation.country_code = 'AW' OR connection_spec.client_geolocation.country_code = 'AX' OR connection_spec.client_geolocation.country_code = 'AZ' OR connection_spec.client_geolocation.country_code = 'BA' OR connection_spec.client_geolocation.country_code = 'BB' OR connection_spec.client_geolocation.country_code = 'BD' OR connection_spec.client_geolocation.country_code = 'BE' OR connection_spec.client_geolocation.country_code = 'BF' OR connection_spec.client_geolocation.country_code = 'BG' OR connection_spec.client_geolocation.country_code = 'BH' OR connection_spec.client_geolocation.country_code = 'BI' OR connection_spec.client_geolocation.country_code = 'BJ' OR connection_spec.client_geolocation.country_code = 'BL' OR connection_spec.client_geolocation.country_code = 'BM' OR connection_spec.client_geolocation.country_code = 'BN' OR connection_spec.client_geolocation.country_code = 'BO' OR connection_spec.client_geolocation.country_code = 'BQ' OR connection_spec.client_geolocation.country_code = 'BR' OR connection_spec.client_geolocation.country_code = 'BS' OR connection_spec.client_geolocation.country_code = 'BT' OR connection_spec.client_geolocation.country_code = 'BW' OR connection_spec.client_geolocation.country_code = 'BY' OR connection_spec.client_geolocation.country_code = 'BZ' OR connection_spec.client_geolocation.country_code = 'CA' OR connection_spec.client_geolocation.country_code = 'CD' OR connection_spec.client_geolocation.country_code = 'CF' OR connection_spec.client_geolocation.country_code = 'CG' OR connection_spec.client_geolocation.country_code = 'CH' OR connection_spec.client_geolocation.country_code = 'CI' OR connection_spec.client_geolocation.country_code = 'CK' OR connection_spec.client_geolocation.country_code = 'CL' OR connection_spec.client_geolocation.country_code = 'CM' OR connection_spec.client_geolocation.country_code = 'CN' OR connection_spec.client_geolocation.country_code = 'CO' OR connection_spec.client_geolocation.country_code = 'CR' OR connection_spec.client_geolocation.country_code = 'CU' OR connection_spec.client_geolocation.country_code = 'CV' OR connection_spec.client_geolocation.country_code = 'CW' OR connection_spec.client_geolocation.country_code = 'CY' OR connection_spec.client_geolocation.country_code = 'CZ' OR connection_spec.client_geolocation.country_code = 'DE' OR connection_spec.client_geolocation.country_code = 'DJ' OR connection_spec.client_geolocation.country_code = 'DK' OR connection_spec.client_geolocation.country_code = 'DM' OR connection_spec.client_geolocation.country_code = 'DO' OR connection_spec.client_geolocation.country_code = 'DZ' OR connection_spec.client_geolocation.country_code = 'EC' OR connection_spec.client_geolocation.country_code = 'EE' OR connection_spec.client_geolocation.country_code = 'EG' OR connection_spec.client_geolocation.country_code = 'ER' OR connection_spec.client_geolocation.country_code = 'ES' OR connection_spec.client_geolocation.country_code = 'ET' OR connection_spec.client_geolocation.country_code = 'FI' OR connection_spec.client_geolocation.country_code = 'FJ' OR connection_spec.client_geolocation.country_code = 'FK' OR connection_spec.client_geolocation.country_code = 'FM' OR connection_spec.client_geolocation.country_code = 'FO' OR connection_spec.client_geolocation.country_code = 'FR' OR connection_spec.client_geolocation.country_code = 'GA' OR connection_spec.client_geolocation.country_code = 'GB' OR connection_spec.client_geolocation.country_code = 'GD' OR connection_spec.client_geolocation.country_code = 'GE' OR connection_spec.client_geolocation.country_code = 'GF' OR connection_spec.client_geolocation.country_code = 'GG' OR connection_spec.client_geolocation.country_code = 'GH' OR connection_spec.client_geolocation.country_code = 'GI' OR connection_spec.client_geolocation.country_code = 'GL' OR connection_spec.client_geolocation.country_code = 'GM' OR connection_spec.client_geolocation.country_code = 'GN' OR connection_spec.client_geolocation.country_code = 'GP' OR connection_spec.client_geolocation.country_code = 'GQ' OR connection_spec.client_geolocation.country_code = 'GR' OR connection_spec.client_geolocation.country_code = 'GS' OR connection_spec.client_geolocation.country_code = 'GT' OR connection_spec.client_geolocation.country_code = 'GU' OR connection_spec.client_geolocation.country_code = 'GW' OR connection_spec.client_geolocation.country_code = 'GY' OR connection_spec.client_geolocation.country_code = 'HK' OR connection_spec.client_geolocation.country_code = 'HN' OR connection_spec.client_geolocation.country_code = 'HR' OR connection_spec.client_geolocation.country_code = 'HT' OR connection_spec.client_geolocation.country_code = 'HU' OR connection_spec.client_geolocation.country_code = 'ID' OR connection_spec.client_geolocation.country_code = 'IE' OR connection_spec.client_geolocation.country_code = 'IL' OR connection_spec.client_geolocation.country_code = 'IM' OR connection_spec.client_geolocation.country_code = 'IN' OR connection_spec.client_geolocation.country_code = 'IO' OR connection_spec.client_geolocation.country_code = 'IQ' OR connection_spec.client_geolocation.country_code = 'IR' OR connection_spec.client_geolocation.country_code = 'IS' OR connection_spec.client_geolocation.country_code = 'IT' OR connection_spec.client_geolocation.country_code = 'JE' OR connection_spec.client_geolocation.country_code = 'JM' OR connection_spec.client_geolocation.country_code = 'JO' OR connection_spec.client_geolocation.country_code = 'JP' OR connection_spec.client_geolocation.country_code = 'KE' OR connection_spec.client_geolocation.country_code = 'KG' OR connection_spec.client_geolocation.country_code = 'KH' OR connection_spec.client_geolocation.country_code = 'KI' OR connection_spec.client_geolocation.country_code = 'KM' OR connection_spec.client_geolocation.country_code = 'KN' OR connection_spec.client_geolocation.country_code = 'KP' OR connection_spec.client_geolocation.country_code = 'KR' OR connection_spec.client_geolocation.country_code = 'KW' OR connection_spec.client_geolocation.country_code = 'KY' OR connection_spec.client_geolocation.country_code = 'KZ' OR connection_spec.client_geolocation.country_code = 'LA' OR connection_spec.client_geolocation.country_code = 'LB' OR connection_spec.client_geolocation.country_code = 'LC' OR connection_spec.client_geolocation.country_code = 'LI' OR connection_spec.client_geolocation.country_code = 'LK' OR connection_spec.client_geolocation.country_code = 'LR' OR connection_spec.client_geolocation.country_code = 'LS' OR connection_spec.client_geolocation.country_code = 'LT' OR connection_spec.client_geolocation.country_code = 'LU' OR connection_spec.client_geolocation.country_code = 'LV' OR connection_spec.client_geolocation.country_code = 'LY' OR connection_spec.client_geolocation.country_code = 'MA' OR connection_spec.client_geolocation.country_code = 'MC' OR connection_spec.client_geolocation.country_code = 'MD' OR connection_spec.client_geolocation.country_code = 'ME' OR connection_spec.client_geolocation.country_code = 'MF' OR connection_spec.client_geolocation.country_code = 'MG' OR connection_spec.client_geolocation.country_code = 'MH' OR connection_spec.client_geolocation.country_code = 'MK' OR connection_spec.client_geolocation.country_code = 'ML' OR connection_spec.client_geolocation.country_code = 'MM' OR connection_spec.client_geolocation.country_code = 'MN' OR connection_spec.client_geolocation.country_code = 'MO' OR connection_spec.client_geolocation.country_code = 'MP' OR connection_spec.client_geolocation.country_code = 'MQ' OR connection_spec.client_geolocation.country_code = 'MR' OR connection_spec.client_geolocation.country_code = 'MS' OR connection_spec.client_geolocation.country_code = 'MT' OR connection_spec.client_geolocation.country_code = 'MU' OR connection_spec.client_geolocation.country_code = 'MV' OR connection_spec.client_geolocation.country_code = 'MW' OR connection_spec.client_geolocation.country_code = 'MX' OR connection_spec.client_geolocation.country_code = 'MY' OR connection_spec.client_geolocation.country_code = 'MZ' OR connection_spec.client_geolocation.country_code = 'NA' OR connection_spec.client_geolocation.country_code = 'NC' OR connection_spec.client_geolocation.country_code = 'NE' OR connection_spec.client_geolocation.country_code = 'NF' OR connection_spec.client_geolocation.country_code = 'NG' OR connection_spec.client_geolocation.country_code = 'NI' OR connection_spec.client_geolocation.country_code = 'NL' OR connection_spec.client_geolocation.country_code = 'NO' OR connection_spec.client_geolocation.country_code = 'NP' OR connection_spec.client_geolocation.country_code = 'NR' OR connection_spec.client_geolocation.country_code = 'NU' OR connection_spec.client_geolocation.country_code = 'NZ' OR connection_spec.client_geolocation.country_code = 'OM' OR connection_spec.client_geolocation.country_code = 'PA' OR connection_spec.client_geolocation.country_code = 'PE' OR connection_spec.client_geolocation.country_code = 'PF' OR connection_spec.client_geolocation.country_code = 'PG' OR connection_spec.client_geolocation.country_code = 'PH' OR connection_spec.client_geolocation.country_code = 'PK' OR connection_spec.client_geolocation.country_code = 'PL' OR connection_spec.client_geolocation.country_code = 'PM' OR connection_spec.client_geolocation.country_code = 'PR' OR connection_spec.client_geolocation.country_code = 'PS' OR connection_spec.client_geolocation.country_code = 'PT' OR connection_spec.client_geolocation.country_code = 'PW' OR connection_spec.client_geolocation.country_code = 'PY' OR connection_spec.client_geolocation.country_code = 'QA' OR connection_spec.client_geolocation.country_code = 'RE' OR connection_spec.client_geolocation.country_code = 'RO' OR connection_spec.client_geolocation.country_code = 'RS' OR connection_spec.client_geolocation.country_code = 'RU' OR connection_spec.client_geolocation.country_code = 'RW' OR connection_spec.client_geolocation.country_code = 'SA' OR connection_spec.client_geolocation.country_code = 'SB' OR connection_spec.client_geolocation.country_code = 'SC' OR connection_spec.client_geolocation.country_code = 'SD' OR connection_spec.client_geolocation.country_code = 'SE' OR connection_spec.client_geolocation.country_code = 'SG' OR connection_spec.client_geolocation.country_code = 'SI' OR connection_spec.client_geolocation.country_code = 'SK' OR connection_spec.client_geolocation.country_code = 'SL' OR connection_spec.client_geolocation.country_code = 'SM' OR connection_spec.client_geolocation.country_code = 'SN' OR connection_spec.client_geolocation.country_code = 'SO' OR connection_spec.client_geolocation.country_code = 'SR' OR connection_spec.client_geolocation.country_code = 'SS' OR connection_spec.client_geolocation.country_code = 'ST' OR connection_spec.client_geolocation.country_code = 'SV' OR connection_spec.client_geolocation.country_code = 'SX' OR connection_spec.client_geolocation.country_code = 'SY' OR connection_spec.client_geolocation.country_code = 'SZ' OR connection_spec.client_geolocation.country_code = 'TC' OR connection_spec.client_geolocation.country_code = 'TD' OR connection_spec.client_geolocation.country_code = 'TG' OR connection_spec.client_geolocation.country_code = 'TH' OR connection_spec.client_geolocation.country_code = 'TJ' OR connection_spec.client_geolocation.country_code = 'TK' OR connection_spec.client_geolocation.country_code = 'TL' OR connection_spec.client_geolocation.country_code = 'TM' OR connection_spec.client_geolocation.country_code = 'TN' OR connection_spec.client_geolocation.country_code = 'TO' OR connection_spec.client_geolocation.country_code = 'TR' OR connection_spec.client_geolocation.country_code = 'TT' OR connection_spec.client_geolocation.country_code = 'TV' OR connection_spec.client_geolocation.country_code = 'TW' OR connection_spec.client_geolocation.country_code = 'TZ' OR connection_spec.client_geolocation.country_code = 'UA' OR connection_spec.client_geolocation.country_code = 'UG' OR connection_spec.client_geolocation.country_code = 'US' OR connection_spec.client_geolocation.country_code = 'UY' OR connection_spec.client_geolocation.country_code = 'UZ' OR connection_spec.client_geolocation.country_code = 'VA' OR connection_spec.client_geolocation.country_code = 'VC' OR connection_spec.client_geolocation.country_code = 'VE' OR connection_spec.client_geolocation.country_code = 'VG' OR connection_spec.client_geolocation.country_code = 'VI' OR connection_spec.client_geolocation.country_code = 'VN' OR connection_spec.client_geolocation.country_code = 'VU' OR connection_spec.client_geolocation.country_code = 'WF' OR connection_spec.client_geolocation.country_code = 'WS' OR connection_spec.client_geolocation.country_code = 'XY' OR connection_spec.client_geolocation.country_code = 'YE' OR connection_spec.client_geolocation.country_code = 'YT' OR connection_spec.client_geolocation.country_code = 'ZA' OR connection_spec.client_geolocation.country_code = 'ZM' OR connection_spec.client_geolocation.country_code = 'ZW') AND IS_EXPLICITLY_DEFINED(web100_log_entry.connection_spec.remote_ip) AND IS_EXPLICITLY_DEFINED(web100_log_entry.connection_spec.local_ip) AND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.HCThruOctetsAcked) AND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.SndLimTimeRwin) AND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.SndLimTimeCwnd) AND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.SndLimTimeSnd) AND project = 0 AND IS_EXPLICITLY_DEFINED(connection_spec.data_direction) AND connection_spec.data_direction = 1 AND web100_log_entry.snap.HCThruOctetsAcked >= 8192 AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000 AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd +  web100_log_entry.snap.SndLimTimeSnd) < 3600000000 AND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.CongSignals) AND web100_log_entry.snap.CongSignals > 0 AND (web100_log_entry.snap.State == 1 OR (web100_log_entry.snap.State >= 5 AND web100_log_entry.snap.State <= 11)) AND blacklist_flags == 0 GROUP BY country ORDER BY country ASC;"	"{0: {'username': 'Chris Ritzo', 'response_date': 'Jun 11, 2018, 7:39:11 AM', 'response_content': 'Hello Eireann,  M-Lab recently updated our BigQuery datasets and tables, so I believe you will only need to change table names and update your queries slightly. You can read complete details on the most recent update in this blog post:   \ue5d3 \ue5d3   -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': 'Chris Ritzo', 'response_date': 'Jun 11, 2018, 7:42:24 AM', 'response_content': 'With apologies for the duplicate message:  Our recent blog post describing the transition to our open source ETL pipeline and new table/schema changes: https://www.measurementlab.net/blog/etl-pipeline/  We recommend most people query the BigQuery views in the release dataset:  https://bigquery.cloud.google.com/dataset/measurement-lab:release  Finally, we have a document describing the most common query changes to make when updating your queries: https://www.measurementlab.net/data/docs/bq/legacymigration/  best regards, Chris Ritzo - M-Lab \ue5d3'}, 2: {'username': 'conci...@cantab.net', 'response_date': 'Jul 9, 2018, 5:00:36 AM', 'response_content': 'Thanks! \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}}"
183	▌isat◆2018▐---call-for-papers	1521345522.0	2018-03-17 20:58:42	ISAT	[Apologies if you receive multiple copies of this CfP]    ISAT proceedings are being published by Springer in the series Advances in Intelligent Systems and Computing and indexed by ISI Thomson Reuters (Web of Science), Elsevier's SCOPUS, DBLP, Ei Compendex and Google Scholar since 2015.    39th International Conference Information Systems Architecture and Technology ISAT 2018 SEPTEMBER 16 - 18, 2018, NYSA, POLAND www.isat.pwr.edu.pl Dear Friends and Colleagues, Both the International Program Committee and the Local Organizing Committee have pleasure inviting you to participate in 39th International Conference Information Systems Architecture and Technology - ISAT 2018. The aim of the conference is to provide a platform to the researchers and practitioners from both academia as well as industry to meet and share cutting-edge development in the field of computer science and management. ISAT is a forum for specific disciplinary research, as well as on multi-disciplinary studies to present original contributions and to discuss different subjects of today's information systems designing, development and implementation. Topics considered in 2018 ISAT edition are presented on the ISAT website. Prospective authors are invited to submit full original papers which are not submitted or published anywhere in other conferences or journals, in electronic format using our conference paper submission system. PUBLICATION ISAT proceedings (11 books) were published by Springer in the series Advances in Intelligent Systems and Computing and indexed by ISI Thomson Reuters (Web of Science), Elsevier's SCOPUS, DBLP, Ei Compendex and Google Scholar since 2015. The 2018 proceedings will also be published in Springer's AISC Series and submitted to ISI Thomson, Elsevier's SCOPUS, DBLP, Ei Compendex for Review and Indexing. IMPORTANT DATES May 14, 2018 - Registration and submission of full papers. June 30, 2018 - Notification of paper acceptance. July 9, 2018 - Camera ready version submission. July 30, 2018 - Fee payment. August 5, 2018 - Registration of participation. September 16-18, 2018 - The conference time. ISAT 2018 is organized by Department of Computer Science, Faculty of Computer Science and Management, Wrocław University of Science and Technology, Poland, and University of Applied Sciences in Nysa, Poland. ISAT 2018 will be held in the Court Park Hotel in Nysa and at the University of Applied Sciences in Nysa, Poland from 16 to 18, September 2018. Further details on ISAT 2018 are available on the conference Web-site www.isat.pwr.edu.pl. Our website is mobile friendly. Please take the time to explore the website, and keep yorself up to date on recent changed, as well as discover the history of the ISAT conference series. We look forward to welcoming you in Nysa, Poland in September 2018. Sincerely yours    Leszek Borzemski   Zofia Wilimowska   Jerzy Świątek    Local Organizing Committee	{}
184	i-have-just-run-the-mlabs-test-on-my-sony-laptop-using-sucks-opps,-i-mean-cox-as-my-wireless-provider	1519934171.0	2018-03-01 12:56:11	btno...@gmail.com	using Mlabs, speed tests no discernable actions needed to be taken  _ I am attaching the results of the tests  however, I work for and really believe in the Visualware performance and testing products-  there is a freemium model for tests and purchased testing that is used by over 3000 users.  the results shown on the screenshots, are from the same date and time, provider and using a quality test point (that anyone can use)   Visualware -every time is able to determine accurate results of why MY internet is so slow! when I am playing for the highest amount sold.   with that said, anyone can use the Visualware site connectivity testing.   We will work with anyone to provide testing resources for this or your services.  thanks and let me know how I can help  Noreen   2093099522	{}
185	an-update-on-m-lab-resources	1518550466.0	2018-02-13 12:34:26	Chris Ritzo	Greetings all:  The M-Lab team wanted to send a brief update to the dis...@measurementlab.net group, about some new content on the website.  In our blog post in May of last year, we outlined that we were beginning changes to our data processing pipeline. That work is now complete, and our entire data processing pipeline is now open source and more extensible to new experiments. If you query M-Lab data, you'll want to review the full details in our blog post, as our BigQuery Datasets, table names, and view names have changed. The new open source ETL pipeline is one project in a larger initiative to update all components of the M-Lab platform, which we are continuing work on this year.  Additionally, because there has been a steady increase in third party integrations of M-Lab tests, we recently added a Developer section on the website. If you have feedback on these resources or suggestions for improvement, please let us know.   Best regards, Chris Ritzo M-Lab Support & Operations sup...@measurementlab.net o...@measurementlab.net	"{0: {'username': 'Fenwick Mckelvey', 'response_date': 'Feb 19, 2018, 7:05:15 AM', 'response_content': 'Thanks Chris for the update. Very exciting to hear tests might have ASN numbers appended in the future.   Thank you and your team for all the data maintenance.   \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
186	histogram-of-ndt-download-speeds-by-quantile?	1515096145.0	2018-01-04 13:02:25	Fenwick Mckelvey	Hi all, I am trying to improve my BiqQuery skills and I'd like to write a query to generate a histogram of Download speeds grouped by quantile. Below is a script that uses buckets of 10 Megs, but I'd like to find a way to use BigQuery's quantile function to create the buckets, instead of my hand-coded ones  then count the number of tests per bucket.  Any ideas?  SELECT CASE WHEN DownloadSpeed BETWEEN 0 AND 10 THEN 'Up to 10 Meg' WHEN DownloadSpeed BETWEEN 10.1 AND 20 THEN 'Up to 20 Meg' WHEN DownloadSpeed BETWEEN 20.1 AND 30 THEN 'Up to 30 Meg' WHEN DownloadSpeed BETWEEN 30.1 AND 40 THEN 'Up to 40 Meg' WHEN DownloadSpeed BETWEEN 40.1 AND 50 THEN 'Up to 50 Meg' WHEN DownloadSpeed BETWEEN 50.1 AND 60 THEN 'Up to 60 Meg' WHEN DownloadSpeed BETWEEN 60.1 AND 70 THEN 'Up to 70 Meg' WHEN DownloadSpeed BETWEEN 70.1 AND 80 THEN 'Up to 80 Meg' WHEN DownloadSpeed BETWEEN 80.1 AND 90 THEN 'Up to 90 Meg' WHEN DownloadSpeed BETWEEN 90.1 AND 100 THEN 'Up to 100 Meg' WHEN DownloadSpeed  > 100 THEN '100 Meg and higher' ELSE 'None' END as tiers, count(DownloadSpeed)  FROM ( SELECT  (8 * web100_log_entry.snap.HCThruOctetsAcked/(web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd)) AS DownloadSpeed, FROM     plx.google:m_lab.ndt.all WHERE connection_spec.data_direction = 1 AND blacklist_flags = 0 AND web100_log_entry.is_last_entry IS NOT NULL AND web100_log_entry.snap.HCThruOctetsAcked IS NOT NULL AND web100_log_entry.snap.HCThruOctetsAcked >= 8192 AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000 AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 3600000000 AND web100_log_entry.snap.CongSignals IS NOT NULL AND web100_log_entry.snap.CongSignals > 0 AND log_time > 1483228800 AND log_time < 1514764800 AND connection_spec.client_geolocation.city IS NOT NULL AND connection_spec.client_geolocation.country_name = 'Canada' AND (connection_spec.server_geolocation.country_name = 'Canada' OR connection_spec.server_geolocation.country_name = 'United States')   )   GROUP BY   tiers   ORDER BY   tiers DESC  Best, Fenwick	"{0: {'username': 'Chris Ritzo', 'response_date': 'Feb 13, 2018, 2:41:49 PM', 'response_content': ""Hi Fen,  We discussed a couple ideas on how to best use BigQuery to get to quantiles, but I wanted to share here also in case it spawns more discussion or helps others.  Your query looks good as a means of manually setting different levels for download test speeds. If you want to get normalized buckets for the quantiles, you can use the APPROX_QUANTILES function to get evenly distributed buckets of the inner select statement:  #standardSQL ### Approx Quantiles (5) for Download measurements in Canada or US  SELECT APPROX_QUANTILES(DownloadSpeed, 5) AS approx_quantiles FROM ( SELECT   (8 * web100_log_entry.snap.HCThruOctetsAcked/(web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd)) AS DownloadSpeed FROM      `measurement-lab.release.ndt_all` WHERE ...snip...  This specifies 5 buckets, but you can use however many you like. You could then use those as the values for the different groupings/quantiles.  You might also be interested in looking at the PERCENTILE_CONT() function. Here's an example using the same query you provided (adapted for our new tables/views and StandardSQL), but nested to return a 5+1 summary of download speed and standard deviation:  #standardSQL SELECT   MAX(minimum) AS minimum,   MAX(percentile10) AS percentile10,   MAX(median) AS median,   MAX(percentile90) AS percentile90,   MAX(maximum) AS maximum,   AVG(average) AS average,   MAX(standard_dev) AS standard_dev   FROM (     SELECT       PERCENTILE_CONT(download, 0) OVER() AS minimum,       PERCENTILE_CONT(download, 0.1) OVER() AS percentile10,       PERCENTILE_CONT(download, 0.5) OVER() AS median,       PERCENTILE_CONT(download, 0.9) OVER() AS percentile90,       PERCENTILE_CONT(download, 1) OVER() AS maximum,       AVG(download) OVER() AS average,       STDDEV_POP(download) OVER() AS standard_dev       FROM        (         ### Approx Quantiles for Download measurements in Canada or US            SELECT             (8 * web100_log_entry.snap.HCThruOctetsAcked/(web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd)) AS download           FROM                `measurement-lab.release.ndt_all`           WHERE           connection_spec.data_direction = 1 AND           web100_log_entry.snap.HCThruOctetsAcked IS NOT NULL AND           web100_log_entry.snap.HCThruOctetsAcked >= 8192 AND           (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000 AND           (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000 AND           web100_log_entry.snap.CongSignals IS NOT NULL AND           web100_log_entry.snap.CongSignals > 0 AND            web100_log_entry.log_time > 1483228800 AND           web100_log_entry.log_time < 1514764800 AND           connection_spec.client_geolocation.city IS NOT NULL AND           connection_spec.client_geolocation.country_name = 'Canada' AND           (connection_spec.server_geolocation.country_name = 'Canada' OR connection_spec.server_geolocation.country_name = 'United States')       )    )  Hope this helps! Has anyone else used these functions? I'd be interested in your thoughts.  -Chris \ue5d3""}, 1: {'username': 'Bob Ballance', 'response_date': 'Feb 13, 2018, 3:16:53 PM', 'response_content': 'Hi Chris & Fen -  I’m using a query similar to your PERCENTILE_CONT example for one of my data views, and displaying the data as box-and-whisker charts. In my case, I actually down-selected to take the maximum test speed per client per day. I noticed, however, that you’ve bumped the maximum bound on the times from an earlier example. Is that significant?  . . . Bob  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 2: {'username': 'Chris Ritzo', 'response_date': 'Feb 13, 2018, 3:26:15 PM', 'response_content': 'Hi Bob,  I don\'t think I\'d changed the date limits from Fen\'s original query (2017):   web100_log_entry.log_time > 1483228800 AND web100_log_entry.log_time < 1514764800 AND  or were you referencing something else?  -Chris  \ue5d3 \ue5d3  . . . Bob  \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3'}, 3: {'username': 'Bob Ballance', 'response_date': 'Feb 13, 2018, 3:33:32 PM', 'response_content': 'I was looking at the time limits and comparing to what I’ve been using, and if I now count the zeros, you’ve decreased the upper limit: (my bad). However, the question is still pertinent.  From an example you sent me a while back:   AND (web100_log_entry.snap.SndLimTimeRwin +      web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd) >= 9000000   AND (web100_log_entry.snap.SndLimTimeRwin +     web100_log_entry.snap.SndLimTimeCwnd +     web100_log_entry.snap.SndLimTimeSnd) < 3600000000  vs. the example today     (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000 AND           (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000 AND         . . . Bob \ue5d3'}, 4: {'username': 'Chris Ritzo', 'response_date': 'Feb 13, 2018, 3:53:34 PM', 'response_content': 'Ah, I see. Yes, that change is also now reflected on our page about calculating common metrics. That value was recommended by our staff more familiar with the internals of NDT as a more sensible upward the time bound of a test. \ue5d3'}}"
187	linking-ndt-to-traceroute-data	1517609691.0	2018-02-02 15:14:51	Ryan Mitchell	Any update to this question asked a couple of years ago?  What's the best way to match up clients in both ndt and traceroute tables?  I'm interested in the queries used to generate the interconnection report.  I can understand conceptually the methodology to figure out the bottlenecks at transit ISP borders, but for a given ndt run I want to know all the hops.  Generating the interconnect report would have involved both ndt and traceroute datasets, right?  thank you.	"{0: {'username': 'Chris Ritzo', 'response_date': 'Feb 6, 2018, 6:31:22 AM', 'response_content': 'Hi Ryan,  The interconnection report did not involve PT data. It just involved the source and destination information and NDT data. Queries for the report were conducted using a tool called Telescope: https://github.com/m-lab/telescope which uses a JSON formatted selector file as specified here: https://github.com/m-lab/telescope/tree/master/documentation  The report links to the original data used in the report: https://console.cloud.google.com/storage/browser/m-lab/interconnection-study-2014 One of the files there provides the selector files that were used with Telescope in the interconnection report.  You may also wish to review the report\'s methodological overview: https://github.com/m-lab/mlab-wikis/blob/master/InterconnectionStudyMethodology.md  If you\'re wanting to examine Paris Traceroutes for NDT tests, the best way is to query for traceroutes that occurred to the same IP address within an hour of the NDT test.  So join on the destination IP, and add the condition that the time of the PT test is within an hour of the time of the NDT test. An hour is likely overkill, but should give you want you need.  Hope this helps.  -Chris  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': 'Ya Chang', 'response_date': 'Feb 6, 2018, 12:18:47 PM', 'response_content': 'Hi, Ryan,  We launched Rollins in the middle of 2016 which helped linking NDT and Paris TraceRoute (PT) data.  In the current PT test, the filename for each test is in format like:  20180131T16:15:45Z-87.198.51.112-54601-193.1.12.211-3001.paris  time_stamp + client_IP + client_port  + server_IP that triggered this PT test + server_port  In this case 193.1.12.211 is the server for NDT tests on that M-Lab site. 3001 (and 3010) is the NDT port.  The first line of this PT test is like:  traceroute [(193.1.12.204:33460) -> (87.198.51.112:54601)], protocol icmp, algo exhaustive, duration 3 s  The PT test server is 193.1.12.204.  With this information, you can link the NDT and PT test with a time frame with much higher precision.  Ping me if you have more question.  Ya    \ue5d3'}}"
188	paristraceroute-has-a-bug,-and-it-causes-some-bad-data	1516807545.0	2018-01-24 08:25:45	Peter Boothe™	"Paris Traceroute has a bug, and it causes some bad data In December 2017, M-Lab was notified of oddities in the Paris Traceroute data. Upon investigation, a bug in the Paris Traceroute code was identified. The bug caused bad measurement data in 2.7% of the traceroutes since July 2016.   The M-Lab team is doing development to work around the bug in several ways: By changing how we call Paris Traceroute to reduce the probability that the bug condition occurs. By adding more sophisticated bad data detection and elimination code to our parsing of Paris Traceroute data. By adding monitoring to our parser so that we can know how much of our raw data is affected at any given time. By reprocessing our historical raw data archives in order to eliminate all bad traceroute data caused by this bug from our BigQuery database  Through disclosures and analyses like these, M-Lab re-confirms its commitment to open data and open science. Our raw data, warts, bugs, and all, is and will be always available ( https://console.developers.google.com/storage/browser/m-lab/), while our processed data (https://bigquery.cloud.google.com/dataset/measurement-lab:public?pli=1) continues to reflect our best understanding of the state of the Internet represented by that raw data. Read More: The bug and its fixes The root cause of the reported problem is a design flaw in Paris Traceroute, exacerbated by Rollins, the wrapper script that M-Lab uses to run it. The Rollins wrapper script went into production in first half of 2016 (replacing an older script which had its own flaws).  Every connection made to M-Lab systems triggers a Paris Traceroute to run from the M-Lab server back to the computer that initiated the connection. As the number of simultaneous traceroutes has increased, this has exposed a bug in Paris Traceroute where two independent traceroutes that overlap in time can become intermixed in the resulting Paris Traceroute output.  For example, if we were to simultaneously run a traceroute from server S to clients A and B, the S-A path reported by the tool might contain hops that are exclusive to the S-B path, or it could switch in the middle of Paris Traceroute's output from being the S-A path into being the S-B path.   In the following example, the output from Paris Traceroute switches without warning from being the output for  $ paris-traceroute 35.188.101.1 into containing the data for the contemporaneously-run command $ paris-traceroute 139.60.160.135 The resulting output from the first command (shown below) shows a link that doesn't exist from 216.239.51.185 to 173.239.28.18, on lines 8 and 9 and (worse!) switches without warning into the output from the second command (which we have highlighted in orange, and we have highlighted the suspiciously large RTT in red):  traceroute [(173.205.3.38:33458) -> (35.188.101.1:40784)], protocol icmp, algo exhaustive, duration 14 s  1  P(6, 6) 173.205.3.1 (173.205.3.1)  0.138/5.405/31.541/11.688 ms   2  P(6, 6) xe-1-0-6.cr2-sjc1.ip4.gtt.net (89.149.137.5)  19.090/21.052/24.168/1.898 ms   3  P(6, 6) as15169.sjc10.ip4.gtt.net (199.229.230.134)  19.105/19.611/21.314/0.796 ms   4  P(6, 6) 108.170.243.13 (108.170.243.13)  19.872/20.275/20.931/0.446 ms   5  P(6, 6) 209.85.246.206 (209.85.246.206)  20.092/20.545/21.096/0.331 ms     MPLS Label 697177 TTL=1  6  P(6, 6) 209.85.248.127 (209.85.248.127)  53.493/54.490/57.796/1.493 ms     MPLS Label 638493 TTL=1  7  P(6, 6) 216.239.47.251 (216.239.47.251)  52.755/56.170/67.922/5.386 ms     MPLS Label 402431 TTL=1  8  P(6, 6) 216.239.51.185 (216.239.51.185)  52.455/52.652/52.981/0.228 ms   9  P(6, 6) csd180.gsc.webair.net (173.239.28.18)  4802.776/4803.621/4807.622/1.790 ms  10  P(6, 6) 173.239.11.1 (173.239.11.1)  66.509/66.524/66.561/0.018 ms  11  P(6, 6) 173.239.57.74 (173.239.57.74)  66.634/69.047/72.354/2.442 ms  12  P(6, 6) 139.60.160.1 (139.60.160.1)  67.066/70.367/72.034/2.327 ms  13  P(6, 6) 139.60.160.135 (139.60.160.135)  62.542/64.001/66.941/2.020 ms  This is obviously quite worrying, so the M-Lab team set about investigating why this is happening, how to prevent (or at least reduce the frequency of) its occurrence, and how to filter or annotate bad data in our database (while, of course, preserving the original raw data in our historical archives).  Paris Traceroute relies on a single 16 bit ""tag"" field to disambiguate returning ICMP messages, and that tag is essentially the output of a hash function. This single field is used both to identify which request packet (what initial TTL) and which session it belongs to. When there are two overlapping tests, it is possible to have a collision of tag values, exactly analogous to a hashtable collision. When one test starts first, that test runs for a bit, and then after the second (colliding) test starts, spurious data begins to arrive to the first test. The symptoms of this are that, in the middle of the first test, the results of the second test begin to pollute the results of the first. Just like with hash tables, the incidence rate of this bug scales up with usage. Sites with minimal numbers of connections saw no collisions, and sites with large numbers of connections saw an increased percentage of tests affected.   To prevent the collection of bad data, we have created a workaround in our Paris Traceroute wrapper to bring down the expected number of incidents and that workaround will be deployed to M-Lab servers soon.  To prevent the inclusion of any bad data in our BigQuery tables, we are porting the detection code from a standalone tool into our parser. We are also adding monitoring to measure the error rates going forwards.  We will soon be reparsing our historical archives, and over the next quarter as all our historical archives get reprocessed, all bad data caused by this bug should be eliminated from or tagged within our BigQuery database. M-Lab's raw data will remain untouched, as our raw data reflects the data we actually got from M-Lab servers, not the data we wish we had gotten from M-Lab servers.  Once remediation is completed, we will provide a longer write up going in to more depth about the issue and the remediation.  Thanks to Amogh Dhamdhere for flagging the Paris Traceroute data issue!  -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful. Peter Boothe - Coder at Google, working in support of M-Lab"	{}
189	paris-traceroute-geolocation	1515011126.0	2018-01-03 13:25:26	Fenwick Mckelvey	Hi, We're trying to gather statistics for boomerang or trumpet redirects that involve domestic connections being redirected outside of the origin/destination country. Origin and destination country data is available for clients/server but these statistics don't seem to be calculated per hop for the Paris Traceroute data. The goal is to determine how much traffic leaves the country via boomerang redirection.  I'm curious to know if there is a table containing geodata for paris traceroute data that can be queried or if there is a way to determine the geolocation of paris traceroute hops (origin and destination) using BigQuery. In the past we've used the variable paris_traceroute_hop.src_geolocation.country_code.  Thanks, Trevor and Fen	"{0: {'username': 'Nick Feamster', 'response_date': 'Jan 3, 2018, 1:44:32 PM', 'response_content': 'We’ve written a paper on this: https://arxiv.org/abs/1605.07685  We also have a related paper that looks at the phenomenon specifically in Africa: https://www.cs.princeton.edu/~arpitg/pdfs/pam14.pdf  The answer to your question is “no”. Geolocating traceroute data is quite hard. Most of the geolocation services (MaxMind, etc.) are notoriously inaccurate for network infrastructure (routers).  However, there are some workarounds, some of which are described in the above paper. The short answer is you often don’t need precise geolocation to characterize tromboning.  If you need any of the data for this paper, it is available at: https://ransom.cs.princeton.edu  Let us know if we can help further.  Thanks, -Nick \ue5d3 > -- > You received this message because you are subscribed to the Google Groups ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. > To post to this group, send email to dis...@measurementlab.net. > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': 'Fenwick Mckelvey', 'response_date': 'Jan 3, 2018, 2:44:31 PM', 'response_content': ""Thanks Nick. I'll have a look at these papers and I'll likely have more comments.   Being based in Canada, I really respect Clement and Obar's work on IXMaps. We're interested in studying tromboning/boomerang routing on a global scale (as you do in the first paper) to see if Canada is exceptional. We had been hoping to use the Paris Traceroute data for countries with an M-Lab node to measure the % of tests beginning and ending in the country that have hops that exit the country. Given the limitations of Maxmind for locating routers, I thought using country might be an acceptable level of geolocation.  Our issue seems to be the BQ data. We previously had access to gelocation per hop and that seems to be missing. We're wondering if that data structure of the M-Lab BQ has changed.   I am less familar with the RIPE data though open to using it to calculate global trends in boomerang routing. I'll look at the public data too.   Best, Fen \ue5d3""}, 2: {'username': 'Ethan Katz-Bassett', 'response_date': 'Jan 6, 2018, 2:01:30 PM', 'response_content': ""+Vasilis Giotsas   Hi folks,  Few more pointers: - New IMC paper on accuracy of geolocation databases for routers: (paper) https://conferences.sigcomm.org/imc/2017/papers/imc17-final96.pdf (slides) https://conferences.sigcomm.org/imc/2017/slides/router-geo-databases-20171106-wide.pdf - For one of our (not yet published) projects, Vasilis (cc'ed) developed a geolocation technique that works by smartly figuring out which RIPE Atlas vantage points (VPs) MIGHT be close to a router, then pinging the router from those VPs and geolocating it if the RTT from one of the VPs is less than 1ms (which given speed of light means that the router can't be very far from that VP). We used it to geolocate the border routers between ASes in a set of traceroutes from 30 Ark vantage points to 360K prefixes, and it worked very well. We could locate 82% of the border router IP addresses to be within 1ms or less of a VP with a known location.  We could not locate 10% of IP addresses because they did not respond to pings, and 8% were responsive but we were unable to find a vantage point within 1ms. Due to Vasilis's very smart vantage point selection, our technique probed each IP address from an average of only 8.3 vantage points in order to find the nearby one. - Vasilis built the technique into a service as part of a new RIPE service that uses multiple techniques to provide geolocation results. Unfortunately I can't find a link to it, but hopefully either you can find the link to the service or to the RIPE meeting talk that I believe they gave, or Vasilis can provide a link. \ue5d3""}, 3: {'username': 'Vasilis Giotsas', 'response_date': 'Jan 7, 2018, 9:14:46 AM', 'response_content': 'Hi all,  Thanks for cc\'ing me Ethan.   The slides and video from the presentation of the RIPE tool that uses our approach is below: https://ripe75.ripe.net/archives/video/121/ This service is ""beta"", we\'re working on improving many aspects of it but the core idea is the same.  I first presented a preliminary version of this work at the RIPE 73 Hackathon: https://ripe73.ripe.net/archives/video/1447/  We\'re currently working on a paper but if you like we can share some more technical details, or if you have a set of addresses to geolocate we can run the code for you.  Best wishes for 2018!  Vasileios  \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  > To post to this group, send email to dis...@measurementlab.net. > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.  -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3'}, 4: {'username': 'Fenwick Mckelvey', 'response_date': 'Jan 16, 2018, 12:23:38 PM', 'response_content': 'Hi all, Thanks so much for these sources, especially on geolocation of core routers. Has there been any attempts to operationalize these recent findings, creating a data set of traceroutes with each route geolocated? As a policy scholar, I am trying to engage with the implications of these routing trends and using the Paris Traceroute data was my first attempt to get at the issue.  Best, Fen  \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  > To post to this group, send email to dis...@measurementlab.net. > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.  -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}}"
190	asn-specific-measurments	1512383104.0	2017-12-04 03:25:04	Eireann Leverett	Hello,  I'm back again using wonderful M-Lab data and thanks for all the hard work!  How would I look at all the test values in a given year for a specific ASN?   Or more generally, could you give me some visibility into the field/table/column names we use for Big Query?  Eireann	"{0: {'username': '☕Peter Boothe', 'response_date': 'Dec 4, 2017, 8:29:14 AM', 'response_content': 'We are planning on adding ASN annotation to our BigQuery system in 2018.  Until then, when using BigQuery you must specify the netblocks of interest. Data that has been more heavily processed can be divided up by ISP at viz.measurementlab.net, but the processing that makes the data ready for visualization uses data from more sources besides BigQuery.    -Peter  \ue5d3 \ue5d3  Eireann  -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.    -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.'}, 1: {'username': 'Ben Dowling', 'response_date': 'Dec 4, 2017, 11:07:52 AM', 'response_content': ""We (https://ipinfo.io) have ASN data in BigQuery and can join it to the M-Lab data to aggregate speeds by ASN. It's not currently public, but would be happy to make it public, or share the aggregations. Not sure how best to go about it?  \ue5d3""}, 2: {'username': 'Eireann Leverett', 'response_date': 'Dec 6, 2017, 7:38:55 AM', 'response_content': ""Got it. Can you give me an example query for netblock with big query? IN other words, I run a country specific query like this: connection_spec.client_geolocation.country_code = 'NO' What's do I need for a netblock? Are these field names documents somewhere I am missing? Eireann \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3""}, 3: {'username': 'Eireann Leverett', 'response_date': 'Dec 6, 2017, 7:44:02 AM', 'response_content': ""I've answered my own question, but am posting it here both to let you know and for other noobs like me! https://www.measurementlab.net/data/docs/bq/schema/  On 04/12/17 15:28, '☕Peter Boothe' via discuss wrote: \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3""}, 4: {'username': 'Eireann Leverett', 'response_date': 'Dec 6, 2017, 8:15:12 AM', 'response_content': 'So my goal query is something like quartiles for download and upload speeds across a netblock.  From the documentation I see how to get specific for IP:  web100_log_entry.connection_spec.remote_ip == ""179.181.99.49"" or web100_log_entry.connection_spec.remote_ip == ""179.181.99.50""  However, it doesn\'t look like I can use CIDR notation:   web100_log_entry.connection_spec.remote_ip == ""179.181.99.49/32""  ...for example yields 0 results.  Then once I solve that, I have another problem which is that my current query does quartiles like this:  SELECT web100_log_entry.connection_spec.remote_ip AS ip, NTH(1, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration, 101)) AS uploadMin, NTH(26, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration, 101)) AS uploadLower, NTH(51, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration, 101)) AS uploadMedian, NTH(76, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration, 101)) AS uploadUpper, NTH(101, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration, 101)) AS uploadMax, FROM  Which produces quartiles per IP or Row in the results, when I would prefer one line for each netblock.  Any advice? \ue5d3'}, 5: {'username': 'Ben Dowling', 'response_date': 'Dec 6, 2017, 9:58:16 AM', 'response_content': ""I don't think there are any netblock details in the table, you'd need to join to an ASN/netblock dataset. You can aggregate to an arbitrary netblock with NET.IP_TRUNC though, eg this will convert IPs into the equivalent /24:  NET.IP_TRUNC(NET.SAFE_IP_FROM_STRING(web100_log_entry.connection_spec.remote_ip), 24) \ue5d3""}}"
191	paris-traceroute-data	1511387305.0	2017-11-22 14:48:25	richard schreier	I have been querying the MLab NDT data for some time with no restrictions in Big Query, today I tried to access Paris Traceroute data and got the following error:  Error: Quota exceeded: Your project exceeded quota for free query bytes scanned.  I have never had a quota exceeded error on the NDT data and don't understand why it is limited for Paris Traceroute data.  Any ideas?  Thanks Richard	"{0: {'username': 'Chris Ritzo', 'response_date': 'Nov 23, 2017, 9:06:55 AM', 'response_content': 'Hi Richard,  Could share the query you are using? I will attempt to replicate the error.  To gather more information, could you also share: - how you are executing the query: BigQuery web interface, the bq command in the Google cloud SDK, or using a custom script that leverages the BigQuery APIs? - are only querying the Paris traceroute data to save the results locally, or are you writing results to a BigQuery table within a project on your account?  Best regards, Chris Ritzo   \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
192	what-is-the-maximum-speed-that-we-can-use?	1511404895.0	2017-11-22 19:41:35	Aofzide Csiperos	I test on measurement speed with M-Lab to compare with other application. If > 100m+ M-Lab cannot be get more than 100m. Can it upgrade to more speed?	{}
193	a-confusing-phenomenon-of-mlab-pt-traces-and-ndt-data	1508804878.0	2017-10-23 17:27:58	Xiaohong Deng	"Hi Chris and all,  Last time you asked about our opinions on newly upgraded BigQuery system. We find it works fine. Thank you for making it upgraded.  However, there's something of Mlab NDT data and it's assocation with Pairs Trace route that caught our attention.  Firstly, we find there is an Client IP ""45.56.98.222"" that contributes large amount of NDT tests all most every month continiously, and that IP actually registered under to Mlab domain itself? In March 2017's NDT data it contributed 1/3 of all tests.  Then, when we try to associate that Client IP with the Paris traces we found actually traces that have a different IP as destination IP, but last hop reached  ""45.56.98.222"".  For instance, below is an trace takes ""192.189.187.106"" as destination IP but  ""45.56.98.222"" as last hop.  We are particularly interested in understanding this phenomena, because it confuses the algorithm we use to infer inter-domain links from Mlab data in our research work.  If anyone could give some insight and/or pointers to make it clearer to us how to comprehend and hence deal with this case, that'd be highly appreciated.    Here is another traceroute to AS7726: traceroute [(67.106.215.204:33466) -> (192.189.187.106:19439)], protocol icmp, algo exhaustive, duration 31 s  1  P(6, 6) 67.106.215.193.ptr.us.xo.net (67.106.215.193)  0.248/0.263/0.284/0.013 ms   2  P(6, 6) 67.111.23.93.ptr.us.xo.net (67.111.23.93)  0.622/0.730/0.867/0.086 ms   3  P(0, 6)  4  P(6, 6) FEDERAL-EXP.ear3.Denver1.Level3.net (4.14.114.14)  36.417/36.466/36.520/0.037 ms   5  P(6, 6) if-ae-2-2.tcore2.AEQ-Ashburn.as6453.net (216.6.87.1)  56.756/57.231/58.815/0.727 ms     MPLS Label 540091 TTL=1  6  P(6, 6) if-ae-11-2.thar2.NJY-Newark.as6453.net (216.6.87.242)  47.342/47.952/49.564/0.733 ms   7  P(6, 6) 66.198.111.166 (66.198.111.166)  48.158/48.477/49.644/0.526 ms   8  P(6, 6) 173.255.239.1 (173.255.239.1)  0.146/1460.583/4094.052/1491.610 ms   9  P(1, 6) eb.measurementlab.net (45.56.98.222)  0.128/0.128/0.128/0.000 ms  Kind Regards, Xiaohong - Simplicity is not a given. It is an achievement."	"{0: {'username': 'Chris Ritzo', 'response_date': 'Oct 26, 2017, 10:13:41 AM', 'response_content': 'Xiaodeng,  Thanks very much for your detailed question on your research with M-Lab data. We appreciate you and your colleagues\' feedback on the new table schema.    Eb.measurementlab.net (45.56.98.222), is part of M-Lab\'s monitoring infrastructure. We run scheduled tests from it to each server on our platform to confirm whether the NDT server is working properly. These tests function as a basic health check, to confirm that NDT is working across the platform end to end. This end to end test has been in place since ~March 2016 and generates 144 tests per server per day.  n regions with a lot of test traffic, this is a minimal amount of data. However, in areas where test volumes are lower, it is likely wise to exclude test results from this IP from your analysis. For the research you\'ve described, we would suggest that you exclude the test results from this IP address. Based on this inquiry our development team has been exploring ways to flag data from this IP so that it can be easily excluded from queries if desired. This will likely be an indicator in the ""blacklist_flag"" field.   Additionally, along with the updates we are planning for table schemas, we are discussing the usefulness of creating pre-defined BigQuery views of the data. For example, this would allow us to define a view for completed NDT tests that met specific parameters for completeness, or to automatically exclude results with the blacklist_flags field set, or to include data only for specific values in the blacklist_flags field. If there are specific views you think would be useful to your research, please let me know.  Lastly, it\'s also worth mentioning that in the immediate future, our development team will be proceeding with a complete rewrite of NDT which will allow us to replace this health check test using a different method that will allow us to monitor the state of each NDT server without adding data to the NDT dataset.  Thanks again, and if you have more questions please let us know  Best regards, Chris    Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036      \ue5d3'}}"
194	google-fiber-vs-gigamonster:-1gbps-service-in-charlotte-nc-compared-(m-labs-&-speedtest.net)	1507580731.0	2017-10-09 13:25:31	Rajan Patel	I am comparing Measurement Labs tests taken at www.internethealthtest.org from my Macbook Pro, using a wired Internet connection. I am astonished at how poorly Google Fiber performed.  First, I connected a wire from my Google Fiber network box, which has 1gbps service, and got the following results:  speedtest.net: https://goo.gl/oTE8rF internethealthtest.org: https://goo.gl/K3Bkwj  Then I removed the Google Fiber wired connection and replaced it with an ethernet cable with Gigamonster 1gbps service  speedtest.net: https://goo.gl/DxgC2g internethealthtest.org: https://goo.gl/Epwmkh  What are the next steps for me to get a knowledgeable explanation from Google Fiber about these shortcomings in their service?  I am trying to do an apples to apples comparison, and everything indicates that my fastest and lowest latency connectivity is through Gigamonster.   Appreciate feedback...  Rajan	"{0: {'username': 'Jim Warner', 'response_date': 'Oct 9, 2017, 4:52:54 PM', 'response_content': 'Speed test results are strongly colored by the round trip time between the client and the server. You have RTTs of 38 mS (google) and 13 mS (gigamonster). That will affect your apples-to-apples comparison.    \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': 'Rajan Patel', 'response_date': 'Oct 9, 2017, 4:57:30 PM', 'response_content': 'Jim, if you were in my shoes what service would you keep, and which would you cancel? Any other tests I can perform to give you the information you would want to know to make this decision? Rajan  On Mon, Oct 9, 2017, 7:52 PM Jim Warner <war...@ucsc.edu> wrote: Speed test results are strongly colored by the round trip time between the client and the server. You have RTTs of 38 mS (google) and 13 mS (gigamonster). That will affect your apples-to-apples comparison.    On Mon, Oct 9, 2017 at 1:25 PM, Rajan Patel <rajan...@responsiveweb.com> wrote: I am comparing Measurement Labs tests taken at www.internethealthtest.org from my Macbook Pro, using a wired Internet connection. I am astonished at how poorly Google Fiber performed.  First, I connected a wire from my Google Fiber network box, which has 1gbps service, and got the following results:  speedtest.net: https://goo.gl/oTE8rF internethealthtest.org: https://goo.gl/K3Bkwj  Then I removed the Google Fiber wired connection and replaced it with an ethernet cable with Gigamonster 1gbps service  speedtest.net: https://goo.gl/DxgC2g internethealthtest.org: https://goo.gl/Epwmkh  What are the next steps for me to get a knowledgeable explanation from Google Fiber about these shortcomings in their service?  I am trying to do an apples to apples comparison, and everything indicates that my fastest and lowest latency connectivity is through Gigamonster.   Appreciate feedback...  Rajan -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}, 2: {'username': 'Jim Warner', 'response_date': 'Oct 9, 2017, 5:35:03 PM', 'response_content': 'I can\'t tell where the servers you were testing against are located. I\'d want some data where I knew that the servers didn\'t change between my google fiber and gigamonster comparisons. It looks like both of the tests you selected use the ""closest"" server for some meaning of ""closest"" that might not be the same for different providers. I would probably run iperf tests against a collection of endpoints and repeat the same at different times of the day.   \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3'}}"
195	subscribe	1506955186.0	2017-10-02 07:39:46	Patrick Holahan	--  Patrick Holahan Senior Network Engineer Tertiary Education & Research Network of South Africa NPC Fault Reporting: +27(21)763-7147 or sup...@tenet.ac.za Mobile: +27(79)523-5555 http://www.tenet.ac.za/contact	{}
196	re:-[m-lab-discuss]-understanding-a-traceroute-measurement	1505315333.0	2017-09-13 08:08:53	☕Peter Boothe	"That path consists of 7 hops, originating at 162.219.49.38, and then proceeding 162.219.49.38 -> 162.219.49.1 -> 184.105.64.89 -> 72.52.92.165 -> 195.66.224.207 -> 62.128.207.217 -> 185.20.96.130 -> 37.220.21.130  I believe the names come from reverse DNS, and the P(6,6) indicates how many probes were sent (the first number) and how many of those probes were responded to (second number). The last column contains summary latency information that I would have to go to the documentation (`man paris-traceroute` and then searching from there) in order to explain what each means.    -Peter  On Sun, Sep 10, 2017 at 5:22 PM, <aqure...@gmail.com> wrote: Hi, please forgive me for asking this question which might be quite naive for you. However, i am quite a newbie in understanding 'Internet Traffic and Measurements'. I am pasting a traceroute measurement (taken from Paris Traceroutes). Could you please give me a quick start as how to understand this traceroute:  traceroute [(162.219.49.38:33457) -> (37.220.21.130:42217)], protocol icmp, algo exhaustive, duration 2 s  1  P(6, 6) 162.219.49.1 (162.219.49.1)  6.446/8.440/10.978/1.549 ms   2  P(6, 6) 100ge12-1.core1.nyc4.he.net (184.105.64.89)  12.058/16.099/24.585/5.643 ms   3  P(6, 6) 100ge7-2.core1.lon2.he.net (72.52.92.165)  79.758/87.655/97.809/5.479 ms   4  P(6, 6) be20.asr01.thn.as20860.net (195.66.224.207)  81.877/82.123/82.344/0.152 ms   5  P(6, 6) po200.core1.dc10.as20860.net (62.128.207.217)  84.869/85.699/89.342/1.631 ms   6  P(6, 6) 91.zone.1.r.dc9.redstation.co.uk (185.20.96.130)  85.347/117.434/262.091/64.741 ms   7  P(6, 6) lnman1.samknows.com (37.220.21.130)  83.149/83.272/83.434/0.105 ms   -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.    -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful."	"{0: {'username': 'Mark Boolootian', 'response_date': 'Sep 13, 2017, 9:29:58 AM', 'response_content': ""If you don't have a solid understanding of how traceroute itself works, you might find the Richard Steenbergen NANOG tutorial of interest:  https://www.youtube.com/watch?v=4dUqVlZ6trU  Slides here: https://www.nanog.org/meetings/nanog47/presentations/Sunday/RAS_Traceroute_N47_Sun.pdf""}, 1: {'username': 'Matt Mathis', 'response_date': 'Sep 13, 2017, 2:32:01 PM', 'response_content': 'One very important detail:  The delay measurements at each hop are extremely noisy and normally confounded by phenomena unrelated to queueing delay or congestion.  Much time has been wasted trying to infer congestion from these statistics.   Although I have used traceroute for performance measurement, it basically stopped working in about 1995, when ""fast path"" routing became the default.  Thanks, --MM-- The best way to predict the future is to create it.  - Alan Kay  Privacy matters!  We know from recent events that people are using our services to speak in defiance of unjust governments.   We treat privacy and security as matters of life and death, because for some users, they are.  \ue5d3 \ue5d3 -- \ue5d3'}, 2: {'username': 'Richard A Steenbergen', 'response_date': 'Sep 19, 2017, 1:52:54 PM', 'response_content': ""Oh god, must we really bring up the 2009 version? :)  Apparently I haven't presented this at NANOG in a while, but the current version of the slides lives at:  https://www.slideshare.net/RichardSteenbergen/a-practical-guide-to-correctly-troubleshooting-with-traceroute  I also have a lengthier and more detailed version here:  http://cluepon.net/ras/traceroute.pdf    \ue5d3 \ue5d3 -- \ue5d3""}, 3: {'username': 'Matt Mathis', 'response_date': 'Sep 19, 2017, 2:49:33 PM', 'response_content': 'Yea, but the bigger point is that the Internet has been ""virtualized"" to the point where traceroute it pretty useless for debugging somebody else\'s network.    If you know the gear, you might be able to make sense of the results, but if you don\'t know the gear you can not possibly figure out what is going on.  Here is a simple example: if the delay stats look good to hop 3 and bad at hop 4, it is easy to assume that hop 4 has a problem.  But for many modern devices the TTL is checked on input processing, and the proper ICMP can be returned by the input line card, even if hop3 is totally out of backplane or output capacity....  hop 4 might be just fine.  (The point being that a router itself is a network with multiple switches and queues, and you can not tell where the TTL check happens relative to any other processing).  Richard, your presentations do not mention SDN...  Thanks, --MM-- The best way to predict the future is to create it.  - Alan Kay  Privacy matters!  We know from recent events that people are using our services to speak in defiance of unjust governments.   We treat privacy and security as matters of life and death, because for some users, they are.  \ue5d3'}, 4: {'username': 'Richard A Steenbergen', 'response_date': 'Sep 24, 2017, 10:32:51 AM', 'response_content': 'None of this is new. It\'s still perfectly possible to troubleshoot, you just need to be aware of these effects and do a lot more than just ""look for the spot where the *\'s happen"". That\'s the entire point of my presentation. :)  Not sure what else I could say about SDN that has any relevance to traceroute?   --  Richard A Steenbergen <r...@e-gerbil.net>       http://www.e-gerbil.net/ras GPG Key ID: 0xF8B12CBC (7535 7F59 8204 ED1F CC1C 53AF 4C41 5ECA F8B1 2CBC) \ue5d3'}}"
197	network-flow-control-calculations	1506116622.0	2017-09-22 14:43:42	plaf...@gmail.com	"Hi,  I was wondering if it is possible to calculate the network flow control throughput limit from the NDT data and how this calculation is done? For example, in the detailed output section the test reports ""The network based flow control limits the throughput to 142.91 Mbps"". I was able to replicate the maximum theoretical throughput calculation from the NDT output and the Mathis formula but haven't found any documentation on what output variables are needed to make the flow control calculation.  Thanks! Paul"	"{0: {'username': 'Kim Sovan', 'response_date': 'Sep 23, 2017, 9:38:45 AM', 'response_content': 'Sent from my iPhone  Begin forwarded message:  From: Kim Sovan <kimso...@gmail.com> Date: September 23, 2017 at 14:36:46 GMT+7 To: plaf...@gmail.com Cc: Ibi Subscriptions \'Csd <Subscr...@Informa.com> Subject: Re: [M-Lab-Discuss] network flow control calculations    Sent from my iPhone \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
198	internship	1505900690.0	2017-09-20 02:44:50	devashishshu...@gmail.com	Where and how can i apply for the internship in mLab?	{}
199	comcast-blocking-of-m-labs	1504373741.0	2017-09-02 10:35:41	John Simpson	I have noticed that since my conflict with Comcast has gone rather public... I am now being blocked somehow from M-Lab, Speakeasy, and other testing sites.  The only ones that currently can connect using Firefox (Chrome has too many resource hogging protocols), are Testmynet, Speedof.me, and Fast.com.  Fast.com is hosted by Netflix... and strangely is the only one that shows upwards of 70mbps... and it is a paid service, so you have that to tak into account as well.  My research is starting to reflect the FCC rulings against preferential bandwidth allocation to large media services already.  I fear this is going to get ugly here in the United States, before anything changes.  Anyway, I just thought that my friends here at M-Labs would like to know that M-Labs tests are currently BLOCKED from being run on any of my home PCs or Mobile (Android) Devices.  M-Labs may want to investigate this and sue Comcast/Xfinity.  Included are some screenshots I took before sending this email, for proof of my claim:	"{0: {'username': 'Livingood, Jason', 'response_date': 'Sep 2, 2017, 10:45:37 AM', 'response_content': 'Hi John – I work at Comcast and spend a lot of time on measurement-related issues. I am not sure what conflict you are referring to but I am happy to help with any service issues if you want to email me your account details off-list. I can assure you, however, that Comcast is not blocking any M-Labs tests.   Regards Jason \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': 'Rajan Patel', 'response_date': 'Sep 2, 2017, 6:06:13 PM', 'response_content': 'What browser and browser versions have you tried with? Do you have any plugins on the browser that may be interfering with the websockets implementation of NDT? Is it possible to try this test on an incognito version of the latest Chrome browser?  Have you tried installing Neubot, and tracking it\'s progress over the course of a week?  Neubot data is also tracked my mlabs.    On Sep 2, 2017 1:45 PM, ""Livingood, Jason"" <Jason_L...@comcast.com> wrote: ...'}}"
200	neubot-data-not-available-in-google-cloud-service-with-bigquery	1502912184.0	2017-08-16 12:36:24	Jhonny Barbosa da Silva	Hi.  I am interested in Neubot data, and was trying to access it through Google cloud service, in a Node.js client. It appears that the data that we can find in Google Storatge (inside all of those compressed files)  is not yet available at google cloud service.   Am I right? Is there a way I can access them through big queries?   Thanks!	"{0: {'username': 'Simone Basso', 'response_date': 'Aug 17, 2017, 8:40:09 AM', 'response_content': ""\ue5d3 Hello!  Yes, to the best of my knowledge there was never a import of Neubot's data into BigQuery; I guess downloading files is your only option.  Best,  Simone Basso  -- Simone Basso https://github.com/bassosimone""}, 1: {'username': 'Jhonny Barbosa da Silva', 'response_date': 'Aug 17, 2017, 11:02:48 AM', 'response_content': ""What would it take to get part of Neubot data up there? Or there isn't even possiblity of doing it?  I know it would be extra work for somebody, and I would be available to do it I was given permission.  Is there anyone I can get in contact to study that possibility?  Thanks! \ue5d3""}, 2: {'username': 'Jhonny Barbosa da Silva', 'response_date': 'Aug 21, 2017, 8:17:07 AM', 'response_content': 'Hi? Anyone in here that could help about this? :) \ue5d3'}, 3: {'username': 'Georgia Bullen', 'response_date': 'Aug 22, 2017, 10:16:10 AM', 'response_content': 'Hi All,  This is likely more possible in the future than it was in the past with the new pipeline work that the team has been doing (https://www.measurementlab.net/blog/transitioning-data-pipeline/). I\'ll bring it up with the team and see what\'s possible.  In the meantime, I think downloading the raw data is your best option.  -Georgia  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.    -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/  Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon'}, 4: {'username': 'Jhonny Barbosa da Silva', 'response_date': 'Aug 22, 2017, 10:42:25 AM', 'response_content': 'Thank you! Let us know if the team can move the data from the buckets to the cloud sometime in the near feature. That would impact my decisions for my project.  In the meantime I will download the data, filter it and store it somewhere I can access with few queries.  I am working on something that could be interesting for the community I think. Not sure.  Anyways, thanks again for taking a time to read this.    \ue5d3 -- Jhonny Barbosa  Software Developer and Sound Designer jhonny...@gmail.com'}, 5: {'username': 'Georgia Bullen', 'response_date': 'Aug 25, 2017, 11:24:40 AM', 'response_content': ""Hi Jhonny,  A few of the people needed for this are on vacation at the moment, so I'll be able to follow up in a few weeks when folks are back, but overall it sounds like this should be something that we would welcome help on and that you and Simone could collaborate on. I'll reach out when folks are back, and also share more widely this process when we have the documentation ready.  Thanks!  -Georgia \ue5d3""}, 6: {'username': 'Jhonny Barbosa da Silva', 'response_date': 'Aug 25, 2017, 7:51:53 PM', 'response_content': 'Thank you, I really appreciate it!  \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/  Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon -- Jhonny Barbosa  Software Developer and Sound Designer jhonny...@gmail.com \ue5d3'}}"
201	enumerating-ndt-servers-/-selecting-a-specific-server	1503457179.0	2017-08-22 19:59:39	rhys.p...@gmail.com	Hello.  A few questions here. First, this is awesome  Is it possible to force a connection to a specific NDT server? It seems to be fully automatic when you go here: https://www.measurementlab.net/tests/ndt/  It would be great to be able to specify what backend server to connect to, as we like to know both the local speed to the closest server, and to say the speed to something close to one of our international data centers.  I've seen some references to peoples specifying servers from the command line tools, but nowhere that has the definitive list of what is available.  I see that you can get the 'closest' server to you by querying: http://mlab-ns.appspot.com/ndt  .. but I can't seem to get the full list of available servers.  I would be okay with resorting to a native application if required.  Any insight would be greatly appreciated.  Thank you.	"{0: {'username': 'rhys.p...@gmail.com', 'response_date': 'Aug 22, 2017, 8:00:40 PM', 'response_content': 'Similar to how you can select different servers via speedtest.net. \ue5d3'}, 1: {'username': 'Ovidiu M', 'response_date': 'Aug 23, 2017, 5:07:47 AM', 'response_content': 'Disclaimer: I\'m not involved with the MLab project in any way.  I know that they built a Chrome extension that allows selecting the location of the server, but not the provider: https://chrome.google.com/webstore/detail/m-lab-measure/leijmacehibmiomcnpaolboihcdepokh  I thought that selecting both may be useful. I found that all servers are listed on https://mlab-ns.appspot.com/admin/map/ipv4/ndt in the initialize() function in the cities variable.  I built my own interface that allows selecting any combination of location and provider here: https://netperf.tools/#throughput  It\'s just a wrapper around the ndt client JS code.  It has some quirks: * It needs to be updated manually each time the servers change. It would be great if MLab would offer a clean js file with just the servers, assuming that they are open to people using different GUIs for their service, of which I\'m not sure. * It needs to be kept in sync with the official ndt client JS code. This one is more than 1 year old. I don\'t know if anything has changed in the meantime that might affect measurements. * The latency measurement code is completely different from the ndt latency measurement. I measure latency both before the transfers and also during the upload and download, to detect bufferbloat. Last time I checked, the NDT code was measuring latency only during one of the transfers.  I have just updated the server list on the site today; but normally I don\'t do it regularly. If needed I can share the code with you so you can deploy it and maintain it yourself; all that is needed is a static web server.  All the best Ovidiu \ue5d3 > -- > You received this message because you are subscribed to the Google Groups > ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, send an > email to discuss+u...@measurementlab.net. > To post to this group, send email to dis...@measurementlab.net. > Visit this group at > https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 2: {'username': 'Georgia Bullen', 'response_date': 'Aug 23, 2017, 5:29:54 AM', 'response_content': 'Hi All!  Just to add to what Ovidiu was describing and provide some docs that might be helpful.  If you go here: https://mlab-ns.appspot.com/admin/map/ipv4/all (which is also available here: https://www.measurementlab.net/status/) you can see the sites available, and there\'s a link to the Design Doc for mlab-ns (https://docs.google.com/document/d/1eJhS75EZHDLmC6exggStr_b1euiR24_MVBJc1L6eH2c/view#heading=h.ubhijxy606i) which will help with showing you all of the functions that are available for seeing what servers are available.  The M-Lab team recommends that you use mlab-ns to get available servers rather than picking specific servers or maintaining your own list, as server status can change for a variety of reasons. Using mlab-ns should give you ways to find what servers are available and meet the conditions that you need for your application/tool.  Thanks for sharing your site Ovidiu! I hadn\'t seen that before!  -Georgia  \ue5d3 \ue5d3 \ue5d3 > email to discuss+unsubscribe@measurementlab.net.  > To post to this group, send email to dis...@measurementlab.net. > Visit this group at > https://groups.google.com/a/measurementlab.net/group/discuss/.  -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.    -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/  Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon'}, 3: {'username': 'Ovidiu M', 'response_date': 'Aug 23, 2017, 5:51:29 AM', 'response_content': 'I published my source code here: https://github.com/o9o/ndt-speed-test  The program I used to split the whois and geolocation databases so that they can be used from javascript in a static website is missing, but I will try to add it when I have time. For these lookups, only IPv4 is supported. These are not essential for the measurement, only after the measurement when the page shows statistics for the country the user is located in. \ue5d3 >> > email to discuss+u...@measurementlab.net. >> > To post to this group, send email to dis...@measurementlab.net. >> > Visit this group at >> > https://groups.google.com/a/measurementlab.net/group/discuss/. >> >> -- >> You received this message because you are subscribed to the Google Groups >> ""discuss"" group. >> To unsubscribe from this group and stop receiving emails from it, send an >> email to discuss+u...@measurementlab.net. \ue5d3'}}"
202	fwd:-[gaia]-africomm-internet-measurements-workshop-(lagos,-nigeria):-submission-deadline-extension---17-september	1503421406.0	2017-08-22 10:03:26	Georgia Bullen	Hi All,  Just wanted to share this opportunity with the list! We don't plan to deluge the list with paper solicitations, but we wanted to pass this on since M-Lab has sites in the region. There's unaddressed research opportunities, and we are eager to connect with organizations and institutions that would be interested in collaborating on M-Lab's growing presence in Africa. Let us know if you submit anything!  -Georgia  ---------- Forwarded message ---------- From: Josiah Chavula <josiah...@gmail.com> Date: Wed, Aug 16, 2017 at 6:24 AM Subject: [gaia] AFRICOMM Internet Measurements Workshop (Lagos, Nigeria): Submission Deadline Extension - 17 SEPTEMBER To: ga...@irtf.org   Call for Papers   International Workshop on Internet Measurements Research in Africa    Aim of the workshop is to facilitate discussions around mechanisms and challenges of measuring Africa’s Internet; to evaluate the breadth of Internet measurements research and to formulate strategic directions for such research in Africa; and to initiate and accelerate collaboration among Africa’s Internet measurements researchers.   The workshop is calling for high-quality papers that are focused on Internet measurements research in Africa. Papers are invited on topics related to: ● End-to-end Internet performance metrics ● Internet topology characteristics, including peering and routing ● Application-level performance, including DNS, Web, CDNs, Cloud Computing ● Physical layer performance measurements, including for TVWS, WiFi, and 3G/4G ● Detection of middleboxes, censorship, and content filtering ● Data analytics for network monitoring, traffic analysis and network  ● Network topology and performance visualization  ● Internet access, use, and Quality of Experience (QoE)   Submissions should be made electronically as PDF in the Confy system: IMRA track . Papers will be selected through a single-blind peer-review process. Accepted papers will be included in the conference proceedings and will be published in Springer digital library.   Important deadlines   Submission 17 SEPTEMBER 2017 Notification 1 OCTOBER 2017 Camera-ready submission 30 OCTOBER 2017 Conference takes place 11-12 DECEMBER 2017   Submission Guidelines and Paper Submission:   Please check the submission guidelines here: http://africommconference.org/2017/show/initial-submission All the papers should be in English and formatted according to the Author's Kit IMRA papers should be submitted into IMRA track in confy   Publications: Accepted papers will be published in Springer's LNICST series and will appear in the SpringerLink, one of the largest digital libraries online that covers a variety of scientific disciplines, as well as in the EAI's own EU Digital Library (EUDL). LNICST volumes are submitted for inclusion to leading indexing services, including DBLP, Google Scholar, ISI Proceedings, EI Engineering Index, CrossRef, Scopus.   _______________________________________________ gaia mailing list ga...@irtf.org https://www.irtf.org/mailman/listinfo/gaia     -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/  Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon	{}
203	ddos-metrics	1503386112.0	2017-08-22 00:15:12	Eireann Leverett	Hi M-Lab,  The esteemed Aaron Kaplan and I used your data to demonstrate a methodology towards understanding global potential DDoS capacity (as a set of which all DDoS events come from in a given instance). The paper is out now, and we hope you like it.  http://www.tandfonline.com/eprint/9miQbGZc8Akfk3xgYEbz/full  Eireann	{}
204	blogpost:-monitoring-interconnection-performance-since-the-open-internet-order	1502723391.0	2017-08-14 08:09:51	Collin Anderson	Hello Discuss List –  From time to time, M-Lab submits technical recommendations and data-driven facts pertinent to its operations into regulatory proceeding around the world where appropriate. In the interest of more transparency on those interventions, we have started to maintain a public record on the site. I wanted to call attention to our most recent filing, into the Restoring Internet Freedom docket of the FCC, which is a followup from our past publication and post about interconnection performance. I found it to be an interesting exercise to see the alignment between press releases and the changes in network performance, so hopefully it might encourage others to pick up the data further.  Excerpt:   In this post, we review historical interconnection congestion episodes that appeared to have had a negative impact on consumer broadband and followed how these relationships had changed since the Open Internet Order. Since our last blogpost on interconnection over two years ago, the relationships between operators have changed, resulting in overall improvement in consumer performance and a notable remediation of congestion episodes covered in our initial reports. Often the improvements are sudden, reversing months long underperformance within days. The remediation of congestion parallels an overall improvement across networks in performance for broadband users, and in our analysis we do not find the same patterns of sustained degradation described in past reports.  Full Post: https://www.measurementlab.net/blog/interconnection_update/ Other Regulatory Filings: https://www.measurementlab.net/publications/#government--regulatory-filings  As always, please send me any comments, critiques, or recommendations. We're always interested to hear where we can extend the research or further open up the data to those interested in such topics.   Cordially, Collin Anderson	{}
205	updated-privacy-policy-and-acceptable-use-summary	1502297296.0	2017-08-09 09:48:16	Collin Anderson	Dear M-Lab Discuss List,  As you may have noticed, M-Lab has been in the process of modernizing its technical and non-technical operations in recent months. One of the most common questions we receive from users and collaborators is what measures we take we protect people's privacy and what we do with the measurement data. It's easy to understand why: our policies up to this point have often been arcanely written, scattered across documents, and too brief.   In the interest of more transparency and accessibility, we have updated the Privacy Policy and the Acceptable Use Policy on the M-Lab site. Nothing about the way that M-Lab collects data or the requirements on partners has changed. Instead, this provides what we hope to be an easier to read document that reflects how we operate and provides the basis for reviewing those practices in the future.   Over the next few months, there will be a few more notices as we continue to modernize our policies and documentation. We had shared these drafts for comment with a few members of the community that have previously expressed interest in privacy issues, but we always strive for an open and consultative process around platform operations. If anyone is interested in being included in the process, please feel free to reach out.   Cordially, Collin Anderson	{}
206	internet-speed-test	1484100438.0	2017-01-10 19:07:18	yahoo...@gmail.com	Hay, I'm trying to understand why I'm getting two different results in my internet downloaded test using two deferent software from my web browser. One test result is 100mbps and another test using a deferent app is 30mbps. I'm not sure which test is correct. I'm using Ookla and other is http://www.bandwidthplace.com/	"{0: {'username': 'Juan C. Marin', 'response_date': 'Jul 18, 2017, 6:11:45 AM', 'response_content': 'Go to fast.com and try again there is a diffrence between the server you use to test, you should take the closest where you are. \ue5d3'}, 1: {'username': 'Chris Ritzo', 'response_date': 'Jul 18, 2017, 6:57:10 AM', 'response_content': 'Which test is correct is sort of the wrong way to look at this. Ookla, fast.com, etc. and NDT are all correct. They do measure different paths or distances though, which is one reason for differences in measured speeds. We have an FAQ about this explaining the differences with respect to NDT hosted on M-Lab. When you run NDT M-Lab\'s load balancer directs your browser to conduct the test against our closest server, similar to Juan\'s comment about using the closest fast.com server. The difference is whether that server is on the edge of your ISP\'s network, or outside it as M-Lab\'s servers are.    Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036       \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 2: {'username': '☕Peter Boothe', 'response_date': 'Jul 18, 2017, 8:07:35 AM', 'response_content': 'Expanding on Chris\' answer: There is not a great unified definition of ""Internet speed"", so all tests test something slightly different.  Even worse, the speed you get will also be dependent on where the test server is located, so even the same test can give you different results depending on how far away the test server is - farther servers will tend to give lower results. Note, however, that this far-away server might be giving you a more accurate measurement if the applications you care about are also served from far away.  I wish there was a simple answer, but unfortunately the truth about Internet speed is as complicated as the Internet.    -Peter \ue5d3 -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.'}}"
207	thank-for-in-information-you-team	1500134913.0	2017-07-15 09:08:33	edi esporwadi		{}
208	fwd:-[gaia]-ripe-ncc-raci-programme	1497967447.0	2017-06-20 07:04:07	Georgia Bullen	Thought this might be of interest to some folks on M-Lab Discuss.  -Georgia  ---------- Forwarded message ---------- From: Jane Coffin <cof...@isoc.org> Date: Mon, Jun 19, 2017 at 10:45 AM Subject: [gaia] RIPE NCC RACI Programme To: gaia <ga...@irtf.org>   Hi All –  I assume you know about RIPE NCC’s RACI programme.  If not, see below for an opportunity to present (and be funded to do so) at RIPE meetings.  Dear colleagues,  The RIPE Academic Cooperation Initiative (RACI) is looking for talented academics in the field of Internet technology. Successful applicants receive complimentary tickets, travel and accommodation to the meetings and the opportunity to present their research.  If you are working on something interesting, please apply! If you know someone in your network who is, please forward them this message.  https://www.ripe.net/raci  --------------------- Application deadlines --------------------- ENOG 14 (9-10 October, Minsk): apply by 20 August 2017 RIPE 75 (22-26 October, Dubai): apply by 20 August 2017  At ENOG 14 you can present in either Russian or English.  --------------------------- Examples of relevant topics --------------------------- - Network measurements and analyses - IPv6 deployment - BGP routing - Network security - Internet governance - Peering and interconnectivity - Internet of Things  ------------------------------------------------- Get the latest news on RACI and Internet research ------------------------------------------------- - Subscribe to the RACI mailing list: https://www.ripe.net/raci/mailing-list  - Follow us on Twitter: https://twitter.com/raci_ripe  - Join our group on LinkedIn: http://www.ripe.net/raci/linkedin  Please let me know if you have any questions. Have a lovely summer day!  Best regards, Gergana  -- Gergana Petrova External Relations RIPE NCC   Best, Jane   Internet Society | www.internetsociety.org Skype:  janercoffin Mobile/WhatsApp:  +1.202.247.8429  From: gaia <gaia-b...@irtf.org> on behalf of Amreesh Phokeer <amreesh...@gmail.com> Date: Wednesday, June 14, 2017 at 8:04 AM To: gaia <ga...@irtf.org> Subject: [gaia] Local Connectivity Solutions for the Unconnected session at WSIS'17  https://www.itu.int/net4/wsis/forum/2017/Agenda/Session/338#intro  -- Amreesh Phokeer  _______________________________________________ gaia mailing list ga...@irtf.org https://www.irtf.org/mailman/listinfo/gaia     -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/  Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon	{}
209	comcast-is-claiming-m-lab's-speedtest-is-inaccurate.	1497043051.0	2017-06-09 14:17:31	John Simpson	I have been fighting with Comcast since they installed my service about not getting anywhere near the speeds that I am paying for, and they will only accept testing results done through their own methods, and claiming that M-Labs and the 5 other testing sites I use are never accurate.  I thought that you should know, as I am only one of thousands, maybe millions, of others that are experiencing this problem with Comcast and other ISP's here in the USA.  Charter was claiming the same thing, as of 2 years ago, but as I am no longer with their service, I do not know if they are doing anything differently or not.  Once again... Comcast is saying that your test is bunk.	"{0: {'username': 'Livingood, Jason', 'response_date': 'Jun 9, 2017, 2:24:22 PM', 'response_content': 'IMO NDT isn’t great at testing end user connection speed. But don’t take my word for it -- see https://groups.csail.mit.edu/ana/Publications/Understanding_broadband_speed_measurements_bauer_clark_lehr_TPRC_2010.pdf and read Sections 4.1 and 4.2.5. The latter section on NDT says “In other words, this is an excellent testing tool and infrastructure. The insights to draw from this data, however, are not simple averages of the upload and download speeds from different user populations. This, in fact, would not be an appropriate use of the data as far too many factors confound such an interpretation.” Also http://cfp.mit.edu/events/10Oct/CFP-Munich-2010-Slides/BAUER-Slides.CFP.Munich.2010.pdf and https://www.caida.org/workshops/isma/1202/slides/aims1202_sbauer.pdf. So it has its uses but perhaps not what you are trying to do with it.   In any case, it sounds like maybe you have an RF problem with your connection. I work for Comcast and would be happy to help you off list. You should absolutely be getting the advertised speeds. I will ping you 1:1.   Jason     On 6/9/17, 5:17 PM, ""John Simpson"" <stonew...@gmail.com> wrote:   I have been fighting with Comcast since they installed my service about not getting anywhere near the speeds that I am paying for, and they will only accept testing results done through their own methods, and claiming that M-Labs and the 5 other testing sites I use are never accurate.  I thought that you should know, as I am only one of thousands, maybe millions, of others that are experiencing this problem with Comcast and other ISP\'s here in the USA.  Charter was claiming the same thing, as of 2 years ago, but as I am no longer with their service, I do not know if they are doing anything differently or not.  Once again... Comcast is saying that your test is bunk. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': 'Nick Feamster', 'response_date': 'Jun 9, 2017, 2:28:23 PM', 'response_content': 'What Jason says.  Also, see our Sigcomm 2011 paper ""Broadband Internet Access: A View from the Gateway"".  In that work, we evaluate single threaded throughput tests (the type NDT uses) in that paper. These types of tests frequently underestimate throughput by 30%, and sometimes more.  -Nick \ue5d3'}, 2: {'username': 'Matt Mathis', 'response_date': 'Jun 9, 2017, 3:39:33 PM', 'response_content': '+Steve Bauer  I have been discussing that report with Steve.  We know that there is something fishy with the NDT data because IHT runs on top of MLab NDT.  Aside from IHT reporting the maximum of multiple NDT runs, the underlying distributions should be identical, and they clearly aren\'t.  My understanding from my conversations with Steve is that the NDT data was collected using a DIY integration of our NDT client into a runtime environment that we have not tested.  Inspecting the MLab web100 logs suggests that the main runtime event loop only ran the NDT threads once every 16mS.   We are aware of a number of runtime environments that perform extremely poorly.  Several of them seem to block the main event loop on frame rendering.  (The telltale signature: changing display settings sometimes changes the measured performance by exactly 60Hz/70Hz).  We also have the .pcap files for all of the tests in the report, so we can go quite deep in the analysis if we need to.   The other oddity in the data is that the NDT performance is not multi-modal, even though it would be expected to be spread across multiple MLab sites with slightly different RTTs.   The lack of modes very strongly suggests that the bottleneck is local to the client and does not depend on the path at all.   (Nearly all network bottlenecks, except a completely filling a link with zero cross traffic, show some RTT sensitivity).  The client configurations that we do support (and are used in all portals that we are aware of) are routinely subjected to a battery of automated performance and qualification tests.  Steve, would you care to add anything?  Thanks, --MM-- The best way to predict the future is to create it.  - Alan Kay  Privacy matters!  We know from recent events that people are using our services to speak in defiance of unjust governments.   We treat privacy and security as matters of life and death, because for some users, they are.  \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.  -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3'}}"
210	ndt-data-availability-update	1496781162.0	2017-06-06 13:32:42	Collin Anderson	"Hi discuss list,  The pipeline has been run, and the data should be up to date in BigQuery and Cloud Storage. We are still in the process of transitioning the pipeline, and anticipate that the data should be posted on a regular schedule. We do not expect pauses, but if it should occur, we will update this thread. Thank you for the patience.  Cordially, Collin  On Mon, May 1, 2017 at 4:10 PM, Greg Russell <g...@google.com> wrote: Hi Srikanth,   We have had a couple issues coming together to cause some trouble with NDT.  The significant increase in volume has generated some quota issues that have caused failures lately, causing us to fall behind a bit in processing and publishing the new data.  We are close to publishing everything up to April 20 - hopefully in the next couple days.  At the same time, we have been developing a new ingestion system which we are planning to launch later in May.  This should make all our lives much better, but we have been prioritizing getting the new system in place, over maintaining the old system.  At this point it looks likely that there will be another delay in processing at least some of the data in May, but we should be caught up again in early June.  We will try to keep you updated if anything changes.  Thanks, Greg   On Wed, Feb 22, 2017 at 5:34 PM Collin Anderson <col...@measurementlab.net> wrote: Hi Srikanth,  For the moment, the pipeline runs about once per week. That was scaled back from the more regular interval due to the dramatic increases in data that M-Lab has been collecting over the past nine months. We were running into unforeseen issues that had the possibility of snowballing a bit, so the decision was made to monitor it more closely and on a manual basis. Our hope is to return it to normal soon, and in the process of doing so we will have more resilient and open code powering the pipeline process.  My apologies for the inconvenience, I can empathize from being similarly constrained.   Cordially, Collin  On Wed, Feb 22, 2017 at 2:54 PM, Srikanth S <srkn...@gmail.com> wrote: Hello,  We've been running some tests using the NDT client over the last week, and we would like to access the pcaps from the server. It looks as though the latest files are from the 16th; how often does it get updated?  Thanks, Srikanth  -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.  -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- Gregory |  Russell |  g...@google.com |  123-458-7890 https://memegen.googleplex.com/4558349824688128"	{}
211	can-one-run-a-local,-non-ui-version-of-the-tests?	1495059237.0	2017-05-17 15:13:57	kray2...@gmail.com	I was thinking, when I started looking at the tests, that I could load a copy of the tests on my laptop, maybe I would have to build from source but ok, set up a few crontab entries and then, once every whenever, when my laptop is up and can see the internet, it would run the tests and submit results. And this would just be automatic.  Is it possible to do this? Looking further in the site, I am not seeing it.  Maybe I am not an interesting case, as I live in San Jose CA, but on the other hand we have surprising crappy local internet service.  So, anyway. Let me know if the tests can be installed to be run in the background.  thanx - ray	"{0: {'username': 'Ovidiu M', 'response_date': 'May 18, 2017, 12:49:40 AM', 'response_content': 'Ray, I am not involved in the project, but I\'ve used a couple of years ago the NDT command line client available from https://github.com/ndt-project/ndt. Not sure if it\'s still working.  I would be interested to know if automated tests are allowed for NDT (since https://www.measurementlab.net/faq/ mentions that they might not be, but it\'s not clear if it\'s a design decision or a user restriction).  IIUC other tests, like those of neubot, are running automatically. \ue5d3 > -- > You received this message because you are subscribed to the Google Groups > ""discuss"" group. > To unsubscribe from this group and stop receiving emails from it, send an > email to discuss+u...@measurementlab.net. > To post to this group, send email to dis...@measurementlab.net. > Visit this group at > https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': '☕Peter Boothe', 'response_date': 'May 18, 2017, 8:35:58 AM', 'response_content': 'Hello!  Automated testing is allowed, but we want to make sure people are smart about it. In particular, if enough people naively put ""test every hour on the hour"" into crontab.hourly, then we\'ll end up with a nice DDOS happening every hour on the hour, which would be a bummer for everybody (bad data for the people running tests and bad data put into the MLab results database).  There are several ways one might run the command-line client repeatedly, and which one you want will depend on a bunch of things, including what you want to do with the output. If you want to get the output of your testing by using Google BigQuery (for example, you log your IP address somewhere else and then SELECT all tests in the MLab database that come from one of the IP addresses you have had), then the easiest thing to do is to use the Docker image I cooked up for precisely that purpose.  First install docker (possibly called docker-engine, depending on your linux distribution). Then the command    sudo docker run pboothe/test-runner  will run tests repeatedly, to a random US MLab server, spaced out exponentially-random in time to give you a Poisson distribution of test times. This spacing is a desirable thing from a ""good science"" perspective. The code that makes up that docker image can be found in:   https://github.com/pboothe/mlab-test-runner   If that meets your needs, then do that. The next recommendation is more painful and requires you to understand more things:  If you want to do something more custom with the output, then you should install the ndt command-line client and then drop an entry into cron.hourly or cron.daily to run that client. In both cases, please add some jitter to the start time.  For cron.daily, it would be nice if, prior to the test command, you added    sleep $[ ${RANDOM} % (24*60*60) ];  which will sleep for a random number of seconds (but no more than a day\'s worth) before running the test.  For cron.hourly, do   sleep $[ ${RANDOM} % (60*60) ]; if you are running one of those custom crons that supports randomness, just use that.  If you don\'t want to hard-code the servername to connect to, you can do the following to get a random server that is online and chosen from the set of servers geographically closest to you:   curl mlab-ns.appspot.com/ndt | sed -e \'s/.*fqdn"": ""//\' -e \'s/"".*//\'  Putting this all together, I\'d recommend putting:   sleep $[ ${RANDOM} % (60*60) ]; SERVER=$(curl --silent mlab-ns.appspot.com/ndt | sed -e \'s/.*fqdn"": ""//\' -e \'s/"".*//\'); ./web100clt --name=${SERVER} --port=3001 > /tmp/$(date +%Y-%m-%d-%H:%M:%S).${SERVER}.ndtresult  in your cron.hourly to test hourly. This will cause a timestamped series of files to appear in /tmp, and then you can do with those files whatever you want.  Hopefully, the answers you need can be found in this long-winded explanation. Good luck!    -Peter  \ue5d3 \ue5d3 \ue5d3 > email to discuss+unsubscribe@measurementlab.net.  > To post to this group, send email to dis...@measurementlab.net. > Visit this group at > https://groups.google.com/a/measurementlab.net/group/discuss/.  -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.    -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.'}}"
212	getting-latest-ndt-data	1487793261.0	2017-02-22 12:54:21	Srikanth S	Hello,  We've been running some tests using the NDT client over the last week, and we would like to access the pcaps from the server. It looks as though the latest files are from the 16th; how often does it get updated?  Thanks, Srikanth	"{0: {'username': 'Collin Anderson', 'response_date': 'Feb 22, 2017, 3:34:12 PM', 'response_content': 'Hi Srikanth,  For the moment, the pipeline runs about once per week. That was scaled back from the more regular interval due to the dramatic increases in data that M-Lab has been collecting over the past nine months. We were running into unforeseen issues that had the possibility of snowballing a bit, so the decision was made to monitor it more closely and on a manual basis. Our hope is to return it to normal soon, and in the process of doing so we will have more resilient and open code powering the pipeline process.  My apologies for the inconvenience, I can empathize from being similarly constrained.   Cordially, Collin  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': 'Greg Russell', 'response_date': 'May 1, 2017, 1:10:32 PM', 'response_content': 'Hi Srikanth,   We have had a couple issues coming together to cause some trouble with NDT.  The significant increase in volume has generated some quota issues that have caused failures lately, causing us to fall behind a bit in processing and publishing the new data.  We are close to publishing everything up to April 20 - hopefully in the next couple days.  At the same time, we have been developing a new ingestion system which we are planning to launch later in May.  This should make all our lives much better, but we have been prioritizing getting the new system in place, over maintaining the old system.  At this point it looks likely that there will be another delay in processing at least some of the data in May, but we should be caught up again in early June.  We will try to keep you updated if anything changes.  Thanks, Greg  On Wed, Feb 22, 2017 at 5:34 PM Collin Anderson <col...@measurementlab.net> wrote: Hi Srikanth,  For the moment, the pipeline runs about once per week. That was scaled back from the more regular interval due to the dramatic increases in data that M-Lab has been collecting over the past nine months. We were running into unforeseen issues that had the possibility of snowballing a bit, so the decision was made to monitor it more closely and on a manual basis. Our hope is to return it to normal soon, and in the process of doing so we will have more resilient and open code powering the pipeline process.  My apologies for the inconvenience, I can empathize from being similarly constrained.   Cordially, Collin On Wed, Feb 22, 2017 at 2:54 PM, Srikanth S <srkn...@gmail.com> wrote: Hello,  We\'ve been running some tests using the NDT client over the last week, and we would like to access the pcaps from the server. It looks as though the latest files are from the 16th; how often does it get updated?  Thanks, Srikanth  -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- Gregory |  Russell |  g...@google.com |  123-458-7890 https://memegen.googleplex.com/4558349824688128'}, 2: {'username': 'Greg Russell', 'response_date': 'May 2, 2017, 7:39:33 AM', 'response_content': 'FYI, the bigquery data should now be available up to April 20.  April 21 - May should be available in a day or two. \ue5d3'}, 3: {'username': 'Srikanth S', 'response_date': 'May 2, 2017, 11:38:46 AM', 'response_content': 'Thanks Greg. Any sense of when the NDT pcap data will get updated?  Thanks, Srikanth  On Tue, May 2, 2017 at 7:39 AM, Greg Russell <g...@google.com> wrote: FYI, the bigquery data should now be available up to April 20.  April 21 - May should be available in a day or two. On Mon, May 1, 2017 at 4:10 PM Greg Russell <g...@google.com> wrote: Hi Srikanth,   We have had a couple issues coming together to cause some trouble with NDT.  The significant increase in volume has generated some quota issues that have caused failures lately, causing us to fall behind a bit in processing and publishing the new data.  We are close to publishing everything up to April 20 - hopefully in the next couple days.  At the same time, we have been developing a new ingestion system which we are planning to launch later in May.  This should make all our lives much better, but we have been prioritizing getting the new system in place, over maintaining the old system.  At this point it looks likely that there will be another delay in processing at least some of the data in May, but we should be caught up again in early June.  We will try to keep you updated if anything changes.  Thanks, Greg On Wed, Feb 22, 2017 at 5:34 PM Collin Anderson <col...@measurementlab.net> wrote: Hi Srikanth,  For the moment, the pipeline runs about once per week. That was scaled back from the more regular interval due to the dramatic increases in data that M-Lab has been collecting over the past nine months. We were running into unforeseen issues that had the possibility of snowballing a bit, so the decision was made to monitor it more closely and on a manual basis. Our hope is to return it to normal soon, and in the process of doing so we will have more resilient and open code powering the pipeline process.  My apologies for the inconvenience, I can empathize from being similarly constrained.   Cordially, Collin On Wed, Feb 22, 2017 at 2:54 PM, Srikanth S <srkn...@gmail.com> wrote: Hello,  We\'ve been running some tests using the NDT client over the last week, and we would like to access the pcaps from the server. It looks as though the latest files are from the 16th; how often does it get updated?  Thanks, Srikanth  -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- Gregory |  Russell |  g...@google.com |  123-458-7890 https://memegen.googleplex.com/4558349824688128 \ue5d3'}, 4: {'username': 'Greg Russell', 'response_date': 'May 4, 2017, 7:07:32 AM', 'response_content': 'Sorry for delay getting back to you.  Didn\'t realize you needed the pcap data.  We are planning to process and publish the pcap data over the next week or so, but it sounds like that will be too late for you.  Let me discuss with colleagues if there is a way we can get the pcap data sooner than that.  IIUC, you are looking for data from tests you have been initiating.  Could you let me know what region you need the pcap data from?  If you can let us know the ""pods"" that you are running tests against, (the three letter + two digit city code that follows ""mlabNN.""), we may be able to cherry pick the data from those pods for you.  Thanks, Greg  \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- Gregory |  Russell |  g...@google.com |  123-458-7890 https://memegen.googleplex.com/4558349824688128 -- Gregory |  Russell |  g...@google.com |  123-458-7890 https://memegen.googleplex.com/4558349824688128 \ue5d3'}, 5: {'username': 'Srikanth S', 'response_date': 'May 4, 2017, 7:27:26 AM', 'response_content': 'Oh, that would be great. We are running tests only against one node -- lga03 (TATA server in NY).   \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- Gregory |  Russell |  g...@google.com |  123-458-7890 https://memegen.googleplex.com/4558349824688128 -- Gregory |  Russell |  g...@google.com |  123-458-7890 https://memegen.googleplex.com/4558349824688128 \ue5d3'}, 6: {'username': 'Ya Chang', 'response_date': 'May 4, 2017, 7:30:56 AM', 'response_content': 'Hi, Srikanth,  Which time range do you need for pcap on lga03? Thanks! \ue5d3'}, 7: {'username': 'Srikanth S', 'response_date': 'May 4, 2017, 7:33:55 AM', 'response_content': 'Up until the end of April would be great. The bucket already has data till March 30.  \ue5d3'}}"
213	m-lab-update-on-paris-traceroute-issues-and-resolution	1491930278.0	2017-04-11 10:04:38	Chris Ritzo	Greetings all:  In February 2017, M-Lab was notified of issues with the M-Lab data available in BigQuery. Upon investigation, a problem was identified with the Paris Traceroute collection daemon which resulted in a reduction in Paris Traceroute measurements beginning in June 2016. At the peak of the outage, fourth quarter 2016 - January 2017, approximately 5% of NDT tests had an associated Paris Traceroute test. Additionally, an issue within the data processing pipeline resulted in Paris Traceroute data that was measured and collected, not being inserted into the BigQuery tables and therefore available for use.  Both defects were resolved in mid-February, additional monitoring was added, and BigQuery has been brought up to date with the available data.   For complete details on this issue and resolutions put into place, please read our recently published blog post on the event.  Best, Chris   Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036     	{}
214	bigquery-data-is-outdated	1486747752.0	2017-02-10 10:29:12	Ben	The documentation at https://www.measurementlab.net/data/ suggests that the data in both BigQuery and CloudStorage are updated every 24 hours. I see new data in CloudStorage, but I'm not seeing anything more recent than Sept 6, 2016 in BigQuery, based on this query:  >> SELECT MAX(SEC_TO_TIMESTAMP(log_time)) FROM [plx.google:m_lab.paris_traceroute.all] > 2016-09-06 23:59:47 UTC   Is the BigQuery data still getting updated, and at what frequency?	"{0: {'username': 'Kim Prince', 'response_date': 'Feb 10, 2017, 2:28:41 PM', 'response_content': 'Hi Ben,  I recently ran some queries on the NDT data and it was up to date.  It might have been a week or so old, but not a month.  Kim  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}, 1: {'username': 'Ben Dowling', 'response_date': 'Feb 10, 2017, 2:43:07 PM', 'response_content': ""My query was against the traceroute data. Any reason why that's not updating? \ue5d3""}, 2: {'username': 'Kim Prince', 'response_date': 'Feb 10, 2017, 2:58:36 PM', 'response_content': 'Sorry Ben, I have not tried the traceroute data. \ue5d3'}, 3: {'username': 'Xiaohong Deng', 'response_date': 'Feb 10, 2017, 3:14:52 PM', 'response_content': 'Hi Ben,  Are you able to query Paris Traceroute data up to Sep 2016 at all?  I used follow query in the hope of querying couple of months of PT data from US servers. But it only returns one day\'s data.   If you are able to query more data. Can you share your Query here? My Query is as below, if anyone can have a look, much appreciated.  SELECT  YEAR(FORMAT_UTC_USEC(log_time*1000000)), MONTH(FORMAT_UTC_USEC(log_time*1000000)), DAY(FORMAT_UTC_USEC(log_time*1000000)), HOUR(FORMAT_UTC_USEC(log_time*1000000)), test_id, log_time, connection_spec.client_ip,  connection_spec.server_ip, paris_traceroute_hop.src_ip,  paris_traceroute_hop.dest_ip, paris_traceroute_hop.src_hostname,  paris_traceroute_hop.dest_hostname FROM  [plx.google:m_lab.paris_traceroute.all]  WHERE  log_time >= PARSE_UTC_USEC(""2016-07-01 00:00:00"") / POW(10, 6)    AND log_time < PARSE_UTC_USEC(""2017-01-12 00:00:00"") / POW(10, 6) AND connection_spec.server_geolocation.country_code = ""US"" ORDER BY test_id DESC  Thanks! Xiaohong  \ue5d3 \ue5d3 -- \ue5d3'}, 4: {'username': 'Chris Ritzo', 'response_date': 'Feb 10, 2017, 4:21:09 PM', 'response_content': 'Hi Ben,   Thank you for inquiring about this. As you noted, Paris Traceroute data has continued to be collected and is available in raw format, but parsing raw data to BigQuery stopped at some point. Our team is investigating the issue and will update when we have more information.   Thanks for your patience, Chris    \ue5d3 \ue5d3 -- \ue5d3'}, 5: {'username': 'Ben', 'response_date': 'Feb 10, 2017, 4:27:40 PM', 'response_content': 'Thanks for confirming Chris.  Xiaohong, I\'m seeing traces in Sept but it looks as though there\'s a significant drop in the number of traces after May 2016:  SELECT SUBSTR(STRING(SEC_TO_TIMESTAMP(log_time)), 0, 7) AS month, COUNT(1) AS total_traces, SUM(INTEGER(connection_spec.server_geolocation.country_code = ""US"")) AS us_loc_traces, SUM(INTEGER(connection_spec.server_geolocation.country_code IS NULL)) AS null_loc_traces, FROM [plx.google:m_lab.paris_traceroute.all] GROUP BY 1 ORDER BY 1 DESC LIMIT 10    On Friday, 10 February 2017 15:21:09 UTC-8, Chris Ritzo wrote: Hi Ben,   Thank you for inquiring about this. As you noted, Paris Traceroute data has continued to be collected and is available in raw format, but parsing raw data to BigQuery stopped at some point. Our team is investigating the issue and will update when we have more information.   Thanks for your patience, Chris   On Feb 10, 2017 12:29 PM, ""Ben"" <ben.m....@gmail.com> wrote: The documentation at https://www.measurementlab.net/data/ suggests that the data in both BigQuery and CloudStorage are updated every 24 hours. I see new data in CloudStorage, but I\'m not seeing anything more recent than Sept 6, 2016 in BigQuery, based on this query:  >> SELECT MAX(SEC_TO_TIMESTAMP(log_time)) FROM [plx.google:m_lab.paris_traceroute.all] > 2016-09-06 23:59:47 UTC   Is the BigQuery data still getting updated, and at what frequency? -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}, 6: {'username': 'Xiaohong Deng', 'response_date': 'Feb 13, 2017, 3:43:55 AM', 'response_content': 'Thanks for sharing Ben.  Hi Chris,  I wanted to query one month\'s Paris Trace route data. and using following to specify time range. But it always gives me Error: Resources exceeded during query execution. log_time >= PARSE_UTC_USEC(""2016-06-01 00:00:00"") / POW(10, 6)    AND log_time < PARSE_UTC_USEC(""2017-06-30 00:00:00"") / POW(10, 6)   Is there any way around to avoid this error in order to get one month or a specific time period Paris Tracce route data?  Full Query here:  SELECT  test_id, log_time, connection_spec.client_ip,  connection_spec.server_ip, paris_traceroute_hop.src_ip,  paris_traceroute_hop.dest_ip, paris_traceroute_hop.src_hostname,  paris_traceroute_hop.dest_hostname FROM  [plx.google:m_lab.paris_traceroute.all]  WHERE log_time >= PARSE_UTC_USEC(""2016-06-01 00:00:00"") / POW(10, 6)    AND log_time < PARSE_UTC_USEC(""2017-06-30 00:00:00"") / POW(10, 6) AND connection_spec.server_geolocation.country_code = ""US"" ORDER BY test_id DESC  Thank you! Xiaohong \ue5d3'}, 7: {'username': 'Ben Dowling', 'response_date': 'Feb 13, 2017, 7:57:55 AM', 'response_content': ""You could try something like this:  > WHERE SUBSTR(STRING(SEC_TO_TIMESTAMP(log_time)), 0, 7) = '2016-09'  Not sure how it compares in terms of efficiency, but works for me. \ue5d3""}, 8: {'username': 'Greg Russell', 'response_date': 'Feb 13, 2017, 8:54:28 AM', 'response_content': 'It looks like your dates are selecting 13 months instead of 1 month.  I would have thought that should still work, but I\'m relatively new to the system.  FYI, we are debugging the more general problems of paris traceroute collection and processing, and will provide an update soon.  \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- Gregory |  Russell |  g...@google.com |  123-458-7890 https://memegen.googleplex.com/4558349824688128'}, 9: {'username': 'Xiaohong Deng', 'response_date': 'Feb 13, 2017, 12:57:34 PM', 'response_content': 'That does not work with previous months.  For instance: WHERE SUBSTR(STRING(SEC_TO_TIMESTAMP(log_time)), 0, 7) = \'2016-06\' Returns same error. Error: Resources exceeded during query execution.  By several blind tries, I think I figured out something here.    log_time >= PARSE_UTC_USEC(""2016-06-01 00:00:00"") / POW(10, 6)    AND log_time < PARSE_UTC_USEC(""2016-06-01 23:00:00"") / POW(10, 6)  This supposedly 8 hours time of 2016-06-01, returned 1,387,414 rows, compare to the whole records of 27,575,243 in 2016-06, seems a sensible amount.  But it doesn\'t allow save as CSV file because the records are too many.  Even by trunk the time to five minutes time granularity, it returns 11,142 which prevents to download as CSV. So it suggests to save as Table, but when I tired, it says I didn\'t have access to create tables.   The aim here is to  query a substantial amount of PT data to process.Preferably one month US data. What would you suggest might work?  I know meanwhile you are debugging with raw format porting to Bigquery problems, much appreciated for that effort too. \ue5d3'}, 10: {'username': 'Chris Ritzo', 'response_date': 'Feb 13, 2017, 1:14:17 PM', 'response_content': ""Hello everyone:  As Greg mentioned, the M-Lab team is debugging for root causes and solutions and will post a detailed reply once that work is ready. We will also post about it on our blog.   In the interim, knowing that researchers may be working on conference or writing deadlines, we also will post an example for parsing the Paris Traceroute raw format data as soon as we can. If you have a pressing deadline please reply here or reply to me off-list so to help the team prioritize.  Lastly, specific to your last note, Xiaohong, it sounds like you are using the BigQuery web interface to run queries and download CSV results. This normally works fine for most uses, but as you've noted, when the results are particularly large the CSV download is not available on the web. Two options come to mind that would help get around this.   First, if you are able to install and use the Google Cloud SDK, you can use the BigQuery command line tools to run queries and save the output directly as CSV or JSON. See the documentation on our site for installing and using the Gcloud SDK. If you run into issues installing or using, please let me know and I can support you.   Second, if you use R or R studio, there is a BigQuery package available, bigrquery. I have found this package useful in my own work, as it allows you to save queries as text files and import results directly into dataframes. I'm a relative novice at R, but I'm happy to talk with any other R users who might want to explore this option.  Thanks everyone, and we will be in touch on list with more information as we have it.  Best, Chris   ᐧ   Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036      \ue5d3""}, 11: {'username': 'Xiaohong Deng', 'response_date': 'Feb 14, 2017, 9:49:38 PM', 'response_content': 'Hello Chris,  Thank you for advise here.  I managed to put together BigQuery APIs with Python code. And as my google account is whitelisted by Bigquery, when I run python code on my own Mac, it pops up a Web interface requiring me input my google account credentials. After input, It works fine.  But now I need copy this set up to a Linux server to which I only have ssh access. So I wonder is there a way to embed my credentials with ""client_secrets.json""? Could not find associated manual to do so.  There seems two fields relevant:  auth_uri"":""https://accounts.google.com/o/oauth2/auth"" and ""client_email"":： but not a field that I can embed a password with and avoid being redirected to autentification URL? because from a ssh session I don\'t have access to pop up browser.  p.s Would be nice you can put a R query example sometime in future. Many researchers are getting heavily involved with R programming including myself.  Thanks again. Your effort to support research community is highly appreciated.  Cheers, Xiaohong      \ue5d3'}, 12: {'username': 'Chris Ritzo', 'response_date': 'Feb 15, 2017, 10:22:09 AM', 'response_content': ""Hello Xiaohong,  You're quite welcome and I'm glad to hear the response was helpful.   For authenticating your Python application on your remote server with your user account, I believe you should find good documentation here: https://cloud.google.com/bigquery/authentication  For applications I've used (not developed) that require the same thing, I believe the Oauth2 flow within the application prompts you to visit a URL in your browser, where you Oauth with your user account, and then are provided with a code to paste back into your shell to authorize the application.  On the R query example request, I will follow up on this thread when I can.  Best, Chirs   ᐧ   Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036       \ue5d3""}, 13: {'username': 'Chris Ritzo', 'response_date': 'Feb 15, 2017, 2:02:46 PM', 'response_content': ""Xiaohong,   I've put together a very basic R Studio project that shows a basic example of using the rbigquery package to run a query and save the results as a dataframe.   I'll add to this as I have time, and if others have worked with this package and would like to contribute examples, please feel free to send me pull requests.  The project is on my Github account: https://github.com/critzo/rbigquery-examples  Cheers, Chris ᐧ   Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036       \ue5d3""}, 14: {'username': 'Xiaohong Deng', 'response_date': 'Feb 15, 2017, 3:04:17 PM', 'response_content': 'Chris,  Thanks a lot for putting a R example in such a timely manner. It looks much simpler than the Python approach.  I tried your code with a query of Paris Traceroute data (see below), which I assume shall work with this example code. Or not really?  The authentication seems worked fine. But it returns NULL results, whereas Python API codes returns 11k+ rows. == > PT_2016_download_results <- query_exec(PT_2016_download_query, project=""measurement-lab"", max_pages=Inf) Running query:   RUNNING 126.3s 0 bytes processed  Would you have a clue about this? Thanks.  SELECT         YEAR(FORMAT_UTC_USEC(web100_log_entry.log_time*1000000)) AS year,         MONTH(FORMAT_UTC_USEC(web100_log_entry.log_time*1000000)) AS month,         DAY(FORMAT_UTC_USEC(web100_log_entry.log_time*1000000)) AS day,         HOUR(FORMAT_UTC_USEC(web100_log_entry.log_time*1000000)) AS hour,         MINUTE(FORMAT_UTC_USEC(web100_log_entry.log_time*1000000)) AS minute,          test_id, log_time, connection_spec.client_ip,         connection_spec.server_ip, paris_traceroute_hop.src_ip,         paris_traceroute_hop.dest_ip, paris_traceroute_hop.src_hostname,         paris_traceroute_hop.dest_hostname FROM         [plx.google:m_lab.paris_traceroute.all]         WHERE         log_time >= PARSE_UTC_USEC(""2016-06-01 00:00:00"") / POW(10, 6)         AND log_time < PARSE_UTC_USEC(""2016-06-01 00:01:00"") / POW(10, 6)         #AND log_time < PARSE_UTC_USEC(""2016-06-30 23:59:00"") / POW(10, 6)          AND connection_spec.server_geolocation.country_code = ""US""         ORDER BY test_id DESC \ue5d3'}, 15: {'username': 'Xiaohong Deng', 'response_date': 'Feb 15, 2017, 3:24:46 PM', 'response_content': ""Chris,  Please ignore my previous question. It indeed successfully returned PT data. Thanks!  Except that following doesn't work correctly with time convert. (all rows are: 1970/1/1/0/0 ) That works with NDT data though. Do you have an example of convert PT data to Year, month, day, hour and minute which will be useful for answering our research questions. Cheers, YEAR(FORMAT_UTC_USEC(log_time*1000000)), MONTH(FORMAT_UTC_USEC(log_time*1000000)), DAY(FORMAT_UTC_USEC(log_time*1000000)), HOUR(FORMAT_UTC_USEC(log_time*1000000)),   \ue5d3""}, 16: {'username': 'Chris Ritzo', 'response_date': 'Feb 16, 2017, 1:56:25 PM', 'response_content': ""Xiaohong,  I'm happy to hear you were able to query for PT data. I've spent a little more time today confirming some details about the PT data and the issue you are encountering converting time data, and I have some recommendations on strategies for querying for PT data generally using the Rbigquery package.  First, I attempted to re-create the error you mentioned (all data rows showing 1970/1/1/0/0). I have not used the YEAR, MONTH, DAY functions much, so I can't speak directly to their correct use, but I do know that using lots of functions in your query can consume resources and make you hit query limits. So for example, rather than querying for YEAR(), MONTH(), DAY().. etc. separately using these functions, you could just query for a single datetime field and process out the day, month, year as a part of data prep once you have it. For example:    ᐧ   Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036       \ue5d3""}, 17: {'username': 'Chris Ritzo', 'response_date': 'Feb 16, 2017, 1:57:11 PM', 'response_content': 'Apologies, I accidentally hit send. I will send a follow up complete reply -Chris ᐧ   Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036       \ue5d3'}, 18: {'username': 'Collin Anderson', 'response_date': 'Feb 16, 2017, 2:05:06 PM', 'response_content': ""Hi Xiaohong,  The web100_log_entry.log_time propriety is not marked in PT's records, but log_time is. The issue you are encountering is that web100_log_entry.log_time is returning null as a result, which then falls back on the FORMAT... functions to the start of the Unix epoch. If you use log_time instead, which you were in the YEAR() queries, everything should work fine.  Cordially, Collin \ue5d3""}, 19: {'username': 'Chris Ritzo', 'response_date': 'Feb 16, 2017, 2:06:49 PM', 'response_content': 'Xiaohong,  I\'m happy to hear you were able to query for PT data. I\'ve spent a little more time today confirming some details about the PT data and the issue you are encountering converting time data, and I have some recommendations on strategies for querying for PT data generally using the Rbigquery package.  First, I attempted to re-create the error you mentioned (all data rows showing 1970/1/1/0/0). I have not used the YEAR, MONTH, DAY functions much, so I can\'t speak directly to their correct use, but I do know that using lots of functions in your query can consume resources and make you hit query limits. So for example, rather than querying for YEAR(), MONTH(), DAY().. etc. separately using these functions, you could just query for a single datetime field and process out the day, month, year as a part of data prep once you have it.   For example the query portion below returns a value like this (2016-06-01 11:54:39) :  STRFTIME_UTC_USEC((INTEGER(log_time) * 1000000), \'%Y-%m-%d %T\') AS UTC_date_time   Using functions of your statistics package (like R) you could then separate out the individual time components for your analysis.  Additionally, and as relates to the inquiries of others on the large number of results in the PT data, I\'ve re-run your query within my RStudio project to see where I run into query resource limits. Using the query below, I\'ve been able to use the rbigquery package to get ~1/2 day of data at a time without hitting resource limits:  SELECT   STRFTIME_UTC_USEC((INTEGER(log_time) * 1000000), \'%Y-%m-%d %T\') AS UTC_date_time,    test_id, connection_spec.client_ip, connection_spec.server_ip,    paris_traceroute_hop.src_ip, paris_traceroute_hop.dest_ip,    paris_traceroute_hop.src_hostname, paris_traceroute_hop.dest_hostname  FROM   [plx.google:m_lab.paris_traceroute.all] WHERE   project = 3   AND IS_EXPLICITLY_DEFINED(paris_traceroute_hop.src_ip)   AND connection_spec.server_geolocation.country_code = \'US\'   AND ((log_time >= PARSE_UTC_USEC(""2016-06-01 12:00:00"") / POW(10, 6))   AND (log_time < PARSE_UTC_USEC(""2016-06-01 23:59:59"") / POW(10, 6))) ORDER BY test_id DESC  This is obviously not ideal for gathering large amounts of data, but as Peter mentioned, we hope to soon have our tables updated so that these resource limits will no longer affect us in this way. As a workaround, however, I\'ll be adding an example to my RStudio project repo, some R code that can be used to run subsequent queries and append them to the same data frame.  Hope this helps.  Chris  ᐧ   Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036       \ue5d3'}, 20: {'username': 'Xiaohong Deng', 'response_date': 'Feb 21, 2017, 10:59:12 PM', 'response_content': ""Hi Chris/Collin,  It definitely helps. Thank you.  Seems I was able to query one day's PT data without hitting the limit.  Yes. Please announce when you update the example R code.  Thanks, Xiaohong  \ue5d3""}, 21: {'username': 'Xiaohong Deng', 'response_date': 'Feb 27, 2017, 11:22:24 AM', 'response_content': ""Hi Chris/Collin,  We are now able to get one month's PT data by separating R queriers into each hour and combine the results in the end. Not the most convenient approach. But can live with that.  But the most recent fully month PT data available is 2016 May. Sine June 2016, data starts missing and size decreasing.  In our research, we would want to have a large scale of most recent PT data. I know you have been working on Bigquery missing data issue. Is there a timeline for that? Say, When could we have whole PT data in Bigquery?  Thank you, Xiaohong  \ue5d3""}, 22: {'username': 'Chris Ritzo', 'response_date': 'Feb 28, 2017, 12:00:01 PM', 'response_content': ""Hello Xiaohong,  I do not have a timeline for when the missing BigQuery data will be restored, but I can report that the issue has been identified and getting the PT BigQuery data updated is on our staff's plate this week. We will post here once the data has been processed and is again available in BigQuery.  Best. Chris \ue5d3""}, 23: {'username': 'Xiaohong Deng', 'response_date': 'Feb 28, 2017, 12:34:12 PM', 'response_content': ""Hi Chris,  That's great.  Keep us posted. Thank you.  All the best, Xiaohong  \ue5d3""}, 24: {'username': 'Ben', 'response_date': 'Apr 3, 2017, 11:50:48 AM', 'response_content': 'I\'m seeing new data in the tables, so it looks like this has been resolved! It doesn\'t look like all of the old data has been backfilled though, based on this query:  SELECT SUBSTR(STRING(SEC_TO_TIMESTAMP(log_time)), 0, 7) AS month, COUNT(1) AS total_traces FROM   [plx.google:m_lab.paris_traceroute.all] GROUP BY 1 ORDER BY 1 DESC LIMIT 10  Will the missing rows from Sept - Jan eventually get added?  Thanks, Ben \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}, 25: {'username': 'Chris Ritzo', 'response_date': 'Apr 3, 2017, 4:40:55 PM', 'response_content': 'Hello Ben,  Thanks for checking in on this issue. The short answer is that, yes, the issue has been resolved. We are reviewing a blog post now which we will post soon which discusses the issue in detail, what was done to resolve it, as well as communicate expectations about Paris Traceroute data between June 2016 and Feb 2017.  We will also post that content here on M-Lab discuss.   Best, Chris   Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036       \ue5d3'}}"
215	announcing-the-new-m-lab-dataviz-tool!	1488987647.0	2017-03-08 08:40:47	Georgia Bullen	"Hello all!  As I eluded at the end of January, we've been working on some new data visualization tools to help all of you with visualizing and accessing the data more easily. Thank you to the many of you who participated in the design process -- so much of where M-Lab is today has to do with all of the great questions that you ask on this list and in support emails, etc. We hope that these tools continue to open the M-Lab data to the world.  Read more about the tool here: https://www.measurementlab.net/blog/new-dataviz-site/ Explore the data using the visualizations here: https://viz.measurementlab.net  Ping us with questions, concerns, interesting stories and finds here or at sup...@measurementlab.net.   -Georgia  On Tue, Jan 24, 2017 at 6:29 AM, Georgia Bullen <geo...@opentechinstitute.org> wrote: Hi Kim,  We're looking into it! Apologies for the problems.   We'll also be launching some new visualization tools this month -- so more soon on that!  -Georgia Measurement Lab Team  On Mon, Jan 23, 2017 at 6:31 PM, Kim Prince <k...@kimprince.com> wrote: Hi,  Just came across M-Lab - looks awesome.  I notice that the Observatory (http://www.measurementlab.net/observatory/) is not working.  Tried it yesterday and today, both Mozilla and Chrome.  The Javascript console reports lots of errors, starting with 404 responses from google API's.  (I can post the detail if that's helpful).  Is anyone else having this problem?  I am based in Australia.  Not sure if that is a factor?  Kim -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.    -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/  Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon    -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/  Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon"	"{0: {'username': 'valay.v...@gmail.com', 'response_date': 'Mar 16, 2017, 8:38:02 AM', 'response_content': 'Hello,  This is vkumar shah from Variance Infotech  I would like to discuss with you about the business regards  If you dont mind can you add me on skype or send me Email schedule meeting :-  - skype :- valay.variance - Email :- valay.v...@gmail.com  We are based from IT Firm and looking for business partner  Thanks  Vkumar   On Wednesday, March 8, 2017 at 9:10:47 PM UTC+5:30, Georgia Bullen wrote: Hello all!  As I eluded at the end of January, we\'ve been working on some new data visualization tools to help all of you with visualizing and accessing the data more easily. Thank you to the many of you who participated in the design process -- so much of where M-Lab is today has to do with all of the great questions that you ask on this list and in support emails, etc. We hope that these tools continue to open the M-Lab data to the world.  Read more about the tool here: https://www.measurementlab.net/blog/new-dataviz-site/ Explore the data using the visualizations here: https://viz.measurementlab.net  Ping us with questions, concerns, interesting stories and finds here or at sup...@measurementlab.net.   -Georgia  On Tue, Jan 24, 2017 at 6:29 AM, Georgia Bullen <geo...@opentechinstitute.org> wrote: Hi Kim,  We\'re looking into it! Apologies for the problems.   We\'ll also be launching some new visualization tools this month -- so more soon on that!  -Georgia Measurement Lab Team On Mon, Jan 23, 2017 at 6:31 PM, Kim Prince <k...@kimprince.com> wrote: Hi,  Just came across M-Lab - looks awesome.  I notice that the Observatory (http://www.measurementlab.net/observatory/) is not working.  Tried it yesterday and today, both Mozilla and Chrome.  The Javascript console reports lots of errors, starting with 404 responses from google API\'s.  (I can post the detail if that\'s helpful).  Is anyone else having this problem?  I am based in Australia.  Not sure if that is a factor?  Kim -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/  Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon \ue5d3'}, 1: {'username': 'Livingood, Jason', 'response_date': 'Mar 27, 2017, 6:58:55 AM', 'response_content': 'Does anyone know the source of what look like subscriber numbers when you go to “Facet By”, then “Client ISPs” and enter an ISP name? For Google Fiber it shows ~411,000 and for Comcast it shows 39.2M. Not sure on the former but for the latter (where I work) the real number is ~24.7 per our most recent SEC filing.   Just curious.   Thanks Jason   On 3/8/17, 10:40 AM, ""Georgia Bullen"" <geo...@opentechinstitute.org> wrote:   Hello all!   As I eluded at the end of January, we\'ve been working on some new data visualization tools to help all of you with visualizing and accessing the data more easily. Thank you to the many of you who participated in the design process -- so much of where M-Lab is today has to do with all of the great questions that you ask on this list and in support emails, etc. We hope that these tools continue to open the M-Lab data to the world.   Read more about the tool here: https://www.measurementlab.net/blog/new-dataviz-site/ Explore the data using the visualizations here: https://viz.measurementlab.net   Ping us with questions, concerns, interesting stories and finds here or at sup...@measurementlab.net.    -Georgia   On Tue, Jan 24, 2017 at 6:29 AM, Georgia Bullen <geo...@opentechinstitute.org> wrote: Hi Kim,   We\'re looking into it! Apologies for the problems.    We\'ll also be launching some new visualization tools this month -- so more soon on that!   -Georgia Measurement Lab Team On Mon, Jan 23, 2017 at 6:31 PM, Kim Prince <k...@kimprince.com> wrote: Hi,  Just came across M-Lab - looks awesome.  I notice that the Observatory (http://www.measurementlab.net/observatory/) is not working.  Tried it yesterday and today, both Mozilla and Chrome.  The Javascript console reports lots of errors, starting with 404 responses from google API\'s.  (I can post the detail if that\'s helpful).  Is anyone else having this problem?  I am based in Australia.  Not sure if that is a factor?  Kim -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/   Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon     -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/   Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}, 2: {'username': 'Chris Ritzo', 'response_date': 'Mar 27, 2017, 10:53:21 AM', 'response_content': 'HI Jason,   Thanks for inquiring about the Facet By Client ISP option in our visualization\'s Compare page.   The number shown in this case is not subscriber count but the number of tests conducted from subscribers to the ISP selected. So in this case, there have been 39.2M tests from Comcast subscribers.   Our original announcement also left out code references. For those who may be interested in reviewing the code that produces this visualization of M-Lab data, the three repositories below are available:  Pipeline - https://github.com/m-lab/mlab-vis-pipeline API - https://github.com/m-lab/mlab-vis-api Client - https://github.com/m-lab/mlab-vis-client  Best, Chris    Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036       \ue5d3 \ue5d3 \ue5d3 \ue5d3 -Georgia   \ue5d3 \ue5d3 \ue5d3 \ue5d3 -- \ue5d3 To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/   Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon     -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/   Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.   -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. \ue5d3'}}"
216	variability-in-results	1487758773.0	2017-02-22 03:19:33	Jerry Helffrich	I just began using the m-lab site for speed testing tonight, but I'm struck by how much variation there is in the results taken just 30 seconds apart. I began getting 6 Mbps down and 1 Mbps up (this is a DSL connection) and after 4 successive tries I steadily went down to 1 Mbps down and 0.4 Mbls up. Not only are the numbers depressing in the absolute sense, but these tests are being done at 3:30 AM CST, when I would expect congestion and latency to be at their minimums--and the connection is being made from San Antonio to DFW, which I'm guessing is the Dallas Fort Worth airport. So, is there any reason (buffer filling?) that my speed should steadily go down when testing at 30 second intervals? If this is normal, which number is the correct one? A factor of six variation in download speed is a lot.Results summary below: TCP receive window: 317856 current, 317856 maximum 0.10 % of packets lost during test Round trip time: 27 msec (minimum), 1128 msec (maximum), 409 msec (average) Jitter: - 0.00 seconds spend waiting following a timeout TCP time-out counter: 894 332 selective acknowledgement packets received  No duplex mismatch condition was detected. The test did not detect a cable fault. No network congestion was detected.  0.8043 % of the time was not spent in a receiver limited or sender limited state. 0.1468 % of the time the connection is limited by the client machine's receive buffer. Optimal receive buffer: - bytes Bottleneck link: - 333 duplicate ACKs set	{}
217	even-more-basic-intro?	1487278952.0	2017-02-16 14:02:32	David Radin	I have run a couple queries, including getting all the previous NDT tests run from my public IP. But I can't seem to figure out - and I'm sure this is me being incredibly dense - what speeds were logged. There isn't a download or upload speed column in plx.google:m_lab.ndt.all, and it doesn't seem that there are fields I could calculate speeds from (like test duration and data transferred). What am I missing?	"{0: {'username': 'Chris Ritzo', 'response_date': 'Feb 16, 2017, 2:15:26 PM', 'response_content': 'Hi David,  Upload and Download speeds are calculated from fields in the data. We have some examples on our old wiki page that have yet to make it to the examples on our website. Sorry about that. I\'ll add an issue to our tracker to add them.   Here\'s the section of the old wiki which explains how to calculate these metrics:  https://github.com/m-lab/mlab-wikis/blob/master/PDEChartsNDT.md#compute-test-level-metrics  Please note that the query examples on that page are based on our older, legacy tables. These are still published, so they should all still work, but if you want faster results, please also review the section of our schema page on legacy tables (http://www.measurementlab.net/data/bq/schema/#legacy-tables) as well as the legacy tables migration guide (http://www.measurementlab.net/data/bq/legacymigration) as you look at these and craft your queries against the table: plx.google:m_lab.ndt.all which will provide the fastest query results.  Hope this helps. Chris ᐧ   Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036       On Thu, Feb 16, 2017 at 4:02 PM, David Radin <david...@gmail.com> wrote: I have run a couple queries, including getting all the previous NDT tests run from my public IP. But I can\'t seem to figure out - and I\'m sure this is me being incredibly dense - what speeds were logged. There isn\'t a download or upload speed column in plx.google:m_lab.ndt.all, and it doesn\'t seem that there are fields I could calculate speeds from (like test duration and data transferred). What am I missing? -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
218	client-geo-location-data	1486030683.0	2017-02-02 03:18:03	Kim Prince	Presumably the client geo-location data in test results is the location of the client's ISP.  Is that correct?	"{0: {'username': '☕Peter Boothe', 'response_date': 'Feb 2, 2017, 8:39:35 AM', 'response_content': 'MLab looks the IP up in the open-source MaxMind database, and that\'s the location we report.    -Peter  On Thu, Feb 2, 2017 at 5:18 AM, Kim Prince <k...@kimprince.com> wrote: Presumably the client geo-location data in test results is the location of the client\'s ISP.  Is that correct? -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.    -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.'}, 1: {'username': 'Chris Ritzo', 'response_date': 'Feb 2, 2017, 9:02:54 AM', 'response_content': ""Kim, yes, the client geo-location fields are the location of the client based on the IP address of their ISP. Those fields are:  connection_spec.client_geolocation.latitude and connection_spec.client_geolocation.longitude   As Peter mentioned, M-Lab determines the client's ISP by taking the IP from connection_spec.client_ip and looking it up in a free database provided by MaxMind, which they update monthly. You can download the most current version of the MaxMind database we use here: http://download.maxmind.com/download/geoip/database/asnum/GeoIPASNum2.zip  Best, Chris   Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036      \ue5d3""}, 2: {'username': 'Kim Prince', 'response_date': 'Feb 2, 2017, 10:27:58 PM', 'response_content': 'Thanks, that\'s very helpful   On Friday, February 3, 2017 at 3:02:54 AM UTC+11, Chris Ritzo wrote: Kim, yes, the client geo-location fields are the location of the client based on the IP address of their ISP. Those fields are:  connection_spec.client_geolocation.latitude and connection_spec.client_geolocation.longitude   As Peter mentioned, M-Lab determines the client\'s ISP by taking the IP from connection_spec.client_ip and looking it up in a free database provided by MaxMind, which they update monthly. You can download the most current version of the MaxMind database we use here: http://download.maxmind.com/download/geoip/database/asnum/GeoIPASNum2.zip  Best, Chris   Chris Ritzo  Senior Technologist, Open Technology Institute @ New America  740 15th Street NW, Suite 900  Washington, DC 20036       On Thu, Feb 2, 2017 at 10:38 AM, \'☕Peter Boothe\' via discuss <dis...@measurementlab.net> wrote: MLab looks the IP up in the open-source MaxMind database, and that\'s the location we report.    -Peter On Thu, Feb 2, 2017 at 5:18 AM, Kim Prince <k...@kimprince.com> wrote: Presumably the client geo-location data in test results is the location of the client\'s ISP.  Is that correct? -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net. \ue5d3'}}"
219	can-i-browse-the-bigquery-tables?	1486027356.0	2017-02-02 02:22:36	Kim Prince	I'm just finding my way around BigQuery using the Web UI.  I obviously have access to the MLab data because when I include a table (such as plx.google:m_lab.ndt.all) in a query, it works as expected.  From what I can see however, I can't actually browse the tables as they do not appear in the datasets on the left of the screen.  Am I doing something wrong?  Or do we not have access to browse the tables?  It would be good to be able to browse the tables to get familiar with the data.	"{0: {'username': '☕Peter Boothe', 'response_date': 'Feb 2, 2017, 8:18:31 AM', 'response_content': 'Unfortunately, our use of Google\'s query system predates the existence of BigQuery, and so our plumbing from our more-custom backend to the BigQuery frontend makes some features unavailable. We anticipate fixing this issue in 2017.  When trying to get a sense of the tables, I recommend the following queries: SELECT * FROM   [plx.google:m_lab.ndt.all] LIMIT 1;  and  SELECT COUNT(*) FROM   [plx.google:m_lab.ndt.all];    -Peter  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.    -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.'}, 1: {'username': 'Kim Prince', 'response_date': 'Feb 2, 2017, 10:24:33 PM', 'response_content': ""Thanks, that's very helpful \ue5d3""}}"
220	how-does-m-lab-pick-which-server-to-test-against?	1485646766.0	2017-01-28 16:39:26	Ron Dallmeier	Anyone have some insight or a link to a document? Specifically when running the NDT performance test.  Also, there are a lot of perfsonar servers run by R&E networks, which also employ the NDT test. Is there an effort to collect result log data from those servers and make them available to the m-lab dataset?  ...Ron	"{0: {'username': 'Collin Anderson', 'response_date': 'Jan 30, 2017, 11:54:27 AM', 'response_content': 'Hi Ron,  In most NDT clients associated with M-Lab, the selection will be based on determining the physically-closest site to the user based on IP geolocation services. M-Lab provides the mlab-ns service in order to facilitate this pairing. However, if another client or integration would like to use an alternative approach, they are welcome to do so. So its based on which deployment of NDT you are using, but I would assume physically-closest is the answer.  M-Lab does not include data collected perfsonar servers. We would certainly be open to provide comparison, and our primary limitation to including the data in our general datasets is that we are concerned about the conditions and capabilities under which tests are performed. As a result, we have been shifting toward more standardization in the fleet, and more rigorous qualification of M-Lab sites. Hence, it would be important to differentiate those to datasets in any form of comparison (not to dismiss perfsonar in any manner of course, only a communications challenge).  Cordially, Collin  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}}"
221	observatory-not-working?	1485214316.0	2017-01-23 16:31:56	Kim Prince	Hi,  Just came across M-Lab - looks awesome.  I notice that the Observatory (http://www.measurementlab.net/observatory/) is not working.  Tried it yesterday and today, both Mozilla and Chrome.  The Javascript console reports lots of errors, starting with 404 responses from google API's.  (I can post the detail if that's helpful).  Is anyone else having this problem?  I am based in Australia.  Not sure if that is a factor?  Kim	"{0: {'username': 'Georgia Bullen', 'response_date': 'Jan 23, 2017, 10:29:26 PM', 'response_content': 'Hi Kim,  We\'re looking into it! Apologies for the problems.   We\'ll also be launching some new visualization tools this month -- so more soon on that!  -Georgia Measurement Lab Team  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.    -- Georgia Bullen Director of Technology Projects Book a meeting: https://calendly.com/georgiabullen/  Open Technology Institute @ New America 740 15th Street NW, Suite 900, Washington DC, 20005 @georgiamoon'}, 1: {'username': 'sylvain.s...@orange.com', 'response_date': 'Jan 24, 2017, 2:20:31 AM', 'response_content': 'Hi Kim   I do have the same problem  from France. Sylvain   De : Kim Prince [mailto:k...@kimprince.com] Envoyé : mardi 24 janvier 2017 00:32 À : discuss Objet : [M-Lab-Discuss] Observatory Not Working? \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. _________________________________________________________________________________________________________________________  Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc pas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler a l\'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d\'alteration, Orange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.  This message and its attachments may contain confidential or privileged information that may be protected by law; they should not be distributed, used or copied without authorisation. If you have received this email in error, please notify the sender and delete this message and its attachments. As emails may be altered, Orange is not liable for messages that have been modified, changed or falsified. Thank you.'}, 2: {'username': 'Georgia Bullen', 'response_date': 'Jan 27, 2017, 12:21:08 PM', 'response_content': 'Hi All -- just an update that this is fixed now! Sorry for the interruption.  -Georgia Measurement Lab Team  On Tue, Jan 24, 2017 at 4:20 AM, <sylvain.s...@orange.com> wrote: Hi Kim   I do have the same problem  from France. Sylvain   De : Kim Prince [mailto:k...@kimprince.com] Envoyé : mardi 24 janvier 2017 00:32 À : discuss Objet : [M-Lab-Discuss] Observatory Not Working?   Hi,  Just came across M-Lab - looks awesome.  I notice that the Observatory (http://www.measurementlab.net/observatory/) is not working.  Tried it yesterday and today, both Mozilla and Chrome.  The Javascript console reports lots of errors, starting with 404 responses from google API\'s.  (I can post the detail if that\'s helpful).  Is anyone else having this problem?  I am based in Australia.  Not sure if that is a factor?  Kim -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. _________________________________________________________________________________________________________________________  Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc pas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler a l\'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d\'alteration, Orange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.  This message and its attachments may contain confidential or privileged information that may be protected by law; they should not be distributed, used or copied without authorisation. If you have received this email in error, please notify the sender and delete this message and its attachments. As emails may be altered, Orange is not liable for messages that have been modified, changed or falsified. Thank you. -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.  To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/. \ue5d3'}, 3: {'username': 'Kim Prince', 'response_date': 'Jan 27, 2017, 6:12:11 PM', 'response_content': 'Nice one, looks great. \ue5d3'}}"
222	"speed-test-no-longer-works-since-comcast-""speed-upgrade"""	1483761988.0	2017-01-06 21:06:28	michael...@gmail.com	"I received an email from Comcast today instructing me to shut down my computers and power cycle my Comcast cable modem for a ""speed upgrade"". Since doing this, the standard Google speed test applet fails to run due to ""The test can't be completed due to a problem with the network. Try again later."". The ""Ookla"" speed test which, by default, selects the closest Comcast server, shows ~250MB/sec download and ~12MB/sec upload. "	{}
223	defunct-use-mlab-sandbox-project	1483669520.0	2017-01-05 19:25:20	Paul Connelly	"Hi there,  I would like to explore the mlab dataset on BigQuery, and have followed the 2 steps on http://www.measurementlab.net/data/bq/quickstart/ however when I go into the IAM & Admin Projects area of the Google Developers Console, all I see is ""DEFUNCT use mlab-sandbox"" project with the Project ID of 'measurement-lab'.  This project is also appearing in BigQuery console.  When I explore the ""DEFUNCT use mlab-sandbox"" project on BigQuery, these are the datasets it lists:  fcc_samknows_data ic2012 m_lab MaxMind_CountryLite maxmind_lite metrics_api_server mlab_test mlab_validation neubot neubot_sandbox ookla_net_index Is this the correct project that I should have gained access to once joining this group, or have I missed a step?  Paul"	"{0: {'username': 'Uri Klarman', 'response_date': 'Jan 5, 2017, 8:37:32 PM', 'response_content': 'I was wondering the same thing, and would be happy to read a clarification on the matter... Uri \ue5d3'}, 1: {'username': '☕Peter Boothe', 'response_date': 'Jan 5, 2017, 9:15:57 PM', 'response_content': 'Aha! This is my fault, and an error on my part!  I had renamed it to encourage M-Lab team members (some of whom who were using this group for their experiments and as a playground for new ideas) to put their experiments into the more appropriate project mlab-sandbox. For the purpose of doing queries against MLab data and the like, this is still the RIGHT project, and the one you should be using.  The name is now changed to ""MLab project - public BigQuery"", which is an accurate reflection of its purpose.  Thanks for bringing this up, Peter  \ue5d3 \ue5d3 -- You received this message because you are subscribed to the Google Groups ""discuss"" group. To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net. To post to this group, send email to dis...@measurementlab.net. Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.    -- ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.'}}"
