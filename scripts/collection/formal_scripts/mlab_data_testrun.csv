,post_id,title,date,author,content,replies
0,113041922695286406930368834841905121223,new-ookla-speedtest-app-for-ios,"May 11, 2022, 7:30:12 AM",Dave Taht,"The latest ookla speedtest app (just for apple's ios presently), is
finally tracking ""working latency"",
and ""responsiveness"".

Try it!

--
FQ World Domination pending: https://blog.cerowrt.org/post/state_of_fq_codel/
Dave Täht CEO, TekLibre, LLC",{}
1,188810130514559392520960441246123640879,download-sppeds-desreprencies-when-running-speed-test,"Apr 13, 2022, 9:38:01 AM",Paul Zahra,"I noticed when I run your speed test at times the dpwnload speeds are much, much lower then when using OOkla,   This moing test showed  sub 1 MB , but OOKLA showed at least 40MB  .Can you explain the possible differences?   My connection does seem slow. 

Thaks for any insight you can provide,

Regards,
Paul Zahra","{'Lai Yi Ohlsen': ""Hi everyone,\n\nThank you all for your thoughtful notes. It’s evident that there are a number of shared goals, the most prominent being to use data to improve Internet performance for end users. More specifically, I agree with the latter parts of Nick’s last statement about the need for measurements that help end users and their public representatives actually solve problems. M-Lab is also keen to make progress here.\n\nThere’s a lot of details here that we could go back and forth on but I’m curious how we can channel the obvious energy on these topics into actionable, consensus-driven plans. Afterall, our shared goals are not small :) and would only benefit from a cooperative approach. Would the folks in this thread (including anyone following along) be interested in participating in a working group focused on these topics (e.g. “speed” tests,  network topologies, data collection methodologies etc.) and supporting M-Lab’s efforts to contribute here?\n\nPlease let me know if so! A reply to this email works great.\n\nAs/If the thread continues, I'll insert a gentle reminder of our community guidelines. Take care all. \n\n\ue5d3"", 'Paul Zahra': 'Hello Lai and Group,\n\nJust some more info on my exploits here.  I continued to see the differences in Speed test results yesterday.  I decided to reboot my router and  the speed test results changed to where NDT and OOKLA are measuring the same fast speeds . 50MB.\n Woke up this morning and ran the tests and again, speed differences showed up  sub 1MB and 50MB,  rebooted and then the speeds were the same again > 50MB.  \n\n\nRegards,\nPaul\n\n\ue5d3', 'Livingood, Jason': 'Good idea on channeling energy towards a constructive activity – I’d suggest considering adding a speed test (aggregate capacity) to the M-Labs platform. This could potentially leverage some of the open source tests out there or new standards such as https://datatracker.ietf.org/doc/html/draft-ietf-ippm-capacity-protocol.\n  It is worth bearing in mind that my concern over (mis)use & (mis)representation of NDT data is not theoretical. There are tens of billions of dollars of public grant money in the United States that will be spent over the next few years to build Internet connectivity to areas that are currently unserved. I have observed instances of grant decision-makers being told in public meetings which areas have no service based on the purported results of NDT “speed tests” and of grant applicants using NDT “speed tests” to show where broadband is not available or suggesting NDT “speed tests” can be used after the fact to confirm that the new address is receiving broadband service.\n  Jason\n  From: Lai Yi Ohlsen <la...@measurementlab.net>\nDate: Friday, April 15, 2022 at 09:41\nTo: Nick Feamster <feam...@gmail.com>\nCc: discuss <dis...@measurementlab.net>, ""etha...@gmail.com"" <etha...@gmail.com>, ""pza...@logitech.com"" <pza...@logitech.com>\nSubject: [EXTERNAL] Re: [M-Lab-Discuss] Download sppeds desreprencies when running Speed test\n  Hi everyone,\n\ue5d3\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcMm0_4h4k1s%3D8%3D5smXzC4gCNxP3Za9qND%2BCNgWz9s6_7A%40mail.gmail.com.', 'jpartr...@gmail.com': 'To M-Lab\'s credit, you all have repeatedly acknowledged:\n\n-""access link capacity is not what NDT measures""\n-""Ookla\'s speedtest.net...{is} better suited for researchers looking to only measure the last-mile connection""\n-ISP services ""would be best measured by a multi-stream test""\n-""NDT from M-Lab on the other hand, isn\'t intended to be a measurement of an Internet connection\'s maximum capacity""\n-and now yesterday, ""NDT does not answer the question how big is your pipe""\n\nThe problem is that many stakeholders, and the public at large, are misinterpreting and misrepresenting NDT data. Whether they are doing it naively, or willfully and maliciously, they are holding up NDT data as being indicative of performance that M-Lab has repeatedly stated it is not. And that is problematic! M-Lab would actually be assisting the research community by removing this misinformation, rather than simply issuing disclaiming caveats. As Sara Wedeman and David Clark noted in their paper, ""In short, NDT was a diagnostic tool, not a measuring stick. The purpose was not to evaluate or compare residential broadband speeds delivered by ISPs, but rather to find and fix network problems."" At another point they observed: ""Our high-level conclusions {are} that these are not tests that reveal variation in the access technology, and computing a mean or median of these measurements will tell us nothing about the speed of the access link."" And finally, Wedeman and Clark also observe: ""The data from M-Lab is free and publicly available - and despite M-Lab’s cautionary messages on its Web site, M-Lab data can be, and has been used inappropriately on more than one occasion."" As noted earlier, this is problematic!\n\n\n\n\n\ue5d3', 'Glenn Fishbine': ""Just my 2 cents worth.\n\nBefore declaring that MLab is not a speed test, first you have to have agreement as to what a speed test is.\n\nA speed test measures something.  That something has a context usually related to usability for a purpose.\n\nIf the purpose is to determine the size of the pipe maybe MLab isn't the best choice.\n\nIf the purpose is to determine if a specific task can be accomplished, maybe Mlab is the best choice.\n\nThere is a clear difference on the type of speed test to be used if:\n\n1.  you want to know if you can stream Netflix 4k videos without buffering\n\n2.  If Johnny can get responses to his homework answers in less than 3 seconds.\n\n3.  If you can hold a video conference call on a service that has single port streaming.\n\nI'm sure there are other answers, but it depends on what purpose you have in mind when you declare a speed test adequate, or not, for that purpose.\n\nLet me point out that our dear friends at the FCC built Mlab into their mobil speed test, and further point out that their own research subsequently declared that MLab was a more than adequate test for their purposes in a way that was acceptable, albeit different, from Ookla, which was also acceptable.  \n\n\n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/fdf7d530-20f0-41b4-b136-59b26ba45de2n%40measurementlab.net."", 'Ethan Katz-Bassett': 'I think this is a great summary of key differences! \n\nHowever, as an additional caveat in interpreting the data, it\'s not clear to me what off-net vs on-net measurements meaningfully represent in terms of ""the complete path across the Internet from user to content."" For many (probably most) Internet users, much (probably most) of their traffic comes either from an on-net Content Delivery Network (CDN) node or across a dedicated network interconnection to the content provider. So it\'s not clear to me that traffic crossing one or a few particular network interconnections between me and the assigned MLab server is a more meaningful measure of the performance I\'d get to content than a measurement to an on-net server -- I suspect that neither exercises any interdomain interconnections that my traffic encounters when using YouTube, Netflix, Facebook, services hosted on the major cloud providers, services hosted on a number of widely-used CDNs, etc. If the NDT measurement is constrained by issues at the interconnection, the issues could apply to any services I use that happen to share that interconnection, but that\'s probably not the case for most services I use, and it requires a good amount of Internet measurement to understand which ones do share it.\n\nEthan\n\n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcMg5JOuFWy4Fd6G4CKnE3CQN0m0nWXCbCGoZg_S1vcuxw%40mail.gmail.com.', 'Nick Feamster': 'A few thoughts:\n\n1. All of these tests are subject to severe sampling bias, particular under-representation of samples in communities where connectivity gaps are most dire.  This I believe is a fundamental issue that is common across *all* of today’s methodologies. Client-based tests face severe sampling limitations; even the MBA program stratifies its sample by ISP and thereby severely undersamples most geographies, making it not very useful for many types of studies.  See our TPRC paper for some initial discussion of these issues: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3786158\n\n2. All of these tests are subject to various issues with client-based measurements, from WiFi bottlenecks to limitations of the radios on (old) client devices. A particular issue we discovered at one point was that many NDT tests on higher speed links were being performed from old iPhones whose radios did not support speeds of greater than 100 Mbps. In short, the NDT test was measuring the radio of the mobile device, not the ISP. See our CACM paper for more discussion on that. https://dl.acm.org/doi/pdf/10.1145/3372135\n\n3. I am not sure it is accurate to say that NDT answers the question of “how well is you pipe transferring data”. A more precise statement would be that it measures the transfer rate across a single transport connection—at one point a fairly outmoded version of TCP, and now a single BBR stream.  And so it might represent how well the connection transfers data across that transport, but it’s also worth pointing out that no modern application that seeks to maximize capacity relies on a single transport connection—everything from browsers to streaming clients on smart TVs use multiple parallel connections (some do so in rather extreme fashion, but that’s another topic).\n\n4. Off-net measurements have their own caveats. One notable one—which came to light in none other than an M-Lab report!—was that as a result of an end-to-end path to an off-net server that crossed Cogent, the report mis-diagnosed the location of congestion (and its resolution).  Cogent’s CEO also acknowledged this particular issue (read my FCC filing on the issue for more about that: https://www.fcc.gov/ecfs/file/download/DOC-578d040705800000-A.pdf).\n\n5. To the point about the Google search “one box”—characterizing the loss of NDT measurements as a “great loss to the research community” presumes that “more data is better” and “open data is better""—independent of the *quality* of those measurements.  But, I’d argue we need to rethink that. As Jim and Jason have both pointed out, the data has been actively misused and mischaracterized over many years—and this continues to happen. Part of the reason I believe this to be the case is the reason Lai Yi mentions: there are “so few alternatives”.  It’s time to change that because regardless of the facts, people will take the path of least resistance. Casting it in the most charitable light—while some stakeholders may be willfully misrepresenting the data, I suspect others simply don’t have the time or interest in understanding the nuance that this group is familiar with. Taking shortcuts like that is sloppy and unscientific—something that has bothered me for quite some time—but I think some groups have gotten away with it because there’s little denying that there *are* gaps in infrastructure, connectivity, etc.—nevermind that the data itself doesn’t actually tell you much about the specific nature of any particular problem, people are happy to talk in broad strokes and handwave if the data conveniently speaks to an agenda. But now, as we think about actually *solving* problems, this becomes a more serious problem—the existing tools and methods—measurement techniques, data, sampling approaches—do very little in helping anyone actually work towards fixing these problems.  I believe that’s where we should be turning our focus in the next 5-10 years.\n\ue5d3', 'rjmcmahon': 'A few thoughts from somebody testing WiFi chips for over a decade now\nand someone maintaining iperf 2.\n\nOn Latency: is not the same as RTT or ping. We\'ve added one-way delay in\niperf 2. It does require synchronized clocks. We measure packet times,\nwrite to read times, et.. GPS atomic time is quite accurate.\n\nOn actionable engineering: For sure end/end is interesting but defining\nkey telemetry on the sub-graphs seems required. Interesting nodes are\nthings like wired to wireless and last-mile *peering points* to end-user\ndevice. It seems like ""on-net"" should include servers at the peering\npoints used by the major content providers vs optimizing the last mile\nonly. A flight to a major hub for an airline matters more than a\nsouthwest flight between Austin and Dallas. These hubs are critical to\nflight times (and to flight delays.)\n\nThe measurement institution(s) have to be at arms length.\n\nBob\n\ue5d3\n>> community guidelines [1]. Take care all.\n\ue5d3\n>> In short, NDT does not answer the question “how big is yourA few\n>> notes.\n\nOn LLatency is not the same as RTT or ping. We\'ve added one way delay in\niperf 2. It does require synchronized clocks.\n\n>> pipe” but rather “how well is your pipe transferring data.” We\n>> consider both metrics to be important for understanding\n>> connectivity. For more reading, you can reference How fast is my\n>> Internet? Speed Tests, Accuracy, NDT & M-Lab [2] which digs more\n>> into the definition of “speed” and NDT Data in NTIA Indicators\n>> of Broadband Need [3], which though focuses on the US federal\n\ue5d3\n>> [4].\n>>\n>> --\n>>\n>> Lai Yi Ohlsen\n>>\n>> Director, Measurement Lab [5]\n>> Code for Science & Society [6]\n>>\n>> --\n>> You received this message because you are subscribed to the Google\n>> Groups ""discuss"" group.\n>> To unsubscribe from this group and stop receiving emails from it,\n>> send an email to discuss+u...@measurementlab.net.\n>\n>> To view this discussion on the web visitA few notes.\n\nOn LLatency is not the same as RTT or ping. We\'ve added one way delay in\niperf 2. It does require synchronized clocks.\n\n>>\n> https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcMg5JOuFWy4Fd6G4CKnE3CQN0m0nWXCbCGoZg_S1vcuxw%40mail.gmail.com\n>> [7].\n>\n> --\n>\n> Lai Yi OhlsenA few notes.\n\nOn LLatency is not the same as RTT or ping. We\'ve added one way delay in\niperf 2. It does require synchronized clocks.\n\n>\n> Director, Measurement Lab [5]\n> Code for Science & Society [6]\n>\n> --\n> You received this message because you are subscribed to the Google\n> Groups ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it, send\n> an email to discuss+u...@measurementlab.net.\n> To view this discussion on the web visit\n> https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAK0jp%2B-rE_c6oPASz4D5gdBBaac-WP71eXgD_D_k_CuTHeqRpA%40mail.gmail.com\n> [8].\n>\n>\n> Links:\n> ------\n> [1] https://www.measurementlab.net/community-guidelines/\n> [2]\n> https://www.measurementlab.net/blog/speed-tests-accuracy/#how-fast-is-my-internet?-speed-tests,-accuracy,-ndt-&amp;-m-lab\n> [3]\n> https://www.measurementlab.net/blog/ntia/#ndt-data-in-ntia-indicators-of-broadband-need\n> [4]\n> https://groups.google.com/a/measurementlab.net/d/msgid/discuss/a609ce0e-7be6-4b4e-a231-227d7cd4106bn%40measurementlab.net?utm_medium=email&amp;utm_source=footer\n> [5] http://www.measurementlab.net\n> [6] https://codeforscience.org/\n> [7]\n> https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcMg5JOuFWy4Fd6G4CKnE3CQN0m0nWXCbCGoZg_S1vcuxw%40mail.gmail.com?utm_medium=email&amp;utm_source=footer\n> [8]\n> https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAK0jp%2B-rE_c6oPASz4D5gdBBaac-WP71eXgD_D_k_CuTHeqRpA%40mail.gmail.com?utm_medium=email&utm_source=footer', 'Dave Taht': 'Ironically, one of my big pushes to get into the NTIA $70B broadband\nbuildout is better, , more secure, constantly upgraded, and more\nstandards compliant, home routers and CPE, and to find ways to\nregulate better reliability into them in the first place.\n\nCeroWrt\'s routers had uptimes measured in *years*. So my suggestion\nwould be to get a better router. I\'m big on reflashing older ones to\nopenwrt, and installing ""smart queue managemen"" (SQM), which will\nchange the characteristics of your NDT results for the better, but the\nkind of the results you get now may well be a reflection of the kind\nof bugs in your router than millions share.\nTurris and evenroute are also pretty good.\n\ue5d3\n> To view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAK0jp%2B-rE_c6oPASz4D5gdBBaac-WP71eXgD_D_k_CuTHeqRpA%40mail.gmail.com.\n\n\n\n--\nI tried to build a better future, a few times:\nhttps://wayforward.archive.org/?site=https%3A%2F%2Fwww.icei.org\n\nDave Täht CEO, TekLibre, LLC'}"
2,88010683186914105338533645964615171769,ndt7-issue-on-raspberry-pi-/-ubuntu,"May 21, 2021, 10:01:55 AM",Guilherme Martins,"Dear,

we found this strange behavior running ndt7-client-go on ubuntu 20.04 raspberry pi 4. The speed seems to be limited at ~150Mbps (dw) even running on connections capable of >300Mbps.  The problem does not occur with Ookla's speedtest on the same device and it does not occur with Ndt7 running on Jetson Nano at all. Please let us know if there's anything we can do to help investigate this one.
A full log of executions can be found here: https://github.com/m-lab/ndt7-client-go/issues/59.

Thank you,

Guilherme Martins","{'Simone Basso': '\ue5d3\n\ue5d3\nThanks for the heads up, I\'ve replied directly on GitHub.\n\nThanks,\n\nSimone\n Thank you,\n\nGuilherme Martins\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/f9703f5d-385f-4d96-8ffb-587bca635594n%40measurementlab.net.'}"
3,26208003393858456277374790833538497680,understanding-of-overview-of-the-test-and-statements.,"Mar 2, 2021, 6:39:47 AM",Vijay Ahire,"Hi 
i want to understand if subscriber in United states subscribe for a broadband plan of 100Mbps and he is trying to do speedtest using servers located in INDIA.

so will he get the 100Mbps speed ??
according to Mlab they trying to do tests on OFFnets, how can i check on which country or location they trying to perform tests ?
i did not find any conclusive information like which servers or ip address being used to perform tests on .
Regards
Vijay A","{'margaret agbo': 'Hello Vijay\nSure of course. I got the extension here or here  Mlab. There are other choices too to suit your need.\n\nEnjoy!!\n\n\n\n\n\nIZZYLYF\n\n\n\nOn Fri, 5 Mar 2021 at 06:21, Vijay Ahire <vi...@my7star.com> wrote:\nHi Chris,\nThank you for your response.\n\nDo you support hosting speedtest servers in internet exchange point in country or ISP datacenter.\n\nAlso I would like to know how can I have access to test data.\n\nRegards\nVijay A.\n\ue5d3', 'Vijay Ahire': 'Hi Chris,\nThank you for your response.\n\nDo you support hosting speedtest servers in internet exchange point in country or ISP datacenter.\n\nAlso I would like to know how can I have access to test data.\n\nRegards\nVijay A.\n\n\nOn Thu, Mar 4, 2021, 19:18 Chris Ritzo <cri...@measurementlab.net> wrote:\n\ue5d3', 'Chris Ritzo': 'Hi Vijay,\nYou can find a map of our servers, and more information about them here: https://www.measurementlab.net/status/\nSome of our servers are hosted in Internet Exchanges or Research and Education networks, but most are in commercial datacenters where ISPs peer. Each set of servers at each location has the requirements listed on our Contribute page.\nTo access the data produced by M-Lab tests, you can learn more about all the datasets we host on the Data Overview page, and to access our public datasets, please review and follow our BigQuery Quickstart guide.\n\nBest,\nChris\n\ue5d3'}"
4,242662832491130831213793381832462850468,rsvp-for-nov-dec-m-lab-community-calls,"Oct 26, 2020, 2:29:59 PM",Lai Yi Ohlsen,"Hi all, 

I hope you're all doing the 2020 version of well :) I am writing to invite you to Measurement Lab's upcoming Community Calls. Similar to what we did in May, we'll hold 3 different calls throughout November/December, each one focused on a different level of expertise and area of focus. 

Please RSVP HERE to receive information about the call(s). 

Wednesday, Nov 18 11am-12pm EST - M-Lab Community Call
Updates and discussion related to the use of M-Lab's platform, data, and community tools.

Wednesday, Dec 2 11am-12pm EST - Internet Measurement Research
Deep dives into topics related to Internet measurement methodology. Technical expertise encouraged but not required.

Wednesday, Dec 9 11am-12pm EST - Broadband Policy/Advocacy
Discussion and presentations related to the use of M-Lab data in digital inclusion and broadband research. Policy/advocacy expertise welcome but not required. 

If you've been following along with our blog, you'll know that we've been quite busy and have a lot to discuss, but if you can't make it, no worries. Throughout 2021 we'll start hosting each call in a regular rotation, so there will be plenty of times to chat.  

Again, please RSVP HERE to receive information for the call(s). Feel free to respond directly or to sup...@measurementlab.net with any questions. 

--
Lai Yi Ohlsen
Project Director, Measurement Lab
www.measurementlab.net","{'Lai Yi Ohlsen': ""Hi all,\n\nThanks to those of you who joined our Broadband Advocacy/Policy call on 12/9. Here is a summary of the call: \n\nDefined broadband measurement terms:\nBandwidth and latency, on-net and off-net, interconnect, access link capacity, end to end path capacity, single stream and multi-stream, and bulk transport capacity are all useful terms for you to know and use in your broadband advocacy/policy work. \nThey are specifically useful when looking at the different broadband data sources that are often referenced, including M-Lab’s NDT data, 3rd party client integrations of M-Lab’s, Form 477 data and Ookla’s Speedtest.\nTalking points from these definitions and comparisons are in the slides. \nWe plan to follow up with a blog post for reference to document in more detail but please feel free  to reach out if you have any questions or would like to cite these definitions elsewhere. \nFactoring Data Influences\nThere are many influences on Internet measurement data including the platform and the endpoint environment. Our recommendations for factoring them in your analysis include: \nAcknowledging that a number of things can cause the data to swing 10-30% in any direction. The data changing, by say, 90% is likely a real change. But considering context when deciding upon a threshold is important, and so we recommend not having a hard threshold, and if you do, we recommend it not be below 30%. \nWe strongly recommend distributions e.g. bucketing data into 1,2,5,10,20,50,100 Mbps buckets and looking at the fraction of tests in each bucket. \nThe best choice is always to compare the data to itself. Examples of this include:\nCompare competing ISPs in the same region\nCompare an ISP's performance to its performance last year\nWhen you do this, you are much more likely to be comparing apples to apples. \nCommon Analysis Pitfalls and Recommendations\nWe also reviewed a number of common analysis pitfalls we’ve started to recognize in the past few years including: \nExcluding invalid data e.g. monitoring data, errored tests\nFailing to compensate for client bias\nM-Lab NDT data is a mix of infrequent manually triggered tests and beacons that test frequently. Without de-biasing, beacons often dominate the stats.\nDividing data too finely; segmenting until there are too few samples in a segment to be meaningful e.g. rural zip-codes and census tracts may have only 1 or 2 tests per month.\nOversimplifying e.g. using medians (or averages) to summarize multi-modal data. \nWe recommend avoiding linear scales and linear averages.\nWe recommend digging deeper into multimodal distributions by examining the influence of ASNumber, of socio-economic and rural/urban influences, and exclude tests to very distant servers. \nOur team’s understanding of our data is always evolving alongside the community’s; we invite you to share your insights as we share ours.\n\nThe slides from the meeting can be found here. Standard reminder that the slides and the summary are artifacts of a larger conversation. If you have questions about how the information was meant to be understood or would like to cite it elsewhere, please feel free to reach out. \n\nThanks to all who have joined us for the last round of community calls. Please look out for our 2021 schedule, coming soon. If we don't speak before, have a safe and happy holiday and we look forward to working with you next year. \n\ue5d3"", 'Romain Fontugne': 'Hi Lai,\n\nThanks for the response. I will play with the current aggregates and report here if I find any problems.\n\nRomain\n\ue5d3', 'rjmcmahon': 'Hi All,\n\nI\'m not sure if this is helpful but we\'re releasing iperf 2.0.14. We\nhave found that\nmeasuring RTT isn\'t really enough. We\'ve added end/end write to read\nlatencies\nfor both TCP writes and isochronous (video traffic) as useful. It does\nrequire clock sync. man page is here\n\nhttps://iperf2.sourceforge.io/iperf-manpage.html\n\nAlso, we\'ve been clustering are latency distributions, which are\nnon-parametric, using\nthe kolmogorov smirnov distances (and distance matrices)\n\nhttps://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test\nhttps://www.statisticshowto.com/parametric-and-non-parametric-data/\n\nThen mostly monitoring the tails of the latendy PDFs/CDFs as latency\nmeans\naren\'t very useful, rather the tail is driving customer experience.\n\nAn advert: If you volunteer to test with iperf 2.0.14 then will give you\na shirt.\n\nBob\n\n> Hi all,\n> Thanks to those of you who joined today. Here is a summary of the\n> topics we covered:\n> Collaboration\n>\n> *\n>\n> Through 2021 and beyond, M-Lab would like to pursue more collaboration\n> with the Internet Research community. We invite the insight of others\n> to point our blindspots and help us find solutions to our unique\n> challenges. Towards this end, look out for the 2021 Community Call\n> schedule coming soon.\n>\n> Data\n>\n> *\n>\n> Multi-track views are available, which allow for the separation of\n> your research question from data selection and grooming. You can see\n> example queries in the slides. A blog post is coming soon.\n> *\n>\n> We have many data types available other than NDT: pcap, tcpinfo,\n> switch, traceroute, data-annotations.\n>\n> Open Research Questions\n>\n> There are many influences on Internet measurement data including the\n> platform and the endpoint environment. We invite the insight and\n> expertise of the Internet Research community as we consider how each\n> of the following research questions are affected by one or more of\n> these factors.\n>\n> *\n>\n> Platform Engineering: The effect of the design decisions made within\n> Locate API, Geo Annotations and Switch Discards are currently tracked\n> but unquantified and open for exploration.\n> *\n>\n> IP Anonymization: IP Anonymization in radically open data is a\n> “wicked” problem. Test users want it, researchers don\'t, and\n> regardless, the world is moving towards it. We are currently\n> considering our options for how to preserve user privacy, remain open\n> and maintain data validity. We imagine using client pseudonyms, issued\n> by the locate service but are still in the design process.\n> *\n>\n> Analysis Pitfalls: We have started to observe some common Analysis\n> Pitfalls including: failing to compensate for client bias, dividing\n> data too finely, and using medians (or averages) to summarize\n> multi-modal data. We welcome community researchers\' insight as other\n> pitfalls are discovered.\n> *\n>\n> Test Labeling: At least two factors significantly complicate data\n> analysis and interpretation: Client bias, and in-home bottlenecks,\n> (or poor cellular SNR). We are considering approaches for labeling\n> tests that appear to demonstrate these characteristics.\n> *\n>\n> ndt7 Early Exit: We are pursuing an implementation of ndt7 that uses\n> BBR to decide when to stop a download measurement. The goal is to do\n> so without degrading measurement quality.\n>\n> The slides from the meeting can be found here [2]. They include some\n> useful information, though were meant to be shared through the context\n> of the presentation. If you have questions about how it was meant to\n> be understood, please feel free to reach out.\n>\n> Have a great week!\n>\n> On Tue, Dec 1, 2020 at 1:52 PM Lai Yi Ohlsen\n> <la...@measurementlab.net> wrote:\n>\n>> Hi everyone,\n>>\n>> Writing to remind you of the Internet Research Community Call\n>> happening this Wednesday (tomorrow), December 2 at 11:00a Eastern.\n>>\n>> If you have already RSVP\'d, you should have received a calendar\n>> invite with the call information. If you have not received the\n>> calendar invite, please let me know directly.\n>> If you have not RSVP\'d and you would like to, you can still do so\n>> here [1] and we\'ll send you the call info asap.\n>>\n>> The agenda and slides for our call can be found in the calendar\n>> invite and here [2]. Topics will include:\n\ue5d3\n>> here [3] and we\'ll send you the call info asap.\n>>\n>> The agenda and slides for our call can be found in the calendar\n>> invite and here [2]. Topics will include items of interest to:\n>> - Developers who have integrated NDT into their application\n>> - Anyone analyzing NDT data across August 2020 (see our blog posts\n>> [4] on NDT\'s evolution for background information)\n>> - Researchers and developers interested in ingesting M-Lab data into\n>> their application using an API\n>>\n>> We will also be giving a roadmap update and discussing our plans for\n>> the next 6 months, as shared in this blog post [5]. Topics related\n>> to Internet Research and Broadband Advocacy/Policy will be discussed\n>> on December 2 and 9, respectively.\n>>\n>> As always, feel free to reach out with questions or comments.\n>> Looking forward to connecting!\n>>\n>> On Mon, Oct 26, 2020 at 5:29 PM Lai Yi Ohlsen\n>> <la...@measurementlab.net> wrote:\n>>\n>> Hi all,\n>>\n>> I hope you\'re all doing the 2020 version of well :) I am writing to\n>> invite you to Measurement Lab\'s upcoming Community Calls. Similar to\n>> what we did in May, we\'ll hold 3 different calls throughout\n>> November/December, each one focused on a different level of\n>> expertise and area of focus.\n>>\n>> PLEASE RSVP HERE [1] TO RECEIVE INFORMATION ABOUT THE CALL(S).\n>>\n>> Wednesday, Nov 18 11am-12pm EST - M-LAB COMMUNITY CALL\n>> Updates and discussion related to the use of M-Lab\'s platform, data,\n>> and community tools.\n>>\n>> Wednesday, Dec 2 11am-12pm EST - INTERNET MEASUREMENT RESEARCH\n>> Deep dives into topics related to Internet measurement methodology.\n>> Technical expertise encouraged but not required.\n>>\n>> Wednesday, Dec 9 11am-12pm EST - BROADBAND POLICY/ADVOCACY\n>> Discussion and presentations related to the use of M-Lab data in\n>> digital inclusion and broadband research. Policy/advocacy expertise\n>> welcome but not required.\n>>\n>> If you\'ve been following along with our blog, you\'ll know that we\'ve\n>> been quite busy and have a lot to discuss, but if you can\'t make it,\n>> no worries. Throughout 2021 we\'ll start hosting each call in a\n>> regular rotation, so there will be plenty of times to chat.\n>>\n>> AGAIN, PLEASE RSVP HERE [1] TO RECEIVE INFORMATION FOR THE CALL(S).\n>> Feel free to respond directly or to sup...@measurementlab.net with\n>> any questions.\n>>\n>> --\n>>\n>> LAI YI OHLSEN\n>> Project Director, Measurement Lab\n>> www.measurementlab.net [6]\n>>\n>> --\n>>\n>> LAI YI OHLSEN\n>> Project Director, Measurement Lab\n>> www.measurementlab.net [6]\n>\n> --\n>\n> LAI YI OHLSEN\n> Project Director, Measurement Lab\n> www.measurementlab.net [6]\n>\n> --\n>\n> LAI YI OHLSEN\n> Project Director, Measurement Lab\n> www.measurementlab.net [6]\n>\n> --\n> You received this message because you are subscribed to the Google\n> Groups ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it, send\n> an email to discuss+u...@measurementlab.net.\n> To view this discussion on the web visit\n> https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcM0g9OyLD3%3DdGUbXxTLag-U3myiMdro_bzrM%2BnSGq%3DLXQ%40mail.gmail.com\n> [7].\n>\n>\n> Links:\n> ------\n> [1]\n> https://docs.google.com/forms/d/e/1FAIpQLSfjMN4f_QHPEH6-2oPutKCDCyXeh-iHyfb8LBhO0Jv9K0H82A/viewform?usp=sf_link\n> [2] https://bit.ly/3kzQsJd\n> [3] https://forms.gle/a385i1vMFd9mAiPr8\n> [4] https://www.measurementlab.net/blog/category/ndt7/\n> [5]\n> https://www.measurementlab.net/blog/roadmap-update/#m-lab-roadmap-update---q4-2020\n> [6] http://www.measurementlab.net\n> [7]\n> https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcM0g9OyLD3%3DdGUbXxTLag-U3myiMdro_bzrM%2BnSGq%3DLXQ%40mail.gmail.com?utm_medium=email&utm_source=footer'}"
5,48609822809568570454847756389337132428,this-data-is-not-even-close-to-being-accurate,"Nov 16, 2020, 9:06:39 AM",Bruce Kushnick,"#2. Jersey
Jersey is the first juris diction in the world to make pure fibre (FTTP) available to every broadband user. Jersey's shift from third to second shows that uptake has been healthy -- https://kushnickbruce.medium.com/americas-digital-divide-made-easy-7-states-7-maps-7-broadband-failures-a73c0e68c362  
These are maps of 7 US states, the one on the top left with the squiggly lines is New Jersey-- it is less than 50% covered -- and the rest is COPPER-based -- the speeds your giving out are not surveys of New Jersey but a subset and they aren't close when you realize that the other areas could be getting DSL speeds of less than 15mbps. or dial up speeds, or wireless at 10mbps down 1 up.  And this goes for every state listed. Verizon New Jersey never completed the fiber build outs. -I Included some details and links in the article. The problem is -- policies are being created based on your data-- which is wildly overstating the speeds and coverage. --These caveats should be right up front. 
In fact, all of the speed tests are quoted and all of them are skewing public policies in the US -- making it appear that the telcos are doing a good job... when, as you can see from the maps, they let the entire state utilities deteriorate as the copper should have been replaced starting in the 1990s-- as we documented. ","{'Livingood, Jason': 'FWIW I get a 404 error trying to access that URL, Bruce.\n  Related to mapping and M-Lab data, this recent Ookla blog post and paper will interest folks here:\nBlog @ https://www.speedtest.net/insights/blog/better-funding-decisions-accurate-broadband-network-data/\nPaper @ https://resources.ookla.com/hubfs/Ookla%20-%20Make%20Better%20Funding%20Decisions%20with%20Accurate%20Broadband%20Network%20Data.pdf\n  Regards\nJason\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/7ef2c7d5-36d0-428d-8d52-649d8bf090efn%40measurementlab.net.'}"
6,215429662908874906111233032823999715768,mlab-speed-test-is-incorrect?,"Jan 26, 2017, 9:17:17 AM",David Radin,"I'm on my office network, which is not heavily utilized and has a 75/75 fiber connection to the internet. On speedtest.net or dslreports.com speed test, I get results that are in the neighborhood of 70/65, which is what I'd expect when an office of 40ish people are using the internet.

MLab's test consistently shows speeds in the 12/6 range. Why would its results be so much slower?","{'Ron Dallmeier': 'From the FAQ:\n\nWhy are my M-Lab results different from other speed tests?\nInternet performance tests may provide different results for a lot of reasons. Three of the main reasons for different results among tests are listed below:\n1. Differences in the location of testing servers\nEvery performance test has two parts:\nclient: This is the software that runs on the user’s machine and shows the user their speed results.\nserver: This is the computer on the Internet to which the client connects to complete the test.\nA test generates data between the client and the server, and measures performance between these two points. The location of these two points is important in terms of understanding the results of a given test.\nIf the server is located within your Internet Service Provider’s (ISP’s) own network (also known as the “last mile”), this is referred to as an “on-net” measurement. This approach lets you know about how your Internet connection is performing intra-network within your ISP, but it does not necessarily reflect the full experience of using the Internet, which almost always involves using inter-network connections (connections between networks) to access content and services that are hosted somewhere outside of your ISP. Results from on-net testing are often higher than those achieved by using other methods, since the “distance” traveled is generally shorter, and the network is entirely controlled by one provider (your ISP).\n“Off-net” measurements occur between your computer and a server located outside of your ISP’s network. This means that traffic crosses inter-network borders and often travels longer distances. Off-net testing frequently produces results that are lower than those produced from on-net testing.\nM-Lab’s measurements are always conducted off-net. This way, M-Lab is able to measure performance from testers’ computers to locations where popular Internet content is often hosted. By having inter-network connections included in the test, test users get a real sense of the performance they could expect when using the Internet.\n2. Differences in testing methods\nDifferent Internet performance tests measure different things in different ways. M-Lab’s NDT test tries to transfer as much data as it can in ten seconds (both up and down), using a single connection to an M-Lab server. Other popular tests try to transfer as much data as possible at once across multiple connections to their server. Neither method is “right” or “wrong,” but using a single stream is more likely to help diagnose problems in the network than multiple streams would. Learn more about M-Lab’s NDT methodology.\nI would suggest a couple of things. When you run the m-lab test, note which server it is running the test against. It shows you as the test is running. It would be something like: NDT.IUPUI.MLAB1.ORD02.MEASUREMENT-LAB.ORG\n\nORD is the airport code for Chicago O\'Hare in this example. It is certainly important to note, which server it used.\n\nAnother suggestion would be to select the ""Details"" from the results page. In here you will get a summary of the test results. This can shed some light as to whether the test observed any potential causes for bad results. Two big factors for TCP based throughput are Packet Loss and Latency. Here is an example:\nYour system: -\nPlugin version: - (-)\n\nTCP receive window: 893408 current, 894848 maximum\n0.00 % of packets lost during test\nRound trip time: 21 msec (minimum), 68 msec (maximum), 33 msec (average)\nJitter: -\n0.00 seconds spend waiting following a timeout\nTCP time-out counter: 232\n473 selective acknowledgement packets received\n\nNo duplex mismatch condition was detected.\nThe test did not detect a cable fault.\nNo network congestion was detected.\n\n0.9633 % of the time was not spent in a receiver limited or sender limited state.\n0.0000 % of the time the connection is limited by the client machine\'s receive buffer.\nOptimal receive buffer: - bytes\nBottleneck link: -\n469 duplicate ACKs set\n...Ron\n\n\n\ue5d3', 'Kim Prince': ""It seems to me that the usual speed testing sites are well suited to testing the user's 'last mile', and perhaps other 'reasonably local' elements of their connection.  By contrast, the M-Lab tests are designed to help the user understand their overall internet performance, i.e. what performance they can expect when downloading/uploading to a 'representative' location on the internet.\n\nBy testing with the usual sites, you can confirm that your ISP is living up to their promised connection speed.  To understand how well that ISP is 'interconnected' to the rest of the web however, you need to consider the M-Lab results.\n\nI picked this up from reading the M-Lab page at http://www.measurementlab.net/observatory/#tab=help&, particularly under the heading 'The Internet'.  Am I on the right track?\n\n\n\ue5d3"", '☕Peter Boothe': 'The intent of the Measurement Lab speed test is to test your Internet speed from your location to places where content lives. This is why Measurement Lab test servers are hosted in data centers that also contain major content providers.  On the other hand, as Kim Prince mentioned, many other speed tests attempt to measure only your last-mile performance, and as such are frequently hosted within the ISP they are testing.\n\nUnless you are getting geographically mis-routed to a cluster that is unreasonably far away from you (possible, but hopefully unlikely) then it sounds like you are connected at high speeds to your local ISP, but your connection through that ISP to content on the Internet may not be as good due to latency (more likely) or congestion along the path (less likely, but also possible)*.\n\n* - There are of course more than two opportunities, and network people are often pedantic, so let me note here that there are other things that could cause the slowdown. But latency and congestion are the two most likely culprits.\n\n  -Peter\n\ue5d3\nᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.', 'David Radin': 'ML measures the ""real world"" throughput, where peering connections between ISPs can become a bottleneck.\n\nDSLReports and Ookla tend to measure the ""last mile"" throughput of the connection between customer premises and the ISP\'s headend.\n\nBoth are valid approaches. It just depends what you\'re trying to determine.\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to a topic in the Google Groups ""discuss"" group.\nTo unsubscribe from this topic, visit https://groups.google.com/a/measurementlab.net/d/topic/discuss/vOTs3rcbp38/unsubscribe.\nTo unsubscribe from this group and all its topics, send an email to discuss+unsubscribe@measurementlab.net.\n\ue5d3', 'ma...@hoppes.us': 'Running a second test I got 3megabits the first time and 60 the second to Washington D.C.  Explain please?', 'Collin Anderson': 'Hello Discuss List,\n\nMy apologies for not following up on this thread publicly. We had received a couple of similar emails at the same time to our support address and replied directly rather than publicly. However, since this is a public list I wanted to provide a bit more clarity in a way that I hope may be broadly useful, rather than address one particular network. \n\nWhile there are a number of speed tests that are available, they all have differences related to measurement methods and server placement that lead to divergent numbers. There are a number of papers out there that attempt to account for these differences, and we have tried to surface some of those themes in the FAQ in a manner that is comprehendible to the lay reader. M-Lab has always taken the position that \'more is better,\' even where M-Lab isn\'t used, and that the critical factor is understanding why those differences exist and how they tell different stories about accessibility and performance.\n\nOn occasion we receive inquiries from Internet service providers, typically small-to-medium networks that are interested in why their numbers are different from other tests. What we often find is that the issue is related to peering and topology between those providers and the networks that we are located in. M-Lab chooses prominent transit and content providers as neutral places for our sites that should reflect user experience – the names well known among this community, and not arcane locations. It\'s difficult to remotely diagnose particular networks from the other side, however, we generally find that in those cases where there are lower-than-expected numbers, some intermediary provider is experiencing degraded conditions, e.g. packet loss and higher latency. In one of the recent cases, we found that there were two or three networks between us and the provider, and there appeared to be substantial loss on that ISP\'s upstream – neither a failure with M-Lab nor within their network, but a real issue facing users. \n\nIn the past three years, we have expanded our presence in each market to include multiple sites, covering different providers for each location. This was meant to be a diagnostic resource for the community. I realize that the ""Washington, D.C."" label in some of the integrations of NDT is not so descriptive of these variables in a way that would better enable accounting of differences for those who know – especially when for each refresh of the page, D.C. might mean Level 3, Tata, X.O, etc. As I understand some other tests select servers based on latency, whereas most integrations of M-Lab and NDT randomly select a server within the same geographic location. Sometimes this sole difference is the most significant factor in the result, but both tests are correct within their context. This topology and selection factor seems like a more prevalent matter for smaller ISPs that are reliant on one or two networks for transit – in those cases, one directly-connected network will perform well, whereas others where there are additional intermediaries in the path do not perform as expected. \n\nSo, rather than platform issues, we tend to find those differences result from the more common infrastructure challenges that all operators contend with, which does have the impact on consumers reflected in the measurement. When questions arise, we encourage networks to check their peering between them and our sites in BGP, run traceroutes (check reverse traceroutes in M-Lab\'s BigQuery dataset), and conduct comparative tests across all sites in the region to see how they perform differently. \n\nWe have long meant to expose more technical information about our platform for those who are interested in metadata and documentation. As we update our documentation, we will aim to also have a ""FAQs for Operators"" that more clearly lays out how methodological and topological difference lead to different-than-expected results, and how to use M-Lab as a diagnostic resource. In the interim, we take such questions quite seriously and try to provide support to operators where we can. \n\nPlease feel free to reach out directly to me and our support address (support@) in the future. \n\nCordially,\nCollin Anderson', 'dominic...@yarris.com': ""I'm getting unexpected results from the test. My upload speed is twice that of my download speed.\nI don't believe that is correct.\n\n\ue5d3"", 'xgma...@gmail.com': ""All of that is assuming the ISP has a gigabit capable network in the area which ours does not. I was told specifically that ours runs on three channels. I have the same ISP at home with the same modem and I get exactly the same results at almost exactly 1/3rd of my capacity. I'm just trying to offer this as an explanation for the results the other user posted. I have seen the exact same thing and found an explanation for it. Also I wouldn't focus on speed and latency out on the web as much as I would good house keeping on my own router. I've found the most impact I've had on my networks with all my testing and tweaking has been to get my buffer-bloat under control which has made noticeable differences in our speeds and reduces connection timeouts to nearly non-existent. My point is Measurement Labs played no part in our improvements other than to throw us off and confuse us making us think there were issues when according to EVERY other speed/network check, we were right on the money. I measure RESULTS, not fanboyism for an outdated service. Thousandeyes helped me verify the bull%$@ that is ML. \n\ue5d3"", 'Livingood, Jason': 'On 1/18/18, 10:59 AM, ""xgma...@gmail.com"" <xgma...@gmail.com> wrote:\n  > Modern modems are run with multiple channels now. You\'re one internet connection can be a 2 or 3 separate connections or data channels tied together in a bundle to give you speeds faster than the technology alone. An example of this is WOW\'s Docsis modems. With a Docsis 2 modem you have 2 channels and speeds up to 60mbps. Docsis 3 modem 3 channels are now used and speeds can be upwards of 100mbps. \n  [JL] FWIW, according to a 2016 Arris report (https://www.arris.com/globalassets/resources/white-papers/scte-future-directions-for-fiber-deep-hfc-deployments.pdf) in the near future most DOCSIS 3.0 networks will move to 32 bonded 3.0 channels and 4 DOCSIS 3.1 OFDM channels. This enables 1 Gbps services, which Comcast and other ISP networks are providing over DOCSIS networks (obviously also over fiber, and there are many other fiber-based ISPs). I don’t think there are many measurement tools that can adequately measure those speeds at scale (such as the scale at which Ookla operates).\n  > Measurement Labs does not support this technology which I think is a crock because all the major ISPs have shifted to this methodology for high-speed connections. I have stopped using their testing platform because it only runs on one channel and only effectively tests 1 third of my connection capabilities. I believe that Measurement Labs is an obsolete service and no longer offers valuable real-time information. This information is available on their own website if you read through their FAQ. If you\'re still using a 2-20mbps connection it may still be a valid test but in this day in age, it\'s just obsolete.\n  [JL] Steve Bauer from MIT has done some thinking about this. See his section on the M-Labs test in https://www.measurementlab.net/publications/understanding-broadband-speed-measurements.pdf (Section 4.2.5) and his presentation on testing in the gigabit era at https://www.caida.org/workshops/aims/1602/slides/aims1602_sbauer.pdf.\n\nOn Thursday, January 26, 2017 at 11:17:17 AM UTC-5, David Radin wrote:\nI\'m on my office network, which is not heavily utilized and has a 75/75 fiber connection to the internet. On speedtest.net or dslreports.com speed test, I get results that are in the neighborhood of 70/65, which is what I\'d expect when an office of 40ish people are using the internet.\n  MLab\'s test consistently shows speeds in the 12/6 range. Why would its results be so much slower?\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\ue5d3', 'Srikanth S': 'On Thu, Jan 18, 2018 at 11:15 AM, David Radin <david...@gmail.com> wrote:\nML measures the ""real world"" throughput, where peering connections between ISPs can become a bottleneck.\n\n\nThis is debatable, due to the ML infrastructure. We looked at interconnects between access ISPs and ML targets and access ISPs and Alexa 500 sites, and found there isn\'t much overlap. It\'s not a given that ML is measuring real-world throughput.\n\nSee 5.3 here: https://conferences.sigcomm.org/imc/2017/papers/imc17-final100.pdf\n ', 'Woundy, Richard': ""> An example of this is WOW's Docsis modems. With a Docsis 2 modem you have 2 channels and speeds up to 60mbps. Docsis 3 modem 3 channels are now used and speeds can be upwards of 100mbps.\n  For this thread, are we talking about performance testing over DOCSIS 2, or over DOCSIS 3?\n  DOCSIS 2 uses load balancing to distribute traffic among multiple channels, whereas DOCSIS 3 uses channel bonding.\n  As I understand, ML’s NDT performance test uses a single TCP connection. (Also confirmed in section 4.2.5.1 of the MIT paper cited below.)\n  DOCSIS 2 uses load balancing, so the NDT TCP connection packets will be transmitted over only one of the DOCSIS channels (to keep packets in order), and that channel may be more or less congested than other channels.\n  DOCSIS 3 is more likely to use channel bonding than load balancing, so the NDT TCP connection packets would be striped (ie inverse-multiplexed) across all available channels for transmission.\n  This is less of an issue for Speedtest/Ookla because that performance test uses multiple HTTP threads (aka parallel TCP connections), and they can be load balanced across multiple channels. (see section 4.2.2.1 of the MIT paper).\n\ue5d3"", 'Nick Feamster': '> On Jan 22, 2018, at 4:48 PM, Woundy, Richard <Richard...@comcast.com> wrote:\n>\n> This is less of an issue for Speedtest/Ookla because that performance test uses multiple HTTP threads (aka parallel TCP connections), and they can be load balanced across multiple channels. (see section 4.2.2.1 of the MIT paper).\n\nI’ll also add that the BISmark test has used multiple TCP threads since 2010, as well.\n\nEven with channel bonding, a single-threaded test would have trouble filling a link to capacity. We saw this in experiments that are detailed in our SIGCOMM 2011 paper.\n\nThe inability of a single-threaded TCP connection to fill the link to capacity seems (1) independent of the underlying physical medium (i.e., cable, DSL, fiber); (2) to be present even for access links _well_ below Gigabit speeds.\n\n-Nick', 'trump...@gmail.com': 'I just use 3 services for reliability http://www.speedtest.net/, https://speedof.me/ and http://internet-speed-test.online\n\nчетверг, 26 января 2017 г., 18:17:17 UTC+2 пользователь David Radin написал:\n\ue5d3', 'James Miller': 'The suite of tests run on Measuring Broadband America Program supported by Samknows are also multithreaded.  May be also worth noting that the number of threads are really import for understanding limits of TCP based tests but for UDP tests, for latency for example, the total number of datagrams exchanged has implications for accuracy and precision that can be attained by a given test.  \n\nA well documented, public methodology for tests is critical to understanding measurement results.  \n\n\n--\nJames Miller, Esq.\n\n""Japanese is so Eighties...""\nAnonymous FCC Colleague\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\ue5d3', 'Julian Johnston Jr.': 'I know this post  is old, but every time i use mlab, the measurement is too distant from what I have, just used the service, got 41mb from a 400mb speed but upload was correct, using other test I have seen 480mb, mlab has never been past 41mb.\n\n\nOn Thursday, January 26, 2017 at 11:17:17 AM UTC-5, David Radin wrote:\n\ue5d3', 'Chris Ritzo': 'There are multiple reasons why our test returns measurements that are slower than other tests. We outline a few of them in this FAQ article. You might also be interested in this blog post about speed tests, accuracy, and our primary performance measurement test, NDT.\n\nOne reason for the differences is that our servers are hosted outside last mile access networks, in data centers where networks ""peer"" or interconnect with one another. When providers are well peered, we see closer parity with other speed tests which often host servers at the edge of their last mile networks. The other major difference is that the architecture of our test itself differs from other tests. Our test is a single TCP stream test where others use multiple TCP streams. The use of multiple TCP streams emulates how web browsers typically operate when downloading resources you request from the Internet. Our NDT test\'s measurement using a single stream conforms more closely to accepted standards for performance measurement.\n\nI hope this provides some more context for the differences in measurements from our test versus others.\n\ue5d3'}"
7,194627361557327180725753357296088445232,best-way-to-keep-a-current-testing-environment?,"Feb 10, 2020, 9:06:15 AM",Glenn Fishbine,"A couple of years ago I downloaded a javascript library that you created that permits me to do the speed tests from my own server.

As new features come about, I realized that your current distributions are always better than mine, and you take into account location when assigning a server, which I do not.  Further it has a really sick headache with Safari.

The key difference between what you do by default and what I do, is I have the latitude and longitude of the actual location, and I don't mean HTML5 geolocation.

What I'd really like to do is run your most current test, and somehow get the jitter, ping, up and download speeds returned to my calling application so I can merge with my latitude longitude results.

Is there a browser independent way to call your test, let you do the testing, and somehow get a return value for jitter, ping, up and down?","{'Chris Ritzo': 'Hi Glenn,\nThanks for posting this question and apologies for the delayed reply.\n\nThere is a reference JavaScript client for the new ndt7 protocol which is in the final stages of development. You can track that work here: https://github.com/m-lab/ndt-server/issues/237\n\nThe current JavaScript client code that M-Lab maintains for the ndt5 protocol, I would recommend borrowing from this repository: https://github.com/m-lab/mlab-speedtest - specifically: https://github.com/m-lab/mlab-speedtest/tree/master/app/assets/js\n\nIf you are interested in a browser independent way of testing, I would recommend:\n- https://github.com/m-lab/ndt7-client-go\n- https://github.com/m-lab/ndt5-client-go\n\nI hope this helps in your work.\n\nBest, Chris\n\ue5d3', 'Glenn Fishbine': 'Thank you Chris.  I\'ll check them out. :-)\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/8a8786ba-8f13-4ca2-8809-c4d6081518ee%40measurementlab.net.'}"
8,4270869769117972945610700481851412326,what-exact-algorithm-is-being-used-when-running-a-test-on-https://speed.measurementlab.net/#/?,"Sep 19, 2019, 3:53:12 AM",Jakub Sławiński,"Hi,

what exact algorithm is being used when running a test on https://speed.measurementlab.net/#/? How to check that?

Is it possible that https://github.com/m-lab/ndt-server/issues/171 affects the download results? Sometimes (especially on the first run, when all the name resolution magic is being done) the speeds achieved are surprisingly small.


Regards,
  Jakub.

--
Jakub Sławiński
Chief Technical Officer
jslaw...@soldevelo.com / +48 514 780 384


SolDevelo Sp. z o.o. [LLC] / www.soldevelo.com
Al. Zwycięstwa 96/98, 81-451, Gdynia, Poland
Phone: +48 58 782 45 40 / Fax: +48 58 782 45 41","{'Chris Ritzo': 'Hello Jakub,\n\nThe code for the website https://speed.measurementlab.net can be reviewed in this repository: https://github.com/m-lab/mlab-speedtest\nThe test used is the Network Diagnostic Tool (NDT), using JavaScript. The test code within that repo can be found here: https://github.com/m-lab/mlab-speedtest/blob/master/app/services/mlabService.js\n\nRegarding the ndt-server issue you referenced, this refers to ongoing work on the new ndt-server, currently in global pilot on the M-Lab platform, in parallel to the web100 version of NDT server. The new server is running on 1/3 of our fleet for production testing and final QA before it is scheduled for launch later this year. \n\nIf you have seen issues with tests using servers that have been upgraded as part of the global pilot, please report them here or as issues in https://github.com/m-lab/ndt-server\n\nBest regards,\nChris - M-Lab Support\n\ue5d3', 'Peter Boothe ¶': 'It is worrying and strange to me that you would be getting slow speeds on speed.measurementlab.net\n\nIf you keep track of the server to which you are getting slow speeds (or happen to know your public-facing IP - both IPv4 and, if relevant, IPv6) then I can investigate further.\n\n  -Peter\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAFa%2B0sSRqwqS-omjWaRZvw9qP%3D_RRO07VSTUzQ%2BoQW%3Dbto2JTQ%40mail.gmail.com.\n\n\n--\nᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful, always with the goal of making the Internet better for the people who use it.', 'Jakub Sławiński': ""Hi Peter,\n\nsure, my public IP is 213.192.95.26.\n\nI tried the tests several times, but couldn't reproduce extremely small numbers (i.e. < 1 Mb/s, which I achieved earlier). Also I had in the past the situation that the tests freezes completely.\n\nIs there any way to enable debugging on the browser to see more info from NDT?\n\nWhen using m-lab, I achieved the download speeds in the range of 18.08 Mb/s - 41.30 Mb/s, which is quite comparable with the Ookla single thread download speeds: 18.68 Mb/s - 25.08Mb/s.\n\nRegarding the upload, the distribution when using m-lab is a little larger: 8.51 Mb/s - 74.79 Mb/s vs. 44.78 Mb/s - 70.71 Mb/s from Ookla.\n\nI tested the same path with both tools, i.e. from my computer to a server in Hamburg.\n\n\nRegards,\n  Jakub.\n\ue5d3""}"
9,152328470783889662570041730658036640785,fwd:-huge-inconsistency-between-google-speed-test-and-ndt7-client,"May 30, 2019, 4:36:32 AM",roger peppe,"Hi,

I've been seeing very low bandwidth from Google's ""speed test"" results. As they say they're partnering with M-Lab, I built the ndt7-client program (trivial - yay for Go!) and ran that to try to find out a bit more about what's happening.

ndt7-client program consistently reports about 60Mbps down, 17Mbps up. Google speed test was reporting 2.7Mbps down, 17Mbps up.

The Google speed test is using the ""Dublin"" server (193.1.12.203), and ndt7-client reports that it's using ndt-iupui-mlab4-dub01.measurement-lab.org. The ""dub01"" makes me think that it might be an a similar location; it's also using IPv4. My ISP is TalkTalk.

Sorry if this is inappropriate for this list, but I wondered if someone might have some useful input here, especially as these results might be being recorded and taken as somehow representative.

Thanks very much for any thoughts you might have,

   Roger Peppe.","{'Chris Ritzo': 'Hi Nick,\nI\'ll have to defer to Matt and others on the team with these questions, and happy to arrange a time with you to meet with the team on this as well. The team is QA testing now and we\'ve discussed comparisons with Speedtest and potentially others, but perhaps this is something to collaborate on with you? \n\nOn the BISmark data, I\'ll follow up with you on another thread. I think that the data is not yet in GCS with our other test data.\n\nBest,\nChris\n\ue5d3\n\ue5d3\n> >>> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n> >>> To post to this group, send email to dis...@measurementlab.net.\n> >>> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n> > --\n> > You received this message because you are subscribed to the Google Groups ""discuss"" group.\n> > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n> > To post to this group, send email to dis...@measurementlab.net.\n> > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n> >\n> >\n> > --\n> > You received this message because you are subscribed to the Google Groups ""discuss"" group.\n> > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n> > To post to this group, send email to dis...@measurementlab.net.\n> > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n>\n>\n> --\n> You received this message because you are subscribed to the Google Groups ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\ue5d3', 'roger peppe': 'Thanks very much for your swift reply. A bit more specific information in case it helps. I just ran ndt7-client, then ran a google speed test, then ran ndt7-client again. I\'ve attached the results of those two runs (min speed 57.4Mbps). In between the two runs, I got a google speed test result of 5.7Mbps down. After the second run, I ran google speed test again and got 12Mbps; then I just ran it again a moment ago and got 0.13Mbps.\n\nOut of curiosity, I just started a google speed test, and then started ndt7-client while that was in progress. The google speed test started at about 0.5Mbps and continued at that level, but the ndt7-client results were showing at least 27Mbps (running at the same time!).\n\nSo it seems that google speed test is wildly inconsistent betwen runs, which I guess might equate to some throttling somewhere in the network, or... I\'ve no idea :)\n\nYesterday, I was seeing very low speeds to other providers such as Amazon EC2 us-east-1 region too, but I\'m not sure how much I can trust the measurement tool I was using (https://cloudharmony.com/speedtest-for-aws).\n\nThe slow speeds did seem to correspond with low speeds to other sites (I was struggling to run a Zoom video call, and other pages seemed slow to load), but I can\'t say for sure if there\'s any causal relation there.\n\nI\'d be very interested to hear if there\'s anything more I can do to find out if there\'s a real issue here.\n\n  cheers,\n    rog.\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.', 'Livingood, Jason': ""> As I mentioned in my reply to Jason, NDT7 does address all of the concerns addressed in your and Jason's paper.\n  (as Nick said) Technically it may just address the issues with a single TCP stream, so performance relative to other web-based sorts of tests as well as native client tests. But all of those sorts of tests are still burdened with self-selection bias, low sampling rates, no knowledge of concurrent uses of the network, and are affected by WiFi and other client limitations.\n  In any case, I look forward to kicking the tires on the new NDT7 test! Thanks for the info.\n  Jason\n "", 'Nick Feamster': 'Yes, I’d enthusiastically collaborate with you folks on this. For me, it will be a learning experience about BBR, which would be welcome!\n\nBISmark: yes, let’s follow up offline. We can fix.\n\n-Nick\n\ue5d3\n> > >>> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n> > >>> To post to this group, send email to dis...@measurementlab.net.\n> > >>> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n> > > --\n> > > You received this message because you are subscribed to the Google Groups ""discuss"" group.\n> > > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n> > > To post to this group, send email to dis...@measurementlab.net.\n> > > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n> > >\n> > >\n> > > --\n> > > You received this message because you are subscribed to the Google Groups ""discuss"" group.\n> > > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n> > > To post to this group, send email to dis...@measurementlab.net.\n> > > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n> >\n> >\n> > --\n> > You received this message because you are subscribed to the Google Groups ""discuss"" group.\n> > To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n> > To post to this group, send email to dis...@measurementlab.net.\n> > Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n>\n>\n> --\n> You received this message because you are subscribed to the Google Groups ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\ue5d3', 'Matt Mathis': ""One of the cool things about ndt7 is that the main client version was Dockerized from the very beginning.   Thus it is a no brainer to create an ndt7 autotest image that will run on any CPE running a modern OS.  (Getting global load regulation right requires some engineering that we have not done yet, but it is on our roadmap).\n\nThe really powerful thing about Docker is that it completely decouples measurement SW version management from platform SW and HW version management.   This scales way better than integrating measurement tools into other peoples stacks and build environments.\n\nA cool idea (that is NOT on our roadmap) would be a meta tool to compare CPE, prefix neighbors and client device performance measurements.    This might be the ultimate tool to re-educate people who blame their ISP because they are expecting too much from their home WiFi swamps.\n\nI am already talking to Steve Bauer about reconstructing some of his experiments using NDT7.  We will not make any claims that we can't document.\n\nI will provide pointers once we have resolved some of the things that obviously don't look right.\n\nWhat is the timeline for your paper?\n \nThanks,\n--MM--\nThe best way to predict the future is to create it.  - Alan Kay\n\nWe must not tolerate intolerance;\n       however our response must be carefully measured: \n            too strong would be hypocritical and risks spiraling out of control;\n            too weak risks being mistaken for tacit approval.\n\n\ue5d3""}"
10,98165581382296771579184135373981949410,performance-of-cuba's-new-3g-mobile-network,"Dec 15, 2018, 12:24:14 PM",Larry press,"Cuba is belatedly rolling out a UMTS 900 900 Mhz 3G mobile network.

Anecdotal reports range between 500 Kbps and 1 Mbps

Assuming no congestion at the base station, what ranges of speed and latencies could they expect?

What would be typical performance?","{'Peter Heinzmann': 'Here are results from people who used the cnlab speedtest https://play.google.com/store/apps/details?id=ch.cnlab.speedtest . \nIn Switzerland. We do not have many 3G measurements nowadays, most tests are with 4G.\n\nThe median speeds i.e. the speed which was reached by 50% of the tests are as follows:\n\nDownload: 3G   4Mbit/s,   4G   28Mbit/s\nUpload:     3G   1Mbit/s,    4G    4Mbit/s\n\nThese resulats are from tests for MCC=228 i.e. Switzerland between 16-12-2017 and 16-12-2018:\n3G:  16\'942 Measurements by 1\'762 Devices   \n4G:  202\'500 Measurement by 19\'660 Devices\n\nIf we look at the results from the last three months the 4G Upload Data Rate is up to 4 Mbit/s. All other values are more constant over the last year.\n\nHere is the cumulative upload and download speed distribution for 3G:\n\n\nThis gives an idea about ""typical performance"" with 3G.\n\ue5d3'}"
11,313807598750333583702983194907973315065,data-use-as-regional-timeseries,"Nov 22, 2018, 10:35:36 AM",Kyle Lillie,"I'd like input on how practical it would be to use this data to create a regional time series representing average municipal download and upload speeds?
On https://regionaldashboard.alberta.ca/#/explore-an-indicator?i=average-download-speed&d=CalculatedValue we have some old data taken from speedtest.net when it was publicly available and would like to have some updated figures.

If speed isn't a good measure to derive, are the other stats that would work better?
Thanks.","{'Chris Ritzo': 'Hello Kyle,\n\nM-Lab\'s data is certainly suitable for what you\'re thinking about. If you need assistance accessing the data, please refer to our documentation, or contact us at sup...@measurementlab.net\n\nBest regards,\nChris\n--\nChris Ritzo\nMeasurement Lab Operations & Support\no...@measurementlab.net | sup...@measurementlab.net\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}"
12,1739124023407925339224437375023095947,google-fiber-vs-gigamonster:-1gbps-service-in-charlotte-nc-compared-(m-labs-&-speedtest.net),"Oct 9, 2017, 1:25:31 PM",Rajan Patel,"I am comparing Measurement Labs tests taken at www.internethealthtest.org from my Macbook Pro, using a wired Internet connection. I am astonished at how poorly Google Fiber performed.

First, I connected a wire from my Google Fiber network box, which has 1gbps service, and got the following results:

speedtest.net: https://goo.gl/oTE8rF
internethealthtest.org: https://goo.gl/K3Bkwj

Then I removed the Google Fiber wired connection and replaced it with an ethernet cable with Gigamonster 1gbps service

speedtest.net: https://goo.gl/DxgC2g
internethealthtest.org: https://goo.gl/Epwmkh

What are the next steps for me to get a knowledgeable explanation from Google Fiber about these shortcomings in their service?

I am trying to do an apples to apples comparison, and everything indicates that my fastest and lowest latency connectivity is through Gigamonster.


Appreciate feedback...

Rajan","{'Jim Warner': 'I can\'t tell where the servers you were testing against are located. I\'d want some data where I knew that the servers didn\'t change between my google fiber and gigamonster comparisons. It looks like both of the tests you selected use the ""closest"" server for some meaning of ""closest"" that might not be the same for different providers. I would probably run iperf tests against a collection of endpoints and repeat the same at different times of the day. \n\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\ue5d3', 'Rajan Patel': 'Jim, if you were in my shoes what service would you keep, and which would you cancel? Any other tests I can perform to give you the information you would want to know to make this decision?\nRajan\n\nOn Mon, Oct 9, 2017, 7:52 PM Jim Warner <war...@ucsc.edu> wrote:\nSpeed test results are strongly colored by the round trip time between the client and the server. You have RTTs of 38 mS (google) and 13 mS (gigamonster). That will affect your apples-to-apples comparison.\n\n\n\nOn Mon, Oct 9, 2017 at 1:25 PM, Rajan Patel <rajan...@responsiveweb.com> wrote:\nI am comparing Measurement Labs tests taken at www.internethealthtest.org from my Macbook Pro, using a wired Internet connection. I am astonished at how poorly Google Fiber performed.\n\nFirst, I connected a wire from my Google Fiber network box, which has 1gbps service, and got the following results:\n\nspeedtest.net: https://goo.gl/oTE8rF\ninternethealthtest.org: https://goo.gl/K3Bkwj\n\nThen I removed the Google Fiber wired connection and replaced it with an ethernet cable with Gigamonster 1gbps service\n\nspeedtest.net: https://goo.gl/DxgC2g\ninternethealthtest.org: https://goo.gl/Epwmkh\n\nWhat are the next steps for me to get a knowledgeable explanation from Google Fiber about these shortcomings in their service?\n\nI am trying to do an apples to apples comparison, and everything indicates that my fastest and lowest latency connectivity is through Gigamonster.\n\n\nAppreciate feedback...\n\nRajan\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\ue5d3'}"
13,13574034382675898561703604803664968224,enumerating-ndt-servers-/-selecting-a-specific-server,"Aug 22, 2017, 7:59:39 PM",rhys.p...@gmail.com,"Hello.

A few questions here. First, this is awesome

Is it possible to force a connection to a specific NDT server? It seems to be fully automatic when you go here: https://www.measurementlab.net/tests/ndt/

It would be great to be able to specify what backend server to connect to, as we like to know both the local speed to the closest server, and to say the speed to something close to one of our international data centers.

I've seen some references to peoples specifying servers from the command line tools, but nowhere that has the definitive list of what is available.

I see that you can get the 'closest' server to you by querying: http://mlab-ns.appspot.com/ndt

.. but I can't seem to get the full list of available servers.

I would be okay with resorting to a native application if required.

Any insight would be greatly appreciated.

Thank you.","{'rhys.p...@gmail.com': 'Similar to how you can select different servers via speedtest.net.\n\ue5d3', 'Ovidiu M': 'I published my source code here: https://github.com/o9o/ndt-speed-test\n\nThe program I used to split the whois and geolocation databases so\nthat they can be used from javascript in a static website is missing,\nbut I will try to add it when I have time. For these lookups, only\nIPv4 is supported. These are not essential for the measurement, only\nafter the measurement when the page shows statistics for the country\nthe user is located in.\n\ue5d3\n>> > email to discuss+u...@measurementlab.net.\n>> > To post to this group, send email to dis...@measurementlab.net.\n>> > Visit this group at\n>> > https://groups.google.com/a/measurementlab.net/group/discuss/.\n>>\n>> --\n>> You received this message because you are subscribed to the Google Groups\n>> ""discuss"" group.\n>> To unsubscribe from this group and stop receiving emails from it, send an\n>> email to discuss+u...@measurementlab.net.\n\ue5d3', 'Georgia Bullen': 'Hi All!\n\nJust to add to what Ovidiu was describing and provide some docs that might be helpful.\n\nIf you go here: https://mlab-ns.appspot.com/admin/map/ipv4/all (which is also available here: https://www.measurementlab.net/status/) you can see the sites available, and there\'s a link to the Design Doc for mlab-ns (https://docs.google.com/document/d/1eJhS75EZHDLmC6exggStr_b1euiR24_MVBJc1L6eH2c/view#heading=h.ubhijxy606i) which will help with showing you all of the functions that are available for seeing what servers are available.\n\nThe M-Lab team recommends that you use mlab-ns to get available servers rather than picking specific servers or maintaining your own list, as server status can change for a variety of reasons. Using mlab-ns should give you ways to find what servers are available and meet the conditions that you need for your application/tool.\n\nThanks for sharing your site Ovidiu! I hadn\'t seen that before!\n\n-Georgia\n\n\ue5d3\n\ue5d3\n\ue5d3\n> email to discuss+unsubscribe@measurementlab.net.\n\n> To post to this group, send email to dis...@measurementlab.net.\n> Visit this group at\n> https://groups.google.com/a/measurementlab.net/group/discuss/.\n\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\n\n\n--\nGeorgia Bullen\nDirector of Technology Projects\nBook a meeting: https://calendly.com/georgiabullen/\n\nOpen Technology Institute @ New America\n740 15th Street NW, Suite 900, Washington DC, 20005\n@georgiamoon'}"
14,198477332756213445712433836801248341146,comcast-is-claiming-m-lab's-speedtest-is-inaccurate.,"Jun 9, 2017, 2:17:31 PM",John Simpson,"I have been fighting with Comcast since they installed my service about not getting anywhere near the speeds that I am paying for, and they will only accept testing results done through their own methods, and claiming that M-Labs and the 5 other testing sites I use are never accurate.  I thought that you should know, as I am only one of thousands, maybe millions, of others that are experiencing this problem with Comcast and other ISP's here in the USA.  Charter was claiming the same thing, as of 2 years ago, but as I am no longer with their service, I do not know if they are doing anything differently or not.  Once again... Comcast is saying that your test is bunk.","{'Livingood, Jason': 'IMO NDT isn’t great at testing end user connection speed. But don’t take my word for it -- see https://groups.csail.mit.edu/ana/Publications/Understanding_broadband_speed_measurements_bauer_clark_lehr_TPRC_2010.pdf and read Sections 4.1 and 4.2.5. The latter section on NDT says “In other words, this is an excellent testing tool and infrastructure. The insights to draw from this data, however, are not simple averages of the upload and download speeds from different user populations. This, in fact, would not be an appropriate use of the data as far too many factors confound such an interpretation.” Also http://cfp.mit.edu/events/10Oct/CFP-Munich-2010-Slides/BAUER-Slides.CFP.Munich.2010.pdf and https://www.caida.org/workshops/isma/1202/slides/aims1202_sbauer.pdf. So it has its uses but perhaps not what you are trying to do with it.\n  In any case, it sounds like maybe you have an RF problem with your connection. I work for Comcast and would be happy to help you off list. You should absolutely be getting the advertised speeds. I will ping you 1:1.\n  Jason\n    On 6/9/17, 5:17 PM, ""John Simpson"" <stonew...@gmail.com> wrote:\n  I have been fighting with Comcast since they installed my service about not getting anywhere near the speeds that I am paying for, and they will only accept testing results done through their own methods, and claiming that M-Labs and the 5 other testing sites I use are never accurate.  I thought that you should know, as I am only one of thousands, maybe millions, of others that are experiencing this problem with Comcast and other ISP\'s here in the USA.  Charter was claiming the same thing, as of 2 years ago, but as I am no longer with their service, I do not know if they are doing anything differently or not.  Once again... Comcast is saying that your test is bunk.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.', 'Nick Feamster': 'What Jason says.\n\nAlso, see our Sigcomm 2011 paper ""Broadband Internet Access: A View from the Gateway"".\n\nIn that work, we evaluate single threaded throughput tests (the type NDT uses) in that paper. These types of tests frequently underestimate throughput by 30%, and sometimes more.\n\n-Nick\n\ue5d3', 'Matt Mathis': '+Steve Bauer\n\nI have been discussing that report with Steve.  We know that there is something fishy with the NDT data because IHT runs on top of MLab NDT.  Aside from IHT reporting the maximum of multiple NDT runs, the underlying distributions should be identical, and they clearly aren\'t.\n\nMy understanding from my conversations with Steve is that the NDT data was collected using a DIY integration of our NDT client into a runtime environment that we have not tested.\n\nInspecting the MLab web100 logs suggests that the main runtime event loop only ran the NDT threads once every 16mS.   We are aware of a number of runtime environments that perform extremely poorly.  Several of them seem to block the main event loop on frame rendering.  (The telltale signature: changing display settings sometimes changes the measured performance by exactly 60Hz/70Hz).\n\nWe also have the .pcap files for all of the tests in the report, so we can go quite deep in the analysis if we need to. \n\nThe other oddity in the data is that the NDT performance is not multi-modal, even though it would be expected to be spread across multiple MLab sites with slightly different RTTs.   The lack of modes very strongly suggests that the bottleneck is local to the client and does not depend on the path at all.   (Nearly all network bottlenecks, except a completely filling a link with zero cross traffic, show some RTT sensitivity).\n\nThe client configurations that we do support (and are used in all portals that we are aware of) are routinely subjected to a battery of automated performance and qualification tests.\n\nSteve, would you care to add anything?\n\nThanks,\n--MM--\nThe best way to predict the future is to create it.  - Alan Kay\n\nPrivacy matters!  We know from recent events that people are using our services to speak in defiance of unjust governments.   We treat privacy and security as matters of life and death, because for some users, they are.\n\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\ue5d3'}"
15,55806508832756795345102790115177247141,download-speed,"Oct 21, 2016, 7:02:34 PM",hank...@gmail.com,"Is there anyone , who can supply me with , or direct me as to where I can find proof , that my internet provider is messing with me . All they repeatedly tell me , is that my connection is fine on their end . I have had constant issues , playing downloaded video , especially using YouTube .

Thank You ","{'Jim Warner': 'An interesting perspective. My understanding is that SamKnows defers testing when it detects local on-premises traffic either on the wire or via WiFi. It does not defer to other traffic on the DSLAM or upstream at ISP peering points. Perhaps someone from SamKnows can comment authoritatively. The advantage of the white box is that it will perform a series of repetitive tests automatically and present the results. Also, if you find yourself in the position of needing to get back in touch with your ISP to get something fixed, as participants in the FCC measurement program, they might find it easier to understand the results. Maybe.\n\n-jim warner, UCSC network eng\n\n\nOn Mon, Oct 24, 2016 at 2:56 AM, <sylvain.s...@orange.com> wrote:\nSamknows whitebox is running tests (bandwidth, browsing, streaming) only when it detects that there’s no other traffic going through the xDSL or Fiber line.\nIt means that , if you ever use your Internet line during peak hours (as most people do, that’s why we call it peak hoursJ ) , the tests will only be run during low traffic periods > Consequently, if your ISP’s network (local loop, DSLAM, Peering) is suffering from congestions during peak hours > Samlnows  whitebox will hardly detect it, unless you are not using your line at this time of the day.\nMoreover, you have to subscribe to their panel in order to receive the Whitebox, as far as I know.\n    The other solution is to perform active bandwidth tests such as Speedtest (www.speedtest com), or Streamtest (https://www.streamtest.net/)\nM-Lab also provides tests tools that can be very helpful: https://www.measurementlab.net/tests/\nYoutube  (https://www.google.com/get/videoqualityreport/#how_video_gets_to_you )  or Netflix (https://fast.com/) have their own Performance Measurement tool..\n  In order to properly measure your performance, you must be sure that there’s no other traffic on your line (If you have kids , tell them  to do their homeworks J, Shut your IPTV down..  ).. And you MUST do the tests through an Ethernet cable connection with your home device (router provided by the ISP): WiFi will underestimate  your line bandwidth.\n  The above mentioned tools will tell you if you have a good or bad quality , but most of them won’t tell you where the problem is : local loop ? DSLAM ? ISP Core Network ? Inteconnection with the Content Provider ? But it will be a proof to discuss with your ISP Support.\n  Last but not least, talking about WiFi: if the Line Bandwidth test appear to be of Good Quality,  have a look on your Home Lan > Home Lan is 30% of bad Quality of Experience. The WiFi can be bothered  by walls or Distance, for example.. If you have a xDSL Line , copper can be disrupted by electric devices such as halogen lamp…\n    Hope this help.\nSylvain\n  De : Jim Warner [mailto:war...@ucsc.edu]\nEnvoyé : samedi 22 octobre 2016 19:15\nÀ : hank...@gmail.com\nCc : discuss\nObjet : Re: [M-Lab-Discuss] Download speed\n  This will do you the most good if your ISP is a cable company or telco: get a whitebox from samknows. It will perform repetitive tests and you will get access to your results.\n  https://www.samknows.com/meet-the-whitebox\n    On Fri, Oct 21, 2016 at 7:02 PM, <hank...@gmail.com> wrote:\nIs there anyone , who can supply me with , or direct me as to where I can find proof , that my internet provider is messing with me . All they repeatedly tell me , is that my connection is fine on their end . I have had constant issues , playing downloaded video , especially using YouTube .\n  Thank You \n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\ue5d3', 'sylvain.s...@orange.com': 'Hi James\n  I totally agree with you , as long you’re trying to have an overall understanding, for statistics.\nTo get back to the beginning of this conversation, Hank’s problem was to check if its ISP was telling the truth or was wrong when saying that there was no trouble with his line.\nIn this specific case, I believe that it’s important to run  tests at the right time (the moment when trouble occurs), with a close control on the environment.\n  You seem to have good knowledge of the Whitebox new features: As I said before, when we studied it 2 or 3 years ago , IPTV traffic couldn’t be detected (that was a major problem for us)   Do you know if it is possible now ?\n  Thanks\n      De : James Miller [mailto:yosi...@gmail.com]\nEnvoyé : lundi 24 octobre 2016 17:51\nÀ : SALVARELLI Sylvain DTSI/DERS; dis...@measurementlab.net; Jim Warner; hank...@gmail.com\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n--\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n_________________________________________________________________________________________________________________________\n  Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc\npas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler\na l\'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d\'alteration,\nOrange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.\n  This message and its attachments may contain confidential or privileged information that may be protected by law;\nthey should not be distributed, used or copied without authorisation.\nIf you have received this email in error, please notify the sender and delete this message and its attachments.\nAs emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.\nThank you.\n_________________________________________________________________________________________________________________________\n  Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc\npas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler\na l\'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d\'alteration,\nOrange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.\n  This message and its attachments may contain confidential or privileged information that may be protected by law;\nthey should not be distributed, used or copied without authorisation.\nIf you have received this email in error, please notify the sender and delete this message and its attachments.\nAs emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.\nThank you.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\ue5d3', 'Janusz Jezowicz': 'You can also use our Windows tool - http://www.broadbandspeedchecker.co.uk/scheduledTest.html\nYou get access to results for free, but it testing whenever you scheduled it to (no matter if connection is in use or not)\n\nYou will need to make sure you are on wired connection or know that there are no wifi issues though, to be able to prove to your ISP its not the local network issue\n\nRegards,\n\nJanusz Jezowicz\nSpeedchecker Ltd\nemail: jan...@speedchecker.xyz\nskype: jezowicz\nphone: +442032863573\nweb: www.speedchecker.xyz\nThe Black Church, St. Mary’s Place, Dublin 7, D07 P4AX, Ireland\n\n\n\nOn 24 October 2016 at 11:56, <sylvain.s...@orange.com> wrote:\nSamknows whitebox is running tests (bandwidth, browsing, streaming) only when it detects that there’s no other traffic going through the xDSL or Fiber line.\nIt means that , if you ever use your Internet line during peak hours (as most people do, that’s why we call it peak hoursJ ) , the tests will only be run during low traffic periods > Consequently, if your ISP’s network (local loop, DSLAM, Peering) is suffering from congestions during peak hours > Samlnows  whitebox will hardly detect it, unless you are not using your line at this time of the day.\nMoreover, you have to subscribe to their panel in order to receive the Whitebox, as far as I know.\n    The other solution is to perform active bandwidth tests such as Speedtest (www.speedtest com), or Streamtest (https://www.streamtest.net/)\nM-Lab also provides tests tools that can be very helpful: https://www.measurementlab.net/tests/\nYoutube  (https://www.google.com/get/videoqualityreport/#how_video_gets_to_you )  or Netflix (https://fast.com/) have their own Performance Measurement tool..\n  In order to properly measure your performance, you must be sure that there’s no other traffic on your line (If you have kids , tell them  to do their homeworks J, Shut your IPTV down..  ).. And you MUST do the tests through an Ethernet cable connection with your home device (router provided by the ISP): WiFi will underestimate  your line bandwidth.\n  The above mentioned tools will tell you if you have a good or bad quality , but most of them won’t tell you where the problem is : local loop ? DSLAM ? ISP Core Network ? Inteconnection with the Content Provider ? But it will be a proof to discuss with your ISP Support.\n  Last but not least, talking about WiFi: if the Line Bandwidth test appear to be of Good Quality,  have a look on your Home Lan > Home Lan is 30% of bad Quality of Experience. The WiFi can be bothered  by walls or Distance, for example.. If you have a xDSL Line , copper can be disrupted by electric devices such as halogen lamp…\n    Hope this help.\nSylvain\n  De : Jim Warner [mailto:war...@ucsc.edu]\nEnvoyé : samedi 22 octobre 2016 19:15\nÀ : hank...@gmail.com\nCc : discuss\nObjet : Re: [M-Lab-Discuss] Download speed\n  This will do you the most good if your ISP is a cable company or telco: get a whitebox from samknows. It will perform repetitive tests and you will get access to your results.\n  https://www.samknows.com/meet-the-whitebox\n    On Fri, Oct 21, 2016 at 7:02 PM, <hank...@gmail.com> wrote:\nIs there anyone , who can supply me with , or direct me as to where I can find proof , that my internet provider is messing with me . All they repeatedly tell me , is that my connection is fine on their end . I have had constant issues , playing downloaded video , especially using YouTube .\n  Thank You \n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n_________________________________________________________________________________________________________________________\n\nCe message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc\npas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler\na l\'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d\'alteration,\nOrange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.\n\nThis message and its attachments may contain confidential or privileged information that may be protected by law;\nthey should not be distributed, used or copied without authorisation.\nIf you have received this email in error, please notify the sender and delete this message and its attachments.\nAs emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.\nThank you.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\ue5d3', 'Chris Ritzo': 'Thanks for the If you use the mention of M-Lab tests. \n\nNetwork Diagnostic Tool is the primary performance measurement test provided by M-Lab, and you can run it in several ways:\n- from our website at https://www.measurementlab.net/tools/ndt/\n- at https://speed.measurementlab.net/\n\nIf you use the Chrome web browser, the M-Lab Measure Chrome extension could be helpful to schedule regular measurement of your connection:\nhttps://chrome.google.com/webstore/detail/m-lab-measure/leijmacehibmiomcnpaolboihcdepokh \n\nBest regards,\n\n Chris Ritzo\n Senior Technologist, Open Technology Institute @ New America\n 740 15th Street NW, Suite 900\n Washington, DC 20036     \n\ue5d3', 'James Miller': 'That\'s a good point.  I agree having a measurement at the time of the test is really helpful.  That said a stat measured over a longer period and randomly scheduled showing poor performance would be compelling and maybe easier to followup on.  If you had a white box stat showing a low peak performance over a month period would be difficult to disregard.\nAlso anything not running on a dedicated client would require a look at the client environment and would generally be viewed more sceptically.  So if you run browser based or others tests on your laptop/tablet/smartphone record the os hardware CPU and memory state.\nI agree though gathering more data is always helpful!\nOn the IPTV question, originally in the first few years of the program in the US the white box served as a wifi ap and replaced the user or providers equipment.  Later we moved the white box to the inside of that equipment but would then use the bridge mode on the device and mutiport utp ports to ensure traffic like the IPTV equipment passed through the white box in bridge mode (enabling the tx/Rx measurement).  Even for traffic outside the white box there are some APIs available on many devices to query current traffic flow for determining crosstalk and traffic volume..\nBut as you know, there are so many permutations of customer and provider equipment scenarios that\'s a struggle. ;)\nAnyone interested in the Samknows / MBA program topics should drop me a note.  We hold monthly open ""collaborate"" meetings to discuss the program methodology, architecture, data and our annual reports.  Fun stuff!\n\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n--\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n_________________________________________________________________________________________________________________________\n  Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc\npas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler\na l\'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d\'alteration,\nOrange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.\n  This message and its attachments may contain confidential or privileged information that may be protected by law;\nthey should not be distributed, used or copied without authorisation.\nIf you have received this email in error, please notify the sender and delete this message and its attachments.\nAs emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.\nThank you.\n_________________________________________________________________________________________________________________________\n  Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc\npas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler\na l\'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d\'alteration,\nOrange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.\n  This message and its attachments may contain confidential or privileged information that may be protected by law;\nthey should not be distributed, used or copied without authorisation.\nIf you have received this email in error, please notify the sender and delete this message and its attachments.\nAs emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.\nThank you.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n_________________________________________________________________________________________________________________________\n\nCe message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc\npas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler\na l\'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d\'alteration,\nOrange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.\n\nThis message and its attachments may contain confidential or privileged information that may be protected by law;\nthey should not be distributed, used or copied without authorisation.\nIf you have received this email in error, please notify the sender and delete this message and its attachments.\nAs emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.\nThank you.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\ue5d3', 'sandro....@anacom.pt': 'Dear all,\n\nThe samknowns controlled environment is an interesting approach but the crowdsourcing approach is generally being adopted as a measuring schema to endorse the EU QoS regulation. In this approach we in Anacom believe that despite the biased aspects being client based and thus dependent of the system performance and access simultaneous crossing traffic we believe that in some extend we can take some features to this approach that might bring some reliability to the measurement. Some of these features might include having a dashboard showing containers for"" each equipment terminal-gateway"" where a collection of measures (e.g. one week) during off and on busy hour that after a measure period (e.g. month) could present some statistical measures (e.g. median, average) that could bring some light about the Internet QoS in the life of one user. Of course those measurements should be compared against the others users indicators in the same local for the same ISP and against the competition (others ISPs).\n\nIn the end is not enough to make a simple measurement but instead provide a set of information that might help the consumer to evaluate his own usage and confirm his perception.\n\nIn Anacom we have a tool that we are currently upgrading to meet those requirements, you may check it here:www.netmedepro.pt (sorry is in Portuguese..) for more info don\'t hesitate to contact me.\n\nSandro Parranca\n\n\n________________________________\nFrom: yosi...@gmail.com [yosi...@gmail.com] on behalf of James Miller [james...@nihonlinks.com]\nSent: 24 October 2016 21:08\nTo: sylvain.s...@orange.com\nCc: hank5937; Jim Warner; dis...@measurementlab.net\nSubject: RE: [M-Lab-Discuss] Download speed\n\n\nThat\'s a good point. I agree having a measurement at the time of the test is really helpful. That said a stat measured over a longer period and randomly scheduled showing poor performance would be compelling and maybe easier to followup on. If you had a white box stat showing a low peak performance over a month period would be difficult to disregard.\n\nAlso anything not running on a dedicated client would require a look at the client environment and would generally be viewed more sceptically. So if you run browser based or others tests on your laptop/tablet/smartphone record the os hardware CPU and memory state.\n\nI agree though gathering more data is always helpful!\n\nOn the IPTV question, originally in the first few years of the program in the US the white box served as a wifi ap and replaced the user or providers equipment. Later we moved the white box to the inside of that equipment but would then use the bridge mode on the device and mutiport utp ports to ensure traffic like the IPTV equipment passed through the white box in bridge mode (enabling the tx/Rx measurement). Even for traffic outside the white box there are some APIs available on many devices to query current traffic flow for determining crosstalk and traffic volume..\n\nBut as you know, there are so many permutations of customer and provider equipment scenarios that\'s a struggle. ;)\n\nAnyone interested in the Samknows / MBA program topics should drop me a note. We hold monthly open ""collaborate"" meetings to discuss the program methodology, architecture, data and our annual reports. Fun stuff!\n\nOn Oct 24, 2016 12:46, <sylvain.s...@orange.com<mailto:sylvain.s...@orange.com>> wrote:\nHi James\n\nI totally agree with you , as long you’re trying to have an overall understanding, for statistics.\nTo get back to the beginning of this conversation, Hank’s problem was to check if its ISP was telling the truth or was wrong when saying that there was no trouble with his line.\nIn this specific case, I believe that it’s important to run tests at the right time (the moment when trouble occurs), with a close control on the environment.\n\nYou seem to have good knowledge of the Whitebox new features: As I said before, when we studied it 2 or 3 years ago , IPTV traffic couldn’t be detected (that was a major problem for us) Do you know if it is possible now ?\n\nThanks\n\n\n\nDe : James Miller [mailto:yosi...@gmail.com<mailto:yosi...@gmail.com>]\nEnvoyé : lundi 24 octobre 2016 17:51\nÀ : SALVARELLI Sylvain DTSI/DERS; dis...@measurementlab.net<mailto:dis...@measurementlab.net>; Jim Warner; hank...@gmail.com<mailto:hank...@gmail.com>\nObjet : Re: [M-Lab-Discuss] Download speed\n\nFrom: sylvain.s...@orange.com<mailto:sylvain.s...@orange.com>:\n\n""Samknows whitebox is running tests (bandwidth, browsing, streaming) only when it detects that there’s no other traffic going through the xDSL or Fiber line.""\n""In order to properly measure your performance, you must be sure that there’s no other traffic on your line (If you have kids , tell them to do their homeworks J, Shut your IPTV down.. ).. And you MUST do the tests through an Ethernet cable connection with your home device (router provided by the ISP): WiFi will underestimate your line bandwidth.""\n\nVery interesting discussion! Three great points are made about isolating the impact of PC/Browser performance from the speed test, making sure measurements are reflecting the portion of the Internet connection you\'re interested in (namely what you pay your ISP to provide), and making sure the time of the tests is relevant to what you\'re interested in. I add a little detail below that may be helpful but Jim Warner suggested contacting SamKnows and getting a ""whitebox"" as that approach will automate alot of these concerns so you don\'t have to sit at your PC all day in order to bring data to a discussion. Feel free to contact SamKnows or myself at James....@FCC.gov<mailto:James....@FCC.gov> if you have other questions. More discussion, below:\n\nSylvain identified above the important ""cross-talk"" point. As he explained you don\'t want to measure when there\'s use of a connection because the ""cross-talk"" is an undefined load induced on the line, not reflecting the capacity of the line.\n\nImagine trying to measure your gas mileage on the highway where drag is a concern and the kids keep opening and closing the windows. You wouldn\'t be sure if the MPG you calculated was lower than what your car was capable of because you wouldn\'t be able to isolate how much impact the kids fooling around with the windows had on your measurement. (In the Internet metric case.. the kids fooling around playing league of legends or watching MEME youtube videos can certainly be a drag on a family\'s MPG for the Internet connection). So a test that quantifies the amount of load during the test isolates the volume metric that together with fixed time of the test supports a determination of the rate.\n\nSylvain suggests that a ""manual"" test rather than a ""scheduled"" test is better because you can isolate yourself whether your system has any use of the Internet connection, and also suggests using an ethernet rather than WiFi connection to your connection to your carrier. It\'s good advice to isolate the the cross-traffic and also consider whether your test is impacted by a poor WiFi condition that didn\'t represent the speed available from your Internet connection.\n\nIn the case of our FCC Measuring Broadband America Program (the SamKnows methodology Jim Warner mentions), the tests are run on a dedicated independent probe (we call a ""whitebox"") that sits directly next to your connection and avoids the impacts your PC and Browser might have on a test, as well as any connectivity issues between your personal equipment and your connection to your provider. Both of these features are important to isolating things that could be influencing a test of what your provider is making available to you.\n\nTests that are scheduled are typically more informative than ones you have to initiate because typically you will have more measurements and and a more statistically useful view of your Internet performance. That said our whiteboxes will soon have the ability to initiate manual tests as well.\n\nIn our program, tests that are deferred when there is more than 400k of traffic on the line get rescheduled and because multiple tests are constantly run throughout both peak and off-peak times, you get a very continuous view of your performance and how it changes across the 24-hour day as well as through the week. We focus on peak-performance in our reporting on carrier performance and actually recently increased the number the number of tests that whiteboxes run during peak period.\n\n\n\n\n\n\n--\nJames Miller, Esq.\n\n""Japanese is so Eighties...""\nAnonymous FCC Colleague\n\nOn Mon, Oct 24, 2016 at 9:12 AM, <sylvain.s...@orange.com<mailto:sylvain.s...@orange.com>> wrote:\nHi Jim\n\nYou are right to say it does not defers when there’s traffic on DSLAM or on Peering connection (otherwise it wouldn’t perform any test at all ).\nIndeed, it defers tests, when there’s traffic on the line: and it is right to do so, otherwise the test would be corrupted: Doing bandwidth test while someone on the Lan is watching a YT or Netflix Video (which may use 3Mbps), wouldn’t give the true Bandwidth capacity.\n\nIn such case , and in my opinion, the best way to proceed, is to do the test when experiencing problems with YT ( for example, and after checking that no other device is trafficking) , and when there’s no problem (to compare).\n\nAnother point to be aware of, Samknows Whitebox is not able to detect IPTV traffic on specific circumstances (bridge)…that was 2 years ago, I don’t know if this has changed since then. If it’s still the case, it may perform test while the TV’s on (taking up a few Mbps…) > test results would then be biaised.\n\n\n\nDe : Jim Warner [mailto:war...@ucsc.edu<mailto:war...@ucsc.edu>]\nEnvoyé : lundi 24 octobre 2016 14:40\nÀ : SALVARELLI Sylvain DTSI/DERS\nCc : hank...@gmail.com<mailto:hank...@gmail.com>; discuss\n\nObjet : Re: [M-Lab-Discuss] Download speed\n\nAn interesting perspective. My understanding is that SamKnows defers testing when it detects local on-premises traffic either on the wire or via WiFi. It does not defer to other traffic on the DSLAM or upstream at ISP peering points. Perhaps someone from SamKnows can comment authoritatively. The advantage of the white box is that it will perform a series of repetitive tests automatically and present the results. Also, if you find yourself in the position of needing to get back in touch with your ISP to get something fixed, as participants in the FCC measurement program, they might find it easier to understand the results. Maybe.\n\n-jim warner, UCSC network eng\n\n\nOn Mon, Oct 24, 2016 at 2:56 AM, <sylvain.s...@orange.com<mailto:sylvain.s...@orange.com>> wrote:\nSamknows whitebox is running tests (bandwidth, browsing, streaming) only when it detects that there’s no other traffic going through the xDSL or Fiber line.\nIt means that , if you ever use your Internet line during peak hours (as most people do, that’s why we call it peak hours:) ) , the tests will only be run during low traffic periods > Consequently, if your ISP’s network (local loop, DSLAM, Peering) is suffering from congestions during peak hours > Samlnows whitebox will hardly detect it, unless you are not using your line at this time of the day.\nMoreover, you have to subscribe to their panel in order to receive the Whitebox, as far as I know.\n\n\nThe other solution is to perform active bandwidth tests such as Speedtest (www.speedtest<http://www.speedtest> com), or Streamtest (https://www.streamtest.net/)\nM-Lab also provides tests tools that can be very helpful: https://www.measurementlab.net/tests/\nYoutube (https://www.google.com/get/videoqualityreport/#how_video_gets_to_you ) or Netflix (https://fast.com/) have their own Performance Measurement tool..\n\nIn order to properly measure your performance, you must be sure that there’s no other traffic on your line (If you have kids , tell them to do their homeworks :), Shut your IPTV down.. ).. And you MUST do the tests through an Ethernet cable connection with your home device (router provided by the ISP): WiFi will underestimate your line bandwidth.\n\nThe above mentioned tools will tell you if you have a good or bad quality , but most of them won’t tell you where the problem is : local loop ? DSLAM ? ISP Core Network ? Inteconnection with the Content Provider ? But it will be a proof to discuss with your ISP Support.\n\nLast but not least, talking about WiFi: if the Line Bandwidth test appear to be of Good Quality, have a look on your Home Lan > Home Lan is 30% of bad Quality of Experience. The WiFi can be bothered by walls or Distance, for example.. If you have a xDSL Line , copper can be disrupted by electric devices such as halogen lamp…\n\n\nHope this help.\nSylvain\n\nDe : Jim Warner [mailto:war...@ucsc.edu<mailto:war...@ucsc.edu>]\nEnvoyé : samedi 22 octobre 2016 19:15\nÀ : hank...@gmail.com<mailto:hank...@gmail.com>\nCc : discuss\nObjet : Re: [M-Lab-Discuss] Download speed\n\nThis will do you the most good if your ISP is a cable company or telco: get a whitebox from samknows. It will perform repetitive tests and you will get access to your results.\n\nhttps://www.samknows.com/meet-the-whitebox\n\n\n\nOn Fri, Oct 21, 2016 at 7:02 PM, <hank...@gmail.com<mailto:hank...@gmail.com>> wrote:\nIs there anyone , who can supply me with , or direct me as to where I can find proof , that my internet provider is messing with me . All they repeatedly tell me , is that my connection is fine on their end . I have had constant issues , playing downloaded video , especially using YouTube .\n\nThank You\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net<mailto:discuss+u...@measurementlab.net>.\nTo post to this group, send email to dis...@measurementlab.net<mailto:dis...@measurementlab.net>.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net<mailto:discuss+u...@measurementlab.net>.\nTo post to this group, send email to dis...@measurementlab.net<mailto:dis...@measurementlab.net>.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\n_________________________________________________________________________________________________________________________\n\n\n\nCe message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc\n\npas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler\n\na l\'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d\'alteration,\n\nOrange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.\n\n\n\nThis message and its attachments may contain confidential or privileged information that may be protected by law;\n\nthey should not be distributed, used or copied without authorisation.\n\nIf you have received this email in error, please notify the sender and delete this message and its attachments.\n\nAs emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.\n\nThank you.\n\n\n_________________________________________________________________________________________________________________________\n\n\n\nCe message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc\n\npas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler\n\na l\'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d\'alteration,\n\nOrange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.\n\n\n\nThis message and its attachments may contain confidential or privileged information that may be protected by law;\n\nthey should not be distributed, used or copied without authorisation.\n\nIf you have received this email in error, please notify the sender and delete this message and its attachments.\n\nAs emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.\n\nThank you.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net<mailto:discuss+u...@measurementlab.net>.\nTo post to this group, send email to dis...@measurementlab.net<mailto:dis...@measurementlab.net>.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net<mailto:discuss+u...@measurementlab.net>.\nTo post to this group, send email to dis...@measurementlab.net<mailto:dis...@measurementlab.net>.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\n_________________________________________________________________________________________________________________________\n\nCe message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc\npas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler\na l\'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d\'alteration,\nOrange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.\n\nThis message and its attachments may contain confidential or privileged information that may be protected by law;\nthey should not be distributed, used or copied without authorisation.\nIf you have received this email in error, please notify the sender and delete this message and its attachments.\nAs emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.\nThank you.\n\n\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net<mailto:discuss+u...@measurementlab.net>.\nTo post to this group, send email to dis...@measurementlab.net<mailto:dis...@measurementlab.net>.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net<mailto:discuss+u...@measurementlab.net>.\nTo post to this group, send email to dis...@measurementlab.net<mailto:dis...@measurementlab.net>.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\nPense no ambiente. Imprima o conteudo desta mensagem apenas se for absolutamente necessario.\n\nEste email e ficheiros em anexo sao confidenciais e destinados somente ao conhecimento e utilizacao da(s) pessoa(s) ou entidade(s) a quem foram enderecados. Se recebeu este email ou anexos por erro, ou a eles teve acesso nao sendo o destinatario, por favor elimine-os contactando o remetente.\n\nPlease consider the environment before printing this mail note.\n\nThis email and files transmitted with it are confidential and intended for the sole use of the individual or organization to whom they are addressed. If you have received this email in error, please notify the sender immediately and delete it without using, copying, storing, forwarding or disclosing its contents to any other party.\n\nAutoridade Nacional de Comunicacoes http://www.anacom.pt'}"
16,138128874413787301520283344052750767719,testing-from-paraguay,"Mar 9, 2015, 8:19:15 AM",oliv...@gmail.com,"Hi,
here in Paraguay - South America we are experiencing a really bad throttling in all big ISP, during office hours, nationwide while connecting to USA, Europe, etc. in business level connections (even with SLAs)

Is there a way to detect this throttling? I have already installed Neubot myself. I have many colleges having the same issues, and we are interesting in demonstrating this bad internet service from our ISPs.

My questions are:
- after running Neubot for a few week in many installations, where is the data shown?
- is there a way to group a few probe together and have a graph about those probes?

Many thanks
Oliver
http://tinymailto.com/oliversl","{'Simone Basso': 'oliv...@gmail.com wrote:\n> Hi,\n\nHi!\n\n> here in Paraguay - South America we are experiencing a really bad throttling\n> in all big ISP, during office hours, nationwide while connecting to USA,\n> Europe, etc. in business level connections (even with SLAs)\n>\n> Is there a way to detect this throttling? I have already installed Neubot\n> myself. I have many colleges having the same issues, and we are interesting\n> in demonstrating this bad internet service from our ISPs.\n\nJudging from here <http://www.measurementlab.net/infrastructure> there are\nno M-Lab servers deployed in Paraguay.\n\nTherefore probably all Neubot tests can be useful to sense what you report (in\ncase there were servers in Paraguay, only raw and dash would have been\nuseful, since speedtest and bittorrent attempt to use the closest server).\n\nI think the raw test can be especially useful in this case because it\nalso collects\nlow level data on losses and latency thanks to the Web100 kernel.\n\n> My questions are:\n> - after running Neubot for a few week in many installations, where is the\n> data shown?\n\nThe data of individual Neubots are available through the web interface\nof Neubot which you can usually find at http://127.0.0.1:9774/.\n\nM-Lab should aggregate the data saved server side and publish such\ndata on the Google Cloud Storage.\n\nSee <https://code.google.com/p/m-lab/wiki/HowToAccessMLabData>.\n\nAs far as I know, Neubot data is not shown via the observatory of M-Lab\navailable at M-Lab website.\n\n> - is there a way to group a few probe together and have a graph about those\n> probes?\n\nYes. I wrote a tool myself to download Neubot data from there and put it\ninto a MongoDB database for further analysis.\n\nYou can check it out here: https://github.com/bassosimone/neubot-pipeline\n\nThe README.md should explain you the dependencies you need to install, how\nto clone the repository, etc. But, if you have questions, just ask :).\n\nOnce you have the data in MongoDB, I guess you can filter data to only\nget the unique ids of the Neubots installed by you an your colleagues.\n\n(The unique ids are available for example from the settings page of\nNeubot\'s local web interface).\n\nBTW I just noticed that this pipeline only imports the speedtest and\nbittorrent data of Neubot, but you probably want to import all tests to\ndo this kind of analysis.\n\nIf you want to try this, tell me, and I can add the code to import\nthe data of all tests to neubot-pipeline.\n\n> Many thanks\n> Oliver\n> http://tinymailto.com/oliversl\n\nCheers,\n\nSimone\n\n> --\n> You received this message because you are subscribed to the Google Groups\n> ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it, send an\n> email to discuss+u...@measurementlab.net.\n> To post to this group, send email to dis...@measurementlab.net.\n> Visit this group at\n> http://groups.google.com/a/measurementlab.net/group/discuss/.', 'Oliver Schulze': ""Hi Simone,\nmany thanks for your reply.\n\nFor me is good not have a MLab server in Paraguay, because my problem occurs when\nI connect outside Paraguay.\n\nInside Paraguay I have the bandwidth that we pay for. The problem is with dowloads and uploads\nto and from ouside Paraguay.\n\nNeubot indeed show me this problem, it can only download and upload at 1/5 of my bandwidth.\n\nNetalyzer for example does not report my problem, it shows me that I have the bandwidth that I pay for.\n\nIn Paraguay I have many colleges with this same situation, in the 3 top ISP of Paraguay (Tigo, Copaco, Personal)\n\nMy connection is a business class connection, over fiber optic, full duplex. I does not have a big\nbandwidth compared to actual standard, but its a fast a connection inside Paraguays standard.\n\nI will try to test your app, but can promise much.\n\nBottom line:\n- Neubot confirms the shaping tacking place in my connection, in all test (speedtest, bittorrent, raw, dash), will leave Neubot running 24/7 on a Win7 Pro VM\n- Netalyzer does not detect the shaping, it only sees a high TCP connection time (yellow)\n- M-LAB NDT flash test sees the shaping too\n- using mtr --report www.yahoo.com I see packet loss at the last 3 IPs\n- downloading from big CDN, as a user, I see the shaping too\n- all test are confirmed when I'm the only one using the network\n\nRegards,\nOliver\n\n\n--\nOliver Schulze L.\nhttp://tinymailto.com/oliversl\n\ue5d3"", 'Collin Anderson': 'Oliver,\n\nIt’s a pleasure to meet you and thank you for making the connection, Robert. Naturally we would be happy to connect by Hangout if it would be of use, but a few thoughts having done similar research recently. \n\nIt sounds as though there might be an issue with congestion over transit connectivity that those three providers use, rather than explicit throttling of applications or based on hours. It might be useful to differentiate first whether the performance degradation is specific any particular protocols, or all connectivity first, testing against the same servers each time. As long as it’s across the board, I would begin to conduct performance tests against different measurement endpoints, and keep path data (traceroutes, etc) for each test. M-Lab’s closest site is in Colombia, and after that there’s at least four sites in Miami. Either way, and whatever test you use, I would make sure to start to document what networks are involved with the connectivity and the role of those networks in positive or negative performance outcomes.\n\nI wish we had a site in Paraguay for the purpose of comparison against out of country tests. For what it’s worth, our new Colombia site shows an interesting trend: http://www.google.com/publicdata/explore?ds=e9krd11m38onf_&ctype=m&strail=false&bcs=d&nselm=s&met_s=number_of_tests&scale_s=lin&ind_s=false&met_c=download_throughput&scale_c=lin&ind_c=false&ifdim=country&hl=en_US&dl=en_US&ind=false&xMax=180&xMin=-180&yMax=-79.97571094413946&yMin=84.17339026552769&mapType=t&icfg&iconSize=0.5#!ctype=l&strail=false&bcs=d&nselm=h&met_y=download_throughput&fdim_y=mlab_site:CO-Bogota&scale_y=lin&ind_y=false&rdim=country&idim=country:600&ifdim=country&hl=en_US&dl=en_US&ind=false\n\nCordially,\nCollin\n\ue5d3'}"
17,281607176103228925847121169819310364442,traceroute-rfc---request-for-feedback-by-end-of-january,"Jan 18, 2022, 4:57:41 PM",Lai Yi Ohlsen,"Hi everyone, 

M-Lab has published an RFC discussing our transition from MDA traceroute data. If you use our traceroute dataset or plan to in the future, please take a look at the RFC and send us your feedback by the end of January. Excerpt below. 

----

Background
M-Lab’s traceroute-caller (TRC) tool was designed and developed in early 2019 as a sidecar service running on M-Lab servers. Its purpose is to collect traceroute data to any remote IP address after it closes its TCP connection to an M-Lab server. TRC uses the scamper tool for running traceroutes. 

The initial version of TRC called scamper to run the tracelb command and saved the resulting traceroute as traceroute datatype which was renamed to scamper1 datatype.

As described in scamper’s manual page, the tracelb command is used to infer all per-flow load-balanced paths between a source and destination using the Multipath Discovery Algorithm (MDA). Starting in 1Q22, TRC also supports regular traceroutes which take much less time to run and return a simpler result that is saved as scamper2 datatype.

M-Lab would like to start collecting regular traceroutes (in addition to MDA traceroutes) in 1Q22 and stop collecting MDA traceroutes by the end of 2Q22.

Request for Comments
We are publishing this RFC to get feedback from the community regarding our decision to stop running MDA traceroutes by the end of 2Q22 and, instead, run regular traceroutes with the Paris traceroute algorithm.

If you use MDA traceroutes (scamper1 datatype) and this decision impacts you, please let us know via reply to the dis...@measurementlab.net mailing list. Also, please let us know if you are planning research that would benefit from regular traceroutes (scamper2 datatype).

Based on your feedback, we will decide if we need to continue running MDA traceroutes and how to support it beyond what we already have.

Read the full RFC on our website.

Thanks! Happy New Year. 

--
Lai Yi Ohlsen
Director, Measurement Lab
Code for Science & Society","{'Timur Friedman': 'Hello Matt,\n\nAgreed: multipath tracing ought not come at the cost of obtaining a decent single-path trace.\n\nThis strikes me as an implementation issue that could be addressed by tweaking the current tracing tool.\n\nIt is possible to design a route tracing tool so that classic Traceroute\'s demultiplexing issue goes away. \n\nThe original insight was Rob Beverly\'s: to craft the traceroute probe packets in such a way that the ICMP replies are entirely self-identifying. This does away with the need to maintain state on each probe packet sent, in order to match each reply with its corresponding probe packet. He based his high-speed single-path probing tool Yarrp on this insight.\n\nKevin Vermeulen extended the same principle to multipath probing: his Diamond-Miner tool similarly crafts the probe packets so that the ICMP replies are self-identifying, including, in this case, the flow identifiers, or ""Paris IDs"", of each probe packet that provoked a reply.\n\nNow, our Iris measurement platform regularly runs Diamond-Miner route traces towards all routable IPv4 prefixes of the internet at a rate of 100,000 probe packets per second. Under these conditions, there are hundreds of thousands of outstanding probe packets at any given moment, and when the replies do come in, they are successfully associated with the trace of a particular route or, occasionally, if the reply is corrupted in some way, discarded.\n\nThe 100,000 probe packet per second limit is self-imposed so as not to trigger warnings with our ISP. Otherwise, Diamond-Miner could be scaled to run faster, say at a million probe packets per second or more, while all the time correctly identifying the replies.\n\nWe have embodied this behavior in our liberally-licensed free open-source Caracal probing engine. As I mentioned, earlier in this thread, we could easily provide the route tracing tool that M-Lab needs on the basis of this engine. It would be sure to obtain a single-path route trace alongside each multipath trace. And it would withstand whatever case load you send its way. I\'m including Maxime Mouchet, the lead developer and maintainer of the current version of Caracal, in the conversation.\n\n Kind regards,\n\nTimur\n\n\n\n\nOn Thu, Jan 20, 2022 at 5:58 AM Matt Mathis <mattm...@google.com> wrote:\nAnother consideration is that multipath traceroute is more likely to outright fail (zero output) on some of the most interesting paths, because it reaches a time limit or some other resource limit.\n\nMy wish would be to increase the  coverage of the single path traceroutes, possibly by relaxing the coverage on the multipath traceroute.\n\nMy chronic worry is our ability to assure that we are properly demuxing the ICMP replies, under our worst case loads.\n \nThanks,\n--MM--\nThe best way to predict the future is to create it.  - Alan Kay\n\nWe must not tolerate intolerance;\n       however our response must be carefully measured: \n            too strong would be hypocritical and risks spiraling out of control;\n            too weak risks being mistaken for tacit approval.\n\n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/13004FCF-BDCF-4FD6-8FCC-BEB2C14EAD20%40univ-savoie.fr.', 'Stephen Soltesz': 'Thank you, Timur, comments below.\n\nOn Wed, Jan 19, 2022 at 2:39 PM Timur Friedman <t...@oxus.net> wrote:\nHello Lai Yi,\n\nAm I correct in understanding that two things motivate this change?\n\n- The complexity of parsing the multipath traceroute data structure\n- The time that it takes to run the MDA in order to collect a multipath traceroute\n\nFrom my perspective, the primary challenge is using the multipath traceroute data. People often expect the single-path traceroutes, or may require this when combining this dataset with other datasets.\n If so, there are alternatives to abandoning the collection of multipath traceroutes. After all, M-Lab has the largest set of multipath traceroutes (well over one billion!) going back over many years. Anyone who wants to study how multipath routing has evolved over time in the internet would be hard-pressed to find any other comparable dataset.\n\nI like this point. M-Lab was founded to collect longitudinal data. ""Don\'t throw out the baby with the bath water"" so to speak. Do you know anyone who is doing this type of research on multipath traceroutes?\n Regarding the complex data structure, a single-path traceroute could easily be extracted from a multipath traceroute via post-processing. It would not be necessary to conduct the measurement twice.\n\nCan you say more about how to easily extract a single-path traceroute from a multi-path traceroute? We touched on this conversationally but the mechanism was unclear. There are two potential users here: those who wish to process the raw archive files themselves, those who wish to use BigQuery.\n\nBest,\nStephen', 'Kavé Salamatian': 'Hello all, \n\nI am also using these data and I am aware of some people in Columbia also using these data. \n\nAll the bests\n\nRgds\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/9c7b5e18-8af6-41fd-b357-18523549f689n%40measurementlab.net.', 'Matt Mathis': 'Another consideration is that multipath traceroute is more likely to outright fail (zero output) on some of the most interesting paths, because it reaches a time limit or some other resource limit.\n\nMy wish would be to increase the  coverage of the single path traceroutes, possibly by relaxing the coverage on the multipath traceroute.\n\nMy chronic worry is our ability to assure that we are properly demuxing the ICMP replies, under our worst case loads.\n \nThanks,\n--MM--\nThe best way to predict the future is to create it.  - Alan Kay\n\nWe must not tolerate intolerance;\n       however our response must be carefully measured: \n            too strong would be hypocritical and risks spiraling out of control;\n            too weak risks being mistaken for tacit approval.\n\n\nOn Wed, Jan 19, 2022 at 2:07 PM Kavé Salamatian <kave.sa...@univ-savoie.fr> wrote:\n\ue5d3\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/13004FCF-BDCF-4FD6-8FCC-BEB2C14EAD20%40univ-savoie.fr.', 'Ethan Katz-Bassett': 'Chiming in as one of the people at Columbia Kavé mentioned as using the data....\n\n[I\'m also adding the other people on my MLab project ot the thread, including Kevin who developed the Diamond-Miner tool that Timur mentioned]\n\nI agree with everything that Timur said:\n- Most of the drawbacks of multipath tracing that have been mentioned have been solved or seem to be addressable.\n- I hope you\'ll continue issuing multipath measurements.\n- It seems to make sense to extract (in post processing, when storing the data) a single path measurement from each of those and ""present"" that as the basic traceroute that many users will use without looking at the multipath measurement. The multipath measurements can be in a separate table for those who want them, perhaps with a foreign key to join between the two.\n\nOur most common use case has been when we are working on something related to Internet routing/measurement and need a large set of multipath routes or load balancing routers, to help us test the behavior of our measurements in that setting or to help us interpret those results. It\'s useful to have large sets of such measurements already available (from Timur\'s platform and/or M-Lab) that we can easily use to join with our measurements.\n\nEthan\n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CADXAtJ43xRVxwTgxxPPGgRByki6uYF_f9U03Nn9FtApg0S6f-A%40mail.gmail.com.', 'Lai Yi Ohlsen': 'Hi again,\n\nAs noted by Saied in our follow-up to discuss@ (""Traceroute Format Change RFC Results""), we will continue to collect MDA traceroutes as before and archive them as scamper1 datatype. With this decision, we have some follow-up questions about implementation and are in the process of organizing a meeting with the participants on this thread to discuss these details. \n\nIf you would like to also be included in this discussion re: MDA traceroutes or have recommendations for others to include, please let me know by replying to this email. We are also seeking feedback about the use of our traceroute data more broadly -- please see the thread ""Accessing Traceroute data"" for more information. \n\nThanks! \n\ue5d3'}"
18,21991365889148248625523198713967316102,call-for-traceroute-schema-feedback,"Dec 8, 2021, 7:54:47 AM",Lai Yi Ohlsen,"Hi everyone, 

The M-Lab team is working on BigQuery table schemas for our traceroute data and we want to ensure the data is as easy and useful to work with for the community's research purposes. 

We are looking for 1-2+ current or future traceroute data users to spend some time discussing, reviewing and giving feedback. Please reply directly to this email if you are interested. 

We'll continue to publish updates to our blog as we make progress. 

Take care,  

--
Lai Yi Ohlsen
Director, Measurement Lab
Code for Science & Society","{'Emile Aben': 'Hi!\n\nThe RIPE NCC have a prototype service in the google cloud platform that puts RIPE Atlas traceroutes in BigQuery: https://labs.ripe.net/tools/ripe-atlas-on-bigquery/ripe-atlas-on-bigquery/\nIf it\'s not already on your radar, it would be great to figure out if the same schema would work for your data, and if not what the differences would be.\n\ncheers,\nEmile\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcNSfzYJtswsvdSS%2BROFfUzaNWZSvG-egbS8XGBtDSwRyQ%40mail.gmail.com.'}"
19,245388529069052270012600554473332309964,paris-traceroute-geolocation,"Jan 3, 2018, 1:25:26 PM",Fenwick Mckelvey,"Hi,
We're trying to gather statistics for boomerang or trumpet redirects that involve domestic connections being redirected outside of the origin/destination country. Origin and destination country data is available for clients/server but these statistics don't seem to be calculated per hop for the Paris Traceroute data. The goal is to determine how much traffic leaves the country via boomerang redirection.

I'm curious to know if there is a table containing geodata for paris traceroute data that can be queried or if there is a way to determine the geolocation of paris traceroute hops (origin and destination) using BigQuery. In the past we've used the variable paris_traceroute_hop.src_geolocation.country_code.

Thanks,
Trevor and Fen","{'Nick Feamster': 'We’ve written a paper on this:\nhttps://arxiv.org/abs/1605.07685\n\nWe also have a related paper that looks at the phenomenon specifically in Africa:\nhttps://www.cs.princeton.edu/~arpitg/pdfs/pam14.pdf\n\nThe answer to your question is “no”. Geolocating traceroute data is quite hard. Most of the geolocation services (MaxMind, etc.) are notoriously inaccurate for network infrastructure (routers).\n\nHowever, there are some workarounds, some of which are described in the above paper. The short answer is you often don’t need precise geolocation to characterize tromboning.\n\nIf you need any of the data for this paper, it is available at:\nhttps://ransom.cs.princeton.edu\n\nLet us know if we can help further.\n\nThanks,\n-Nick\n\ue5d3\n> --\n> You received this message because you are subscribed to the Google Groups ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n> To post to this group, send email to dis...@measurementlab.net.\n> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.', 'Fenwick Mckelvey': 'Hi all,\nThanks so much for these sources, especially on geolocation of core routers. Has there been any attempts to operationalize these recent findings, creating a data set of traceroutes with each route geolocated? As a policy scholar, I am trying to engage with the implications of these routing trends and using the Paris Traceroute data was my first attempt to get at the issue.\n\nBest,\nFen\n\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\n> To post to this group, send email to dis...@measurementlab.net.\n> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\ue5d3', 'Ethan Katz-Bassett': ""+Vasilis Giotsas \n\nHi folks,\n\nFew more pointers:\n- New IMC paper on accuracy of geolocation databases for routers:\n(paper) https://conferences.sigcomm.org/imc/2017/papers/imc17-final96.pdf\n(slides) https://conferences.sigcomm.org/imc/2017/slides/router-geo-databases-20171106-wide.pdf\n- For one of our (not yet published) projects, Vasilis (cc'ed) developed a geolocation technique that works by smartly figuring out which RIPE Atlas vantage points (VPs) MIGHT be close to a router, then pinging the router from those VPs and geolocating it if the RTT from one of the VPs is less than 1ms (which given speed of light means that the router can't be very far from that VP). We used it to geolocate the border routers between ASes in a set of traceroutes from 30 Ark vantage points to 360K prefixes, and it worked very well. We could locate 82% of the border router IP addresses to be within 1ms or less of a VP with a known location.  We could not locate 10% of IP addresses because they did not respond to pings, and 8% were responsive but we were unable to find a vantage point within 1ms. Due to Vasilis's very smart vantage point selection, our technique probed each IP address from an average of only 8.3 vantage points in order to find the nearby one.\n- Vasilis built the technique into a service as part of a new RIPE service that uses multiple techniques to provide geolocation results. Unfortunately I can't find a link to it, but hopefully either you can find the link to the service or to the RIPE meeting talk that I believe they gave, or Vasilis can provide a link.\n\ue5d3"", 'Vasilis Giotsas': 'Hi all,\n\nThanks for cc\'ing me Ethan. \n\nThe slides and video from the presentation of the RIPE tool that uses our approach is below:\nhttps://ripe75.ripe.net/archives/video/121/\nThis service is ""beta"", we\'re working on improving many aspects of it but the core idea is the same.\n\nI first presented a preliminary version of this work at the RIPE 73 Hackathon:\nhttps://ripe73.ripe.net/archives/video/1447/\n\nWe\'re currently working on a paper but if you like we can share some more technical details, or if you have a set of addresses to geolocate we can run the code for you.\n\nBest wishes for 2018!\n\nVasileios\n\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n> To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\n> To post to this group, send email to dis...@measurementlab.net.\n> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\ue5d3'}"
20,323955961476139106956476131953543032106,fyi---ripe-atlas-hackathon,"Dec 10, 2014, 7:45:55 AM","Livingood, Jason","May be of interest to many of you here. We at Comcast have announced we are partnering with RIPE NCC to sponsor a RIPE Atlas measurement platform hackathon. Announcement at http://corporate.comcast.com/comcast-voices/comcast-sponsors-internet-measurement-hackathon and details on the hackathon at https://labs.ripe.net/Members/suzanne_taylor_muzzin/ripe-atlas-hackathon-2015.

Regards
Jason",{}
21,285671940450706662566362643145553078284,recent-ndt-results---missing-ndtrace-files?,"Nov 3, 2014, 10:47:35 AM","Livingood, Jason","I looked for recent NDT results at https://console.developers.google.com/storage/m-lab/ndt/2014/10/ on the 25th and 31st. I cannot seem to find .ndtrace files within each archive (only checked a few). Do those files take longer to process or be uploaded?

Thanks
Jason Livingood","{'Livingood, Jason': 'I don’t think “clam up or lawyer up” is good advice here, but I always get a good chuckle from these Paul Wall posts. ;-)\n\nPaul, I think we did figure out via list discussion here that it was a documented M-Lab bug that caused the packet captures to stop and it will be fixed in a future release, which is great news. I was luckily able to get packet captures from someone else in the meantime, covering the time frame as recently as yesterday. It doesn’t scale well to do such one-offs; I much prefer M-Lab’s public data system and really, really appreciate that all their data is public. \n\nAs for discrediting research, far from it! I think M-Lab is an interesting public measurement platform and their blog post finding the prioritization change was a huge find by them. Same goes for CAIDA – I like their work too.\n\nJason\n\nPS – Shameless plug for another public measurement system —> RIPE Atlas. There will be a RIPE Atlas hack-a-thon soon that we’re sponsoring (it may even be announced some time today). In my personal opinion, the more public measurement data out there the better – all the more so that people can better understand how networks really function and future improvements be developed. \n\n\n\ue5d3\n\ue5d3\n--\n\ue5d3', 'Collin': 'We are waiting on the final release of v3.7.0 by the NDT developers, which could be a few weeks; however, I have a commitment from one of our platform engineers to apply the update within three days of its release.\n\ue5d3', 'Paul Wall': 'Colin,\n\nI suggest you heed my usual warning and ""drive slow"" when planning future replies.\n\nWhile Jason\'s newfound interest in the MLAB test results may seem altruistic, there is more than meets the eye: Comcast got called out in the report for running its peering hot, and is now trying to discredit any of the research out there.  Don\'t take my word for it, just talk to any of the other academics they contacted over the past month, i.e. CAIDA.\n\nI\'d suggest that you either clam up or lawyer up.  Let me be clear, there is no possible good that will come from indulging Jason on his requests.\n\nPaul WALL\n\ue5d3', 'Paul WALL': ""http://blog.streamingmedia.com/2014/11/cogent-now-admits-slowed-netflixs-traffic-creating-fast-lane-slow-lane.html\n\nI'm not naming names, but SOMEONE is leaking what's happening here to\nthe press. This is why we can't have good things.\n\nDrive Slow,\nPaul WALL\n\ue5d3"", 'Joe Provo': 'A well known sock puppet whinges on a public mailing list that anyone in the world might read said list? Funny, I thought transparency was a good thing.\nSOMEONE may not want to participate on a public list if they worry about daylight breaking their ""nice things"". Hint: if it is public, it isn\'t a ""leak"".\nCheers,\nJoe\n\n--\nJoe Provo\nNetwork Engineer (Mobile Edition)\nAcquisition NetOps\n317-JZP-0JZP\n\ue5d3'}"
22,192770590283987341999798078909076302180,use-m-lab-open-source-tools-in-your-research---rsvp-for-discussion-*next-wednesday*-march-24,"Mar 18, 2021, 10:46:01 AM",Lai Yi Ohlsen,"Want to get ideas for how to use M-Lab’s open source community tools in your research? Join us next Wednesday, March 27, 2021 from 11am-12pm Eastern for a conversation with researchers who are using M-Lab tools to better understand the Internet in their area of interest. Speakers will include: 

Kevin Chege, Director, Internet Development at the Internet Society and Amreesh Phokeer, Research Manager at AFRINIC who are currently researching the resilience of the African Internet.
Chris Ritzo, Program Management and Community lead at Measurement Lab and Colin Rhinesmith, Associate Professor and Director, Community Informatics Lab at Simmons University who recently finished the Measuring Libraries Broadband Networks project, which studied the broadband performance of public libraries across the US. 

Our casual conversation will cover everything from the technical details of their research to the high level successes and lessons learned. Any M-Lab user who is interested in learning more about how M-Lab’s open source tools can enhance their research is encouraged to join. No level of experience or familiarity with M-Lab is required; all we ask is that participants review and respect our community guidelines. 

If you plan on attending please RSVP to our 2021 community calls and indicate that you’d like to be attended to the “General” meetings. You’ll be sent a Zoom link shortly after. If you have any questions, please feel free to reply to this email directly or write to la...@measurementlab.net. 

--
Lai Yi Ohlsen
Project Director, Measurement Lab
www.measurementlab.net","{'Lai Yi Ohlsen': 'Hi everyone, \n\nQuick reminder that this conversation will happen in a little under 2 hours at 11am Eastern. Please RSVP here for M-Lab Community Calls if you would like to attend and feel free to email me directly if you have any questions or issues accessing the meeting. \n\ue5d3'}"
23,265472089796229680706092464985938589204,hiccup-on-denver-pod?,"Mar 3, 2022, 3:25:20 PM",Glenn Fishbine,"We had some unusual results come back today from testing out of Utah through the Denver pod which were  extremely low.  By any chance is there a way to see if the pod had a hiccup today, or is there a way to see if a pod is up or down?","{'Nathan Kinkade': 'Hi Glenn,\n\nThere are actually 4 ""pods"" (i.e., M-Lab sites) in Denver. Each site has 3 production machines (total of 12 production machines in Denver). The sites are as follows:\n\nden02: Lumen (Level3)\nden04: Zayo\nden05: Telia\nden06: GTT\n\nI would be very surprised to find out that, for any given client, performance would differ between any of the machines at a given site. It would not surprise me, however, if performance differed (possibly substantially) between any of the sites. My best guess would be poor peering between the client\'s ISP and one of the transit providers we use in Denver.\n\nThe first step will be to find out to which of those providers the users are seeing very poor performance. Once you\'ve found the problematic transit provider on the M-Lab side, the next step would be to have the client run some traceroutes to one of the machines at the impacted M-Lab site. If it does indeed turn out that the issue is poor peering, then someone could perhaps reach out to the ISP to let them know of the issue, and to see if there anything the ISP can do about. For small ISPs, there may not be much they can do, likely because of a monetary constraint.\n\nFor an ndt7 test, there is no easy way to force the test to a particular server. For ndt5, someone could run a client locally, and specify the exact server. For now, you could perhaps have any user reporting these disparities run traceroutes to one machine at each M-Lab site in Denver, looking for any that might have a suboptimal or long path. For example, to these hosts:\n\nmlab1-den02.mlab-oti.measurementlab.net\nmlab1-den04.mlab-oti.measurementlab.net\nmlab1-den05.mlab-oti.measurementlab.net\nmlab1-den06.mlab-oti.measurementlab.net\n\nThanks,\n\nNathan\n\n\ue5d3', 'Glenn Fishbine': ""I'm getting new reports about low performance out of the Denver pod.  By example, two consecutive tests showed latency of 21 and 42 ms, and the test results dropped by 50% naturally with the 42 ms.  The raw circuit speed was about 200mbps and the mlab tests came in at around 20.  Unfortunately the reports are coming from folks who can't identify which of the 4 servers was involved.  This seems to be a consistent problem where testing is occurring in Utah.  I'm going to try to get traceroutes to see if the problem can be narrowed down to one of the hops or not, but if you could please take a look again at the status on the servers, I'd appreciate it.  By comparison, tests done on the Chicago pod are never questioned by our users.\n\nIs there an easy way to force angular-route.js to return only the Denver route so I can build up a library of tests that may or may not indicate anything?\n\n\ue5d3"", 'Lai Yi Ohlsen': ""Hi Glenn, \n\nThanks for reporting. The M-Lab team will be at our annual planning meeting for the next 3 days, but we'll respond asap. \n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/de1dad19-5bce-4d88-b4e9-9ac71d88e5f9n%40measurementlab.net.\n\n\n--\nLai Yi Ohlsen\nDirector, Measurement Lab\nCode for Science & Society""}"
24,60480890967638934664955098494156449304,migration-to-the-v2-data-pipeline,"Feb 9, 2022, 3:35:26 PM",Stephen Soltesz,"TL;DR - If you typically use the `measurement-lab.ndt.unified_uploads` or `measurement-lab.ndt.unified_downloads` views, then nothing will change.

In the coming days and weeks, we are updating the ndt5, switch, and tcpinfo schemas, removing obsolete views, and renaming some views in preparation for improving ease of use and documentation.

You can find more details here:
https://www.measurementlab.net/blog/v2-data-pipeline-migration/

Please let us know if you have any questions,
Stephen","{'Stephen Soltesz': 'Update:\nWe will delete the `measurement-lab.ndt.traceroute` view today.\nThe data previously accessible there remains available from `ndt_raw.paris1_legacy` and/or `ndt_raw.scamper1`.\nBest,\nStephen\n\ue5d3', 'Cristina Leon': 'Update:\nIn line with the changes described in the Data Pipeline Migration, on April 25th, we will replace the `aggregate.traceroute` view with `traceroute.scamper1` and `traceroute.paris1_legacy`.\nThanks,\nCristina\n\ue5d3'}"
25,335727298043122805243718115979945807736,ndt7-browser-and-node-upload-inconsistencies,"Jan 12, 2022, 9:17:43 AM",Freddie du Plessis,"We seem to be facing upload speed inconsistencies with the nodejs example run locally, compared to the browser based test: the nodejs gets about 70% the upload speed the browser version does. download speeds are similar.
We have tested this on multiple connections, on multiple platforms and in multiple locations and the inconsistency remains consistent.
Upload servers all report locations close to the tests.
Is there perhaps a reason for this we may have missed or has anyone else experienced the same?","{'Chris Ritzo': 'I think some testing has been happening but will need to defer to our engineering folks to respond with more detail.\n\ue5d3', 'Freddie du Plessis': 'Hi Roberto, Just wanted to let you know we got much better results after implementing your suggestions\n\ue5d3', ""Roberto D'Auria"": 'Hi Freddie,\nGlad to hear that, and thank you for reporting the results!\n\n-Roberto\n\ue5d3'}"
26,142632610210249633831474607557510260312,accessing-traceroute-data,"Jan 27, 2022, 4:30:33 PM",Saied Kazemi,"It seems like there is some confusion about accessing M-Lab's recent traceroutes due to a change in its datatype name.

Up until early September 2021, MDA traceroutes were archived in Google Cloud Storage (GCS) as ""traceroute"" datatype.  Since then, they are archived as ""scamper1"" datatype without any changes to the content.

You can visit the links below to access traceroute archives obtained by the ""host"", ""ndt"", and ""neubot"" experiments (replace $experiment accordingly).

Before 2021-09-11: https://console.cloud.google.com/storage/browser/archive-measurement-lab/$expriment/traceroute
After 2021-09-11: https://console.cloud.google.com/storage/browser/archive-measurement-lab/$experiment/scamper1

We will soon update the Traceroute page on M-Lab's website to cover the name change and also provide links to ""scamper1"" datatype.

Saied Kazemi
Software Engineer",{}
28,22239325527333821215628484473293942618,tcp-packet-capture,"Dec 22, 2020, 5:47:27 AM",Danilo Janković,"Dear all,

Can you please provide me info where I can find TCP packet capture for performed tests?
On website I can see that there is link:
https://console.developers.google.com/storage/browser/archive-measurement-lab/ 
But I don't know which folder to use.

Looking forward to hearing from you soon.

Kind regards,
Danilo. ","{'Matt Mathis': ""Would it be ok for me to use extracting your trace for an example for how to do this for public documentation?\n\nOn Mon, Dec 28, 2020 at 11:25 PM Danilo Janković <danilo.j...@gmail.com> wrote:\nI am collecting data from measurement-lab.ndt.unified_downloads and measurement-lab.ndt.unified_downloads.\nI am trying to find this test for example:\nUUID: ndt-9nm6g_1596683030_000000000077F48B\nlog_time: 2020-12-18 12:24:08.010343 UTC\nnode._instrument:  tcpinfo\n\nBut I can't find it in archive-measurement-lab/ndt/tcpinfo when searching by log time. Can you please help?\n\nThank you in advance.\n\nKR,\nDanilo.\n\n\ue5d3\n\n\n--\nThanks,\n--MM--"", 'Peter Boothe ¶': 'Currently, speed.measurementlab.net uses the ndt5 protocol\n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CALkOHCpyFSVFGKU2aDLUnBBfDsQKPZiXJXda4Fr6DDNUWZCRTg%40mail.gmail.com.\n\n\n--\n\ue5d3', 'Danilo Janković': ""I am collecting data from measurement-lab.ndt.unified_downloads and measurement-lab.ndt.unified_downloads.\nI am trying to find this test for example:\nUUID: ndt-9nm6g_1596683030_000000000077F48B\nlog_time: 2020-12-18 12:24:08.010343 UTC\nnode._instrument:  tcpinfo\n\nBut I can't find it in archive-measurement-lab/ndt/tcpinfo when searching by log time. Can you please help?\n\nThank you in advance.\n\nKR,\nDanilo.\n\n\nOn Mon, 28 Dec 2020 at 19:14, Matt Mathis <mattm...@measurementlab.net> wrote:\n\ue5d3""}"
29,45956492391543279145306262624034192063,"""buffer-is-undefined""-issue-caused-by-possible-dns-problem","Jun 23, 2019, 4:28:20 AM",Ryan Olds,"Greetings, 

I noticed an error in our Sentry.io logs:

""Cannot read property 'slice' of undefined""

NDTjs.prototype.parseNdtMessage = function (buffer) {
  var i,
    response = [],
    bufferArray = new Uint8Array(buffer),
    message =  String.fromCharCode.apply(null,
                                         new Uint8Array(buffer.slice(3)));
  for (i = 0; i < 3; i += 1) {
    response[i] = bufferArray[i];
  }
  response.push(message);
  return response;

Ignore the line numbers, it's from a concatenated JS file. It's the line at https://github.com/ndt-project/ndt/blob/master/HTML5-frontend/ndt-browser-client.js#L152. 

When this happens, I see a request error followed by the error about buffer being undefined.

Error: #1
application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19257 WebSocket connection to 'wss://ndt-iupui-mlab1-sea01.measurement-lab.org:3010/ndt_protocol' failed: Error in connection establishment: net::ERR_NAME_NOT_RESOLVED


Error: #2
NDTjs.createWebsocket @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19257
NDTjs.startTest @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19505
(anonymous) @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:21142
dispatch @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:5227
elemData.handle @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:4879
trigger @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:5131
(anonymous) @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:5861
each @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:371
each @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:138
trigger @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:5860
jQuery.fn.<computed> @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:8984
(anonymous) @ application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19748
sentryWrapped @ helpers.ts:85
application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19208 Uncaught TypeError: Cannot read property 'slice' of undefined
    at NDTjs.parseNdtMessage (application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19208)
    at WebSocket.ndtSocket.onerror (application-1375a8e61a06e7f30b7ec24aca6365067e23adf2a2015ce0d78f5fe6c00c7d12.js:19615)

Error #1 looks like a DNS error. 

I've run dig on two servers we get. The first one is the one we are getting the DNS error, the 2nd work works:

$ dig ndt-iupui-mlab1-sea01.measurement-lab.org

; <<>> DiG 9.11.3-1ubuntu1.1-Ubuntu <<>> ndt-iupui-mlab1-sea01.measurement-lab.org
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 47026
;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1


;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 512
;; QUESTION SECTION:
;ndt-iupui-mlab1-sea01.measurement-lab.org. IN A


;; AUTHORITY SECTION:
measurement-lab.org.    300     IN      SOA     sns-pb.isc.org. support.measurementlab.net. 2019061000 3600 600 604800 300


;; Query time: 31 msec
;; SERVER: 192.168.1.1#53(192.168.1.1)
;; WHEN: Sat Jun 22 23:05:39 DST 2019
;; MSG SIZE  rcvd: 143


ryan@DESKTOP-I28ILK0:~$ dig ndt-iupui-mlab1-sea02.measurement-lab.org


; <<>> DiG 9.11.3-1ubuntu1.1-Ubuntu <<>> ndt-iupui-mlab1-sea02.measurement-lab.org
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 22803
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1


;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 512
;; QUESTION SECTION:
;ndt-iupui-mlab1-sea02.measurement-lab.org. IN A


;; ANSWER SECTION:
ndt-iupui-mlab1-sea02.measurement-lab.org. 300 IN A 63.243.224.11


;; Query time: 31 msec
;; SERVER: 192.168.1.1#53(192.168.1.1)
;; WHEN: Sat Jun 22 23:06:18 DST 2019
;; MSG SIZE  rcvd: 86


It looks like DNS record for dig ndt-iupui-mlab1-sea01.measurement-lab.org isn't set and is causing NDT.js clients to fail when it's used.

Thank you for taking the time to look at this,

Ryan","{'Chris Ritzo': 'Thanks for posting this Ryan. This issue is related to some recent sites being renamed (e.g. sea01 became sea08) to standardize the mapping of IPs to virtual servers across all locations. Currently mlab-ns can sometimes still return FQDNs with the old site name. We are going to fix this soon, likely by EOD tomorrow.\n\nBest,\nChris\n\ue5d3'}"
31,135024801039579120177183105482923091672,neubot,"Feb 20, 2018, 8:10:45 PM",kinga Farkas,"Is M-Lab still collecting Neubot data?  I cannot seem to find any Neubot data after 06/2017.


Thanks,

Kinga","{'Simone Basso': 'I think you are using the old bucket. You should now use:\n\n    https://console.cloud.google.com/storage/browser/archive-mlab-oti/?pli=1\n\nSimone\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.', 'Amreesh Phokeer': 'Hello Simone,\n\nI saw on the Neubot client retirement blog post, that there is an intention to continue the DASH measurement project on the new M-Lab platform.\n<http://www.neubot.org/2019/01/retiring-neubot-client.html>\n\nI\'m currently looking into running video performance measurement from end-user devices and thought I should ask you, if you know of any project tool that could help.\n\nThanks,\n-- \nAmreesh Phokeer\n\nOn Wed, Feb 21, 2018 at 12:46 PM Simone Basso <basso...@gmail.com> wrote:\nI think you are using the old bucket. You should now use:\n\n    https://console.cloud.google.com/storage/browser/archive-mlab-oti/?pli=1\n\nSimone\nIl 21 Feb 2018 4:10 AM, ""kinga Farkas"" <kinga....@gmail.com> ha scritto:\nIs M-Lab still collecting Neubot data?  I cannot seem to find any Neubot data after 06/2017.\n\n\nThanks,\n\nKinga\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\n\n--\nAmreesh Phokeer'}"
32,69922173055784278780725935089174806694,"paristraceroute-has-a-bug,-and-it-causes-some-bad-data","Jan 24, 2018, 8:25:45 AM",Peter Boothe™,"Paris Traceroute has a bug, and it causes some bad data
In December 2017, M-Lab was notified of oddities in the Paris Traceroute data. Upon investigation, a bug in the Paris Traceroute code was identified. The bug caused bad measurement data in 2.7% of the traceroutes since July 2016. 

The M-Lab team is doing development to work around the bug in several ways:
By changing how we call Paris Traceroute to reduce the probability that the bug condition occurs.
By adding more sophisticated bad data detection and elimination code to our parsing of Paris Traceroute data.
By adding monitoring to our parser so that we can know how much of our raw data is affected at any given time.
By reprocessing our historical raw data archives in order to eliminate all bad traceroute data caused by this bug from our BigQuery database

Through disclosures and analyses like these, M-Lab re-confirms its commitment to open data and open science. Our raw data, warts, bugs, and all, is and will be always available ( https://console.developers.google.com/storage/browser/m-lab/), while our processed data (https://bigquery.cloud.google.com/dataset/measurement-lab:public?pli=1) continues to reflect our best understanding of the state of the Internet represented by that raw data.
Read More: The bug and its fixes
The root cause of the reported problem is a design flaw in Paris Traceroute, exacerbated by Rollins, the wrapper script that M-Lab uses to run it. The Rollins wrapper script went into production in first half of 2016 (replacing an older script which had its own flaws).

Every connection made to M-Lab systems triggers a Paris Traceroute to run from the M-Lab server back to the computer that initiated the connection. As the number of simultaneous traceroutes has increased, this has exposed a bug in Paris Traceroute where two independent traceroutes that overlap in time can become intermixed in the resulting Paris Traceroute output.  For example, if we were to simultaneously run a traceroute from server S to clients A and B, the S-A path reported by the tool might contain hops that are exclusive to the S-B path, or it could switch in the middle of Paris Traceroute's output from being the S-A path into being the S-B path. 

In the following example, the output from Paris Traceroute switches without warning from being the output for 
$ paris-traceroute 35.188.101.1
into containing the data for the contemporaneously-run command
$ paris-traceroute 139.60.160.135
The resulting output from the first command (shown below) shows a link that doesn't exist from 216.239.51.185 to 173.239.28.18, on lines 8 and 9 and (worse!) switches without warning into the output from the second command (which we have highlighted in orange, and we have highlighted the suspiciously large RTT in red):

traceroute [(173.205.3.38:33458) -> (35.188.101.1:40784)], protocol icmp, algo exhaustive, duration 14 s
 1  P(6, 6) 173.205.3.1 (173.205.3.1)  0.138/5.405/31.541/11.688 ms 
 2  P(6, 6) xe-1-0-6.cr2-sjc1.ip4.gtt.net (89.149.137.5)  19.090/21.052/24.168/1.898 ms 
 3  P(6, 6) as15169.sjc10.ip4.gtt.net (199.229.230.134)  19.105/19.611/21.314/0.796 ms 
 4  P(6, 6) 108.170.243.13 (108.170.243.13)  19.872/20.275/20.931/0.446 ms 
 5  P(6, 6) 209.85.246.206 (209.85.246.206)  20.092/20.545/21.096/0.331 ms 
   MPLS Label 697177 TTL=1
 6  P(6, 6) 209.85.248.127 (209.85.248.127)  53.493/54.490/57.796/1.493 ms 
   MPLS Label 638493 TTL=1
 7  P(6, 6) 216.239.47.251 (216.239.47.251)  52.755/56.170/67.922/5.386 ms 
   MPLS Label 402431 TTL=1
 8  P(6, 6) 216.239.51.185 (216.239.51.185)  52.455/52.652/52.981/0.228 ms 
 9  P(6, 6) csd180.gsc.webair.net (173.239.28.18)  4802.776/4803.621/4807.622/1.790 ms 
10  P(6, 6) 173.239.11.1 (173.239.11.1)  66.509/66.524/66.561/0.018 ms 
11  P(6, 6) 173.239.57.74 (173.239.57.74)  66.634/69.047/72.354/2.442 ms 
12  P(6, 6) 139.60.160.1 (139.60.160.1)  67.066/70.367/72.034/2.327 ms 
13  P(6, 6) 139.60.160.135 (139.60.160.135)  62.542/64.001/66.941/2.020 ms

This is obviously quite worrying, so the M-Lab team set about investigating why this is happening, how to prevent (or at least reduce the frequency of) its occurrence, and how to filter or annotate bad data in our database (while, of course, preserving the original raw data in our historical archives).

Paris Traceroute relies on a single 16 bit ""tag"" field to disambiguate returning ICMP messages, and that tag is essentially the output of a hash function. This single field is used both to identify which request packet (what initial TTL) and which session it belongs to. When there are two overlapping tests, it is possible to have a collision of tag values, exactly analogous to a hashtable collision. When one test starts first, that test runs for a bit, and then after the second (colliding) test starts, spurious data begins to arrive to the first test. The symptoms of this are that, in the middle of the first test, the results of the second test begin to pollute the results of the first. Just like with hash tables, the incidence rate of this bug scales up with usage. Sites with minimal numbers of connections saw no collisions, and sites with large numbers of connections saw an increased percentage of tests affected. 

To prevent the collection of bad data, we have created a workaround in our Paris Traceroute wrapper to bring down the expected number of incidents and that workaround will be deployed to M-Lab servers soon.

To prevent the inclusion of any bad data in our BigQuery tables, we are porting the detection code from a standalone tool into our parser. We are also adding monitoring to measure the error rates going forwards.  We will soon be reparsing our historical archives, and over the next quarter as all our historical archives get reprocessed, all bad data caused by this bug should be eliminated from or tagged within our BigQuery database. M-Lab's raw data will remain untouched, as our raw data reflects the data we actually got from M-Lab servers, not the data we wish we had gotten from M-Lab servers.

Once remediation is completed, we will provide a longer write up going in to more depth about the issue and the remediation.

Thanks to Amogh Dhamdhere for flagging the Paris Traceroute data issue!

--
ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.
Peter Boothe - Coder at Google, working in support of M-Lab",{}
33,294701521728198646834692158900618282923,internet-speed-test,"Jan 10, 2017, 7:07:18 PM",yahoo...@gmail.com,"Hay, I'm trying to understand why I'm getting two different results in my internet downloaded test using two deferent software from my web browser. One test result is 100mbps and another test using a deferent app is 30mbps. I'm not sure which test is correct. I'm using Ookla and other is http://www.bandwidthplace.com/","{'Juan C. Marin': 'Go to fast.com and try again there is a diffrence between the server you use to test, you should take the closest where you are.\n\ue5d3', 'Chris Ritzo': 'Which test is correct is sort of the wrong way to look at this. Ookla, fast.com, etc. and NDT are all correct. They do measure different paths or distances though, which is one reason for differences in measured speeds. We have an FAQ about this explaining the differences with respect to NDT hosted on M-Lab. When you run NDT M-Lab\'s load balancer directs your browser to conduct the test against our closest server, similar to Juan\'s comment about using the closest fast.com server. The difference is whether that server is on the edge of your ISP\'s network, or outside it as M-Lab\'s servers are. \n\n Chris Ritzo\n Senior Technologist, Open Technology Institute @ New America\n 740 15th Street NW, Suite 900\n Washington, DC 20036     \n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.', '☕Peter Boothe': 'Expanding on Chris\' answer: There is not a great unified definition of ""Internet speed"", so all tests test something slightly different.  Even worse, the speed you get will also be dependent on where the test server is located, so even the same test can give you different results depending on how far away the test server is - farther servers will tend to give lower results. Note, however, that this far-away server might be giving you a more accurate measurement if the applications you care about are also served from far away.\n\nI wish there was a simple answer, but unfortunately the truth about Internet speed is as complicated as the Internet.\n\n  -Peter\n\ue5d3\n--\nᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.'}"
34,87242283122997145992627163199736813492,bigquery-data-is-outdated,"Feb 10, 2017, 10:29:12 AM",Ben,"The documentation at https://www.measurementlab.net/data/ suggests that the data in both BigQuery and CloudStorage are updated every 24 hours. I see new data in CloudStorage, but I'm not seeing anything more recent than Sept 6, 2016 in BigQuery, based on this query:

>> SELECT MAX(SEC_TO_TIMESTAMP(log_time)) FROM [plx.google:m_lab.paris_traceroute.all]
> 2016-09-06 23:59:47 UTC 

Is the BigQuery data still getting updated, and at what frequency?","{'Kim Prince': 'Sorry Ben, I have not tried the traceroute data.\n\ue5d3', 'Ben Dowling': ""You could try something like this:\n\n> WHERE SUBSTR(STRING(SEC_TO_TIMESTAMP(log_time)), 0, 7) = '2016-09'\n\nNot sure how it compares in terms of efficiency, but works for me.\n\ue5d3"", 'Xiaohong Deng': ""Hi Chris,\n\nThat's great.\n\nKeep us posted. Thank you.\n\nAll the best,\nXiaohong \n\ue5d3"", 'Chris Ritzo': 'Hello Ben,\n\nThanks for checking in on this issue. The short answer is that, yes, the issue has been resolved. We are reviewing a blog post now which we will post soon which discusses the issue in detail, what was done to resolve it, as well as communicate expectations about Paris Traceroute data between June 2016 and Feb 2017.  We will also post that content here on M-Lab discuss. \n\nBest,\nChris\n\n Chris Ritzo\n Senior Technologist, Open Technology Institute @ New America\n 740 15th Street NW, Suite 900\n Washington, DC 20036     \n\n\ue5d3', 'Ben': 'I\'m seeing new data in the tables, so it looks like this has been resolved! It doesn\'t look like all of the old data has been backfilled though, based on this query:\n\nSELECT SUBSTR(STRING(SEC_TO_TIMESTAMP(log_time)), 0, 7) AS month,\nCOUNT(1) AS total_traces\nFROM\n  [plx.google:m_lab.paris_traceroute.all]\nGROUP BY 1 ORDER BY 1 DESC LIMIT 10\n\nWill the missing rows from Sept - Jan eventually get added?\n\nThanks, Ben\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\ue5d3', 'Greg Russell': 'It looks like your dates are selecting 13 months instead of 1 month.  I would have thought that should still work, but I\'m relatively new to the system.\n\nFYI, we are debugging the more general problems of paris traceroute collection and processing, and will provide an update soon.\n\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n--\nGregory |  Russell |  g...@google.com |  123-458-7890\nhttps://memegen.googleplex.com/4558349824688128', 'Collin Anderson': ""Hi Xiaohong,\n\nThe web100_log_entry.log_time propriety is not marked in PT's records, but log_time is. The issue you are encountering is that web100_log_entry.log_time is returning null as a result, which then falls back on the FORMAT... functions to the start of the Unix epoch. If you use log_time instead, which you were in the YEAR() queries, everything should work fine.\n\nCordially,\nCollin\n\ue5d3""}"
36,72480085655947346296183080471687825206,google-ndt-dataset,"Feb 9, 2015, 7:34:08 PM",raghuveer sj,"Hi,

Let me take a step back to explain you my requirement. The POC am working on is a open source project and as you suggested in one of the other email we cannot use google bigdata platform because of the operational costs, learning curve and service time hits, so i plan to bring NDT dataset into our network.

To do this for datasets before 2014, i had created a service which did the part of ETL but after 2014 the format of the tar files have changes.

1. Is there any library that can parse this, kindly name it.

2. I see most of the zip files dont have ndttrace files. How do i extract the missing information. For example in meta files sometimes source or destination IP is missing i know that it happens due to some issue in transmission between server and client and i would expect it to be a normal case. So in such situation how can we find the missing information.

I am already 3 weeks late kindly help me out.


Regards,
Raghuveer","{'Michael Lynch': ""Hi Raghuveer,\n\nI want to query for NDT dataset. Can you kindly suggest how to load it in https://console.developers.google.com/project/bigdata-calsoft/storage/browser?authuser=0because its asking to register for a free trial first. Also am unable to create my own dataset. Kindly suggest how i can create one.\n\nYou don't need to copy the M-Lab dataset into your own to access the NDT data. You can query against our dataset directly. Creating your own dataset does require a credit card because BigQuery charges for storing your own data, but, again, this is not necessary for accessing our data.\n\nI've created a set of screenshots that walk through the process of querying our data. Can you follow these and let me know at which point you run into issues?\n\nThanks,\nMichael\n\ue5d3"", 'raghuveer sj': 'Thanks a lot, i will try using telescope project and will see where i can reach.\n\nthanks again\n\ue5d3'}"
39,323929757235760705717841317911755818152,"ndt7-client-go-client-""-server""-option-error","Apr 27, 2022, 8:12:46 AM",frog...@gmail.com,"Hi,
It looks like the -server option in ndt7-client-go is not working.
I can run the test using default setting.
~/godir/src/ndt7-client-go/cmd/ndt7-client$ go run main.go
download in progress with ndt-mlab3-dfw02.mlab-oti.measurement-lab.org
Avg. speed  :   463.9 Mbit/s
download: complete
upload in progress with ndt-mlab3-dfw02.mlab-oti.measurement-lab.org
Avg. speed  :   194.7 Mbit/s
upload: complete
         Server: ndt-mlab3-dfw02.mlab-oti.measurement-lab.org
         Client: 2001:48d0:101:501:da9e:f3ff:fe86:e62d
        Latency:    46.0 ms
       Download:   463.9 Mbit/s
         Upload:   194.7 Mbit/s
 Retransmission:    0.15 %


However, I got handshake errors when I try to run NDT again using the same server.
~/godir/src/ndt7-client-go/cmd/ndt7-client$ go run main.go -server=ndt-mlab3-dfw02.mlab-oti.measurement-lab.org
download failed: websocket: bad handshake

download: complete
upload failed: websocket: bad handshake

upload: complete
exit status 2

What should I put into the server option?

Thank you for your help.
Ricky",{}
40,262218769226977878047905258210373051892,unconscious-physiological-effects-of-search-latency-on-users-and-their-click-behaviour,"Apr 20, 2022, 7:19:01 AM",Dave Taht,"""As the response latency of the search engine reaches higher val-ues,
the arousal and the negative valence of the experienced emotions
increase as well. Although those effects did not produce changes on
the *self-reported data*, their impact on users’ physiological
responses was evident. Thus, even if such short latency increases of
under 500ms are not consciously perceived, they have sizeable
physiological effects.""

GOOD paper:

https://www.researchgate.net/publication/282009221_Unconscious_Physiological_Effects_of_Search_Latency_on_Users_and_Their_Click_Behaviour

3sec is the maximum pain point....



--
I tried to build a better future, a few times:
https://wayforward.archive.org/?site=https%3A%2F%2Fwww.icei.org

Dave Täht CEO, TekLibre, LLC",{}
42,78378969283703446491874726967959763416,are-community-calls-recorded-anywhere?-+-quality/performance-disclosures,"Jan 19, 2022, 1:20:17 PM",marin...@gmail.com,"Hi everyone!

As the FCC prepares to kick off a comment period around broadband disclosure labels and what to include in them to better inform US consumers[1], I'm interested in what ideas have been floated in this community around the topic of broadband performance.

I noticed some community calls have touched on the issue and I'm curious if the recordings get posted anywhere.

Also, if anyone knows of any additional resources (papers, talks, webinars, people, etc) around communicating quality of service/quality of experience metrics to consumers and can point me to them, I'd appreciate it!

[1] https://docs.fcc.gov/public/attachments/DOC-378983A1.pdf","{'Lai Yi Ohlsen': 'Hello! \n\nThank you for starting this conversation, I\'m looking forward to hearing the community\'s thoughts on the topic. \n\nRegarding our community call recordings -- we did not record the calls at first in an effort to keep things casual, but did begin to record in August 2021. Here\'s the video of Latency, Bufferbloat and Responsiveness with Matt Mathis, Christophe Paasch and Dave Taht, who discussed metrics for broadband performance alternative to bandwidth (which some feel has been overemphasized/optimized for). And more recently, Dave Clark and Sara Wedeman from MIT discussed their paper Measurement, Meaning and Purpose which explored the M-Lab NDT dataset and its ability to assess broadband performance. The video of that call has not been uploaded yet, but I will post to this discuss@ list when it has.  \n\nFrom an academic, network research perspective, you might find the papers of the recent IAB workshop on Network Quality interesting and relevant. The summary of that event is quite useful. And from a digital inclusion perspective, you might be interested in joining the Marconi Society-led Broadband Mapping Coalition, a network of orgs advocating for the use of open data in broadband planning. \n\nFor M-Lab data specifically, we\'ve written a set of best practices to help guide the use of our data in broadband advocacy and policy work. We\'ve also written a guide to NTIA\'s Indicators of Broadband Need map for researchers trying to make sense of the similar but quite different methodologies that the map draws upon. More broadly, as the national conversation around broadband performance continues to unfold, M-Lab will continue to be a resource by providing open Internet performance data and aim to adapt that resource as needed. Whether that\'s in new analyses of our current data or additions to the measurements that we host, we\'ll be listening for feedback about how we can best contribute. \n\nHope this helps, happy to provide more detail. \n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/2d7d5080-a429-447c-9967-1882e3691902n%40measurementlab.net.\n\n\n--\nLai Yi Ohlsen\nDirector, Measurement Lab\nCode for Science & Society', 'Christine Parker': "" While broadband pricing transparency/speeds are the focus of this report from the Institute for Local Self Reliance, it does discuss some important points about broadband labels that I think will be applicable in regards to broadband performance.\n\n\n\nChristine Parker, PhD (she/her)\nGIS & Data Visualization Specialist | Community Broadband Networks\nInstitute for Local Self Reliance\n\nMy working hours may not be your working hours. Please don't feel obliged to reply to this email outside of your normal working hours.\n\n\n\ue5d3\n\ue5d3\n--\n\ue5d3"", 'Livingood, Jason': 'A few additional thoughts… IMO each ISP will need to choose (and be prepared to defend) the measurement methodology & system behind each specific performance line item. I would guess that such data will usually tend to come from measurement agents installed in user CPE (or device) or via a sample of users that have installed extra probes (a la the FCC MBA program). But perhaps also some can be pulled directly from the FCC MBA data or other independent sources.\n  Beyond that, I am not sure the community yet has consensus on a common approach to measuring each item and there is perhaps some incremental work to do there. I’m giving a little thought to how to potentially do so (with broad involvement – not just ISPs) – anyone interested can feel free to ping me 1:1 off-list.\n  Jason\n\ue5d3', 'marin...@gmail.com': ""Many thanks for all the resources and thoughts being shared.\n\nThe current FCC proposal would have ISPs share the following info with consumers on performance metrics by speed service tier:\n\n- Typical speed downstream (Mbps)\n- Typical speed upstream (Mbps)\n- Typical latency (Milliseconds)\n- Typical packet loss (%)\n\n(you can view the entire proposed label in appendix B of the PDF I mentioned previously--it's meant to look like a 'nutrition facts' label)\n\nThe Latency, Bufferbloat and Responsiveness discussion was really interesting and raised some questions for me around using these traditional metrics. I'm currently making my way through the IAB workshop papers in search of additional perspectives. Thanks so much for all the reading material suggestions, I will do my best to read through it all.\n\n-Marina\n\ue5d3""}"
43,68738023340061410670531872391207883633,blog-posts-&-community-call-updates,"Jul 22, 2021, 2:17:02 PM",Lai Yi Ohlsen,"Hi all, 

Hope you're doing well and staying safe. Writing to share some M-Lab updates from the months of June and July. 

Blog posts
M-Lab's Murakami Tool - Supporting Structured Research Data Collection from the User Perspective discusses the work of the MIRA project, a joint initiative of Internet Society and AFRINIC, and their use of Murakami, an open source tool which offers three key features: a method for collecting standardized data; automatic, recurring measurements; and support for multiple measurement methodologies. Read more if you'd like to use Murakami in your research or help develop the tool in the future. Thank you to the MIRA team for your collaboration and IMLS for the project's initial support.  

NDT Data in NTIA Indicators of Broadband Need is a follow-up to the release of the NTIA Indicators of Broadband Need, a needed and welcome contribution to US broadband mapping. In this blog post, we discuss the inclusion of data from our Network Diagnostic Tool (NDT) in the NTIA map and dig into the detail of each dataset provided in the Indicators of Broadband Need map. The post gives readers a deeper understanding of the differences and context to the various datasets in the NTIA Indicators of Broadband Need Map, as well as our understanding of how each relates to the 25/3 national broadband standard. Thanks to NTIA for including M-Lab data in the map as well as Benton Institute for including our article in your newsletter. 

And on June 29th, 2021 we published an update about recent developments to ndt7, including fixes for Safari and Firefox integrations and more. Thank you to all the community contributors who helped with the core contribution team with these updates. 

Community Calls
According to the schedule we released at the beginning of the year, we are scheduled to host an Internet Research call next week on Wednesday, July 28th, 2021. This call will be rescheduled to a date TBA. As with all our calls, it will take place on a Wednesday at 11am Eastern. If you have received invites to previous calls, you will receive an invite once it is scheduled. If you have not already RSVP'd to our calls, you can do so here. 

That's all for now -- have a great weekend! Talk to you soon when I inevitably remember other updates I forgot to put in this email. As always feel free to reach out with any questions, either to the list or me directly. 

--
Lai Yi Ohlsen
Director, Measurement Lab
Code for Science & Society","{'Glenn Fishbine': ""Thanks Chris, we have a work-around for now so this is not urgent.\n\nI don't have all the information but here's what I do have.\n\nDate was 2022-01-11 around 10 a.m. central\nASN AS20057\nIP 107.62.178,208\nmcc 310\nmnc 16\nActual upload speed was probably < 15mbps\nActual download speed was probably > 17 mbps\n\ntwo test summaries for an IPhone 11 below::\n\nSafari:\nMiami\n0.0     download\n1366.85 upload\n-ms latency\nNaN% retransmission\n  Chrome:\nMiami\n1.0     download\n1300.55 upload\n-ms latency\nNaN% retransmission\n\ue5d3"", 'Chris Ritzo': ""Thanks for reporting these issues.\n\nI'm not sure if this is the exact issue you're users are experiencing, but as you may know the M-Lab engineering team identified some issues with iOS browsers' last June, which were documented in this blog post. Two issues were both related to upstream issues with Safari's WebKit implementation of websockets. Our team will be submitting bug report(s) to Apple soon. Both Safari and Chrome on iOS are affected. Apple now requires apps to use WebKit for accessing the web, so basically Chrome on iOS uses the same engine as Safari, and inherits this problem.\n\nIf you were able to capture JavaScript console logs from an iOS device that is experiencing this, our team could confirm if the above mentioned bugs are the cause. Additionally, if you are comfortable sharing more details about your testing device (date/time of tests, public IP address of the iOS device when the tests were run, or if you have it the UUID of the test result provided back from our servers) this might help our team further diagnose the issue, and potentially provide more detail for the bug report.\n\nPlease feel free to email sup...@measurementlab.net with the above information if you prefer to not post it here in our public group.\n\n--\nChris Ritzo (he/him)\nUser Experience Advocate & Data Support Specialist, Code for Science & Society\n\ue5d3"", 'David Sandel': 'Hi Glenn,\n\nWe had the same problem for all iPhones running\nM-Labs NDT. This was for WiFi or ATT mobile.\n\ntesttype=BPS seems to have solved the problem\nfor the moment across all iPhones and Apple Pads we tested.\n\nSent from my iPhone\nDavid Sandel \niNeighborhoods.us\nSt. Louis, MO.\nAustin, TX.\nEinsteinDesigns.center\n314-435-3658\n\n\nOn Jan 12, 2022, at 11:17 AM, Glenn Fishbine <glen...@gmail.com> wrote:\n\n\ue5d3\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CABs%2BJ_AtS__2DtF7Tu%3DOA2Mm%3DM8Z8QQqVaWe6GSp4%2BSAMdUFCg%40mail.gmail.com.'}"
44,296045374971162488196170477998299909651,"call-for-m-lab-research-fellows---due-monday,-december-6","Nov 15, 2021, 12:31:40 PM",Lai Yi Ohlsen,"Hi everyone, 

I am pleased to share M-Lab's new funding opportunity for researchers, generously supported by Internet Society. Details below, and posted on our website. Please distribute to others who might be interested and feel free to reach out to ap...@measurementlab.net with any questions. 

Link to share: https://bit.ly/325L1OT
Tweet to share: https://twitter.com/MeasurementLab/status/1460306745578995712

Looking forward, 

Lai Yi Ohlsen
Director, Measurement Lab
Code for Science & Society

--

Open Call for M-Lab Research Fellows - due Monday, December 6

How can M-Lab’s data and platform be used to improve the experience of the Internet for the end user? 

Measurement Lab is seeking three Research Fellows to expand Internet performance research beyond the measurement and optimization for bandwidth. Fellows will utilize M-Lab’s longitudinal, open dataset and/or platform to identify under-recognized Internet performance metrics that can be used to improve end user performance. 

Each fellow will be awarded 30,000 USD, paid directly to the researcher, and will be responsible for documenting the process and outcome of their research as well as sharing their work at a workshop at the end of the fellowship. The fellowship will begin in January 2022 and complete in May 2022. The M-Lab team will provide data analysis support, research guidance and community networking opportunities. 

Topics of interest include but are not limited to:
Relation between QoE and network metrics like bandwidth/latency/loss
Novel metrics that can be computed on existing NDT data
New measurements/experiments that could be deployed on M-Lab to diagnose network bottlenecks
Characterizing paths measured by M-Lab clients; stability of paths, relation to paths of interest (eg., paths to content) or network characterization 
Proposals for new experiments to be hosted on the M-Lab platform
Identification of biases in M-Lab data 
Implementing ideas introduced during M-Lab’s Community Call on Latency, Bufferbloat and Responsiveness and/or the IAB workshop on Network Quality

Eligibility:
Students, post docs and independent researchers are welcome to apply.

Important dates:
Proposal due: December 6, 2021
Fellowship start: January 1, 2022
Mid-fellowship progress check-in: March 15, 2022
Fellowship end: May 30, 2022
Workshop: May 2022, exact date TBD

To apply please provide: 
 a two page (12pt single space) description of the research project, including a brief timeline for completing the work, 
 the applicant’s CV 
a brief summary of the applicant’s experience & background. 
Applications will be reviewed for feasibility of the project plan, qualifications of the researcher and demonstrated understanding and relevance to the stated goals of the fellowship. 

Applications should be sent to ap...@measurementlab.net by December 6, 2021 23:59 in the applicant’s local time zone.

The M-Lab Research Fellowship is made possible by the generous support of Internet Society. ","{'Lai Yi Ohlsen': 'Thank you to everyone who submitted an application! If you did not receive a confirmation e-mail in response, please reach out to ap...@measurementlab.net. \n\ue5d3'}"
45,3064177456069070130080355351351006749,mile-high-video-2022---final-call-for-contributions-due-oct-22nd,"Oct 19, 2021, 6:14:04 AM",Cise Midoglu,"Dear all, 
please find below the final call for contributions for MHV'22 (deadline extended to Friday). The venue is most appropriate for multimedia topics that can benefit from an industry-academia collaboration, and measurements + insights from the networking community would be of great interest. If you have any questions, please do not hesitate to contact the TPC co-chair Christian Timmerer (christian...@aau.at). 
Best,
Cise

*

ACM Mile High Video (MHV) 2022
March 1-3, 2022, Denver, CO

Web site: https://mile-high.video/call.php
Abstract submission deadline: Oct. 22, 2021
Prospective speakers are invited to submit an abstract (i.e., approx. 400 words or up to one page using the ACM template) that will be peer-reviewed by the ACM MHV technical program committee (TPC) for relevance, timeliness and technical correctness.

After running as an independent event for several years, starting with 2022, Mile High Video (MHV) will be organized by the ACM Special Interest Group on Multimedia (SIGMM) to grow further. ACM MHV’22 will establish a unique forum for participants from both industry and academia to present, share and discuss innovations from content production to consumption.

ACM MHV’22 welcomes contributions from industry to share real-world problems and solutions as well as novel approaches and results from basic research typically conducted within an academic environment. ACM MHV’22 will provide a unique opportunity to view the interplay of the industry and academia in the area of video technologies.

ACM MHV contributions are solicited in, but not limited to the following areas:
• Content production, encoding and packaging
• Encoding for broadcast, mobile and OTT, and using AI/ML in encoding
• New and developing audio and video codecs
• HDR, accessibility
• Quality assessment models and tools, and user experience studies
• Workflows
• Virtualized headends, cloud-based workflows for production and distribution
• Redundancy and resilience in content origination
• Ingest protocols
• Ad insertion
• Content delivery and security
• Developments in transport protocols and new delivery paradigms
• Protection for OTT distribution and tools against piracy
• Analytics
• Streaming technologies
• Adaptive streaming and transcoding
• Low latency
• Player, playback and UX developments
• Content discovery, promotion and recommendation systems
• Protocol and Web API improvements and innovations for streaming video
• Industry trends
• Advances in interactive and immersive (xR) video
• Video coding for machines
• Cloud gaming and gaming streaming
• Provenance, content authentication and deepfakes
• Standards and interoperability
• New and developing standards in the media and delivery space
• Interoperability guidelines

Prospective speakers are invited to submit an abstract (i.e., approx. 400 words or up to one page using the ACM template) that will be peer-reviewed by the ACM MHV technical program committee (TPC) for relevance, timeliness and technical correctness.

The authors of the accepted abstracts will be invited to optionally submit a full-length paper (up to six pages + references) for possible inclusion into the conference proceedings. These papers must be original work (i.e., not published previously in a journal or conference) and will also be peer-reviewed by the ACM MHV TPC.

Accepted abstracts and full-length papers will be presented at the ACM MHV conference and will be published in the conference proceedings in the ACM Digital Library.

All prospective ACM authors are subject to all ACM Publications Policies, including ACM's new Publications Policy on Research Involving Human Participants and Subjects.

How to Submit an Abstract

Prospective authors are invited to submit an abstract here: https://mhv22.hotcrp.com/

Important Dates
• Abstract submission deadline: Oct. 22, 2021
• Notification of abstract acceptance: Nov. 15, 2021
• (Optional) Full-length paper submission deadline: Nov. 30, 2021
• Notification of full-length paper acceptance: Dec. 31, 2021
• Camera-ready submission (abstracts/full-length papers) deadline: Jan. 31, 2022

ACM MHV’22 Program Chairs
• Christian Timmerer (AAU; christian.timmerer AT aau.at)
• Dan Grois (Comcast; dgrois AT acm.org)

ACM MHV'22 Program Committee Members
• Florence Agboma (Sky, UK)
• Saba Ahsan (Nokia, Finland)
• Ali C. Begen (Ozyegin University, Turkey)
• Imed Bouazizi (Qualcomm, USA)
• Alan Bovik (University of Texas at Austin, USA)
• Pablo Cesar (CWI, The Netherlands)
• Pankaj Chaudhari (Hulu, USA)
• Luca De Cicco (Politecnico di Bari, Italy)
• Jan De Cock (Synamedia, Belgium)
• Thomas Edwards (Amazon Web Services, USA)
• Christian Feldmann (Bitmovin, Germany)
• Simone Ferlin-Reiter (Ericsson, Sweden)
• Carsten Griwodz (University of Oslo, Norway)
• Sally Hattori (Disney, USA)
• Carys Hughes (Sky, UK)
• Mourad Kioumgi (Sky, Germany)
• Will Law (Akamai, USA)
• Zhu Li (University of Missouri, Kansas City, USA)
• Zhi Li (Netflix, USA)
• John Luther (JW Player, USA)
• Maria Martini (Kingston University, UK)
• Rufael Mekuria (Unified Streaming, The Netherlands)
• Marta Mrak (BBC, UK)
• Matteo Naccari (Audinate, UK)
• Mark Nakano (WarnerMedia, USA)
• Sejin Oh (Dolby, USA)
• Mickael Raulet (ATEME, France)
• Christian Rothenberg (University of Campinas , Brazil)
• Lucile Sassatelli (Universite Cote d'Azur, France)
• Tamar Shoham (Beamr, Israel)
• Gwendal Simon (Synamedia, France)
• Lea Skorin-Kapov (University of Zagreb, Croatia)
• Michael Stattmann (castLabs, Germany)
• Nicolas Weil (Amazon Web Services, USA)
• Roger Zimmermann (NUS, Singapore)

ACM MHV Steering Committee Members
• Balu Adsumilli (YouTube, USA)
• Ali C. Begen (Ozyegin University, Turkey), Co-chair
• Alex Giladi (Comcast, USA), Co-chair
• Sally Hattori (Walt Disney Studios, USA)
• Jean-Baptiste Kempf (VideoLAN, France)
• Thomas Kernen (NVIDIA, Switzerland)
• Scott Labrozzi (Disney Streaming Services, USA)
• Maria Martini (Kingston University, UK)
• Hatice Memiguven (beIN Media, Turkey)
• Ben Mesander (Wowza Media Systems, USA)
• Mark Nakano (WarnerMedia, USA)
• Madeleine Noland (ATSC, USA)
• Yuriy Reznik (Brightcove, USA)
• Tamar Shoham (Beamr, Israel)

--
Cise Midoglu
Simula Research Laboratory
https://www.simula.no",{}
46,83701010357939907295526621300529441882,non-aggregated-ndt-data-from-m-lab’s-bigquery,"Aug 3, 2021, 7:46:03 AM",Lizaveta Radzevich,"Hi,
I’m trying to access non-aggregated NDT data from M-Lab’s BigQuery. I’ve tired on public datasets before (set up a project, create service account and key), but it seems like I’m missing some steps to be able to get NDT data. I think you need to set up a service account for me and add it to your access group. You can use my account from discussion group: lizaveta...@gmail.com. I’ll attach code and error message I’m getting, so it would be nice if you can let me know if my theory about service account is wrong!
Thank you,
Lizaveta","{'Chris Ritzo': ""Hi Lizaveta,\nI'm not super familiar with the GIDs in the gadm.org tables. However, Maxmind provides a CSV that maps FIPS to ISO 3166 on this page: https://dev.maxmind.com/geoip/whats-new-in-geoip2\n\nM-Lab annotates NDT test data with the ISO 3166 standard now, but older vintages were annotated with FIPS. See this post for more details: https://www.measurementlab.net/blog/evolution-of-annotations/\n\nBest, Chris\n\ue5d3"", 'Bradley Kalgovas': 'Hi Chris,\n\nWe want to obtain the data for each test in the from the measurement-lab.ndt.unified_downloads table. However, when we are trying to get the data out we are getting errors that the extract size is too big to load into google drive. Is it possible to have 15 mins on the phone to talk on how to extract it without having to pay $2k for some slots. Thanks!\n\nBradley\n\ue5d3', 'Lizaveta Radzevich': 'Hi Chris,\n\nQuick question regarding US GIDs in global_gadm36_2 table. I want to map those codes to FIPS, is there any way to do it?\n\ue5d3', 'Gregory Russell': 'Looks like percentile_cont is also supported, but perhaps not the syntax in your query.\n\nhttps://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators#percentile_cont\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/cd736098-9f68-4a0a-8493-09a6f50ee207n%40measurementlab.net.'}"
47,289541994522798686097305584493141292054,"latency,-bufferbloat,-responsiveness-&-internet-quality---discussion-(next)-wednesday,-august-25","Aug 18, 2021, 11:40:50 AM",Lai Yi Ohlsen,"Internet performance is often measured by download and upload “speed” but there are other metrics that can help measure connectivity, such as latency, bufferbloat and a more recently discussed metric: responsiveness. Join us next Wednesday, August 25, 2021 from 11am-12:30pm Eastern for a conversation with Internet Measurement researchers with expertise and interest in each of these metrics including: 

Matt Mathis, Senior Research Scientist, Measurement Lab, Google
Matt Mathis has been working on Internet performance research and development since 1990.  His work includes measurement tools, models and improvements to protocol standards.  He participated in MLab from its inception in 2009, and came to Google in 2010 to find a larger platform on which to stand.

Dave Taht 
Dave Taht and members of the Bufferbloat Project have made vast improvements to the Internet and to WiFi, as described in the book, “Bufferbloat and Beyond”. He has lectured at Stanford and MIT, NANOG, RIPE, USENIX, IEEE, and the IETF. His R&D work on AQM/FQ technologies on the Internet have been integrated into the Linux, OSX, and IOS kernels, cable modems, and many WiFi chips, and he has created and managed Internet improvement initiatives such as CeroWrt, make-wifi-fast, cake, and more. From these projects we have seen major innovations in congestion control algorithms such as BQL, FQ_codel, FQ_pie, and BBR. 

Christoph Paasch, Networking Architect, Apple
Christoph Paasch has been working on transport layer networking since 2010. Focusing on extensions to TCP, like Multipath TCP or TCP Fast Open. From specification (in the case of MPTCP) and research to the implementation and large scale deployments at Apple. Lately he has shifted his focus on improving the network properties that really matter to the end-user experience by exposing measurement tools to raise awareness to these issues. ""Responsiveness under working conditions"" being now the first primary target.

The conversation will be moderated by Lai Yi Ohlsen, Director of Measurement Lab, a fiscally sponsored project of Code for Science & Society. 

Our casual conversation will include discussion about the significance of these metrics as well as the challenges their collection presents. We welcome audience questions, answers, challenges, and discussion. The discussion will be technical but no familiarity with M-Lab is required; all we ask is that participants review and respect our community guidelines. 

If you have previously RSVP’d to our community calls, you should have already received a calendar invite with a Zoom link included. If not, please reply directly to this email. 

If you have not previously RSVP’d, but would like to attend, please do so here and indicate that you’d like to be attended to the “Internet Research” meetings. You’ll be sent a Zoom link shortly after.

Please note that our conversation will be recorded. If you attend, you will be asked to give your consent to being recorded. The recording will be published and distributed openly.  

If you have any questions, please feel free to reply to this email directly or write to la...@measurementlab.net. 

--
Lai Yi Ohlsen
Director, Measurement Lab
Code for Science & Society","{'rjmcmahon': 'Hi Lai,\n\nWe\'re very interested in this new test. We may want to support a\nfunctionally equivalent test using open source iperf 2, a new test to be\nwritten in python 3 using the open source flows code. I\'ve ok\'d any all\ntest work done at Broadcom per our WiFi group as being something we can\nrelease as open source, including scripts developed per this test.\nhttps://sourceforge.net/p/iperf2/code/ci/master/tree/flows/\n\nAs an aside, we\'ve done a lot of work in iperf 2 around better TCP\ntesting including things like --reverse w/small xfers, connect time\nmeasurements, write to read latencies, scheduling per clock_nanosleep,\netc. More here https://iperf2.sourceforge.io/iperf-manpage.html\n\nOne recent feature we find extremely useful is support for\nTCP_NOTSENT_LOWAT and select() based writes. We really appreciate some\nof the experts here pushing that through the network industry. The iperf\n2 option is --tcp-write-prefetch <bytes>. It really helps with WiFi\nlatency measurements to remove the send side bloat.\n\nThanks,\nBob\n\n> Internet performance is often measured by download and upload\n> “speed” but there are other metrics that can help measure\n> connectivity, such as latency, bufferbloat and a more recently\n> discussed metric: responsiveness. Join us next Wednesday, August 25,\n> 2021 from 11am-12:30pm Eastern for a conversation with Internet\n> Measurement researchers with expertise and interest in each of these\n> metrics including:\n> Matt Mathis, Senior Research Scientist, Measurement Lab, Google\n>\n> Matt Mathis has been working on Internet performance research and\n> development since 1990. His work includes measurement tools, models\n> and improvements to protocol standards. He participated in MLab from\n> its inception in 2009, and came to Google in 2010 to find a larger\n> platform on which to stand.\n> Dave Taht\n>\n> Dave Taht and members of the Bufferbloat Project [1]have made vast\n> improvements to the Internet and to WiFi, as described in the book,\n> “Bufferbloat and Beyond [2]”. He has lectured at Stanford and MIT,\n> NANOG, RIPE, USENIX, IEEE, and the IETF. His R&D work on AQM/FQ\n> technologies on the Internet have been integrated into the Linux, OSX,\n> and IOS kernels, cable modems, and many WiFi chips, and he has created\n> and managed Internet improvement initiatives such as CeroWrt,\n> make-wifi-fast [3], cake, and more. From these projects we have seen\n> major innovations in congestion control algorithms such as BQL,\n> FQ_codel, FQ_pie, and BBR.\n> Christoph Paasch, Networking Architect, Apple\n>\n> Christoph Paasch has been working on transport layer networking since\n> 2010. Focusing on extensions to TCP, like Multipath TCP or TCP Fast\n> Open. From specification (in the case of MPTCP) and research to the\n> implementation and large scale deployments at Apple. Lately he has\n> shifted his focus on improving the network properties that really\n> matter to the end-user experience by exposing measurement tools to\n> raise awareness to these issues. ""Responsiveness under working\n> conditions"" being now the first primary target.\n> The conversation will be moderated by Lai Yi Ohlsen, Director of\n> Measurement Lab, a fiscally sponsored project of Code for Science &\n> Society.\n> Our casual conversation will include discussion about the significance\n> of these metrics as well as the challenges their collection presents.\n> We welcome audience questions, answers, challenges, and discussion.\n> The discussion will be technical but no familiarity with M-Lab is\n> required; all we ask is that participants review and respect our\n> community guidelines [4].\n> If you have previously RSVP’d to our community calls, you should\n> have already received a calendar invite with a Zoom link included. If\n> not, please reply directly to this email.\n> If you have not previously RSVP’d, but would like to attend, please\n> do so here [5] and indicate that you’d like to be attended to the\n> “Internet Research” meetings. You’ll be sent a Zoom link shortly\n> after.\n> Please note that our conversation will be recorded. If you attend, you\n> will be asked to give your consent to being recorded. The recording\n> will be published and distributed openly.\n> If you have any questions, please feel free to reply to this email\n> directly or write to la...@measurementlab.net.\n>\n> --\n>\n> Lai Yi Ohlsen\n>\n> Director, Measurement Lab [6]\n> Code for Science & Society [7]\n>\n> --\n> You received this message because you are subscribed to the Google\n> Groups ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it, send\n> an email to discuss+u...@measurementlab.net.\n> To view this discussion on the web visit\n> https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcNzVfcBT%3DRFK%3DK17srP_GVSje%2B%3Dsayj5ws42rV9dWBapQ%40mail.gmail.com\n> [8].\n>\n>\n> Links:\n> ------\n> [1] https://www.bufferbloat.net/projects/\n> [2] https://blog.tohojo.dk/media/bufferbloat-and-beyond.pdf\n> [3] https://lwn.net/Articles/705884/\n> [4] https://www.measurementlab.net/community-guidelines/\n> [5]\n> https://docs.google.com/forms/d/e/1FAIpQLSeHKN2MUP1IAReB8KNJM9jIdbazpaUQscdj0zZ5PbbO9K0fTA/viewform?usp=sf_link\n> [6] http://www.measurementlab.net\n> [7] https://codeforscience.org/\n> [8]\n> https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcNzVfcBT%3DRFK%3DK17srP_GVSje%2B%3Dsayj5ws42rV9dWBapQ%40mail.gmail.com?utm_medium=email&utm_source=footer'}"
48,52226084505565799873426476842357455339,new-person-needs-advice,"Jul 12, 2021, 4:27:50 AM",Jim Brock,"MY E-mail is (felada@charter;net) not fela...@gmail.com
Deleted that mailbox a longtime ago but some messages still try to send to that address.
I joined this conversation after
 I ran speed test 
Download  28.42 mb/s  upload 11.12 mb/s latency 26 ms.  Now Im reaching out to the community for some advice on how to improve my speed.  Cable company Spectrum (charter) communications.  I am renting their Modum and Router.  Have a wish to improve speed in my home.  Most things in house are connected by WIFI  .
Watch a lot of movies on Netflix and Prime and some regular channels for news and sports.  Hate regular TV because of the over abundance  of commercials.  Any help would be great.  Take into consideration that I know very little about this subject.                  JB",{}
49,66821573801390658790034525782405943977,mlab--measure-varaible-defination,"Jan 20, 2021, 7:23:37 AM",margaret agbo,"Good day support Team,
  With hope this mail meets you well. I am Mrs. Margaret Oluwadare from Nigeria. I am research student in the University of Ibadan. I came across the M-Lab measures plug-in for google chrome online and it was indeed a perfect tool for my proposed research work. Thank you for developing such tool. But I have a challenge currently and it does require urgent attention.
  I have been reading my network connectivity, and exported it as a CSV file. I can understand what some of the variable measures are but bulk of it I don’t have a clue to it.  I wish to request if I can have a link to where I can have a full definition of the variables listed.  I have here attached an except of the data.
  Thank you with great expectation of prompt reply.","{'Chris Ritzo': ""Good day & thanks for writing to us about the M-Lab Measure Chrome browser app.\n\nThe fields saved are the result of the NDT 5 test, which are documented on this page:\nhttps://www.measurementlab.net/tests/ndt/ndt5/\n\nNote that there are field names on that page that may not be present in the Chrome browser app's output. Many of these fields are the TCP statistics collected during the test by our server-side TCP INFO service.  I would recommend searching for the field names in the CSV export on the page above to find the relevant field description.\n\nFor your immediate need, fields relevant to most users like Download, Upload, and Latency, the units as saved in the CSV file are kilobits per second (Download & Upload), and milliseconds (Latency).\n\nAlso, thank you for reporting this need. I've filed an issue to add this information to our public documentation.\n\nIf you have additional questions please let us know.\n\nBest regards,\nChris - M-Lab Support\n\ue5d3""}"
51,292414543297851704626875776503293880626,iperf-2.0.14,"Oct 16, 2020, 5:15:52 AM",Robert McMahon,"Hi All,

I don't know if this is relevant to you or not and, if not, sorry for the spam. We're in an early field test EFT phase for iperf 2.0.14.  One of the new aspects is support for end to end read to write latencies, i.e. speed and capacity, which is a direct measurement of both.  More here

Thanks and my apologies if this seems like spam to you,
Bob McMahon","{'Chris Ritzo': 'Hi Bob,\nThanks for writing to share about the testing for iperf 2.0.14. We have considered the possibility of hosting iperf 2 or 3. I wonder if this is an appropriate thread to discuss the nuances of each and whether one or both would be useful to M-Lab users.\n\nThanks again,\nChris\n\ue5d3', 'Robert McMahon': ""Fine by me.  I do talk with the iperf 3 team and have some idea of their goals.   The number of 2 vs 3 might be confusing as people think a larger number suggests the same but better.  In this context, 2 vs 3 are completely different code bases. \n\nOne technical thing that's been missing by my judgment is direct measurements of both capacity (peak average throughput) and speed (latency.)  Some use throughput/latency or network power as the metric to optimize.  Ping and packet latencies aren't necessarily good proxies for actual use experience.  I think the write-start to read-complete latency is much better.\n\nAlso things like connect times (TCP 3WHS) are a big deal too and should be measured.\n\nWe've added a lot to 2.0.14 per our semi-conductor customers.  We supply NICs, WiFi chips, switch fabric chips, etc. for all types of device and network equipment and this broad customer base has provided some inputs to the features implemented.\n\nBob\n\ue5d3""}"
52,273912681479296032184362354505071440051,ndt7-client-questions,"Jul 27, 2020, 5:16:42 AM",stt9000,"I'm setting up test devices with the ndt7 client installed on them.  I am testing several devices before deployment.   However, they periodically produce the following error:
download (or upload) failed:  No available M-Lab servers

Any idea on what may be causing this?

Also, is there a way to use the M-Lab servers to get a udp latency result?

Thanks,

Shawn Thompson","{'Chris Ritzo': 'Hi Shawn,\nIf your devices are conducting scheduled tests, and it is possible that they are receiving HTTP response code 204 for no content because of a limit we impose on the number of tests per day, per IP address, per M-Lab server, as described in our Developer Guide. If you are using the ndt7 Golang client there is a flag `-hostname` which you could use to test against a specific ndt-server (including a self-hosted one). Self hosting might be ideal if you are testing a large number of devices. You may also be interested in our Murakami code repository, which provides a means for running regular M-Lab and non-M-Lab tests from any machine that supports Docker,.\n\nRegarding UDP latency, unfortunately we do not currently host a measurement service that provides this.\n\nChris Ritzo - M-Lab Support\n\ue5d3'}"
53,229885771854443440569006122785178412075,acm-mmsys'20---calls-for-contributions,"Mar 11, 2020, 10:39:05 AM",Cise Midoglu,"Dear all,

please find below a joint call for contributions to multiple events co-located with the ACM Multimedia Systems Conference (MMSys).

Travel and Childcare Grants have also been announced, feel free to check: https://2020.acmmmsys.org/grants.php for more details.

Best regards,
Cise Midoglu

*

(This email is also available online at https://tinyurl.com/mmsys20-calls)

Dear Colleagues, 

There are multiple calls for the events co-located with ACM MMSys 2020 that will take place in Istanbul on June 8-11.

All accepted papers will be published as part of the MMSys’20 proceedings in the ACM Digital Library. Also note that MMSys’20 will offer a large number of travel grants to students as well as attendees from minority groups and less fortunate countries. All details regarding the calls, submission formats and travel grants are available at https://2020.acmmmsys.org. 

[1] Demo and Industry Track
[2] Open Dataset and Software Track
[3] NOSSDAV’20 (30th Anniversary)
[4] Packet Video 2020 (25th Anniversary)
[5] MMVE 2020 
[6] Grand Challenge on Open-Source HEVC Encoding ($7,500)
[7] Grand Challenge on Adaptation Algorithms for Near-Second Latency ($7,500)

Supporters
Adobe, Ozyegin University, Turkish Airlines, Twitch, YouTube, Comcast, Medianova, MulticoreWare, AMD, Argela, Bigdata Teknoloji, Bitmovin, DASH-IF, Dolby, Mux, Nokia, Pixery, SSIMWAVE, Streaming Video Alliance, Tencent, Unified Streaming, Vispera, Ericsson, Interdigital, Sky

Follow Us
https://twitter.com/acmmmsys 
https://www.facebook.com/acmmmsys/ 
https://www.instagram.com/acmmmsys/   

Demo and Industry Track
Submissions due: February 29
https://2020.acmmmsys.org/calls.php#demo-industry

The goal of the Demo and Industry Track is to bridge the gap between research and industry by showcasing demonstrations of innovative multimedia concepts. Submissions are encouraged in all areas related to multimedia. Researchers are also encouraged to submit demo proposals that concretize their accepted research papers and have a chance to showcase technical aspects of their work.

Open Dataset and Software Track
Submissions due: February 29
https://2020.acmmmsys.org/calls.php#ods 

Those who have created a new dataset or open-source software package that is relevant to the multimedia community should consider submitting it to this track. This includes, but is not limited to, software and datasets relevant to both traditional and emerging areas, traces reflecting network, user or application behavior and performance, both real or synthetic, as well as software from all aspects of production, coding, transmission, use or analysis of multimedia systems. Together with the dataset or source code, authors are asked to also provide a short paper describing the motivation and design, and discussing the way it can be useful to the community.

NOSSDAV’20 (30th Anniversary)
Submissions due: March 27

As in previous years, NOSSDAV will continue to focus on both established and emerging research topics, high-risk high-return ideas and proposals, and future research directions in multimedia systems. In a single-track format the encourages active participation and discussions among academic and industry researchers and practitioners. Out-of-the-box ideas are particularly welcome.

The workshop seeks papers in all areas of multimedia systems with an emphasis on the systems aspects. Authors are especially encouraged to submit papers with real-world experimental results and datasets. Topics of interest include (but are not limited to):

Virtual reality (VR), augmented reality (AR) and immersive systems
Cloud architectures for multimedia coding and processing
Wireless, mobile, IoT, and embedded systems for multimedia applications
Medical multimedia systems
Multi-core and many-core systems, distribution and storage components
Network-distributed video coding and network-based media processing
Multimedia systems for autonomous driving
Multimedia systems support in mobile networks, such as 5G
Networked GPUs, graphics, and virtual environments
Systems for computer vision applications
Security in multimedia systems

Packet Video 2020 (25th Anniversary)
Submissions due: March 27

The 25th Packet Video Workshop (PV’20) is devoted to presenting technological advancements and innovations in video and multimedia transmission over packet networks. The workshop provides a unique venue for people from the multimedia and networking fields to meet, interact and exchange ideas. Its charter is to promote the research and development in both established and emerging areas of video streaming and multimedia networking. 

PV’20 seeks submission of original work in all areas of multimedia networking, including cutting-edge research and novel applications. Authors are especially encouraged to submit papers with real-world experimental results and datasets. Topics of interest include (but are not limited to):

Adaptive media streaming, content storage and content delivery
Novel technologies for interactive audiovisual communications
Next-generation/future video coding, point cloud compression
Cloud and P2P based multimedia
Video streaming over software-defined networks
Multimedia communications over future networks, such as information-centric networks, next-generation 802.11ax networks and 5G wireless
Coding and streaming of immersive media, including VR, AR, 360° video and multi-sensory systems
Machine learning in media coding and streaming systems
Protocols and standards for real-time multimedia communication (e.g., MPEG, 3GPP, IETF and others)
Performance evaluation of proof-of-concept systems for video transmission
Low-delay transmission of conversational multimedia
Emerging applications: social media, game streaming, personal broadcast, healthcare, industry 4.0, multi-camera surveillance, smart transportation, social VR, 6DoF video, etc.

MMVE’20 - Virtual, Augmented and Immersive Media
Submissions due: March 27

In its 12th year, MMVE welcomes all prior and new contributors to a workshop devoted to virtual, augmented and immersive media. Today’s market offers a wide selection of user technology, from head mounted displays and smart glasses to wearable sensors and mobile applications. Yet many domains remain unexplored, and novel technologies need to tackle both new and old challenges and constraints. Innovation in the design and development of these technologies require the combined expertise from several domains.

MMVE is an interdisciplinary forum where academic researchers, industry developers and other professionals can exchange ideas, present findings, initiate collaborations, and move the state of the art forward. The workshop will focus on novel research and new ideas in a wide range of topics related to immersive and virtual media systems and architectures:

Visualization
3D virtual environments
3D graphics and meshes
Light fields and point clouds
Applied contexts
Health, games, education
Storytelling, social communities
Immersive media
Psychological and physiological effects
Experience and perception
Multisensory processes
Learning and memory
Social interactions and human-computer interactions
Quality and performance
Interactivity, media synchronization
Quality of experience
Security and privacy
Scalability, consistency and throughput
Systems
Immersive and interactive multimedia systems
Sensor and vision systems
Wearable, operating and distributed systems
Middleware, mobile and embedded systems
Extended reality systems
Cinematic virtual reality

Grand Challenge on Open-Source HEVC Encoding
Sponsored by: Comcast, MulticoreWare, SSIMWAVE
Submissions due: March 27
https://2020.acmmmsys.org/x265_challenge.php

High-quality and efficient compression of this content is a challenge for the industry due to the high bitrates required for its transmission. HEVC is the codec of choice for UltraHD content, and the open-source x265 project is currently the most widely used HEVC encoder. The goal of this challenge is to produce algorithmic improvements to HEVC encoding, and make them available to the open-source community.

Awards: The winner will be awarded $5,000 and the runner-up will be awarded $2,500.

Grand Challenge on Adaptation Algorithms for Near-Second Latency
Sponsored by: Twitch
Submissions due: March 27
https://2020.acmmmsys.org/lll_challenge.php

The purpose of this challenge is to design an adaptation algorithm tailored towards HTTP chunked transfer streaming in the near-second (1-2s) latency range. It should minimize rebuffering while maximizing bandwidth utilization given the considerations above. The algorithm must also be fair to other clients viewing the same stream - its performance should not come at the expense of another. The proposed algorithm must be implementable on the web and within an HTML5-based player.

Awards: The winner will be awarded $5,000 and the runner-up will be awarded $2,500.

--
Cise Midoglu
Simula Research Laboratory
https://www.simula.no",{}
55,229993195028993476222185968523259991044,are-all-m-lab-tests-guaranteed-to-be-'off-net'?,"Sep 30, 2018, 6:47:08 AM",Zachary Smith,"Hi all,

I'm quite new to Google groups threads, so I don't know the appropriate way to engage here yet! Please let me know if I'm off the mark (and especially if I'm just creating spam).

I'm looking for specific ways to evaluate Internet performance in South Africa and am exploring the M-Lab datasets to see what's available. From the M-Lab status page (https://www.measurementlab.net/status/) I see that there is one M-Lab server setup in South Africa. I thought that this might mean that all tests in South Africa are therefore relative to this single server. But from the FAQs (https://www.measurementlab.net/faq/):

""M-Lab’s measurements are always conducted off-net. This way, M-Lab is able to measure performance from testers’ computers to locations where popular Internet content is often hosted. By having inter-network connections included in the test, test users get a real sense of the performance they could expect when using the Internet.""

I take this to mean that a testing-client will always connect to a server hosted on a separate ISP's network?

For the specific example of South Africa with one M-Lab server in one of the main business districts, could this result in the best internet connections (connections close to the data center where the M-Lab server resides) showing the highest latency/throughput times since there is a 'rule' that will result in NOT using the closest local server that is in the same Access network as the testing client?

In general, how is it ensured that test-client - server connections are all 'off-net'? Alternatively, if this isn't the case, is there a flag somewhere that indicates this?

Best regards,
Zach","{'Chris Ritzo': 'Hello Zach, \nThanks for asking this question, and welcome to the M-Lab Discuss group. \n\nM-Lab servers are always hosted outside of access networks, with direct connections to transit networks. This is how we ensure tests are conducted to off-net servers. Our architecture in this respect is similar to Akamai. To directly answer your question about the FAQ- yes, the testing client will always connect to a server hosted on a transit network.\n\nThe vast majority of testing clients normally are routed to the geographically closest M-Lab server. Some clients allow the user to select a specific M-Lab server to conduct an NDT test, for example if you compiled the NDT command line binary or install the M-Lab Measure Chrome Extension.\n\nHappy to answer additional questions, and thanks for posting in the group.\n\nBest regards, Chris\n--\nChris Ritzo\nMeasurement Lab Operations & Support\no...@measurementlab.net | sup...@measurementlab.net\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}"
56,163711432132050723755446535303457762278,fwd:-2nd-workshop-on-internet-measurements-research-in-africa,"Sep 5, 2018, 5:23:27 AM",Amreesh Phokeer,"FYI

---------- Forwarded message ---------
From: Amreesh Phokeer <amreesh...@gmail.com>
Date: Wed, Sep 5, 2018 at 4:22 PM
Subject: 2nd Workshop on Internet Measurements Research in Africa

{apologies for cross-posting}
{please circulate}

2nd IMRA WORKSHOP
Internet Measurements Research in Africa
co-located to AFRICOMM 2018, 29-30 Nov, Dakar, Senegal

Call for Papers/Presentations

Internet measurements provide useful insights into the accessibility of the Internet (e.g. coverage of WiFi and cellular networks), performance (e.g. Internet throughput and latency) and Internet usage. Internet development campaigners, national regulators, and policy makers in the developing regions are recognising  the crucial role that Internet measurement data can play in facilitating evidence-based policy-making and regulation. Given that the Internet ecosystem comprises a diversity of stakeholders and service providers it is difficult for any other single entity to access all of Internet topology data without the cooperation of the Internet community. For this reason, appropriate acquisition of Internet data requires a variety of cooperative research methods, including wide distribution of Internet probes for technical measurements, located in diverse locations and networks, as well as region-specific techniques and demand-side surveys on Internet access and use.

The aim of the workshop is to facilitate discussions around mechanisms and challenges of measuring Africa’s Internet; to evaluate the breadth of Internet measurements research and to formulate strategic directions for such research in Africa; and to initiate and accelerate collaboration among Africa’s Internet measurements researchers.

The workshop is calling for high-quality papers that are focused on Internet measurements research in Africa. Papers are invited on topics related to tools, methods and analysis of:

End-to-end Internet performance metrics
Internet topology characteristics, including peering and routing
Application-level performance, including DNS, Web, CDNs, Cloud Computing
Physical layer performance measurements, including for TVWS, WiFi, and 3G/4G
Mobile and Cellular technologies
Detection of middleboxes, censorship, and content filtering
Data analytics for network monitoring, traffic analysis and network
Network topology and performance visualization
Internet access, use, and Quality of Experience (QoE) surveys

Committee

General Workshop Chair
Amreesh Phokeer – AFRINIC

Technical Programme Committee
Ahmed Elmokashfi (TPC Co-chair) – Simula Research Laboratory
Josiah Chavula (TPC Co-chair) – University of Cape Town
Amreesh Phokeer – AFRINIC
Gareth Tyson – Queen Mary University of London
Alemnew Asrese – Aalto University
Ermias Walelgne – Aalto University
Assane Gueye – UADB-Senegal
Roderick Fanou – CAIDA/UC San Diego

Publication

Accepted and registered papers will be included in the AFRICOMM conference proceedings.

Submission Instructions

See the instructions for paper submission here:
<http://africommconference.org/initial-submission/>

Workshop papers will be selected through a peer-review process.

N.B Previous and already published peer-reviewed work on Internet measurements may also be accepted for presentation only. Presentations should be emailed to the workshop TPC co-chairs.

Important Dates
Submission deadline: 28th September 2018
Notification deadline: 15th October 2018
Camera-ready deadline: 30th October 2018

--
Amreesh Phokeer


--
Amreesh Phokeer",{}
59,260808154918436793860389916071168975672,re:-[m-lab-discuss]-understanding-a-traceroute-measurement,"Sep 13, 2017, 8:08:53 AM",☕Peter Boothe,"That path consists of 7 hops, originating at 162.219.49.38, and then proceeding
162.219.49.38 -> 162.219.49.1 -> 184.105.64.89 -> 72.52.92.165 -> 195.66.224.207 -> 62.128.207.217 -> 185.20.96.130 -> 37.220.21.130

I believe the names come from reverse DNS, and the P(6,6) indicates how many probes were sent (the first number) and how many of those probes were responded to (second number). The last column contains summary latency information that I would have to go to the documentation (`man paris-traceroute` and then searching from there) in order to explain what each means.

  -Peter

On Sun, Sep 10, 2017 at 5:22 PM, <aqure...@gmail.com> wrote:
Hi, please forgive me for asking this question which might be quite naive for you. However, i am quite a newbie in understanding 'Internet Traffic and Measurements'. I am pasting a traceroute measurement (taken from Paris Traceroutes). Could you please give me a quick start as how to understand this traceroute:

traceroute [(162.219.49.38:33457) -> (37.220.21.130:42217)], protocol icmp, algo exhaustive, duration 2 s
 1  P(6, 6) 162.219.49.1 (162.219.49.1)  6.446/8.440/10.978/1.549 ms 
 2  P(6, 6) 100ge12-1.core1.nyc4.he.net (184.105.64.89)  12.058/16.099/24.585/5.643 ms 
 3  P(6, 6) 100ge7-2.core1.lon2.he.net (72.52.92.165)  79.758/87.655/97.809/5.479 ms 
 4  P(6, 6) be20.asr01.thn.as20860.net (195.66.224.207)  81.877/82.123/82.344/0.152 ms 
 5  P(6, 6) po200.core1.dc10.as20860.net (62.128.207.217)  84.869/85.699/89.342/1.631 ms 
 6  P(6, 6) 91.zone.1.r.dc9.redstation.co.uk (185.20.96.130)  85.347/117.434/262.091/64.741 ms 
 7  P(6, 6) lnman1.samknows.com (37.220.21.130)  83.149/83.272/83.434/0.105 ms 

--
You received this message because you are subscribed to the Google Groups ""discuss"" group.
To unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.
To post to this group, send email to dis...@measurementlab.net.
Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.



--
ᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.","{'Mark Boolootian': ""If you don't have a solid understanding of how\ntraceroute itself works, you might find the Richard\nSteenbergen NANOG tutorial of interest:\n\nhttps://www.youtube.com/watch?v=4dUqVlZ6trU\n\nSlides here: https://www.nanog.org/meetings/nanog47/presentations/Sunday/RAS_Traceroute_N47_Sun.pdf"", 'Matt Mathis': 'Yea, but the bigger point is that the Internet has been ""virtualized"" to the point where traceroute it pretty useless for debugging somebody else\'s network.    If you know the gear, you might be able to make sense of the results, but if you don\'t know the gear you can not possibly figure out what is going on.\n\nHere is a simple example: if the delay stats look good to hop 3 and bad at hop 4, it is easy to assume that hop 4 has a problem.  But for many modern devices the TTL is checked on input processing, and the proper ICMP can be returned by the input line card, even if hop3 is totally out of backplane or output capacity....  hop 4 might be just fine.\n\n(The point being that a router itself is a network with multiple switches and queues, and you can not tell where the TTL check happens relative to any other processing).\n\nRichard, your presentations do not mention SDN...\n\nThanks,\n--MM--\nThe best way to predict the future is to create it.  - Alan Kay\n\nPrivacy matters!  We know from recent events that people are using our services to speak in defiance of unjust governments.   We treat privacy and security as matters of life and death, because for some users, they are.\n\n\ue5d3', 'Richard A Steenbergen': 'None of this is new. It\'s still perfectly possible to troubleshoot, you just need to be aware of these effects and do a lot more than just ""look for the spot where the *\'s happen"". That\'s the entire point of my presentation. :)\n\nNot sure what else I could say about SDN that has any relevance to traceroute?\n\n\n-- \nRichard A Steenbergen <r...@e-gerbil.net>       http://www.e-gerbil.net/ras\nGPG Key ID: 0xF8B12CBC (7535 7F59 8204 ED1F CC1C 53AF 4C41 5ECA F8B1 2CBC)\n\ue5d3'}"
61,178305827661656156160677868173775339009,variability-in-results,"Feb 22, 2017, 3:19:33 AM",Jerry Helffrich,"I just began using the m-lab site for speed testing tonight, but I'm struck by how much variation there is in the results taken just 30 seconds apart. I began getting 6 Mbps down and 1 Mbps up (this is a DSL connection) and after 4 successive tries I steadily went down to 1 Mbps down and 0.4 Mbls up. Not only are the numbers depressing in the absolute sense, but these tests are being done at 3:30 AM CST, when I would expect congestion and latency to be at their minimums--and the connection is being made from San Antonio to DFW, which I'm guessing is the Dallas Fort Worth airport. So, is there any reason (buffer filling?) that my speed should steadily go down when testing at 30 second intervals? If this is normal, which number is the correct one? A factor of six variation in download speed is a lot.Results summary below:
TCP receive window: 317856 current, 317856 maximum
0.10 % of packets lost during test
Round trip time: 27 msec (minimum), 1128 msec (maximum), 409 msec (average)
Jitter: -
0.00 seconds spend waiting following a timeout
TCP time-out counter: 894
332 selective acknowledgement packets received

No duplex mismatch condition was detected.
The test did not detect a cable fault.
No network congestion was detected.

0.8043 % of the time was not spent in a receiver limited or sender limited state.
0.1468 % of the time the connection is limited by the client machine's receive buffer.
Optimal receive buffer: - bytes
Bottleneck link: -
333 duplicate ACKs set",{}
62,44072732287170036631770831132627379200,i-need-logical-description-of-values-in-cputime-file.,"Nov 17, 2015, 4:55:54 AM",naresh...@gmail.com,"Dear MLab,

  I want to know the logic and description of each value separated by space written into the cputime file. For example the cputime file contains the data like below format.
0.00 0 0 0 0
0.10 0 0 0 0
0.20 0 1 0 0
0.30 0 1 0 0
0.40 0 1 0 0
0.50 3 9 0 0
0.60 5 16 0 0
0.70 8 24 0 0
0.80 11 31 0 0
0.90 13 38 0 0
1.00 16 46 0 0
1.10 18 54 0 0
1.20 20 62 0 0
1.30 22 70 0 0
1.40 25 77 0 0
1.50 27 85 0 0
1.60 29 93 0 0
1.70 31 101 0 0
1.80 34 108 0 0
1.90 37 115 0 0
2.00 40 122 0 0

 I checked every cputime file in one tar ball of ndt, it starts with {0.00 0 0 0 0} why it should be like this. I need each value description and logic. Any suggestion would be helpful to me. Based on these data I'm trying to implement some use-cases.

Regards
Naresh","{'Chris Ritzo': 'Hello Naresh,\n\nI would encourage you to read the NDT wiki for more information. The\nlink I provided explains all of these values and what they refer to.\nOther pages on that wiki explain how test values are collected.\n\nIf you have further questions after reading the NDT wiki, I would\nencourage you to address your questions to the NDT users list.\n\nBest regards,\nChris\n\ue5d3\n> <https://mail.internet2.edu/wws/info/ndt-announcendt-users> https://mail.internet2.edu/wws/info/ndt-users\n\ue5d3\n> > an email to discuss+u...@measurementlab.net <javascript:>\n> > <mailto:discuss+u...@measurementlab.net <javascript:>>.\n> > To post to this group, send email to dis...@measurementlab.net\n> <javascript:>\n> > <mailto:dis...@measurementlab.net <javascript:>>.\n> > Visit this group at\n> > http://groups.google.com/a/measurementlab.net/group/discuss/\n> <http://groups.google.com/a/measurementlab.net/group/discuss/>.\n\ue5d3', 'naresh...@gmail.com': ""Hello Chris Ritzo,\n\nThanks for your reply.\n\nI need explanation behind writing values onto cputime trace file. How they are receiving the values in incrementation order. Ex:\n\n0.00 0 0 0 0 --> All values are zero means it is starting point.\n0.10 0 0 0 0 --> First value increased by 0.00 to 0.10 means interval of 0.10 seconds of every line and rest zeros why?\n0.20 0 1 0 0 --> Here third value is 1 why ?\n\n0.30 0 1 0 0\n0.40 0 1 0 0\n0.50 3 9 0 0 --> Here second value is 3 and third value is 9 and rest zeros why ?\n0.60 5 16 0 0 --> Again second and third values are increased and rest zeros...it goes on..why?\n\n0.70 8 24 0 0\n0.80 11 31 0 0\n0.90 13 38 0 0\n\nPlease if give an explanation of these values it would be more helpful to me. I'm planning to implement the use cases on  latency and jitter.\n\nRegards\nNaresh\n\ue5d3"", 'Matt Mathis': ""They are the output of the Linux times() syscall.   For more detail than that you have to look at the kernel sources.  You are seeing some combination of rounding, sampling and aliasing effects.  The times syscall is intended to provide a general idea of how much resources a particular process is consuming, and not an instrumentation grade signal of it's behavior.\n\nThanks,\n--MM--\nThe best way to predict the future is to create it.  - Alan Kay\n\nPrivacy matters!  We know from recent events that people are using our services to speak in defiance of unjust governments.   We treat privacy and security as matters of life and death, because for some users, they are.\n\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\n\ue5d3""}"
63,146619830838724240554851847280074999024,battleforthenet-study,"Jun 24, 2015, 3:16:29 PM",Steve Bauer,"I saw a variety of news articles referencing a BattlefortheNet study
based upon M-lab data but I haven't been able to find the study
itself.

http://www.theguardian.com/technology/2015/jun/22/major-internet-providers-slowing-traffic-speeds

Is it available somewhere?

Thanks,
Steven Bauer
MIT","{'Livingood, Jason': 'In related news, AT&T and GTT today announced a new interconnect agreement.\nhttp://www.marketwatch.com/story/gtt-and-att-enter-into-an-interconnection-agreement-2015-06-30?mod=mw_share_twitter\n\n\ue5d3\n\ue5d3\n--\n\ue5d3', 'Juju': ""That's great work. A pity there is nothing for other countries to compare like Canada or Europeans'\nAnyone knows if there is plan to extend the observatory?\n\nThanks\n\nJulien"", 'jpartr...@gmail.com': 'This piece by Richard Bennett also does a good job of correcting the erroneous speculations surrounding GTT interconnection issues.\n\nGTT’s Growing Pains Behind Over-Hyped Congestion Claims\nhttp://hightechforum.org/gtts-growing-pains-behind-over-hyped-congestion-claims/\n\n\nOn Wednesday, June 24, 2015 at 6:16:29 PM UTC-4, Steven wrote:\n\ue5d3', 'Don Waterloo': 'CIRA is underway \nhttp://cira.ca/content/internet-performance-test-advanced-results\n\n\n\n\ue5d3\n\ue5d3\n--\n\ue5d3', 'Zubair Shafiq': 'Right, this is a well-done piece by Richard Bennett. Thanks for sharing. \n\ue5d3', 'Adam Rothschild': 'I don\'t think it\'s necessary to speculate on the speculation (which is\nprecisely what Messrs Bennett and Rayburn are doing in their editorial\npieces, not dropping hard science), when GTT\'s former CTO laid it out\nin the comments section:\n\nhttp://www.huffingtonpost.com/dan-rayburn/study-of-isp-slowdowns-co_b_7698056.html\n\nFinancial motives on the part of the ""journalists"" should come into\nquestion as well.\n\n$0.02,\n-a\n\ue5d3\n\ue5d3', 'Richard A Steenbergen': ""That would be me. Obviously I'm limited on what I can say with regards to interconnection agreements and capacity between GTT/nLayer and AT&T, but I can definitely confirm that Dan Rayburn's theory is incorrect and baseless. I think the situation is probably best explained by the joint press release announcing additional capacity. How often do you see Tier 1 networks putting out a joint press releases about peering upgrades, and why might that have occurred in this circumstance? To a logical observer, the answer should be obvious.\n\ue5d3""}"
65,13970134611754847332094820805558900541,m-lab-news-again---interconnection,"Mar 13, 2015, 11:58:24 AM","Livingood, Jason","See http://arstechnica.com/information-technology/2015/03/netflix-war-is-over-but-money-disputes-still-harm-internet-users/

Netflix war is over, but money disputes still harm Internet users
AT&T won’t upgrade network without payment; Comcast is working to fix congestion.
by Jon Brodkin - Mar 13, 2015 2:20pm EDT
Share
Tweet
 25
Dominik Meissner
When the months-long financial disputes between Netflix and Internet service providers ended last summer, a lot of network congestion problems that affected Internet consumers were cleared up.
But that doesn’t mean network problems, including some caused by financial disputes, are a thing of the past. They just might be a bit less widespread, and they’re definitely getting less publicity. But they have a real impact on consumers trying to use Internet service, according to the Measurement Lab Consortium (M-Lab).
FURTHER READING
NETFLIX, CALL YOUR LAWYERS: FCC IS READY FOR INTERCONNECTION COMPLAINTS
Netflix might be able to challenge deals it signed with Comcast and other ISPs.
M-Lab, founded by the New America Foundation's Open Technology Institute, the PlanetLab Consortium, Google, and academic researchers, hosts measuring equipment at Internet exchange points where retail Internet providers exchange traffic with Internet backbone operators.
Recent M-Lab data shows problems at interconnection points involving retail operators Comcast and AT&T and backbone operators GTT and Zayo. In some cases, the problems are just as severe as the ones involving Netflix a year ago.
When contacted by Ars, AT&T, Comcast, and GTT confirmed the interconnection problems identified by M-Lab. Zayo has not provided any comment.
AT&T is seeking money from network operators and won’t upgrade capacity until it gets paid. Under itspeering policy, AT&T demands payment when a network sends more than twice as much traffic as it receives.
“Some providers are sending significantly more than twice as much traffic as they are receiving at specific interconnection points, which violates our peering policy that has been in place for years,"" AT&T told Ars. ""We are engaged in commercial-agreement discussions, as is typical in such situations, with several ISPs and Internet providers regarding this imbalanced traffic and possible solutions for augmenting capacity.""
Poor AT&T connections found by M-Lab are with Zayo in Dallas, GTT in Chicago and GTT in Atlanta. The data points are from November to January, but AT&T’s statement to Ars indicated that problems are ongoing. M-Lab also found less severe congestion from back in September between AT&T and Level 3 in San Francisco.
Enlarge
M-Lab
Under the Federal Communications Commission's new net neutrality rules, companies will be able tofile complaints about interconnection disputes that harm Internet performance.
M-Lab data from November also shows poor performance between Comcast and GTT in Chicago. While AT&T is seeking payment to clear up this congestion, Comcast may not be.
Enlarge
M-Lab
Comcast told Ars that the links with GTT are “settlement-free,” meaning no payment is exchanged, and that they are going to be upgraded soon. Comcast acknowledged a capacity shortage with GTT in both Chicago and Ashburn, Virginia.
“We have been in contact with GTT and are working together to increase capacity at two interconnection points,” Comcast told Ars. “We expect that process to be completed shortly and to fully resolve the issue.”
GTT offered a similarly hopeful response. “GTT has been in touch with Comcast and we are working together to increase capacity at the two intersections,” GTT told Ars. “This issue should be resolved shortly.”
A problem caused by the industry, not just one company
M-Lab’s “Internet Observatory” lets you view download and upload speeds, and other measures like latency, for connections between network operators in Atlanta, Chicago, Dallas, Miami, New York, San Francisco, Washington, DC, and other cities.
M-Lab researcher Collin Anderson told Ars that the latest data points show that problems are more widespread than Internet service providers like to admit. The transit provider Cogent has been mixed up in a lot of the most well-known interconnection disputes, including the one with Netflix, leading Internet providers to argue that this is more of a Cogent problem than an industry-wide one.
Cogent was at the center of last year’s battles because its connections to ISPs were overwhelmed by Netflix traffic. Netflix, a customer of Cogent, was delivering traffic over Cogent’s settlement-free links with ISPs, and Cogent refused to pay the ISPs for more capacity. (Cogent exchanges traffic with ISPs without payment, but Comcast, AT&T, Verizon, and Time Warner Cable complained that Cogent was sending too much.)
In January 2014, “the download throughput rate during peak use hours for Comcast and Verizon traffic over Cogent’s network was less than 0.5Mbps,” we reported last year in an article using M-Lab data.
AT&T’s connections to GTT in Atlanta and Chicago have been even worse, going below 0.2Mbps. Comcast’s link to GTT in Chicago dipped below 0.5Mbps.
“What this shows is that there continues to be failures to properly maintain the infrastructure between the major access ISPs and the transit providers,” Anderson told Ars. “This is in line with the assertions made by transit ISPs like Cogent and Level 3 in public, but we are showing that this is occurring on networks that haven't spoken up and is more extreme than past cases.”
While these links don’t carry Netflix traffic, they carry many other types of traffic that home Internet users are likely to access. Congestion is so bad in some cases that “large sections of the Internet are nearly inaccessible for the major access ISPs,” Anderson said.
M-Lab’s data is crowdsourced, with data streams ""sent from the user’s device (laptop, mobile, or other client-side gadget) to the nearest M-Lab measurement point."" This system provides an accurate assessment or what an ordinary Internet user experiences, Anderson said.
“We sit behind the same interconnections as the content served by GTT and Zayo, and so the failures that we see occur for every connection that traverses those network segments,” he said. “M-Lab data is not artificial; it comes from tens of thousands of home users in the United States, so those users are exactly the people that cannot properly access the Internet.”
Like the Netflix and Cogent problems last year, awful performance at interconnection points is often a sign of a business relationship gone awry, Anderson said.
“I would suspect that given this is the core of the business and given the extremes of the degradation that it wouldn't likely be negligence, that there would be a pretty strong incentive in an ideal system for the maintenance of these links,” he told Ars.",{}
66,270027821907566157088924171133571125132,"comments-on-""isp-interconnection-and-its-impact-on-consumer-internet-performance""","Nov 9, 2014, 4:25:01 PM",Constantine Dovrolis,"hi all,

I want to comment on the recent ""ISP Interconnection and its Impact on
Consumer Internet Performance"" MLab report. I would normally send these
comments directly to the authors but this report has received a lot of
publicity during the last two weeks and I think that more people would
be interested in the following than just the authors.

Let me emphasize that my objective is not to criticize the report. I
just hope that these comments will help to better understand what we can
reliably conclude from this study (and what we cannot). I also hope that
these comments will be considered in a ""version 2"" of this work.

The summary of this email is that the main conclusion of this report,
namely that severe performance degradation occurs in the
interconnections between Transit ISPs and Access ISPS, is questionable.
The methodology that is used in this study cannot conclude reliably
whether congestion occurs at specific interconnection links --
congestion may *also* occur inside the Transit ISP's network or it may
even occur *only* inside the Transit ISP's network.

Let me explain in more detail:

The methodology that this study is based on is referred to in the
research literature as ""network tomography"" (I include some references
at the end of this email). The purpose of net-tomography is to infer
properties of network links from the spatial correlation of multiple
end-to-end measurements.

It is well known in the net-tomography literature that, under certain
topological conditions, it is impossible to infer the properties of
specific links. Without getting into any math here, the issue is that if
two or more successive network links are traversed by the same set of
end-to-end flows, then we cannot infer anything about those individual
links.

More specifically, let us refer to Figure A of this report at page-6.
Even though this figure illustrates each Transit (or Access) network as
just one router, in reality there is a multi-hop path that the MLab
flows traverse in the Transit and Access networks. Without knowing the
complete sequence of links in the end-to-end paths followed by MLab
flows, we cannot conclude reliably that it is the interconnection links
between Transit and Access providers that are congested.

Referring to the example of Figure-A, it could be that there is a link
L(X) in the Transit network X that is traversed by all flows that go to
the users of Access ISP A but it is not traversed by any of the flows
that go to users of Access ISP B. According to the report, we would
still conclude that the interconnection between X and A is congested --
which is wrong.

Similarly, it may be that both L(X) and the interconnection X-A are
congested. Again, the report would conclude that only the
interconnection is congested.

To conclude, I think that a more thorough analysis is required, and this
analysis should also consider the traceroutes (or even better, the
Paris-Traceroutes) from the MLab servers to the clients. That
topological information will help us to better localize the observed
congestion -- or at least to reliably conclude the sequence of links
that *may* be congested.

Some references for anyone that wants to learn more about net-tomography:

- Nick Duffield's papers on Binary tomography -- e.g.,
http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4016293

- The work at EPFL (Patrick Thiran and KAterina Argyraki's group):
http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5461918

- Our work in the Pythia project:
http://www.cc.gatech.edu/~dovrolis/Papers/final-sajjad-imc12.pdf
and the earlier paper with Amogh and Renata:
http://dl.acm.org/citation.cfm?id=1364677

- There are many more papers.. Just query Google-Scholar for ""network
tomography"".

--
Constantine

--------------------------------------------------------------
Constantine Dovrolis, Professor
College of Computing, Georgia Institute of Technology
3346 KACB, 404-385-4205
const...@gatech.edu
http://www.cc.gatech.edu/~dovrolis/","{'Adam Rothschild': 'Constantine,\n\nThere is already a wide variety of information in the public domain\n(see: FCC ECFS, Level 3 and Verizon public policy blogs, etc.)\nsupporting that the congestion occurred on the peering interfaces, and\nnot elsewhere on the providers\' networks. As someone interconnecting\nwith/buying transit into a number of the networks in question, that\'s\nlong been my experience as well.\n\nAs an aside, why does your mail not speculate on congestion inside the\n""access"" networks as a possible culprit?\n\nFWIW,\n-a\n\ue5d3\n> --\n> You received this message because you are subscribed to the Google Groups\n> ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it, send an\n> email to discuss+u...@measurementlab.net.\n> To post to this group, send email to dis...@measurementlab.net.\n> Visit this group at\n> http://groups.google.com/a/measurementlab.net/group/discuss/.', 'Collin Anderson': 'Hello Constantine,\n\nThanks for your critical feedback and the references, and I agree with the value of sharing it with the list. I appreciate how well the report has been received, especially in terms of eliciting recommendations such as these from the broader community. There are many points in your message that warrant a response, so let me try to address them and please let me know where I might have missed anything.\n\nFirstly, we appreciated this methodological critique from the start and attempted to address the concern within the ""Study limitations” section, with statements such as:\n\nFuture study could interrogate the routes taken, and delineate more clearly which routes between Access ISP/Transit ISP pairs appear to cross problematic interconnection points and where these points are. For now, we are including the possibility of circuitous routing as an artifact of consumer performance changes (circuitous routing would impact M-Lab and non-M-Lab traffic alike), and are looking simply at the pairwise relationship between specific Access ISPs and specific Transit ISPs, without pinpointing the location of a given problem to one or another specific interconnection point between the two entities. \n\nhttp://www.measurementlab.net/static/observatory/M-Lab_Interconnection_Study_US.pdf\n\nI also noted this limitation on our claims in my RIPE presentation this week. We believe that given the national scale of the patterns of performance witnessed over the course of many months with core transit networks and baselines access providers, that we have reduced possibility of any findings being attributed solely to a tomographic issue. However, we still sought to refer to the degradation events in terms of Access ISP/Transit ISP relationships, rather than attempting to assert that failures occurred on specific links or within intermediaries in that might be in the path of traffic.\n\nHowever, I will mention that within the course of research, we interrogated path data to at least provide a preliminary check on our assertions and methodological approach. I was particularly interested in this with regard to our statements on XO, due to only having one endpoint within that Transit ISP during the period. Preliminary examination found indications that this did not run into what you described as the ‘Transit network X’ problem. Still, we sought to couch this section in more qualified language than others until we covered this issue more extensively later on, in terms of both endpoint coverage and complementary path data. Moreover, since we don’t include that data in the report or toolkit, we don’t make reference to it within the published works and attempted to be cautious overall.\n\nWe anticipate continuing this research based on Measurement Lab’s collection of traceroute information for clients testing against its endpoints. However, given the scope and importance of the work, we sought to be fully reproducible and understandable in our research methodology – this initial tomographic approach struck what we felt like was an appropriate balance and was the reason for our inclusion of what I hope was seen as a forthright limitations section within the first few pages. In that regard, I also acknowledge that some of our ‘how Measurement Lab works\' images were simplicity representations meant for a broader audience.\n\nAs I mentioned on another thread, there was a list of aspects of the research that were deferred to subsequent blogposts or follow-on reports for lack of space and the tendencies of such research to continue interminably. To me, this is the amongst the more exciting lines of enquiry, since I think the data demonstrates a more rich and expansive picture of congestion across the United States. I’d certainly welcome others’ thoughts on this and will follow up as the work progresses.\n\nCordially,\nCollin\n\ue5d3\n\ue5d3\n\ue5d3', 'Livingood, Jason': 'As I mentioned on another thread, there was a list of aspects of the research that were deferred to subsequent blogposts or follow-on reports for lack of space and the tendencies of such research to continue interminably. \n\nI did like your idea to delve into the prioritization issue further and would encourage that. Once the NDT traces are available again it seems likely  that you could do a prioritization detection system to see if an ISP is prioritizing M-Lab traffic and to/from what networks.\n\n- Jason\n\nPS – This issue may touch on 3 of the points that President Obama articulated today. M-Lab traffic was sped up relative to other traffic, we only learned about it via M-Lab testing rather that proactive and transparent disclosure, and the traffic prioritized with M-Lab traffic was higher fee retail traffic. ', 'Nick Feamster': '> On Nov 10, 2014, at 1:04 PM, Livingood, Jason <Jason_L...@cable.comcast.com> wrote:\n>\n> I may have incorrectly assumed the authors were the Steering Committee (http://www.measurementlab.net/who) or some other superset of the supporting partners. Perhaps that is not the case (unclear to me if the Steering Committee endorsed it)?\n\nThe steering committee did not have a chance to review this document before its release. We did not know about the draft being prepared, and we only saw the document about an hour or so before it was released to the public (hardly enough time for comment).\n\nSpeaking as a steering committee member, I can say that we did not have the opportunity to review this document and (as I’ve already said on the steering committee list after I had a chance to read the document…after its public release), I have several concerns about the technical soundness of the methods.\n\nOne issue I pointed out was the one that Constantine raised on this list, as well; another is the use of a single-threaded throughput test to make absolute claims about throughput (cf. the report’s discussion of 4 Mbps and the FCC’s minimum thresholds for broadband).\n\nWhile it is highly unlikely that my concerns invalidate the claims of the document—it’s likely that the informal conclusions do reflect reality, as they’re the most likely explanation---I do not completely endorse the methods of the study. They certainly provide circumstantial evidence of phenomena that many of us know/presume to be true, but that’s independent of whether the methods would be considered rigorous.\n\nI have pressed the MLab powers-that-be to publish the document with the authors’ names on the document, as while I think the document certainly has merit for the ongoing discussions, I did not have the opportunity to endorse it before it was published, nor do I fully endorse its measurement methods. Hopefully we’ll see a version with an author list of the people who interpreted the MLab data.\n\n-Nick', 'Constantine Dovrolis': 'Hi Collin,\n\nI appreciate your thorough response. Please count me in if you want\ncomments for a revised, second version of this report.\n\nIn my opinion, given the wide publicity that this report has attracted,\nit is important and urgent that you publish a revision soon, making the\nlimitations of the study more transparent to the reader -- especially to\nfolks that do not understand the technical part in depth.\n\nI also suggest that you include the author names in any future revision.\nPeople are suspicious of ""anonymous"" documents. This is certainly true\nin the research literature. Imagine how many people would have claimed\nthat they discovered a cure for cancer if they were not hesitant about\ntheir scientific reputation.\n\ue5d3\n\ue5d3', 'jpartr...@gmail.com': 'On Jason\'s last point ""the traffic prioritized with M-Lab traffic was higher fee retail traffic"" - it was quite interesting to hear Dave Schaeffer, the Cogent CEO, reveal on Friday\'s 3Q14 earnings call that ""our corporate customers represent 3% of our traffic but 53.5% of our revenues.""', 'Chase, Chris': 'Cogent\'s use of TOS applies as much to their egress connections as to internal connections.\n\nIf the congestion was at the egress link to access ISP interconnect then Congent\'s TOS marked ""retail"" traffic could be priority queued (or higher weight queued) at the egress and mitigate the congestion seen by retail traffic.\n\nAlso, as for link visibility via tomographic methods, in the case of the New York observations, Internap was used a M-lab test point as a control to isolate the Cogent problem. The performance degradation was not seen for the 3 ISPs that performed poorly with the Cogent NYC endpoint. Bi-directional traceroutes would be needed for transparency, but I trust the paths were indeed through the same portions of the access ISP networks other than perhaps the first hop or two.\n\nChris\n\ue5d3'}"
100,4282009391285077099814474290641818059,question-about-client-rate-limits,"May 17, 2021, 12:43:26 PM",Albert Liang,"Hello!

Wanted to ask for some clarification.  On the developer resources page (https://www.measurementlab.net/develop/), it says that one client can only run 40 tests a day.  If I create a speed test site (publicly open similar to Ookla's) for people to come test their internet speeds, my site will be limited to running 40 speed tests per day?

Or was the definition of a ""client"" the end-user who is hitting the ""Run test"" button?  That end-user can ""only"" run 40 tests a day, but my website overall is unaffected?

Thanks!
Albert","{""Roberto D'Auria"": 'Hello Albert,\n\nWhen integrating the ndt7 speed test on a web page, the client is the user\'s browser. Even if they go through your website, each user runs the test from his own IP address to one of the M-Lab servers and is considered separately for rate-limiting purposes. Hope this helps!\n\nRegards,\nRoberto D\'Auria\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/b128b484-f343-46b6-a182-87468e7359c2n%40measurementlab.net.', 'Albert Liang': ""Thank you!  That's a relief!\n\nBest,\nAlbert\n\ue5d3""}"
101,121950463325576154793567480686172322021,m-lab-newsletter---march-2021,"Mar 5, 2021, 10:59:56 AM",Lai Yi Ohlsen,"Hello!
I hope this finds you well. Today I’m writing with the first of many newsletters that you’ll receive on this mailing list. In each monthly edition, we’ll provide updates about M-Lab such as changes to our platform and pipeline, data schemas, community tools, best practice analyses, community case studies, documentation and guides, and more. Ultimately, our goal is to communicate with you on a more regular basis, so we encourage you to reply with any questions or comments that come to mind. Additionally, as part of our efforts to communicate more effectively, we’ve established a lightweight set of community guidelines that we ask participants to keep in mind as you engage here and on any other M-Lab hosted forum. If there is anything you’d like to see in these newsletters, please do let me know. And without further ado!
We recently published two new blog posts.
Using M-Lab data in Broadband Advocacy and Policy was written as a guide for researchers, policy makers, governing bodies, advocacy groups, or anyone who wants to understand M-Lab data and how it compares to other internet measurement data sets. We plan to continue to develop these recommendations for appropriate use of our data in analyses and reports.
Requiring access tokens for ndt7 announces the requirement for NDT client integrations to use access tokens that are issued by the Locate v2 API. These requirements are relevant to anyone supporting an NDT integration. The latest versions of the ndt7-js, ndt7-client-go, and ndt7-client-android already support the Locate v2 API natively. Update to the latest version and you’re done!
Upcoming updates
In our December 2020 community calls, we announced the development of a pipeline to ease the use of aggregate NDT statistics into third party applications. We have soft launched the pipeline to a group of early testers and plan to release to the public in the next quarter. If you are interested in early testing, please let us know.
Contract opportunities
We currently have two projects that we are looking for a Javascript developer to complete. You can read more about them here. Please reach out to la...@measurementlab.net if you are interested.
Recent events
Project Director Lai Yi Ohlsen recently presented at NTIA’s February 2021 Webinar: Data as the Foundation for Broadband Planning, alongside Karen Perry, Senior Policy Analyst for BroadbandUSA and Bryan Darr, Vice President of Smart Communities at Ookla. The recording, presentation slides, and webinar transcript are available and are good resources for folks who want to learn or educate others more about the use of data in Broadband Planning.
Community Call Schedule
In 2020, we began hosting regular community calls where we discussed topics related to the M-Lab project and its related research topics. Here is the schedule for this year’s calls and the form to RSVP.
--
Lai Yi Ohlsen
Project Director, Measurement Lab
www.measurementlab.net",{}
104,88437575611578576614056717031836529324,convincing-my-isp-that-there-is-a-problem,"Oct 25, 2019, 5:17:06 AM",Michael Petty,"I use the internet to watch tv and this fails at around 9-10pm.
I have a 30Mbs adsl connection and if I use any number of test sites in the daytime they return results of around 23-25Mbs DL.
When the tv service fails ookla and ovh.net who my isp recommend still report 20mbs but M-Labs figures are around 2Mbs.

I am in Spain and with my Spanish not being fluent I am having trouble convincing them there is a problem.

Any thoughts on what the problem may be.

Thanks for reading.","{'keith dawson': 'You can try qualoo.net they are good at solving issues like this,  the problem maybe where your iptv service servers are held, if they are in another country then maybe the way your isp routes to that service is congested,  most probably they have poor quality on their international links and do not know, which service provider do you use?\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/e6184d3d-10c6-4da6-bafa-272d22bb2d35%40measurementlab.net.'}"
107,250313372141903918611519852854947436164,dramatic-download-variance-between-test-sites,"May 24, 2019, 1:50:20 PM",David Petty,"I am consistently seeing the following results between two testing sites:

Mlabs- 
 Download - .65-.75 Mbps
 Upload - 8-9 Mbps

Ookla-
 Download - 25-27 Mbps
 Upload - 10-11 Mbps

I can understand the slight difference between the upload speeds based on previous threads, but the download speeds don't make any sense to me. Does anyone have an explanation. Thank you in advance.","{'Chris Ritzo': ""Hello David,\n\nThe reason you're seeing the difference is that though M-Lab returns the same metrics as Ookla, our platform and test architectures are different. This FAQ describes those differences: https://www.measurementlab.net/faq/#why-are-my-m-lab-results-different-from-other-speed-tests\n\nM-Lab considers both to be valid results and useful for understanding your connection performance to both the edge of your ISP's networks where Ookla servers are typically located, and its performance beyond the ISP edge into the peering points where ISPs connect their networks to one another. \n\nWe've also written a recent blog post that describes the issues of measuring speed more generally, with some specifics as well: https://www.measurementlab.net/blog/speed-tests-accuracy/\n\nI hope this helps answer your question.\n\nBest regards,\nChris - M-Lab Support\n\ue5d3""}"
108,254521015134244093308443400747860375566,internet-speed-test-results-are-at-odds-with-other-speed-test-services.,"Aug 20, 2018, 6:10:44 PM",Cory Rahman,"Results (tested multiple times)

SOURCE / DL mbps / UP mbps


On my home 5Ghz network:

MLAB speed test / 40 / 76
Ookla / 83 / 84
AT&T / 82 / 83
Verizon / 82 / 89


On my home 2.4Ghz network:

MLAB speed test / 45 / 62
Ookla / 82 / 86
AT&T / 82 / 88
Verizon / 81 / 90


Does anyone know why these MLAB speed test results would be so different than the other online speed tests?","{'Cory Rahman': 'I did come across this page:\n\nhttps://www.measurementlab.net/faq/#why-are-my-m-lab-results-different-from-other-speed-tests\n\nWhich seems to claim that the M-Lab tests are more accurate. Is this the case? Are the other 3 speed tests inaccurate?', 'Livingood, Jason': '+1, Simone. All very good points!\n  From: Simone Basso <basso...@gmail.com>\nDate: Tuesday, August 21, 2018 at 1:43 PM\nTo: ""dis...@measurementlab.net"" <dis...@measurementlab.net>\nSubject: [EXTERNAL] Re: [M-Lab-Discuss] Re: Internet Speed Test results are at odds with other speed test services.\n  In the infosec community it often happens that people asking security questions is asked about their threat model. Likewise, I\'d say that perhaps in this community we should help people making questions by consistently asking what they would like to measure.\n  AFAICT, it\'s non-controversial that parallel streams tests better approximate the last mile speed, however they also fail to reveal losses in the network (or elsewhere) that become obvious with a single stream test. In the same vein, on-net and off-net tests have pros and cons.\n  Also, speaking of cognitive dissonance, seeing a much lower than expected result from a single stream test can be as surprising as seeing an all-green report from a multi stream test when interactive communication is stuttering, or streaming does not load.\n  Best,\n  Simone\n  Il giorno mar 21 ago 2018 alle ore 19:23 Jim Partridge <jpartr...@gmail.com> ha scritto:\nThis clearly seems to be an issue of multi-threaded tests versus the single-threaded M-Lab NDT test. I would point you to the Comments that Nick Feamster filed with the FCC in the Restoring Internet Freedom docket (link also pasted below) which included the observation that - The M-Lab NDT test consistently underestimates access link throughput. Off-net versus on-net servers aren\'t going to result in performance metrics that are half of actual capacity. It\'s certainly interesting to note how closely aligned the results are from the three other tests, Ookla, AT&T, and Verizon. Of note, Professor Feamster also states that ""As access link speeds continue to increase...the underestimation {of the single-threaded NDT test} is likely to become even more severe.""\n  Error! Filename not specified.\n\ue5d3\n\ue5d3\n\ue5d3', 'Sascha Meinrath': 'This may be an artifact of multi-threading; but it may also reflect on- vs.\noff-network test servers (i.e., are you testing the connection within an ISPs\nnetwork or to a location that is outside of that single ISPs system).\n\n--Sascha\n\nOn 08/21/2018 11:30 AM, Livingood, Jason wrote:\n> IIRC from prior discussions here, I think it was due to a single connection vs.\n> multiple connections for the other tests.\n>\n>  \n>\n> Jason\n>\n>  \n>\n> *From: *Cory Rahman <cory....@gmail.com>\n> *Date: *Monday, August 20, 2018 at 9:10 PM\n> *To: *discuss <dis...@measurementlab.net>\n> *Subject: *[EXTERNAL] [M-Lab-Discuss] Internet Speed Test results are at odds\n> with other speed test services.\n>\n>  \n>\n> Results (tested multiple times)\n>\n>  \n>\n> SOURCE / DL mbps / UP mbps\n>\n>  \n>\n>  \n>\n> On my home 5Ghz network:\n>\n>  \n>\n> MLAB speed test / 40 / 76\n>\n> Ookla / 83 / 84\n>\n> AT&T / 82 / 83\n>\n> Verizon / 82 / 89\n>\n>  \n>\n>  \n>\n> On my home 2.4Ghz network:\n>\n>  \n>\n> MLAB speed test / 45 / 62\n>\n> Ookla / 82 / 86\n>\n> AT&T / 82 / 88\n>\n> Verizon / 81 / 90\n>\n>  \n>\n>  \n>\n> Does anyone know why these MLAB speed test results would be so different than\n> the other online speed tests?\n>\n>  \n>\n>  \n>\n>  \n>\n> --\n> You received this message because you are subscribed to the Google Groups\n> ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it, send an email\n> to discuss+u...@measurementlab.net\n> <mailto:discuss+u...@measurementlab.net>.\n> To post to this group, send email to dis...@measurementlab.net\n> <mailto:dis...@measurementlab.net>.\n> Visit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n>\n> --\n> You received this message because you are subscribed to the Google Groups\n> ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it, send an email\n> to discuss+u...@measurementlab.net\n> <mailto:discuss+u...@measurementlab.net>.\n> To post to this group, send email to dis...@measurementlab.net\n> <mailto:dis...@measurementlab.net>.\n\ue5d3', 'Chris Ritzo': 'Hi Cory,\n\nAs others have mentioned, there are a variety of factors which are in play here. The FAQ you reference explains several reasons why the M-Lab test reports lower results than other speed tests, including single versus multi-threaded tests as Jason mentioned, and on-net versus off-net placement of servers as Sascha mentioned. M-Lab doesn\'t claim that our test is more accurate than others, but that it is measuring different network conditions. Different network performance tests use differing methodologies as well, which can account for different measurements. All the tests are as accurate as they can be for what they are measuring, and because they report similar metrics it is often assumed that their results should be equal.  I would characterize them as comparable and each accurate in their own right for what is being measured. The M-Lab NDT test measurements are more in line with Akamai tests, in that the server endpoints are off-net. Whether a single threaded test or a multi-threaded test is more accurate is still a question up for debate in the academic internet measurement community-- the article Jason referenced is one supporting multi-threaded tests, and earlier research points to single-threaded testing to be more precise in assessing overall performance. In any case, whatever the test used, they all provide some sense of a connection and I think that combined the results of each one can help paint a nuanced picture of your quality of access overall.\n\nBest regards,\nChris\n\n--\nChris Ritzo\nMeasurement Lab Operations & Support\no...@measurementlab.net | sup...@measurementlab.net\n\nSenior Technologist, Open Technology Institute @ New America\n740 15th Street NW, Suite 900 \nWashington, DC 20036      \n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\n\ue5d3', 'Jim Partridge': 'This clearly seems to be an issue of multi-threaded tests versus the single-threaded M-Lab NDT test. I would point you to the Comments that Nick Feamster filed with the FCC in the Restoring Internet Freedom docket (link also pasted below) which included the observation that - The M-Lab NDT test consistently underestimates access link throughput. Off-net versus on-net servers aren\'t going to result in performance metrics that are half of actual capacity. It\'s certainly interesting to note how closely aligned the results are from the three other tests, Ookla, AT&T, and Verizon. Of note, Professor Feamster also states that ""As access link speeds continue to increase...the underestimation {of the single-threaded NDT test} is likely to become even more severe.""\n\n\nhttps://ecfsapi.fcc.gov/file/1083088362452/fcc-17-108-reply-aug2017.pdf\n\ue5d3', 'Simone Basso': 'In the infosec community it often happens that people asking security questions is asked about their threat model. Likewise, I\'d say that perhaps in this community we should help people making questions by consistently asking what they would like to measure.\n\nAFAICT, it\'s non-controversial that parallel streams tests better approximate the last mile speed, however they also fail to reveal losses in the network (or elsewhere) that become obvious with a single stream test. In the same vein, on-net and off-net tests have pros and cons.\n\nAlso, speaking of cognitive dissonance, seeing a much lower than expected result from a single stream test can be as surprising as seeing an all-green report from a multi stream test when interactive communication is stuttering, or streaming does not load.\n\nBest,\n\nSimone\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\ue5d3'}"
111,45673720909147101276009421119936787531,"speed-test-no-longer-works-since-comcast-""speed-upgrade""","Jan 6, 2017, 9:06:28 PM",michael...@gmail.com,"I received an email from Comcast today instructing me to shut down my computers and power cycle my Comcast cable modem for a ""speed upgrade"". Since doing this, the standard Google speed test applet fails to run due to ""The test can't be completed due to a problem with the network. Try again later."". The ""Ookla"" speed test which, by default, selects the closest Comcast server, shows ~250MB/sec download and ~12MB/sec upload. ",{}
115,219353568922766528746499758705018898692,m-lab-community-call-with-david-clark-and-sara-wedeman-next-wednesday-12/15/2021,"Dec 7, 2021, 1:47:12 PM",Lai Yi Ohlsen,"Hi all,

Writing to share information about our upcoming community call next Wednesday, December 15, 2021 from 11am-12pm Eastern. 

At TPRC 2021, Dave Clark and Sare Wedeman presented “Measurement, Meaning and Purpose: Exploring the NDT Dataset” which raises relevant and timely questions about M-Lab’s NDT dataset and its potential applications. Please join us for a presentation from the authors and a discussion with the M-Lab community.  

Abstract
The speed of a data transfer over the Internet connection is a measure of great interest. It can directly influence quality of experience, it can serve as a measure of equitable access, and it can reveal whether or not the speed matches that which was advertised. One of earliest and longest-standing tools to contain a speed test is the Network Diagnostic Tool (NDT), currently supported by Measurement Lab (M-Lab). NDT, in its various forms, has been used across the globe since 2003. There are billions of measurements archived by M-Lab, with a rich collection of metadata for each measurement. This data allows an in-depth analysis of each measurement, and potentially supports analysis across aggregates of measurements.

The original purpose of NDT was diagnostic: why is my connection operating as it is? However, the archive of this data invites its use in aggregate form to draw conclusions about the overall behavior of the Internet. Such use, however, is confounded by the fact that the individual measurements are triggered by users for a range of reasons: simple curiosity, debugging, anger, bragging rights, or automated checking of operational status (in some cases as often as once a minute). NDT measures network speed, but it equally - if indirectly - measures human behavior.

The goals of this paper are to explore the archived NDT data in order to provide insights about how it can be interpreted; and to distinguish between appropriate uses of the data from uses that may lead to unwarranted conclusions.


Dave Clark, Senior Research Scientist at MIT's Computer Science and Artificial Intelligence Laboratory
David Clark is a Senior Research Scientist at the MIT Computer Science and Artificial Intelligence Laboratory. Since the mid-70s, he has played a leading role in the development of the Internet; from 1981-1989 he acted as Chief Protocol Architect, and chaired the Internet Activities Board. His recent research has focused on the re-definition of the architectural underpinnings of the Internet and the relation of technology and architecture to economic, societal and policy considerations. Specific research areas include Internet security and Internet measurement.

Sara Wedeman, Senior Collaborating Researcher at MIT’s Computer Science and Artificial Intelligence Laboratory.  
Sara Wedeman is a Senior Collaborating Researcher at the MIT Computer Science and Artificial Intelligence Laboratory. With a background in psychology, measurement, and technology, she held senior management positions in Banking and Consulting, before founding, in 2003, one of the first  firms to focus explicitly on the practical application of Behavioral Economics. Sara has been working with computers since 1984 and is expert at conducting action research in technology and the behavioral/social sciences, using advanced data analytics to uncover actionable results. She has over 25 years' experience in Consulting, having brought empirically-based guidance to technology and  financial services companies, academic institutions, and others - including the NTIA's Broadband Measurement program.


To RSVP: 
- If you have previously RSVP’d to our community calls, you should have already received a calendar invite with a Zoom link included. If not, please reply directly to this email. 
- If you have not previously RSVP’d, but would like to attend, please do so here and indicate that you’d like to be attended to the “Internet Research” meetings. You’ll be sent a Zoom link shortly after.

Please note: 
- We welcome audience questions, answers, challenges, and discussion. The discussion will be technical but no familiarity with M-Lab is required; all we ask is that participants review and respect our community guidelines. 
- Our conversation will be recorded. If you attend, you will be asked to give your consent to being recorded. The recording will be published and distributed openly.  

If you have any questions, please feel free to reply to this email directly or write to la...@measurementlab.net. 

Take care, 

--
Lai Yi Ohlsen
Director, Measurement Lab
Code for Science & Society",{}
116,129476719322427752661977343987326755521,is-delivery-architecture-discoverable-by-m-lab?,"Jul 19, 2021, 8:40:13 AM",V. Kelly Bellis,"I'm studying data provided to me from a third party using M-Lab's speed test, and I'm just wondering, is it possible to determine what internet service delivery method is used when the speed test is performed. For example, LTE, CBRS, mobile wireless, fixed wireless, DSL, cable, fiber, etc. Thank you for any reply.
Kind regards,
Kelly","{'Chris Ritzo': ""Thanks for asking this question. Currently M-Lab does not identify the internet service delivery method or access media when the NDT test is performed. We have discussed adding an annotation to results in the future, tagging each test as mobile/non-mobile based on what it possible to learn from the IP address.\n\nIt is possible now to segment mobile and non-mobile tests by looking up each test's IP address in a service like ipinfo.io, during your analysis. This research from 2018 did just that, to look at mobile NDT data specifically: https://a4ai.org/access-is-more-than-cost-measuring-the-quality-of-mobile-broadband-service/\n\nI hope this helps.\n\nBest regards,\nChris - M-Lab Support\n\ue5d3""}"
117,76650567548367074945764318541305424902,"invitation:-using-data-in-broadband-advocacy-and-policy-work---discussion-(next)-wednesday,-may-26","May 20, 2021, 1:57:55 PM",Lai Yi Ohlsen,"Want to discuss the use of Internet measurement data in broadband advocacy and policy work? Join us next Wednesday, May 26, 2021 from 11am-12pm Eastern for a conversation with experienced broadband researchers including: 

Fenwick Mckelvey, Associate Professor at Concordia University
Reza Rajabiun, Research Fellow, Ryerson University; CEO, eFilters Inc. 
Chris Mitchell,  Director of the Community Broadband Networks Initiative, Institute for Local Self Reliance
and moderated by Lai Yi Ohlsen, Director of Measurement Lab 

Our casual conversation will include lessons learned from using measurement data in advocacy and policy, in both the US and Canada, as well as recommendations for its future. We welcome audience questions, answers, challenges, and discussion. No level of experience or familiarity with M-Lab is required; all we ask is that participants review and respect our community guidelines. 

If you have previously RSVP’d to our community calls, you should have already received a calendar invite with a Zoom link included. If not, please reply directly to this email. 

If you have not previously RSVP’d, but would like to attend, please do so here and indicate that you’d like to be attended to the “Broadband Advocacy/Policy” meetings. You’ll be sent a Zoom link shortly after.

If you have any questions, please feel free to reply to this email directly or write to la...@measurementlab.net. 

Looking forward to it! Talk soon.

--
Lai Yi Ohlsen
Project Director, Measurement Lab
www.measurementlab.net","{'Scott Shawcroft': 'Will this be recorded and posted somewhere later? I have another meeting at the same time. \nThanks,\nScott\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAD3WrcOVBkxZ47ebcLnSKHyFM9FCNbK5X9%3D%2BDJ3DKdHL0P1%2BnA%40mail.gmail.com.', 'Lai Yi Ohlsen': ""Hey Scott, \n\nWe haven't yet taken the steps to get each participant's consent for recording these calls, but it's good to know that's something you're interested in (others are as well) and is something that we can prioritize for future calls. \n\nBest, \n\n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/2b6ffd64-5606-48ae-85d3-295e909a37f3%40www.fastmail.com.\n\ue5d3""}"
122,37698878680274177949092843202720440763,m-lab-may-2020-community-calls-(plural!),"Apr 21, 2020, 2:42:45 PM",Lai Yi Ohlsen,"Hello! 

After a successful first Community Call in Q1, Measurement Lab is hosting 3 community calls in May. Each call will be on a Wednesday from 11am-12pm EST. 

As the largest collection of open Internet performance data on the planet, M-Lab has a large, diverse community made up of experts in multiple disciplines including Internet infrastructure and measurement, Broadband advocacy and policy, federal and state government, regional/community networks, digital rights, and more. While this speaks to the universal usefulness of open Internet data, it poses unique questions around how to best meet our community where they're at. By breaking up our engagement into focused conversations, we hope to better address topics that are specific to each of your use cases. Our ultimate goal with each of these is to engage with our users and facilitate your support of one another. 

Wednesday, May 6 11a-12p EST - Internet Measurement Research
Deep dives into topics related to Internet measurement methodology. Technical expertise encouraged but not required. 

Wednesday, May 13 11a-12p EST - Broadband Policy/Advocacy
Discussion and presentations related to the use of M-Lab data in digital inclusion and broadband research. Policy/advocacy expertise welcome but not required. 

Wednesday, May 20 11a-12p EST - M-Lab Community Call
Tutorials and discussion related to the general use of M-Lab's platform, data, and community tools including Piecewise and Murakami. First-time users welcome. 

We welcome any and all to each of the above, but if you are not sure which call will best fit your needs, please feel free to reach out.
To RSVP: https://forms.gle/Ur1FYe8cjW6mo5qU7. 
You will receive a calendar invite after submission. 

Please reach out with any questions, the M-Lab team is looking forward to connecting. Sending health, stay safe! 

--
Lai Yi Ohlsen
Project Director, Measurement Lab
www.measurementlab.net","{'Dieudonne Munganga': ""Good day,\n\nI missed this call, but I get it's not too late to ask a few questions!\n\nI intend to do my Masters in Internet Measurements in under-developed countries like DR Congo. I want to be sure it's worth a field to focus on? Is the field advisable in terms of job market? What techniques and principles required to have such a two years study turn into a success?\n\nHow do I get started with M-lab in context where the study is such regions with no MLab servers? and limited if none previous research done in the country?\n\ue5d3""}"
123,92684333513356671760162264188622961331,broadband-usage-map-?,"May 7, 2020, 12:32:43 PM",David Sandel,"Hi,

Is there something out on MLabs that will let me see the broadband usage in any particular American City ?
By City, County or Zip Code ?

Thanks,

Dave","{'Glenn Fishbine': 'Here is an example for the U.S. & Canada using a 12 month extract of MLab data.  It\'s more or less at the city level.  Pick your state or province, then zoom around to areas of interest.  Where possible, cities are matched with city boundaries.\n\nhttp://expressoptimizer.net/projects/Demos/USMLAB.php  \n\nIf you need higher granularity, here\'s a live example using a heavily modified github version of MLab source from a few years ago.  You can zoom into a particular city on the map.  The address locations have been randomly drifted from the actual locations to preserve privacy.  It is not running on MLab servers.  The data collection is ongoing for the last 4 weeks or so.\n\nhttps://broadband.ramsmn.org/2020/04/13/st-louis-county-broadband-speed-test/ \n \n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/81072f78-d0d1-4a66-b537-9132c07b5ce6%40measurementlab.net.', 'Brian Rathbone': ""Dave,\n\nI don't know of any broadband utilization data set on Mlabs. You could potentially infer usage based on the number of MLabs speed tests per capita in a given area, but that does become a bit challenging when dealing with geolocated by IP address rather than actual end user location.\n\nThe American Community Survey is the only data set I know of with nationwide broadband adoption data, and it's limited to a yes or no question on whether there is a broadband connection in the household. I recall the data being at the census block group level. I don't know of an online interactive map at the granularity you need, but you could potentially download the data and map it locally. I've been working on a few things of this nature recently using QGIS.\n\nOnline map:\nhttps://www.census.gov/library/visualizations/interactive/acs-datamap.html\n\nYou can see how North Carolina used the ACS and FCC Form 477 data to created broadband indices.\n\nhttps://bi.nc.gov/t/DIT-Broadband/views/2017CountyIndices/BBADPStory?:isGuestRedirectFromVizportal=y&:embed=y\n\nhttps://www.ncbroadband.gov/indices/\n\nI hope that's helpful.\nRegards,\nBrian\n\ue5d3"", 'David Sandel': 'Hi Glen,\n\nThanks for sending this along. So if I understand this correctly, the target residents enter their location data \nand then the MLab test is run at that moment ? How is the latitude and longitude calculated?\nAfter this initial test has been run, does MLab continue to run the test in the background on an interval basis ?\n\nBack to you ,\n\nDave\n\ue5d3\n--\nDavid Sandel\nOffice 314-628-0688\niPhone 314-435-3658\nFax 800-640-8643\nTwitter @dsandel @ iNeighborhoods  \n\nFounder iiNeighborhoods\nCo-Founder STL-RIX\n6900 Delmar St. Louis, MO. 63130\nMy LinkedIn Profile', 'Walter': 'You are likely aware, but the FCC publishes broadband deployment data derived from the 477 forms at\n\nhttps://www.fcc.gov/reports-research/reports/broadband-progress-reports/2019-broadband-deployment-report\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/af9ef4d9-81d5-4efa-8f85-81a687843822%40measurementlab.net.', 'ball...@internet-is-infrastructure.org': 'The I3 Connectivity Explorer (https://i3connect.org) brings together the FCC, MLab, Census ACS 5, the National Center for Educational Statistics,  and other data sets and localizes the data to the places we live (counties, school districts, legislative districts, named towns, and tribal areas among others). There’s an overview at https://internet-is-infrastructure.org. But again, it doesn’t have usage data. \n\nBest regards,\n\n. . . Bob\n\nRobert A. Ballance, Ph.D.\nPrincipal, The Center for Internet as Infrastructure, LLC\nhttps://internet-is-infrastructure.org\n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CADeGG%3D7Kp%3Dip%3DKXkWOs_p7m6GNyG3dqztbzdsAjUgmpQiHw26w%40mail.gmail.com.', 'btnoreen': 'Hey Brian and Bob, \n\nI am working on the metrics of Messaging A2P, P2P and various uses of services, example, security, authentication, branding, chat, bot, etc. \nWould you know of any working structure to capture this information in an ongoing manner?  (Like ACS or 477?) \n\nThanks, \nNoreen \n\n\n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CADeGG%3D7Kp%3Dip%3DKXkWOs_p7m6GNyG3dqztbzdsAjUgmpQiHw26w%40mail.gmail.com.', 'James Miller': 'David\n\nWhat do you mean by usage?  \n\nIn FCC parlance, the number of folks that subscribe to a service in a given area is termed \'adoption\', and differentiated from \'deployment\' data that describes what\'s available.(Walt mentioned on this thread and should be easier to search on FCC tprc or other sources \n\nThe volume of traffic, or how much data is used by a typical user, is available in very aggregated stats from akamai and others but I\'m not aware of anything geocoded at zip code, city level.\n\nBeyond the temporal stratification the time period you would like may also be hard.  Diurnal, day of weekly, monthly are often also hard to find.\n\nCalculating usage as total traffic volumes can be tricky with active measurements but especially with a client server model that measures using connectivity shared with other traffic sources. \n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/81072f78-d0d1-4a66-b537-9132c07b5ce6%40measurementlab.net.'}"
125,154209469799469607099908854185189565581,blogpost:-monitoring-interconnection-performance-since-the-open-internet-order,"Aug 14, 2017, 8:09:51 AM",Collin Anderson,"Hello Discuss List –

From time to time, M-Lab submits technical recommendations and data-driven facts pertinent to its operations into regulatory proceeding around the world where appropriate. In the interest of more transparency on those interventions, we have started to maintain a public record on the site. I wanted to call attention to our most recent filing, into the Restoring Internet Freedom docket of the FCC, which is a followup from our past publication and post about interconnection performance. I found it to be an interesting exercise to see the alignment between press releases and the changes in network performance, so hopefully it might encourage others to pick up the data further.

Excerpt: 

In this post, we review historical interconnection congestion episodes that appeared to have had a negative impact on consumer broadband and followed how these relationships had changed since the Open Internet Order. Since our last blogpost on interconnection over two years ago, the relationships between operators have changed, resulting in overall improvement in consumer performance and a notable remediation of congestion episodes covered in our initial reports. Often the improvements are sudden, reversing months long underperformance within days. The remediation of congestion parallels an overall improvement across networks in performance for broadband users, and in our analysis we do not find the same patterns of sustained degradation described in past reports.

Full Post: https://www.measurementlab.net/blog/interconnection_update/
Other Regulatory Filings: https://www.measurementlab.net/publications/#government--regulatory-filings

As always, please send me any comments, critiques, or recommendations. We're always interested to hear where we can extend the research or further open up the data to those interested in such topics. 

Cordially,
Collin Anderson",{}
129,41414442594851312214544409256245931687,m-lab-samknows-impacts?,"Nov 6, 2014, 6:57:58 AM","Livingood, Jason","As a follow-up, the Cogent prioritization changes obviously impacted M-Lab NDT results. Since M-Lab servers are being used by SamKnows in the FCC’s ongoing Measuring Broadband America testing, is M-Lab planning to investigate how this change may have impacted the FCC’s testing (positively or negatively)? Also, do we know if the FCC was aware that this prioritization change was introduced and that it affected the servers they tested against and may have had some influence on the tests? 

Related to this, I would suggest researchers may want to compare the testing results over time between SamKnows servers on Cogent’s network with the ones  on Level 3’s network, as well as ISP networks. That in and of itself may be quite interesting.

Regards
Jason

PS – This list is awful quiet. I thought researchers were a more inquisitive bunch. ;-)","{'Matt Mathis': 'Thanks for the pointers. Yes I was sloppy about language. Sorry about that.\n\n> On the NxN proposal, is the idea that all nodes would test against a single server and round robin through measurement server lists?\n\nNo not at all.\n\nI was imagining multiple Measurement Points in all of the the top N\ntransit ISPs, such that each measurement client could test against all\nN geographically closest measurement points in N different transit\nISPs. MBA would then directly cover any access or interconnection\nperformance problems between any content in the top N transit ISPs and\nall users.\n\nSide issues:\n\n* N has to be large enough where we believe that ISPs outside of the\ntop N have multiple choices in choosing peers to reach all eyeballs.\n\n* All N transit ISPs are somewhat privileged in that their performance\nis explicitly monitored, so they should be subject to access like\nrules even if they are not classified as access ISPs. (e.g. regarding\ndisclosing prioritization, etc.) Note that I don\'t consider\nprioritization to be a bad thing, as long as it is transparent and\nstakeholders can understand and verify its consequences.\n\n* There needs to be enough MP where all transit ISP have have good\ngeographical coverage of all users. Note that M-Lab is making\nprogress here. Alternatively use something like Model Based\nMetrics[1], which can calibrate out the effects of long RTTs.\n\n*There has to be enough total test volume where all bins have\nstatistically significant test populations. This approximately\nraises the total number of required tests by a factor of N.\n\nNote that the above is really a sketch: many of the details can be\naddressed in multiple ways.\n\n[1] M. Mathis, A. Morton, ""Model Based Bulk Performance Metrics"",\nIETF work in progress, July 2014.\nThanks,\n--MM--\nThe best way to predict the future is to create it. - Alan Kay\n\nPrivacy matters! We know from recent events that people are using our\nservices to speak in defiance of unjust governments. We treat\nprivacy and security as matters of life and death, because for some\nusers, they are.\n\n\n\ue5d3', 'James Miller': 'Matt\'s concern to understand clearly what is measured and why is important and thanks for Jim\'s clarifications as well.  \n\nFor the FCC\'s MBA program, we started with a need to provide information to consumers and other stakeholders interested in the broadband ISP\'s performance.  That endeavor starts with understanding what portion of the end-to-end is under the control and management of the provider.\n\nSo it\'s close to ""last mile performance"" but our system is instrumented to capture performance within the scope of the provider\'s network as it touches the ""Internet"", e.g. the nearest tier1 peering point, down to the point where the customer takes control of the link and plugs into equipment provided or managed by the provider.    As our program has evolved we\'ve explored ""special studies"" on WiFi performance in the home and other topics that are beyond our V 1.0 of MBA.  \n\nMatt, I didn\'t understand your change to the MBA methodology to ""redefine[ to] require testing from all measurement clients to servers"".  The clients do a latency check to determine the latency-closest servers to test again but they\'re across all ISPs.  If you\'re proposing some clients testing on a round-robin of all servers to get a feel for the inter-network latencies, that is a different experiment and our current instrumentation may not be tuned to capture issues along the path that might influence performance as the server gets deeper into interconnected links between the providers first tier1 peering point and the other measurement servers.  We have folks looking more closely at that issue and you could certainly bring it up at an upcoming collaborative meeting where we discuss proposals and questions.\n\nJason\'s discussion started with a discussion of how prioritization may have influenced performance, and mostly wanted to clarify first the data is available for anyone interested in looking at it!  Super cool stuff..\n\n\n--\nJames Miller, Esq.\n\n""Japanese is so Eighties...""\nAnonymous FCC Colleague\n\n\ue5d3', 'Jim Partridge': ""Matt, as James Miller pointed out, all data is available, although there is a time delay in its release. I also wanted to clarify some of your mis-statements. The following language from the initial Measuring Broadband America report (at pg. 10) describes the scope of the measurements, which cover more than the last mile. Specifically, the test servers are off-net, meaning they aren't on the networks of the ISPs being tested. Cogent supplies transit to four of the off-net M-Lab test servers, therefore actions taken by Cogent on its transit links did and do impact the measurements taken in the Measuring Broadband America program. I don't completely follow your comment about accidentally encountering widespread transit/interconnect congestion, or which year you are referring to, but in each instance where there has been an adjustment to the testing period or procedures, it has been the FCC that has initiated and proposed any changes.\n\nThis study focused on those elements of the Internet pathway under the direct or indirect\ncontrol of a consumer’s ISP on that ISP’s own network: from the consumer gateway—the\nmodem used by the consumer to access the Internet—to a nearby major Internet gateway\npoint (from the modem to the Internet gateway in Figure 1, above). This focus aligns with the\nbroadband service advertised to consumers and allows a direct comparison across broadband\nproviders of actual performance delivered to the household.\n\nJim \n\ue5d3"", 'John Simpkins': 'There was a NANOG post about this back in October, just as an FYI: http://mailman.nanog.org/pipermail/nanog/2014-October/070428.html.\n\ue5d3', 'Livingood, Jason': 'On 11/7/14, 12:23 PM, ""James Miller"" <yosi...@gmail.com> wrote:\nthe providers first tier1 peering point and the other measurement servers.  We have folks looking more closely at that issue and you could certainly bring it up at an upcoming collaborative meeting where we discuss proposals and questions.\n\nAny idea when the next collaborative meeting will be? It’d be cool to talk about special studies on IPv6 (such as comparative IPv4 vs IPv6 performance across a range of protocols & sources & destinations), maybe something on DNSSEC (not sure what precisely), and other topics.\n\nJL'}"
130,17042426653747739107005892606139661730,m-labs-data-and-cogent-dscp-markings,"Nov 5, 2014, 8:51:09 AM","Kilmer, Hank","Due to the severe level of congestion, the lack of movement in negotiating possible remedies and the extreme level of impact to small enterprise customers (retail customers), Cogent implemented a QoS structure that impacts interconnections during the time they are congested in February and March of 2014. Consistent with recommendations from BITAG (Broadband Internet Technical Advisory Group: http://www.bitag.org/documents/BITAG_-_Congestion_Management_Report.pdf), Cogent prioritized based on user type putting its retail customers in one group and wholesale in another. Retail customers were favored because they tend to use applications, such as VoIP, that are most sensitive to congestion. M-Labs is set up in Cogent’s system as a retail customer and their traffic was marked and handled exactly the same as all other retail customers. Additionally, all wholesale customers traffic was marked and handled the same way as other wholesale customers. This was a last resort effort to help manage the congestion and its impact to our customers.

Hank Kilmer
Cogent","{'Livingood, Jason': 'The bar BoF at next week’s IETF is still an open offer. If folks are interested, indicate your so here:\nhttp://doodle.com/472knhcpm7yisui4 \n\nThanks!\nJason\n\ue5d3', 'Paul Wall': ""Don't do it, Hank, it's a trap!\n\nDrive Slow,\nPaul WALL\n\ue5d3"", 'Matt Tooley': ""As one of the contributors to the BITAG report on congestion management techniques, one of the key recommendations in the group's report is for network operators to be transparent about its network and congestion management techniques.  So it's great that Cogent is now sharing this with everyone as it now makes easier for researchers, network engineers, and consumers to better understand what is going so that they can act accordingly.\n\nAnd and bar BOF at IETF next week would be great.\n\n-- Matt\n\ue5d3""}"
131,261969298593104444792902898099440659592,ndt-results-suboptimal-for-10gbps-paths,"Jan 26, 2022, 9:12:03 AM",Tate Baumrucker,"Good morning,
We're seeing lower than expected tput results from a self-served NDT server for tests across a locally switched 10Gbps path.  iperf3 test results over the same path between the same client/server yield bidirectional > 5Gbps, but NDT results are ~1Gbps down and ~300Mbps up.  Tcpdump reveals significant tcp zero windows during the NDT session.

The server host is running BBR with appropriately tuned stack variables (proven by iperf3 tests).  

Are there any known limitations for 10Gbps link speeds?  Any hints for tuning or places to investigate further?
Thanks in advance,
Tate","{'Chris Ritzo': 'Thanks for adding that detail, Roberto, and clarifying that the initial question posed in this thread concerned testing of a self-provisioned ndt-server. Regarding M-Lab\'s production servers though, one other thing that should be mentioned is that if providers are advertising 5 Gbps and higher link speeds, I am certain that those speeds would only be within their network. Since M-Lab servers are always hosted in peering locations and networks, and NDT is a single stream test, we shouldn\'t expect measurements via those connections to be of total possible link capacity.\n\nBest, Chris\n\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/5eafcc16-15ed-4279-b57d-d9992f6122c0n%40measurementlab.net.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\ue5d3', 'Robert Enger': 'Matt:\n\nA consumer-grade user may be increasingly hard to define, as more and more of us work from home.\nI am retired and do volunteer work.  I have sent large ""pro video"" source files up to file sharing services to be transferred to editors.  \n\nGOOGLE DRIVE allows sustained upload at over 500Mbps, which really cuts down on the wait time.  10GiByte file uploads complete in a few minutes.\n(It would be nice to be faster, but the bottleneck appears to be at GoogleDrive or Google\'s PI with the ISP).   Mlab and other speed test measurements inform that finger pointing.)\n\nIn the LA area, there are many folks who produce and edit from home (for a living), and need to upload and download large files.\nWhile folks in LA (and other pro content creation hubs) are shooting with professional camera gear, consumer generation of large video files may become more common as higher image fidelity creation is supported on mobile devices.\n(Apple sponsors its ""Shot on iPhone"" program.  And other device manufacturers, including Google, are including improved camera sensors in their phones.  I\'ve seen ""shot on iphone"" short films run at film festivals.  Submittal to the festival was by online upload.)\n\nVelma does clinical monitoring of advanced cancer treatments.  While she travels to research centers, she does have a home office and accesses some resources remotely from time to time.\n\nI understand from her and the media that remote-reading of medical imaging occurs frequently.  (The radiologist that evaluates a given test may be in another state or country.)   As the imaging resolutions improve, transferred files will get larger.  (Detail counts when looking for lesions.)  We repeatedly hear that there is a  groundswell of employee support for ""work from home"".   High performance FTTH implementations make that increasingly feasible.\n\nMLAB testing can ensure that the promises of FTTH providers are actually delivered.\nDisparaging high performance seems like the old ""no one will need more than 640k"" mantra.\nI prefer ""if you build it they will come"".  \n\nI certainly enjoy being able to download OS patches and new SW ""quasi-instantaneously"". \nIndeed, downloads are so fast now that when a CDN errantly serves you from sub-optimal source (say one half-way around the globe in Europe) the degradation is readily apparent.\n\nWhen Velma\'s company\'s IT staff first deployed a remote update to her (then new) machine, they called her and told her they suspected it was not working correctly, as it completed so quickly.  (At the time she had one of the newest machines in her company.  It is M.2 based, and she is GigE attached to the home LAN, with Gig FTTH ISP service.)\n\nWindows-11 will force a lot of folks to replace their legacy PCs.  A whole lot of folks will be getting their hands on newer machines, many will be built upon M.2 NVMe.  \nThis will remove yet another layer of performance impediment from the consumer-grade user. Ditto for migrations to wifi-6E mesh systems, and mm-wave 5G for mobile devices (at least in good signal areas).\n\nI think Mlab and the other test services can continue to add value, even as consumer last-mile bottlenecks are removed (albeit at a seeming glacial pace with some ISPs).\nI hope Mlab will continue to support testing of high-speed connections, including the multi-Gig FTTH being deployed by Google, AT&T and some municipal ISPs.\n\nBob Enger\n\ue5d3', ""Roberto D'Auria"": 'Can this functionality be added to the self-hosted versions?  \n\nAssuming you\'re on a Linux environment, yes. This is implemented in the github.com/m-lab/access Go package and enabled via ndt-server\'s command-line flags:\n\n-txcontroller.max-rate=<rate in bits/s>\n-txcontroller.device=<interface name>\n\nThis will monitor the data usage on the specified interface and prevent new measurements from starting when it exceeds max-rate.\nYou can verify that it worked by starting a measurement faster than max-rate, then a separate one in parallel. It should fail to connect until the first measurement has been completed.\n\nPlease note, however, that this approach has a known issue. Specifically, if the client runs a download measurement and an upload measurement immediately afterward and the download speed was above max-rate, the upload will fail to connect. The download and upload measurements are independent events with regard to the ndt7 protocol, even if all the clients I know of run both by default. You can find more details at https://github.com/m-lab/ndt-server/issues/334\n\n-Roberto\n\n\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/5eafcc16-15ed-4279-b57d-d9992f6122c0n%40measurementlab.net.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\ue5d3', 'Tate Baumrucker': 'Can this functionality be added to the self-hosted versions?  \nThanks,\nTate\n\ue5d3', 'Matt Mathis': 'One of my regrets about MLab is that we have been overly focused on whether rich people are getting what they want, rather than whether poor people are getting what they need.\n\nYou are correct, we could raise our performance ceiling.   I first started working on Internet performance at the Pittsburgh Supercomputing Center in 1990.   That year, I was trying to get PSC -> SDSC to run faster than 5 Mb/s.  For many years, my day job was ""TCP tuning"", and every few years we would fix one global problem, but then have a new goal and a new set of problems to debug and deploy.  Yes we could raise MLab\'s target performance to 10 Gb/s.  Improving our  tools is probably doable, but upgrading our fleet would be problematic.\n\nHowever, today I worry far more about the other end of the spectrum.    I fear there are several billion of people (including millions of Americans) who don\'t have sufficient Internet to do basic things that the rest of us now take for granted.  \n\nWe do not know if MLab tools get reliable measurements below 1 Mb/s, and that means we can\'t effectively measure Internet coverage for a huge number of people.  We do know that some of the optimizations that are likely to help the high end have the potential to hurt measurements at the low end (specifically larger buffers).  We do know the data collection and processing pipeline is capable of reporting all the way down to about 1kbit/sec, but the each diagnostic client has it\'s own limits.\n\nYou might find this plot useful: it was on my home page at PSC for many years:\n\n\n\n\n\ue5d3\n--\nThanks,\n--MM--'}"
134,45281939118931811199284084296830165522,blog-post-re-ndt-and-0x48,"Nov 3, 2014, 7:27:54 AM","Livingood, Jason","I noticed the recent blog post at http://www.measurementlab.net/blog. I did want to point out that the line of inquiry to understand why the appearance of the 0x48 ToS setting seemed to correlate to improved NDT performance (and potentially Netflix as well) is very interesting. Keep digging – and see some subsequent emails from me on the subject.

From your blog:
One of the most common questions from reviewers was the change in performance in late February 2014 for AT&T, CenturyLink, Comcast, Time Warner Cable, and Verizon traffic across U.S. Cogent sites. As a graph included in the published report demonstrates (Figure 7), the data shows a sharp remediation in performance across all Access ISP networks in February 2014 for Cogent hosted sites. (The graph covers Los Angeles, but this pattern was repeated across all Cogent hosted sites.)
This February 2014 time period is notable because the sharp remediation occurs across all affected Access ISPs simultaneously. This is observed despite published media reports that business decisions in 2014 to alleviate congestion between ISPs, transit networks, and major content providers did not happen simultaneously. Based on the M-Lab data, it was not possible to determine the cause of this event in our recent report. However, since this remediation represents an important event related to business decisions and traffic patterns, we chose to present it here to the research community in the first of our follow-up posts.
In the interest of further investigating this sharp change, we began to audit the rawndttrace log files retained after the NDT test (and available in BigStore) to see if we could observe patterns that could help explain the sharp performance change.
And, we found something. In the course of this investigation, researchers identified a shift in the marking of the standard ‘type of service’ (ToS) IP header field of incoming packet. This change began February 2014, and correlated with the increased performance observed across Cogent hosted sites. This field is typically used to indicate to routers along the path of a network what the priority and policy for handling the traffic should be. In the case of measurements against M-Lab servers, this field was set to a value that corresponds to ‘Immediate’ priority.
Using the New York Cogent site as an indicator, at the beginning of February 2014, only a tenth of sampled incoming measurements to M-Lab endpoint servers observed packets with a marked ToS field. On February 20, 2014, this number increased to 30% and within five days, this number increased to around 94% of measurements. As Figure 7 demonstrates, a similar increase in download throughput across sites occur at this time. Based on preliminary samples from October 2014, it appears that this quality of service policy continues.
Below we show an example of the ToS field in the IP header of packets received from a Verizon FIOS customers on February 28, 2014 from the data we extracted. Those wishing to explore this more fully are welcome to access the NDT data archives from BigStore. Each M-Lab site should have an extensive sample of ndttrace files.
16:21:09.973746 IP (tos 0x48, ttl 55, id 23787, offset 0, flags [DF], proto TCP (6), length 1500)
    pool-108-41-239-212.nycmny.fios.verizon.net.57090 > 38.106.70.160.40047: Flags [P.], seq 3337041:3338489, ack 0, win 8235, options [nop,nop,TS[|tcp]>
        0x0000:  4548 05dc 5ceb 4000 3706 17e1 6c29 efd4  EH..\.@.7...l)..
        0x0010:  266a 46a0 df02 9c6f 241b 4941 fb8f 03bf  &jF....o$.IA....
        0x0020:  8018 202b f194 0000 0101 080a            ...+........
What does this indicate? It indicates that the recovery from the degradation in performance observed prior to February 2014 may not have been experienced by all consumers.
Why this was applied to M-Lab traffic, or if it was applied more broadly, or if it was applied across all traffic is not clear. What this finding highlights is that network management and the differences in treatment of traffic is instrumental to the performance of consumer access. More importantly it reaffirms the importance of transparency and open data in providing the public with a clear understanding of Internet performance.
We will be exploring this topic and others in upcoming research, looking across the data in the US and elsewhere to see if we can observe other patterns in the IP headers, routes or other data artifacts, and when and if we do, working to understand how these correlate with observed changes in performance.


Jason Livingood
Comcast","{'Collin': 'Hi Jason, \n\nTotally agree that these findings are interesting, and have been parsing out the dataset since first discovery. As you know, “DSCP codepoint” is one of many ways that changes in network behavior might be revealed. There were also avenues with regard to detecting paths, etc. From our perspective, network management practices are an area of the Internet performance that is both consequential to the user and not well-documented; understanding those practices is key to interpretation of the data and design of experiments. The post was intended to call out that one of the next directions M-Lab researchers intend take is investigation of the effects.\n\nOn the questions of the web100 values in BigQuery and missing ndttrace files, I have reached out to other colleagues in M-Lab to investigate. Several people have been travelling over the past day, but we will follow up later this week. \n\nCordially,\nCollin\n\ue5d3', 'Livingood, Jason': 'As a follow-up, I would like to hear if there are any thoughts about the presence of 0x00 and 0x48 ToS on the transit network hosting the M-Lab servers. The NDT data seem to confirm the existence of two different priorities in the network, as the M-Lab blog clearly lays out. We are left to wonder what else on the network was prioritized and what was de-prioritized. But it does seem that, In the vernacular of today’s FCC-related debates, this network had a fast lane and a slow lane… ;-) But back to the technical stuff; there were two priority levels on the network based on the M-Lab/NDT data.\n\nIt also seems possible that congestion (perhaps even quite a lot of it) existed on portions of that network. Usually I would have just concluded that the different DSCP/ToS markings were so that the network operator could apply separate accounting/billing or security policies, which is not uncommon. But the fact that the NDT results immediately and dramatically improved in step with the move of those tests to a higher relative priority suggests to me that whatever was put into the lower priority was overwhelming the network and squeezing out the potential of the NDT tests. Once NDT was prioritized above that other traffic, it could win out over the other traffic competing for bandwidth. Does that make sense to anyone else here?\n\nI suppose one could say it was still a problem at the interconnect points, except that any network receiving packets from this network would generally over-write or otherwise ignore the ToS/DSCP markings (which are generally only impactful within a network domain rather than across network domains, unless there was express agreement & coordination on these values across networks – such as between a customer and upstream service provider). So given that most any large network exchanging packets with this transit network would have (1) ignored the different markings and (2) likely did not massively increase capacity during the Feb 2014 timeframe, that suggests to me NDT performance increase was due more to new network management / congestion management policies on the transit network than anything else. \n\n- Jason \n\ue5d3'}"
150,282618892024283877162294680563337407640,accuracy-of-lat-and-long-in-speed-tests,"Aug 20, 2021, 5:10:31 AM",Bradley Kalgovas,"Hi There, 

How accurate are the lat and long of speed tests? Do you anonymize them in any way or are they pretty accurate to the location where the speed test actually occured. 

Kind regards,
Bradley","{'Chris Ritzo': ""IP address geolocation is the location of whatever infrastructure hands your router an IP address, as opposed to a precise location from GPS. I wrote about the limits of IP address geolocation precision in this blog post, which outlines the differences in context:\nhttps://www.measurementlab.net/blog/exploring-geographic-limits-of-ip-geolocation/\n\nUsing the NDT crowdsourced data alone in BigQuery, unfortunately you can't segment tests by things like access media (cable, dsl, fiber, LTE, etc.), service tier of the subscription, or business vs. home connections. I think that this can be accomplished using an API such as https://ipinfo.io , by looking up individual IP addresses in the NDT dataset and pulling fields from their API. However, it's still crowdsourced data, so many things need to be accounted for when generating any aggregate analyses. See this post for a starting point: https://www.measurementlab.net/blog/mlab-data-policy-advocacy/\n\nPerhaps others on the group have alternative suggestions as well. For example, collecting new data from known locations using a standardized and tested on-premise device is an approach researchers use to control for the issues that need to be addressed in crowdsourced data analyses.\n\nThanks,\nChris\n\ue5d3"", 'b.ra...@gmail.com': 'Also can you let us know what is the difference between the location IP address and the actual test device? Thanks!\n From: Chris Ritzo <cri...@measurementlab.net>\nSent: Friday, August 20, 2021 5:17 AM\nTo: discuss <dis...@measurementlab.net>\nCc: b.ra...@gmail.com <b.ra...@gmail.com>\nSubject: Re: Accuracy of lat and long in speed tests\n Hi Bradley,\n\ue5d3', 'Ralf Lübben': 'Hi,\n\njust to complement, since we looked into the accuracy, too.\n\nThere is a report from 2017\n\nhttps://www.caida.org/catalog/papers/2017_look_at_router_geolocation/look_at_router_geolocation.pdf\n\nand MaxMind has some information, too\n\nhttps://www.maxmind.com/en/geoip2-city-accuracy-comparison\n\nRegards,\nRalf\n\ue5d3\n> --\n> You received this message because you are subscribed to the Google\n> Groups ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it,\n> send an email to discuss+u...@measurementlab.net.\n> To view this discussion on the web visit\n> https://groups.google.com/a/measurementlab.net/d/msgid/discuss/0a4cf65e-2a0b-4c8c-9436-b72f17731003n%40measurementlab.net\n> .'}"
151,283822333051144385537795302697785233106,what-exactly-is-mean-throughput-on-the-ndt7-test?,"Jul 21, 2021, 1:50:39 PM",Kelsey Nanan,"Hi, 

In the schema for the NDT7 test, a.MeanThroughputMbps is defined as follows: 
""The measured rate as calculated by the server. Presented in megabits per second, or Mbit/s, this value is the average of tcp-info snapshots taken at the beginning and end of an ndt7 measurement. Therefore it is identified as “MeanThroughputMbps”.""

I was wondering exactly what TCP Info snapshots are averaged to calculate Mean Throughput, since it seems as there are many TCP Info fields. 
Also, does Mean Throughput average both upload and download speeds? 

Thanks for any help!
Kelsey","{'Chris Ritzo': 'Hi Kelsey,\n\nI might back up and suggest that depending on your line of inquiry or research question, the ndt7 table may not be the right table to look at. If you are interested in looking at all ndt7 tests including those that failed, or were not complete, according to our team\'s best understanding, then continue using the ndt7 table.\n\nHowever, if you are interested in only ndt7 tests that are considered by M-Lab to be complete and valid tests for understanding what ndt7 measures, then our NDT unified views should be your starting point for queries. For more information, this blog post discusses the NDT unified views and what they provide.\n\nI also must recommend that you review our blog post, Using M-Lab Data in Broadband Advocacy and Policy, for our research recommendations when working with NDT data.\n\nndt.unified_uploads and ndt.unified_downloads allow you to query specifically for one or the other or both measurements, and these views are filtered to provide only tests that meet our team\'s understanding of test completeness. You can join the upload and download measurements using the UUID field if you want to get both...\n\nTo query the unified ndt views for only ndt7 tests, you can use the field node._Instruments in the WHERE part of your query. For example: WHERE node._Instruments = ""ndt7"" will return only ndt7 tests.  If the value of this field is ""tcpinfo"" then the test will be from the ndt5 protocol.\n\nSpecific to your questions about the schema pages and the measurements in the ndt7 table, my apologies that the schema descriptions on the website are not up to date. We hope to rectify that soon. The field names and descriptions are valid, but may not be complete or in the same order as those in the BigQuery tables. For the most current schema fields, I would rely in the listing in BigQuery as seen in the screenshot below, and for field descriptions, reference the pages on our website for now.\nThe individual upload and download measurements in the ndt7 table are stored within the raw record section under raw.upload and raw.download. If the row is an upload measurement, the raw.upload fields will be present, and download fields will be blank or null. Vice versa for download measurements. So if you are looking at the field ndt7.a.MeanThroughputMbps, this value will be the upload measurement when the field raw.Upload.UUID is not null, and will be the value for a download measurement if the field raw.Download.UUID is not null.\n\nI hope this helps.\n\nBest,\nChris\n\ue5d3', 'Kelsey Nanan': ""Hi Chris, \n\nThank you so much for your quick response! I ran the following query a while ago (before I knew a bit more about speed tests - upload vs download lol): \n\n\n\n(Sorry for the poor image quality) But would the a.MeanThroughputMbps that I downloaded be average upload or download speed? And if I want to get the individual upload and download mean throughput values, what would those fields be called in the database? I'm looking at the BigQuery schema here - https://www.measurementlab.net/tests/ndt/ndt7/#ndt7-bigquery-schema , sorry if I seem to be missing it.. \n\nThanks for your help! \nKelsey\n\ue5d3""}"
153,225975279623125061932807887233902154346,spanish-instructions/interface-for-speed-test,"Mar 16, 2021, 12:39:54 PM",Rich Stalzer,"Good day, I chair a Broadband Access committee in my rural NY State town, and am about to launch a survey on local broadband availability and affordability.  I plan to link to the m-labs speed test but would like to offer the survey in Spanish as well as English.  Is there a Spanish language instruction or landing page that uses the m-labs infrastructure in the US?

Thanks,
Rich Stalzer
Town of North East, NY Broadband Access Committee","{'Chris Ritzo': 'Hello Rich,\nWith apologies for the delayed reply, yes, you can direct Spanish speaking users to this URL for our speed test: https://speed.measurementlab.net/es/#/\n\nWe had an issue with a recent update to that site where the available translations were not working, but this is now fixed.\n\nBest regards,\nChris - M-Lab Support\n\ue5d3', 'Rich Stalzer': 'Thank you.  \n\nVirus-free. www.avg.com\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/5c3e87bc-ee48-474a-a4fa-e027180ec38dn%40measurementlab.net.'}"
158,262987201061517279439198076148742717915,ndt-upload-speed-calculation-issue,"Dec 5, 2019, 2:35:42 PM",WestNGN Broadband,"Hello, 

I seem to have encountered an issue concerning the calculation of upload throughput while accessing the Measurement Labs NDT database through an SQL query.

The calculation and query is this as per https://www.measurementlab.net/data/docs/bq/ndtmetrics/:
#standardSQL
      8 * (web100_log_entry.snap.HCThruOctetsReceived /
          web100_log_entry.snap.Duration) AS upload_Mbps

The issue is that when I perform this calculation the upload speed always shows less than 1 Mbps, whereas the reported calculation is usually around 10 or 11 Mbps.
Is there some piece of the calculation that I am missing, or is there an issue with my syntax that I'm not seeing? 

Thanks for all of your help in the past, and I hope you can help here as well. 

Regards,
Matthew Wilson from WestNGN ","{'WestNGN Broadband': 'Just to clarify, here\'s the complete SELECT statement\n    SELECT\n      8 * (web100_log_entry.snap.HCThruOctetsAcked /\n        (web100_log_entry.snap.SndLimTimeRwin +\n        web100_log_entry.snap.SndLimTimeCwnd +\n        web100_log_entry.snap.SndLimTimeSnd)) AS download_Mbps,\n      8 * (web100_log_entry.snap.HCThruOctetsReceived /\n          web100_log_entry.snap.Duration) AS upload_Mbps,\n\n        connection_spec.client_geolocation.latitude AS client_lat, \n        connection_spec.client_geolocation.longitude AS client_lon,\n        connection_spec.client_ip AS client_ip,\n        log_time,\n        FORMAT_DATETIME(""%F %X"", DATETIME(log_time, ""UTC"")) AS client_test_time,\n        test_id \n    FROM\n      `measurement-lab.ndt.web100`\n    WHERE\n      partition_date BETWEEN \'2019-10-01\' AND \\now\\\n      AND connection_spec.data_direction = 1\n      AND web100_log_entry.snap.HCThruOctetsAcked >= 8192\n      AND (web100_log_entry.snap.SndLimTimeRwin +\n        web100_log_entry.snap.SndLimTimeCwnd +\n        web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n      AND (web100_log_entry.snap.SndLimTimeRwin +\n        web100_log_entry.snap.SndLimTimeCwnd +\n        web100_log_entry.snap.SndLimTimeSnd) < 600000000\n      AND web100_log_entry.snap.CongSignals > 0\n      AND (web100_log_entry.snap.State = 1 OR\n        (web100_log_entry.snap.State >= 5 AND\n        web100_log_entry.snap.State <= 11))\n\n\n '}"
159,211356664626085069356088486997364769527,m-lab-seeking-contract-developer-for-web-application,"Oct 15, 2019, 5:55:15 AM",Chris Ritzo,"Greetings M-Lab Discuss members,

I'm writing to share an opportunity to do some contract web development for M-Lab.

We are seeking a contract developer to improve and build new features for a web application called Piecewise. This application is a public engagement portal, providing a web-based survey, M-Lab NDT test, and asks the user to consent to share their location to enable fine grained spatial aggregation of the data. Deployments of this application have enabled communities to gather their own data to support policy advocacy at the local level. Most recently, the MERIT network in Michigan used Piecewise in a pilot to study the homework gap in their state (https://mi.broadbandtest.us/).

We now have funding to support taking Piecewise from a prototype application to a containerized or Software as Service product. This will enable more communities to easily deploy and use M-Lab tools and data for their advocacy, research, or public engagement.

The attached work scope describes the current application state, roadmap, timeline, as well as the budget we have to support this work.

If you are interested in learning more, please reach out to myself (cri...@measurementlab.net), or M-Lab Director, Lai Yi Ohlsen (la...@measurementlab.net).

--
Chris Ritzo (he/him)
Program Management & Community Lead, Measurement Lab
sup...@measurementlab.net",{}
160,73412023678843932755314063581352528509,broadband-cooperative---data-deep-dive,"Sep 26, 2018, 1:28:22 PM",Jason Weaver,"Hello

I am consulting with a newly formed Broadband Cooperative and we are looking to use this data to map out un-served or under-served homes in six counties of South Central Pa. 

In the description for the ndt-ws test it indicates that the test pulls geo data. How accurate is the Geo Data being provided? Is the data available as part of the data set that is publicly available? Are there any scripts available that can be deployed an a wordpress site that will assist us in tying the results of a test to a contact with an address?

Thank you advance for your advice.","{'Chris Ritzo': 'Hi Jason,\n\nThanks for sending this inquiry and our apologies for the delay in replying. \n\nM-Lab uses is from the openly available Maxmind Geolite 2 databases to annotate geographic fields for our NDT client tests. Maxmind includes an accuracy radius for it\'s IP address geo-location database. In short, the geo data is as accurate as the Maxmind dataset. We don\'t have anything like a wordpress plugin at the moment, but if you\'re interested in more accurate Geo Location associated with test results, there are some options. A number of cities [1] and other municipal areas [1] have been using an open source web app called Piecewise to host a survey form, the NDT speed test, and map aggregate statistics for a chosen geographic region. In Pennsylvania, there is currently a broadband testing initiative through the legislature\'s Center for Rural PA. These initiatives submit standard M-Lab tests, which are later annotated as described above, but the website integration separately saves more accurate geo-location using HTML5 in a private, non-M-Lab hosted dataset.\n\nIf you have any questions about these initiatives please don\'t hesitate to ask, or email at sup...@measurementlab.net\n\nBest regards,\nChris\n--\nChris Ritzo\nMeasurement Lab Operations & Support\no...@measurementlab.net | sup...@measurementlab.net\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}"
165,125537068253285551689985902348488958675,monthly-download-speeds,"May 11, 2022, 7:30:09 AM",Marlene Wendl,"Hi,

I'm looking for monthly average mobile download speed data by country, specifcally from 2011 onwards (the earlier the better though).

So far I've only been able to find data from 2021.

Can anyone help me with that? I'd be really greatful for any advice!

Thanks in advance!","{'laurent smeets': 'I will follow this, as I am looking to do something fairly similar. The final product I am looking for a  collection of  map (either as raster or a shapefile) of a country (for example Belgium) with local average internet speeds (based on the web100 test) for different years going back to 2010 (so one map per year). The higher the spatial resolution the better, but for now I am thinking of 0.1x0.1 degree lat/lon as the resolution.  I am comfortable in geospatial analysis, but new to BigQuery. Could you help me point to a location where I can find more information on how to construct a query like this or help me create it.\n\ue5d3', 'Lai Yi Ohlsen': 'H both, \n\nThanks for reaching out. Marlene, would you be able to share the query that\'s only sharing data for 2021? \n\nLaurent, I these blog posts might be of use to you: \nExploring NDT Data by Geography in Baltimore City\nAnalysis Recommendations in Context - ARC of Research pt. 1: Asking the Right Questions\nARC of Research pt. 2: Exploring Data Sources Relevant to Our Questions\n\nThe first one particularly, as it describes how we annotate locations in more detail. In short, we use the IP address and annotate it using the MaxMind GeoIP database with a resolution that is much less specific than the one you\'re looking for. I\'d be happy to learn more about your work offline to better understand how we are meeting or not meeting your use case. \n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/3f4440dc-60f6-4908-96a4-e66032201f28n%40measurementlab.net.\n\n\n--\nLai Yi Ohlsen\nDirector, Measurement Lab\nCode for Science & Society'}"
167,278386105536745236081504722614049204308,query-keeps-giving-errors,"Apr 20, 2022, 7:18:52 AM",poonam parab,"Hello 

I am trying to find the latest upload and download speed data for Rhode Island. 
this is the syntax I am trying to run. 

SELECT * FROM
  `measurement-lab.ndt.unified_downloads`
WHERE 
  date BETWEEN ""2022-01-01"" AND ""2022-03-01""
  AND client.Geo.Region = ""RI""
  AND client.Geo.country_code = ""US""
GROUP BY zip_code, ASN
ORDER BY zip_code, ASN

It keeps giving me an error. Can you please help me resolve this? 

Thank you,

Poonam ","{'Phillipa Gill': 'Hi Poonam,\n\n3 things jump out at me looking at this query:\n(1) We recently shifted from using client.Geo.Region for the state to using client.Geo.Subdivision1ISOCode\n(2) The country information is in client.Geo.CountryCode\n(3) zip_code and ASN are not defined in the query snippet you sent. \n\nHope this helps.\n\n-Phillipa\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/179d5e10-90b8-49a9-8c7a-863544250f75n%40measurementlab.net.'}"
170,183522098932564153707256086181616923686,speed-test-issues-when-using-cellphone-browser,"Feb 15, 2022, 10:33:17 AM",Magellan Advisors,"We are using Alcehmer for our surveys and have the speed tests built in.

The speed test on cell phones returns what seems to be invalid speeds on the upload test.  Returns extremely high speeds.  Download test seems reasonable.

Anyone who can help our team with this?

-Kelly","{""Roberto D'Auria"": 'Hi Kelly,\nThanks for reporting this. I assume you are using the ndt7 protocol via the ndt7-js client library? There is a known issue with Webkit-based browsers where the upload speed is reported incorrectly, and I think this might be what you are seeing. It has already been reported upstream on the WebKit bug tracker and we\'re currently waiting for a reply (https://bugs.webkit.org/show_bug.cgi?id=235707)\n\nWe have recently updated our example client code (https://github.com/m-lab/ndt7-js/blob/main/examples/client.html#L48) to report the upload speed using server-side measurements rather than the rate reported by the browser.\n\nWould you be willing to replace the rate calculation in the uploadMeasurement and uploadComplete callbacks with the ones in the example linked above and see if that fixes the issue? Thanks!\n\n-Roberto\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/418692db-cfc3-4cd2-a148-04534736bdb3n%40measurementlab.net.'}"
172,198101303410413083408001446640263081741,api-to-validate/get-a-specific-ndt7-result,"Jan 25, 2022, 12:36:56 PM",Yihwan Kim,"Hi, is it possible to ""validate"" or GET a specific NDT7 result, perhaps using id/uuid?

The idea is to create an app that stores and presents speed test results in a useful way. However, I'd like to protect against malicious behavior (e.g., hammering my app with fake data). One way to do this might be to only send the UUID of a test result to my server, which would then GET all the desired fields using that UUID. 

Also open to any other suggestions or considerations too. Thanks in advance for your help. ","{'Chris Ritzo': ""By BigQuery API, may I assume you mean SQL querying using BigQuery? There isn't an API, it's just querying the NDT data. You can use this guide to get your account on the access list: https://measurementlab.net/quickstart\n\ue5d3"", 'Yihwan Kim': ""Thanks Chris! Just to circle back on this, I requested BigQuery API access a while back by emailing support@, but I haven't heard back yet. Do you know if BigQuery API access is still available? \n\nHappy to share my intended use case or any other information that'd be helpful\n\n\ue5d3""}"
174,96309575932128242265465539697997771071,question-about-inconsistent-upload-speeds-on-iphone-and-duplicate-results-using-ndt7-client-library,"Dec 10, 2021, 12:30:32 PM",Albert Liang,"We have a speed test instance leaning on the javascript NDT7 client library.  We are starting to notice a couple of interesting things:

- Some repeated speed tests have wildly varying upload speeds.  One data block that we're observing ran the same speed test 21 time in a row, and reported 5 data points ~1 Mbps and 12 data points over 1 Gbps.  The download speeds did not vary between any of these runs (held steady between 9-10 Mbps).  The user is on DSL and was using an iPhone and mobile browser to run the test.  We were able to replicate it using an iPhone as well.

- We are also noticing duplicate results that are spaced less than 10 seconds apart.  All result values are identical except for the timestamp.  We don't think it's a user running back-to-back tests because it takes ~20 seconds to complete a test.

Has anyone else experienced these things before?

--
Albert Liang
Software Developer Intermediate

akl...@merit.edu | 734.527.5763 p | 713.301.8907 c | www.merit.edu
880 Technology Drive, Suite B | Ann Arbor, MI 48108-8963

     Learn More About Merit Services","{'frog...@gmail.com': 'Did you check whether the measurements were targeted to the same servers?\nRicky\n\n\ue5d3', 'Chris Ritzo': ""Thanks for reporting these issues.\n\nI'm not sure if this is the exact issue you're users are experiencing, but the M-Lab engineering team identified some issues with iOS browsers' last June, which were documented in this blog post. Two issues were both related to upstream issues with Safari's implementation of websockets. Our team will be submitting bug report(s) to Apple soon. Both Safari and Chrome on iOS are affected.\n\nIf you were able to capture JavaScript console logs from an iOS device that is experiencing this, our team could confirm if the above mentioned bugs are the cause. If you are comfortable sharing more details about your testing device (date/time of tests, public IP address of the iOS device when the tests were run, or if you have it the UUID of the test result provided back from our servers) this might help our team further diagnose the issue.\n\nPlease feel free to email sup...@measurementlab.net with the above information if you prefer to not post it here in our public group.\n\n--\nChris Ritzo (he/him)\nUser Experience Advocate & Data Support Specialist, Code for Science & Society\n\n\ue5d3""}"
175,77393310530205818700973996924667364959,data-for-montenegro---urgent,"Sep 30, 2021, 6:04:15 AM",Danilo Janković,"Dear colleagues,

Can you please tell me how to extract download speed, upload speed, RTT by operator in Montenegro? Which database to use?

This info is urgent so I will appreciate a quick response.

Kind regards,
Danilo.","{'Fabion Kauker': 'Hi Danilo\n\nNot sure if this is what you need but here is what I have done for Kenya. You\'ll need to modify the SELECT to get operator.\n\nThe process is as follows:\n\n1. Goto the BigQuery project - https://console.cloud.google.com/bigquery?project=measurement-lab\n2. Enter this query - \nSELECT client.Geo.longitude, client.Geo.latitude, test_date FROM `measurement-lab.ndt.unified_downloads_20201026x` WHERE date < \'2020-08-31\' AND client.Geo.country_name = \'Kenya\'\n3. Wait ~10 minutes\n4. Export to GDrive\n5. Download csv\n6. (optional) Run unique.sh or cmd - cat bq-results-20210831-223756-jbpp8ss4yyac.csv  | cut -f1-2 -d , | uniq > kenya_unique.csv\n\nFabion\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CALkOHCrwQXNs_rgwDU1x-247gQ_03AfR4E_%2BmDyKj_B5FAwUzQ%40mail.gmail.com.', 'Chris Ritzo': 'Thanks for sharing, Fabion. I was curious if you were using the table:\n`measurement-lab.ndt.unified_downloads_20201026x`\ninstead of:\n`measurement-lab.ndt.unified_downloads`\n\nAdditionally, I wanted to mention that M-Lab\'s statistics pipeline service now provides aggregate statistics by day for various global geographies. Currently data from 2020-01-01 to present is available. \n\nThe data from the statistics service may be accessed in several ways:\nData Studio interactive reports listed on this page\nBigQuery tables in `measurement-lab.statistics`\nJSON API documented here\nFor Danilo\'s question, I would recommend querying `measurement-lab.statistics.v0_countries_asn` or using the corresponding JSON API endpoint.\n\nI hope this is helpful.\n\nBest, Chris\n\nOn Thursday, September 30, 2021 at 11:28:40 AM UTC-4 f.ka...@gmail.com wrote:\nHi Danilo\n\nNot sure if this is what you need but here is what I have done for Kenya. You\'ll need to modify the SELECT to get operator.\n\nThe process is as follows:\n\n1. Goto the BigQuery project - https://console.cloud.google.com/bigquery?project=measurement-lab\n2. Enter this query - \nSELECT client.Geo.longitude, client.Geo.latitude, test_date FROM `measurement-lab.ndt.unified_downloads_20201026x` WHERE date < \'2020-08-31\' AND client.Geo.country_name = \'Kenya\'\n3. Wait ~10 minutes\n4. Export to GDrive\n5. Download csv\n6. (optional) Run unique.sh or cmd - cat bq-results-20210831-223756-jbpp8ss4yyac.csv  | cut -f1-2 -d , | uniq > kenya_unique.csv\n\nFabion\n\nOn Thu, Sep 30, 2021 at 6:04 AM Danilo Janković <danilo.j...@gmail.com> wrote:\nDear colleagues,\n\nCan you please tell me how to extract download speed, upload speed, RTT by operator in Montenegro? Which database to use?\n\nThis info is urgent so I will appreciate a quick response.\n\nKind regards,\nDanilo.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\ue5d3', 'Danilo Janković': 'Dear Fabion, Chris,\n\nThank you very much for your help and reply.\n\nKind regards,\nDanilo.\n\n\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\ue5d3'}"
176,287631318302926377924266770312232741672,australian-speed-test-data-outliers,"Sep 21, 2021, 12:32:59 PM",Bradley Kalgovas,"Hi Chris,

We are looking into the Australian Speed Test data and we noticed that there are some outliers which don't make any sense to us. Specifically, since 1 Jan 2021:
Within the Lower Murray SA3 (10902) which is comprise two SA2s (10902 1178 and 10902 1179) the 10902 1179 SA2 area has 274210 speed tests. This is much greater than Sydney Inner City SA3 (11703) which has 27,409 speed tests (see screenshot 1 and 2). 
Also within the North Canberra SA3 (259,123), there are 259,123 speed tests. While this seems ok as it is the nation's capital, it is confusing as the areas around that do not have such a high level of speed tests (see screenshot 3)
Kind regards,
Bradley","{'Chris Ritzo': ""Hi Bradley,\n\nI think what you may be seeing here as outliers is more an issue of how NDT test results are geolocated.\n\nThe lat/lon coordinates in each NDT test row are a geolocation of the client IP address, as identified by the Maxmind Geolite 2 database. The coordinates are not the location of the person running the test, but the location of the infrastructure that provided them an IP address. A related field in the dataset, client.Geo.AccuracyRadiusKm, also comes from Maxmind and might be useful in your analyses.\n\nTo illustrate, I identified the geographies I think you're using, and loaded them into my GIS program along with all grouped lat/lons from NDT download tests in Australia this year. The results are seen in the maps below. First, the whole country, where we see what I might assume are clusters of tests mostly in the most populated areas. The second image is a zoom in on parts of Sydney, NSW, where you can also see some areas that don't contain geolocated tests.\n\nI hope this helps explain what you're seeing, but please let us know if you have other questions.\n\nBest,\nChris\n\n\n\ue5d3""}"
177,336172831439243593195256305513376318775,record-count-vs-ul/dl-samples,"Aug 27, 2021, 8:46:03 AM",Patrick Duffy,"Hello!

I am working on a small project using M-Lab data and had a question. If I am looking at data for a city broken out by the day, what does the variable ""record count"" mean and how would that differ from the sum of ""Ul Samples"" or the sum of ""Dl Samples""? 

For example, I have data for a particular date that says record count = 24 and sum of Ul Samples = 1248. Does that mean only 24 speed tests were conducted on that day? 

Sorry for being a total beginner and thanks for any help!

Best,
Patrick ","{'Chris Ritzo': 'Hi Patrick,\nSorry for the delay in responding to your questions.\n\nCould you be more specific about the data source? I think you are looking at aggregated data from one of our DataStudio reports, not querying the data using BigQuery. Is that right? ""record count"" sounds like a field provided by a DataStudio report. \n\nIn general, because of the way the NDT test works, the number of upload and download samples could be different. For example, if someone runs the test it appears to be one thing, but the upload and download measurements are stored separately. If a test is cancelled after the upload test completes but before the download does, then there would be one less download measurement than upload. The reverse is also possible depending on where the user ran the test. For example the Google search integration of the test runs download first, but other versions runs upload first.\n\nLet us know more information about where you\'re getting Record Count and samples for a day, and if you are running a query, please feel free to share it as well. \n\nBest,\nChris\n\ue5d3'}"
182,120232539858998306843060267097955421967,mlab-speed-test-data-open-repository,"Apr 24, 2021, 4:06:47 AM",Ankur Khanna,"Hi,

Is Mlab open source repository with speed test data available? I need to analyze data on a global scale for a college project.","{'Ankur Khanna': 'Hi,\n\nI found the Google cloud platform with ndt7 data, which has upload and download folders with json file. Im not sure how to calculate the download n upload speeds from that data. Any help would be appreciated. Thanks\n\ue5d3', 'Chris Ritzo': 'Hello and thank for reaching out.\n\nAccessing the raw test archives in GCS is useful if you wish to study the raw measurements and associated pcap files from NDT tests. However, the recommended starting point for most people is to use SQL within BigQuery. Pcap files are not currently in BigQuery.\n\nWe parse all NDT results into a series of BigQuery tables, and further do some data cleaning and schema standardization across all NDT datatypes (ndt5, ndt7, web100), and finally provide the result in a set of BigQuery views.  Use BigQuery if you wish to perform your own analyses of individual NDT tests using SQL.\nFollow our quickstart guide to add your account to our access group to get started\nNDT Data in BigQuery outlines what datasets, and views to use for querying\nWe also recommend reviewing this blog post for recommendations on conducting your own analyses with NDT data\nFinally, you could also use pre-aggregated statistics for NDT provided by our statistics pipeline service. Read more about that service and the API it provides here:\nhttps://github.com/m-lab/stats-pipeline/#statistics-pipeline-service\n\nI hope this is helpful for your project.\n\nBest regards,\nChris - M-Lab Support\n\ue5d3'}"
185,92922026814325385183593543140785326007,question-re-returning-results,"Nov 9, 2020, 3:29:34 PM",Glenn Fishbine,"Is there a way to return the results of the current NDT test to either a javascript or PHP environment.

My general idea is embed the test in an Iframe, and pick off the download, upload, jitter, and ping averages.

The intent is to store these results in my own environment.

I would run either https://speed.measurementlab.net/#/  OR https://www.measurementlab.net/p/ndt-ws.html and would simply like to scrape those 4 numbers.",{'frog...@gmail.com': 'you can implement a javascript page to run tests using the ndt javascript class.\nhttps://github.com/m-lab/ndt7-js\n\ue5d3'}
186,315010566814876075505166165540438691807,modify-old-query-to-new-data,"Sep 22, 2020, 5:50:49 AM",Tao Fineberg,"Hello 

I have this old query that was used to get ISP specific speed data for a location 

How would I modify it to work with the current data?  

Thanks in advance for the assistance 

Tao 

-----

SELECT 
mm.asn_name AS isp,
8 * (ndt.web100_log_entry.snap.HCThruOctetsAcked / (ndt.web100_log_entry.snap.SndLimTimeRwin +
 ndt.web100_log_entry.snap.SndLimTimeCwnd +
 ndt.web100_log_entry.snap.SndLimTimeSnd)) as download_speed,
(ndt.web100_log_entry.snap.SegsRetrans / ndt.web100_log_entry.snap.DataSegsOut) AS packet_retransmission_rate,
ndt.web100_log_entry.snap.SumRTT/ndt.web100_log_entry.snap.CountRTT as rtt
FROM 
  `measurement-lab.release.ndt_downloads` as ndt,
  `measurement-lab.maxmind_historical.2018_07` as mm
WHERE
ndt.partition_date BETWEEN '2018-01-01' AND '2018-12-31'
AND ndt.connection_spec.client_geolocation.country_code = 'US'
AND (ndt.connection_spec.client_geolocation.region = 'TN' OR ndt.connection_spec.client_geolocation.region = 'Tennessee')
AND ndt.connection_spec.client_geolocation.city = 'Chattanooga'
AND
 TO_BASE64(NET.IP_FROM_STRING(ndt.connection_spec.client_ip)) 
 BETWEEN 
  TO_BASE64(NET.IP_FROM_STRING(mm.min_ip)) AND
  TO_BASE64(NET.IP_FROM_STRING(mm.max_ip))","{'Chris Ritzo': 'Hi all,\n\nWe\'re not able to update all queries for you-- the previous one in this thread was very easy to do. I\'m sorry if I gave the impression that we will do this work for you. We encourage all members of this group who wish to query M-Lab datasets to subscribe to our blog posts, and track changes to our tables and views. We are working to better communicate changes to our platform and datasets publicly so that researchers may self serve and update past queries. This reply will be a first draft of a more comprehensive post and update to our website documentation this fall.\n\nFirst, since this query appears to be in LegacySQL, I should note that our tables and views now only support StandardSQL. BigQuery\'s documentation includes this guide to migrating to StandardSQL. The quantiles aggregation in your query for example, can now be accomplished with the APPROX_QUANTILES function, or other aggregate functions. BigQuery\'s docs are really good.\n\nThere have been many changes to our platform and table/view schemas since 2018, and the upshot is that to query NDT data for tests that meet our team\'s current, best understanding of test completeness and research quality. In addition to working on new documentation and tutorial content, our team has re-engineered how we publish data so that we can present views and tables that meet the needs of researchers in our community who have a wide range of expertise and needs.\n\nIn July we published a blog post that describes our work to standardize the columns provided in our BigQuery datasets, to better enable Long Term Support of stable schemas. The post discusses the first recognizable outcome of that work to our community: ""unified"" views of NDT data that span the entire archive with a standardized schema. Additionally, this blog post provides more details about the NDT unified views.\n\nWe now publish two series of BigQuery Views for NDT data: ""Faithful"" and ""Helpful"". As described on the NDT page:\n\nFaithful Views:\nFaithful Views are the base tables/views for each NDT data type, providing direct access to the unfiltered NDT data and the TCP INFO and Traceroute data associated with NDT tests.\nIn BigQuery, Faithful Views are provided in datasets prepended with raw_\nFaithful views will be of interest mostly to researchers interested in all testing conditions and results.\nHelpful Views:\nA set of tables/views derived from “Faithful Views” that are pre-filtered to only provide the most commonly used fields, and which only show tests that meet our current, best understanding of test completeness and research quality. More details on what constitutes “research quality” is listed on the NDT page linked above.\nIn BigQuery, Helpful Views are provided in datasets labelled for each experiment.\nHelpful views should be the starting point for most people.\nThere are now three NDT protocol types in our dataset: web100, ndt5, & ndt7 . We have schemas with field descriptions for each protocol on their respective pages on our website, and hope to soon mirror those descriptions in the BigQuery website.\n\nAll NDT data prior to ~ November 2019 will be of the web100 protocol, derived from the web100 Linux kernel TCP statistics engine we used before our platform upgrade. In that upgrade, we began using TCPINFO to gather TCP statistics. One of the outcomes of this change is that some fields that you may have used in the web100 protocol NDT data may not be available in TCPINFO.\n\nYou can use sub-queries to pull data and metadata from the different protocols, by using the node._Instruments field in the unified views, which indicates the test protocol version: ndt5, ndt7, or web100. \n\nIf you are updating past queries, please begin by querying the appropriate ""Helpful Views"" for upload or download test results:\n`measurement-lab.ndt.unified_downloads`\n`measurement-lab.ndt.unified_uploads`\nInstead of having to calculate measurements from component fields as is the case in the query posted here, we now provide fields that are named more logically. Below are a series of fields from old tables/views, and their equivalents in unified_uploads and unified_downloads:\nlog_time = a.TestTime \nconnection_spec.client_ip = client.IP\ndownload_Mbps = unified_downloads.a.MeanThroughputMbps \nupload_Mbps = unified_uploads.a.MeanThroughputMbps\nconnection_spec.client_geolocation.latitude  = client.Geo.latitude\nconnection_spec.client_geolocation.longitude = client.Geo.longitude\nconnection_spec.client_geolocation.postal_code = client.Geo.postal_code\nconnection_spec.client_geolocation.region = client.Geo.region \nconnection_spec.client_geolocation.country_code  = client.Geo.country_code\nYou can review the schema column names in the unified views in BigQuery for a complete list of available fields, for example: unified_downloads\nIf you don\'t see a field that you need in the unified views, the next step is to see if the field is available in the Faithful view for the test protocol.\nFor example, Min and Max RTT have equivalent fields for the download (S2C) test in ndt5 and ndt7 tables:\nweb100_log_entry.snap.MaxRTT\nweb100_log_entry.snap.MinRTT\nndt.ndt5.result.S2C.MinRTT\nndt.ndt5.result.S2C.MaxRTT\nndt.ndt7.result.S2C.MinRTT\nndt.ndt7.result.S2C.MaxRTT\nThese can be pulled into your unified views query by matching on the test UUID, for example:\nWHERE ndt.unified_downloads.a.UUID = ndt.ndt5.test_id\n\nThe UUID field is a unique ID for each TCP connection to any of our servers, and is very useful for matching and joining generally.\n\nOne last thing to note is that interactions like this are helpful input for our engineering team for future releases of the unified views\' schemas. They included the most often used fields at first, and will add others as feedback comes in from the community where it makes sense to do so. We\'re looking for your input, so please let us know your thoughts.\n\nBest,\nChris\n\ue5d3', 'Tao Fineberg': 'Thank you very much. \n\ue5d3\n--\nRegards\n\nTao Fineberg\nTel +268 4045504\nFax +268 4045258\nCell +268 6051239\n\nComputronics Systems\nSwaziland', 'Concinnity Risks': ""I'm in the same boat with this old beast from 2018:\n\nWhat can I do to resurrect it?\n\nSELECT\nconnection_spec.client_geolocation.country_code AS country,\nNTH(1, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/\n(web100_log_entry.snap.SndLimTimeRwin +\nweb100_log_entry.snap.SndLimTimeCwnd +\nweb100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadMin,\nNTH(26, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/\n(web100_log_entry.snap.SndLimTimeRwin +\nweb100_log_entry.snap.SndLimTimeCwnd +\nweb100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadLower,\nNTH(51, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/\n(web100_log_entry.snap.SndLimTimeRwin +\nweb100_log_entry.snap.SndLimTimeCwnd +\nweb100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadMedian,\nNTH(76, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/\n(web100_log_entry.snap.SndLimTimeRwin +\nweb100_log_entry.snap.SndLimTimeCwnd +\nweb100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadUpper,\nNTH(101, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsAcked/\n(web100_log_entry.snap.SndLimTimeRwin +\nweb100_log_entry.snap.SndLimTimeCwnd +\nweb100_log_entry.snap.SndLimTimeSnd), 101)) AS downloadMax,\nFROM\nrelease.ndt_downloads_legacysql\nWHERE web100_log_entry.log_time >= PARSE_UTC_USEC('2017-01-01 00:00:00')\n/ POW(10, 6)\nAND web100_log_entry.log_time < PARSE_UTC_USEC('2018-01-01 00:00:00') /\nPOW(10, 6)\nAND\n(connection_spec.client_geolocation.country_code = 'AD'\nOR connection_spec.client_geolocation.country_code = 'AE'\nOR connection_spec.client_geolocation.country_code = 'AF'\nOR connection_spec.client_geolocation.country_code = 'AG'\nOR connection_spec.client_geolocation.country_code = 'AI'\nOR connection_spec.client_geolocation.country_code = 'AL'\nOR connection_spec.client_geolocation.country_code = 'AM'\nOR connection_spec.client_geolocation.country_code = 'AO'\nOR connection_spec.client_geolocation.country_code = 'AQ'\nOR connection_spec.client_geolocation.country_code = 'AR'\nOR connection_spec.client_geolocation.country_code = 'AS'\nOR connection_spec.client_geolocation.country_code = 'AT'\nOR connection_spec.client_geolocation.country_code = 'AU'\nOR connection_spec.client_geolocation.country_code = 'AW'\nOR connection_spec.client_geolocation.country_code = 'AX'\nOR connection_spec.client_geolocation.country_code = 'AZ'\nOR connection_spec.client_geolocation.country_code = 'BA'\nOR connection_spec.client_geolocation.country_code = 'BB'\nOR connection_spec.client_geolocation.country_code = 'BD'\nOR connection_spec.client_geolocation.country_code = 'BE'\nOR connection_spec.client_geolocation.country_code = 'BF'\nOR connection_spec.client_geolocation.country_code = 'BG'\nOR connection_spec.client_geolocation.country_code = 'BH'\nOR connection_spec.client_geolocation.country_code = 'BI'\nOR connection_spec.client_geolocation.country_code = 'BJ'\nOR connection_spec.client_geolocation.country_code = 'BL'\nOR connection_spec.client_geolocation.country_code = 'BM'\nOR connection_spec.client_geolocation.country_code = 'BN'\nOR connection_spec.client_geolocation.country_code = 'BO'\nOR connection_spec.client_geolocation.country_code = 'BQ'\nOR connection_spec.client_geolocation.country_code = 'BR'\nOR connection_spec.client_geolocation.country_code = 'BS'\nOR connection_spec.client_geolocation.country_code = 'BT'\nOR connection_spec.client_geolocation.country_code = 'BW'\nOR connection_spec.client_geolocation.country_code = 'BY'\nOR connection_spec.client_geolocation.country_code = 'BZ'\nOR connection_spec.client_geolocation.country_code = 'CA'\nOR connection_spec.client_geolocation.country_code = 'CD'\nOR connection_spec.client_geolocation.country_code = 'CF'\nOR connection_spec.client_geolocation.country_code = 'CG'\nOR connection_spec.client_geolocation.country_code = 'CH'\nOR connection_spec.client_geolocation.country_code = 'CI'\nOR connection_spec.client_geolocation.country_code = 'CK'\nOR connection_spec.client_geolocation.country_code = 'CL'\nOR connection_spec.client_geolocation.country_code = 'CM'\nOR connection_spec.client_geolocation.country_code = 'CN'\nOR connection_spec.client_geolocation.country_code = 'CO'\nOR connection_spec.client_geolocation.country_code = 'CR'\nOR connection_spec.client_geolocation.country_code = 'CU'\nOR connection_spec.client_geolocation.country_code = 'CV'\nOR connection_spec.client_geolocation.country_code = 'CW'\nOR connection_spec.client_geolocation.country_code = 'CY'\nOR connection_spec.client_geolocation.country_code = 'CZ'\nOR connection_spec.client_geolocation.country_code = 'DE'\nOR connection_spec.client_geolocation.country_code = 'DJ'\nOR connection_spec.client_geolocation.country_code = 'DK'\nOR connection_spec.client_geolocation.country_code = 'DM'\nOR connection_spec.client_geolocation.country_code = 'DO'\nOR connection_spec.client_geolocation.country_code = 'DZ'\nOR connection_spec.client_geolocation.country_code = 'EC'\nOR connection_spec.client_geolocation.country_code = 'EE'\nOR connection_spec.client_geolocation.country_code = 'EG'\nOR connection_spec.client_geolocation.country_code = 'ER'\nOR connection_spec.client_geolocation.country_code = 'ES'\nOR connection_spec.client_geolocation.country_code = 'ET'\nOR connection_spec.client_geolocation.country_code = 'FI'\nOR connection_spec.client_geolocation.country_code = 'FJ'\nOR connection_spec.client_geolocation.country_code = 'FK'\nOR connection_spec.client_geolocation.country_code = 'FM'\nOR connection_spec.client_geolocation.country_code = 'FO'\nOR connection_spec.client_geolocation.country_code = 'FR'\nOR connection_spec.client_geolocation.country_code = 'GA'\nOR connection_spec.client_geolocation.country_code = 'GB'\nOR connection_spec.client_geolocation.country_code = 'GD'\nOR connection_spec.client_geolocation.country_code = 'GE'\nOR connection_spec.client_geolocation.country_code = 'GF'\nOR connection_spec.client_geolocation.country_code = 'GG'\nOR connection_spec.client_geolocation.country_code = 'GH'\nOR connection_spec.client_geolocation.country_code = 'GI'\nOR connection_spec.client_geolocation.country_code = 'GL'\nOR connection_spec.client_geolocation.country_code = 'GM'\nOR connection_spec.client_geolocation.country_code = 'GN'\nOR connection_spec.client_geolocation.country_code = 'GP'\nOR connection_spec.client_geolocation.country_code = 'GQ'\nOR connection_spec.client_geolocation.country_code = 'GR'\nOR connection_spec.client_geolocation.country_code = 'GS'\nOR connection_spec.client_geolocation.country_code = 'GT'\nOR connection_spec.client_geolocation.country_code = 'GU'\nOR connection_spec.client_geolocation.country_code = 'GW'\nOR connection_spec.client_geolocation.country_code = 'GY'\nOR connection_spec.client_geolocation.country_code = 'HK'\nOR connection_spec.client_geolocation.country_code = 'HN'\nOR connection_spec.client_geolocation.country_code = 'HR'\nOR connection_spec.client_geolocation.country_code = 'HT'\nOR connection_spec.client_geolocation.country_code = 'HU'\nOR connection_spec.client_geolocation.country_code = 'ID'\nOR connection_spec.client_geolocation.country_code = 'IE'\nOR connection_spec.client_geolocation.country_code = 'IL'\nOR connection_spec.client_geolocation.country_code = 'IM'\nOR connection_spec.client_geolocation.country_code = 'IN'\nOR connection_spec.client_geolocation.country_code = 'IO'\nOR connection_spec.client_geolocation.country_code = 'IQ'\nOR connection_spec.client_geolocation.country_code = 'IR'\nOR connection_spec.client_geolocation.country_code = 'IS'\nOR connection_spec.client_geolocation.country_code = 'IT'\nOR connection_spec.client_geolocation.country_code = 'JE'\nOR connection_spec.client_geolocation.country_code = 'JM'\nOR connection_spec.client_geolocation.country_code = 'JO'\nOR connection_spec.client_geolocation.country_code = 'JP'\nOR connection_spec.client_geolocation.country_code = 'KE'\nOR connection_spec.client_geolocation.country_code = 'KG'\nOR connection_spec.client_geolocation.country_code = 'KH'\nOR connection_spec.client_geolocation.country_code = 'KI'\nOR connection_spec.client_geolocation.country_code = 'KM'\nOR connection_spec.client_geolocation.country_code = 'KN'\nOR connection_spec.client_geolocation.country_code = 'KP'\nOR connection_spec.client_geolocation.country_code = 'KR'\nOR connection_spec.client_geolocation.country_code = 'KW'\nOR connection_spec.client_geolocation.country_code = 'KY'\nOR connection_spec.client_geolocation.country_code = 'KZ'\nOR connection_spec.client_geolocation.country_code = 'LA'\nOR connection_spec.client_geolocation.country_code = 'LB'\nOR connection_spec.client_geolocation.country_code = 'LC'\nOR connection_spec.client_geolocation.country_code = 'LI'\nOR connection_spec.client_geolocation.country_code = 'LK'\nOR connection_spec.client_geolocation.country_code = 'LR'\nOR connection_spec.client_geolocation.country_code = 'LS'\nOR connection_spec.client_geolocation.country_code = 'LT'\nOR connection_spec.client_geolocation.country_code = 'LU'\nOR connection_spec.client_geolocation.country_code = 'LV'\nOR connection_spec.client_geolocation.country_code = 'LY'\nOR connection_spec.client_geolocation.country_code = 'MA'\nOR connection_spec.client_geolocation.country_code = 'MC'\nOR connection_spec.client_geolocation.country_code = 'MD'\nOR connection_spec.client_geolocation.country_code = 'ME'\nOR connection_spec.client_geolocation.country_code = 'MF'\nOR connection_spec.client_geolocation.country_code = 'MG'\nOR connection_spec.client_geolocation.country_code = 'MH'\nOR connection_spec.client_geolocation.country_code = 'MK'\nOR connection_spec.client_geolocation.country_code = 'ML'\nOR connection_spec.client_geolocation.country_code = 'MM'\nOR connection_spec.client_geolocation.country_code = 'MN'\nOR connection_spec.client_geolocation.country_code = 'MO'\nOR connection_spec.client_geolocation.country_code = 'MP'\nOR connection_spec.client_geolocation.country_code = 'MQ'\nOR connection_spec.client_geolocation.country_code = 'MR'\nOR connection_spec.client_geolocation.country_code = 'MS'\nOR connection_spec.client_geolocation.country_code = 'MT'\nOR connection_spec.client_geolocation.country_code = 'MU'\nOR connection_spec.client_geolocation.country_code = 'MV'\nOR connection_spec.client_geolocation.country_code = 'MW'\nOR connection_spec.client_geolocation.country_code = 'MX'\nOR connection_spec.client_geolocation.country_code = 'MY'\nOR connection_spec.client_geolocation.country_code = 'MZ'\nOR connection_spec.client_geolocation.country_code = 'NA'\nOR connection_spec.client_geolocation.country_code = 'NC'\nOR connection_spec.client_geolocation.country_code = 'NE'\nOR connection_spec.client_geolocation.country_code = 'NF'\nOR connection_spec.client_geolocation.country_code = 'NG'\nOR connection_spec.client_geolocation.country_code = 'NI'\nOR connection_spec.client_geolocation.country_code = 'NL'\nOR connection_spec.client_geolocation.country_code = 'NO'\nOR connection_spec.client_geolocation.country_code = 'NP'\nOR connection_spec.client_geolocation.country_code = 'NR'\nOR connection_spec.client_geolocation.country_code = 'NU'\nOR connection_spec.client_geolocation.country_code = 'NZ'\nOR connection_spec.client_geolocation.country_code = 'OM'\nOR connection_spec.client_geolocation.country_code = 'PA'\nOR connection_spec.client_geolocation.country_code = 'PE'\nOR connection_spec.client_geolocation.country_code = 'PF'\nOR connection_spec.client_geolocation.country_code = 'PG'\nOR connection_spec.client_geolocation.country_code = 'PH'\nOR connection_spec.client_geolocation.country_code = 'PK'\nOR connection_spec.client_geolocation.country_code = 'PL'\nOR connection_spec.client_geolocation.country_code = 'PM'\nOR connection_spec.client_geolocation.country_code = 'PR'\nOR connection_spec.client_geolocation.country_code = 'PS'\nOR connection_spec.client_geolocation.country_code = 'PT'\nOR connection_spec.client_geolocation.country_code = 'PW'\nOR connection_spec.client_geolocation.country_code = 'PY'\nOR connection_spec.client_geolocation.country_code = 'QA'\nOR connection_spec.client_geolocation.country_code = 'RE'\nOR connection_spec.client_geolocation.country_code = 'RO'\nOR connection_spec.client_geolocation.country_code = 'RS'\nOR connection_spec.client_geolocation.country_code = 'RU'\nOR connection_spec.client_geolocation.country_code = 'RW'\nOR connection_spec.client_geolocation.country_code = 'SA'\nOR connection_spec.client_geolocation.country_code = 'SB'\nOR connection_spec.client_geolocation.country_code = 'SC'\nOR connection_spec.client_geolocation.country_code = 'SD'\nOR connection_spec.client_geolocation.country_code = 'SE'\nOR connection_spec.client_geolocation.country_code = 'SG'\nOR connection_spec.client_geolocation.country_code = 'SI'\nOR connection_spec.client_geolocation.country_code = 'SK'\nOR connection_spec.client_geolocation.country_code = 'SL'\nOR connection_spec.client_geolocation.country_code = 'SM'\nOR connection_spec.client_geolocation.country_code = 'SN'\nOR connection_spec.client_geolocation.country_code = 'SO'\nOR connection_spec.client_geolocation.country_code = 'SR'\nOR connection_spec.client_geolocation.country_code = 'SS'\nOR connection_spec.client_geolocation.country_code = 'ST'\nOR connection_spec.client_geolocation.country_code = 'SV'\nOR connection_spec.client_geolocation.country_code = 'SX'\nOR connection_spec.client_geolocation.country_code = 'SY'\nOR connection_spec.client_geolocation.country_code = 'SZ'\nOR connection_spec.client_geolocation.country_code = 'TC'\nOR connection_spec.client_geolocation.country_code = 'TD'\nOR connection_spec.client_geolocation.country_code = 'TG'\nOR connection_spec.client_geolocation.country_code = 'TH'\nOR connection_spec.client_geolocation.country_code = 'TJ'\nOR connection_spec.client_geolocation.country_code = 'TK'\nOR connection_spec.client_geolocation.country_code = 'TL'\nOR connection_spec.client_geolocation.country_code = 'TM'\nOR connection_spec.client_geolocation.country_code = 'TN'\nOR connection_spec.client_geolocation.country_code = 'TO'\nOR connection_spec.client_geolocation.country_code = 'TR'\nOR connection_spec.client_geolocation.country_code = 'TT'\nOR connection_spec.client_geolocation.country_code = 'TV'\nOR connection_spec.client_geolocation.country_code = 'TW'\nOR connection_spec.client_geolocation.country_code = 'TZ'\nOR connection_spec.client_geolocation.country_code = 'UA'\nOR connection_spec.client_geolocation.country_code = 'UG'\nOR connection_spec.client_geolocation.country_code = 'US'\nOR connection_spec.client_geolocation.country_code = 'UY'\nOR connection_spec.client_geolocation.country_code = 'UZ'\nOR connection_spec.client_geolocation.country_code = 'VA'\nOR connection_spec.client_geolocation.country_code = 'VC'\nOR connection_spec.client_geolocation.country_code = 'VE'\nOR connection_spec.client_geolocation.country_code = 'VG'\nOR connection_spec.client_geolocation.country_code = 'VI'\nOR connection_spec.client_geolocation.country_code = 'VN'\nOR connection_spec.client_geolocation.country_code = 'VU'\nOR connection_spec.client_geolocation.country_code = 'WF'\nOR connection_spec.client_geolocation.country_code = 'WS'\nOR connection_spec.client_geolocation.country_code = 'XY'\nOR connection_spec.client_geolocation.country_code = 'YE'\nOR connection_spec.client_geolocation.country_code = 'YT'\nOR connection_spec.client_geolocation.country_code = 'ZA'\nOR connection_spec.client_geolocation.country_code = 'ZM'\nOR connection_spec.client_geolocation.country_code = 'ZW')\nAND IS_EXPLICITLY_DEFINED(web100_log_entry.connection_spec.remote_ip)\nAND IS_EXPLICITLY_DEFINED(web100_log_entry.connection_spec.local_ip)\nAND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.HCThruOctetsAcked)\nAND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.SndLimTimeRwin)\nAND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.SndLimTimeCwnd)\nAND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.SndLimTimeSnd)\nAND IS_EXPLICITLY_DEFINED(connection_spec.data_direction)\nAND connection_spec.data_direction = 1\nAND web100_log_entry.snap.HCThruOctetsAcked >= 8192\nAND (web100_log_entry.snap.SndLimTimeRwin +\nweb100_log_entry.snap.SndLimTimeCwnd +\nweb100_log_entry.snap.SndLimTimeSnd) >= 9000000\nAND (web100_log_entry.snap.SndLimTimeRwin +\nweb100_log_entry.snap.SndLimTimeCwnd + \nweb100_log_entry.snap.SndLimTimeSnd) < 3600000000\nAND IS_EXPLICITLY_DEFINED(web100_log_entry.snap.CongSignals)\nAND web100_log_entry.snap.CongSignals > 0\nAND (web100_log_entry.snap.State == 1 OR (web100_log_entry.snap.State >=\n5 AND web100_log_entry.snap.State <= 11))\nGROUP BY country ORDER BY country ASC; \n\n\ue5d3""}"
187,288826591747017912910867553687880400351,unable-to-find-results-in-bigquery,"Jun 15, 2020, 7:05:19 AM",Avneesh Jain,"I ran a speed test on June 12th using ndt7 go client and I was expecting to see the results in BigQuery the next day, but I do not see the results when I run this query:

SELECT * FROM `measurement-lab.ndt.ndt5` where result.Control.UUID='ndt-nhlrk_1589233788_0000000000518FE3'


Here is the output sinppet from the test, from which I found the UUID
============================
avneesh@avneesh-ThinkPad-X220:~/projects/opensource_repos/ndt7-client-go/cmd/ndt7-client$ ./ndt7-client --format json
{""Key"":""starting"",""Value"":{""Test"":""download""}}
{""Key"":""connected"",""Value"":{""Test"":""download"",""Server"":""ndt-iupui-mlab2-maa01.mlab-oti.measurement-lab.org""}}
{""Key"":""measurement"",""Value"":{""AppInfo"":{""NumBytes"":65536,""ElapsedTime"":339408},""Origin"":""client"",""Test"":""download""}}
{""Key"":""measurement"",""Value"":{""AppInfo"":{""NumBytes"":122880,""ElapsedTime"":615181},""Origin"":""client"",""Test"":""download""}}
{""Key"":""measurement"",""Value"":{""AppInfo"":{""NumBytes"":196608,""ElapsedTime"":903576},""Origin"":""client"",""Test"":""download""}}
{""Key"":""measurement"",""Value"":{""BBRInfo"":{""BW"":300557,""MinRTT"":29998,""PacingGain"":256,""CwndGain"":512,""ElapsedTime"":499458},""ConnectionInfo"":{""Client"":""106.197.224.127:24192"",""Server"":""121.242.229.88:443"",""UUID"":""ndt-q78l5_1589309573_000000000052839D""},""Origin"":""server"",""Test"":""download"",""TCPInfo"":{""State"":1,""CAState"":0,""Retransmits"":0,""Probes"":0,""Backoff"":0,""Options"":7,""WScale"":119,""AppLimited"":0,""RTO"":287000,""ATO"":40000,""SndMSS"":1288,""RcvMSS"":536,""Unacked"":17,""Sacked"":0,""Lost"":0,""Retrans"":0,""Fackets"":0,""LastDataSent"":9,""LastAckSent"":0,""LastDataRecv"":516,""LastAckRecv"":25,""PMTU"":1500,""RcvSsThresh"":64076,""RTT"":69388,""RTTVar"":4757,""SndSsThresh"":14,""SndCwnd"":24,""AdvMSS"":1448,""Reordering"":3,""RcvRTT"":0,""RcvSpace"":14600,""TotalRetrans"":0,""PacingRate"":312691,""MaxPacingRate"":-1,""BytesAcked"":122366,""BytesReceived"":852,""SegsOut"":116,""SegsIn"":71,""NotsentBytes"":104328,""MinRTT"":29998,""DataSegsIn"":3,""DataSegsOut"":114,""DeliveryRate"":300580,""BusyTime"":552000,""RWndLimited"":0,""SndBufLimited"":0,""Delivered"":98,""DeliveredCE"":0,""BytesSent"":144262,""BytesRetrans"":0,""DSackDups"":0,""ReordSeen"":0,""ElapsedTime"":499458}}}
=================================================

Is the above query correct? Are ndt7 test results stored in some other tables? Even looking by IP address didnt return the results for my test (it showed results from some other days):

SELECT * FROM `measurement-lab.ndt.ndt5` where result.ClientIP='106.197.224.127'

Thanks
Avneesh","{'Chris Ritzo': 'Hello Avneesh,\n\nThe table `measurement-lab.ndt.ndt5` contains results from the ndt5 test. Since you are using an ndt7 client, and ndt7 is still in public beta, M-Lab has not yet begun parsing ndt7 test data to a separate table/view. When we do, it will be `measurement-lab.ndt.ndt7`.\n\nUntil that time, you can however find ndt7 test data in the table `measurement-lab.ndt.tcpinfo`, using a query like this:\n\nSELECT * FROM `measurement-lab.ndt.tcpinfo`\nWHERE UUID = ""ndt-q78l5_1589309573_000000000052839D""\n\nBest regards, Chris - M-Lab Support', 'Avneesh Jain': 'Thanks Chris, for pointing me to the right table.\n\n-Avneesh\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/5a9481d9-f231-4eb0-9442-72fc20a13119o%40measurementlab.net.'}"
190,277973434054651302429338641642743319801,huge-drop-in-number-of-tests-since-6th-november,"Nov 12, 2019, 8:27:46 AM",Thomas Buck,"Hi all,

I'm worried that I'm querying BigQuery data in the wrong way. Running the following SQL goes from a count of 20,000-40,000 tests per day down to double figures - e.g. 35 _total_ - since the 6th of November:

SELECT partition_date, COUNT(*) FROM `measurement-lab.ndt.downloads` M WHERE partition_date BETWEEN '2019-10-15' AND '2019-11-11'  AND connection_spec.client_geolocation.country_name = 'Germany' GROUP BY partition_date ORDER BY partition_date

Am I looking at the wrong column? I haven't had a chance to test other countries in more detail, it holds up for Germany, France, and the United Kingdom.

Thanks!
Tom.","{'Peter Boothe™': 'C2S is for client to server (aka upload) tests.  S2C is for server to client (aka download) tests.\n\nS2C result data is inside the result.S2C struct. You likely only care about mean throughput and min RTT, which can be selected like:\nSELECT result.S2C.MeanThroughputMbps, result.S2C.MinRTT\nFROM `measurement-lab.ndt.ndt5`\nWHERE result.S2C IS NOT NULL\nC2S result data is inside the result.C2S struct. The relevant query for you is probably:\nSELECT result.C2S.MeanThroughputMbps\nFROM `measurement-lab.ndt.ndt5`\nWHERE result.C2S IS NOT NULL\n\nOne of the nice features of the new schema is how little calculation is required to get the data you want :)\n\n-Peter\n\n\n\nOn Tue, Nov 12, 2019 at 2:19 PM Thomas Buck <t...@moounlimited.com> wrote:\nHi Peter,\n\nThis is amazing, thank you for your quick and comprehensive reply. Can you point me in the right direction for pulling out speed measurements from the new schema? \n\nI’m fine without the geolocation stuff, it’s download / upload mbps and min RTT that I’m most interested in. \n\nExploring at `measurement-lab.ndt.ndt5`, I’m not seeing any populated values:\n\nSELECT partition_date, \n  COUNT(*) AS total_rows,\n  SUM(CASE WHEN result.C2S IS NULL THEN 1 ELSE 0 END) AS null_c2s,\n  SUM(CASE WHEN result.Download IS NULL THEN 1 ELSE 0 END) AS null_downloads,\n  SUM(CASE WHEN result.Upload IS NULL THEN 1 ELSE 0 END) AS null_uploads\nFROM `measurement-lab.ndt.ndt5`\nWHERE partition_date BETWEEN \'2019-10-15\' AND \'2019-11-11\'  \nGROUP BY partition_date\nORDER BY partition_date\n\n\nRow\npartition_date\ntotal_rows\nnull_c2s\nnull_downloads\nnull_uploads\n1\n2019-10-15\n1580639\n979435\n1580639\n1580639\n2\n2019-10-16\n1548101\n956595\n1548101\n1548101\n3\n2019-10-17\n1515766\n938295\n1515766\n1515766\n4\n2019-10-18\n1543635\n954888\n1543635\n1543635\n5\n2019-10-19\n1570913\n973059\n1570913\n1570913\n6\n2019-10-20\n1529246\n950606\n1529246\n1529246\n7\n2019-10-21\n1521549\n943600\n1521549\n1521549\n8\n2019-10-22\n1580653\n974895\n1580653\n1580653\n9\n2019-10-23\n1655781\n1015297\n1655781\n1655781\n10\n2019-10-24\n1881269\n1142739\n1881269\n1881269\n11\n2019-10-25\n2231778\n1349355\n2231778\n2231778\n12\n2019-10-26\n2202261\n1338717\n2202261\n2202261\n13\n2019-10-27\n2198697\n1344825\n2198697\n2198697\n14\n2019-10-28\n2251075\n1374445\n2251075\n2251075\n15\n2019-10-29\n2430001\n1466670\n2430001\n2430001\n16\n2019-10-30\n2563155\n1541106\n2563155\n2563155\n17\n2019-10-31\n2455425\n1486344\n2455425\n2455425\n18\n2019-11-01\n2490693\n1515257\n2490693\n2490693\n19\n2019-11-02\n2515799\n1533997\n2515799\n2515799\n20\n2019-11-03\n2485304\n1522871\n2485304\n2485304\n21\n2019-11-04\n2468385\n1509086\n2468385\n2468385\n22\n2019-11-05\n2869215\n1734356\n2869215\n2869215\n23\n2019-11-06\n3187630\n1938870\n3187630\n3187630\n24\n2019-11-07\n3203866\n1953382\n3203866\n3203866\n25\n2019-11-08\n3321079\n2044216\n3321079\n3321079\n26\n2019-11-09\n3357889\n2073160\n3357889\n3357889\n27\n2019-11-10\n2082386\n1316249\n2082386\n2082386\n28\n2019-11-11\n1852342\n1152755\n1852342\n1852342\n\nI’ve taken a brief look at the tcpinfo schema; should I be calculating metrics based on that?\n\nMany thanks,\nTom.\n\nOn 12 Nov 2019, at 17:51, Peter Boothe ¶ <pbo...@google.com> wrote:\n\nHello!\n\nWe are in the process of migrating our infrastructure to what we have called MLab2.0.  The new NDT server implementation produces results in a different schema stored in the `measurement-lab.ndt.ndt5` table.\n\nSELECT partition_date, COUNT(*)\nFROM `measurement-lab.ndt.ndt5`\nWHERE partition_date BETWEEN \'2019-10-15\' AND \'2019-11-11\'  \nGROUP BY partition_date\nORDER BY partition_date\n\nReturns many results:\n  Row partition_date f0_\n1\n2019-10-15\n1580639\n2\n2019-10-16\n1548101\n3\n2019-10-17\n1515766\n4\n2019-10-18\n1543635\n5\n2019-10-19\n1570913\n6\n2019-10-20\n1529246\n7\n2019-10-21\n1521549\n8\n2019-10-22\n1580653\n\n...\n\nThe NDT5 table is not currently geolocated, but the associated tcpinfo table is.  (Nota bene: The NDT5 table will get geolocation data added, the migration just has a lot of moving parts)\nFor now, to query the geolocation information, join the ndt table with the tcpinfo table, like:\n\nSELECT ndt5.partition_date, COUNT(*)\nFROM `measurement-lab.ndt.ndt5` as ndt5 INNER JOIN  `measurement-lab.ndt.tcpinfo` as tcpinfo ON (ndt5.result.S2C.UUID = tcpinfo.UUID)\nWHERE ndt5.partition_date BETWEEN \'2019-10-15\' AND \'2019-11-11\'  \n  AND ndt5.result.S2C.UUID IS NOT NULL AND ndt5.result.S2C.UUID != """"\n  AND tcpinfo.Client.Geo.country_name = \'Germany\'\nGROUP BY ndt5.partition_date\nORDER BY ndt5.partition_date\n\nAnd then you can see that Germany has lots of data:\nRow partition_date f0_\n1\n2019-10-15\n35361\n2\n2019-10-16\n32341\n3\n2019-10-17\n33809\n4\n2019-10-18\n34078\n5\n2019-10-19\n35931\n6\n2019-10-20\n36907\n7\n2019-10-21\n32207\n8\n2019-10-22\n34505\n...\nAlthough our parsing has apparently fallen a bit behind.\n\nAgain, this ""you need to join to query geo information""  feature is a bug, and it is a bug we are actively working on.  In the future (meaning early next year) everything should have geo information and querying should be more straightforward.  For now, this is a note to say: the data is still there. You can query it right now if you want to.\n\n  -Peter\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/f40ab949-e27b-4885-b393-f057c694d6ee%40measurementlab.net.\n\n\n--\nᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful, always with the goal of making the Internet better for the people who use it.\n\n\n\n--\nᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.\nPeter Boothe - Coder at Google, working in support of M-Lab'}"
225,173209679976504859382210704897694188792,histogram-of-ndt-download-speeds-by-quantile?,"Jan 4, 2018, 1:02:25 PM",Fenwick Mckelvey,"Hi all,
I am trying to improve my BiqQuery skills and I'd like to write a query to generate a histogram of Download speeds grouped by quantile. Below is a script that uses buckets of 10 Megs, but I'd like to find a way to use BigQuery's quantile function to create the buckets, instead of my hand-coded ones  then count the number of tests per bucket.

Any ideas?

SELECT
CASE
WHEN DownloadSpeed BETWEEN 0 AND 10 THEN 'Up to 10 Meg'
WHEN DownloadSpeed BETWEEN 10.1 AND 20 THEN 'Up to 20 Meg'
WHEN DownloadSpeed BETWEEN 20.1 AND 30 THEN 'Up to 30 Meg'
WHEN DownloadSpeed BETWEEN 30.1 AND 40 THEN 'Up to 40 Meg'
WHEN DownloadSpeed BETWEEN 40.1 AND 50 THEN 'Up to 50 Meg'
WHEN DownloadSpeed BETWEEN 50.1 AND 60 THEN 'Up to 60 Meg'
WHEN DownloadSpeed BETWEEN 60.1 AND 70 THEN 'Up to 70 Meg'
WHEN DownloadSpeed BETWEEN 70.1 AND 80 THEN 'Up to 80 Meg'
WHEN DownloadSpeed BETWEEN 80.1 AND 90 THEN 'Up to 90 Meg'
WHEN DownloadSpeed BETWEEN 90.1 AND 100 THEN 'Up to 100 Meg'
WHEN DownloadSpeed  > 100 THEN '100 Meg and higher'
ELSE 'None'
END as tiers,
count(DownloadSpeed)

FROM (
SELECT
 (8 * web100_log_entry.snap.HCThruOctetsAcked/(web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd)) AS DownloadSpeed,
FROM
    plx.google:m_lab.ndt.all
WHERE
connection_spec.data_direction = 1 AND
blacklist_flags = 0 AND
web100_log_entry.is_last_entry IS NOT NULL AND
web100_log_entry.snap.HCThruOctetsAcked IS NOT NULL AND
web100_log_entry.snap.HCThruOctetsAcked >= 8192 AND
(web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000 AND
(web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 3600000000 AND
web100_log_entry.snap.CongSignals IS NOT NULL AND
web100_log_entry.snap.CongSignals > 0 AND
log_time > 1483228800 AND
log_time < 1514764800 AND
connection_spec.client_geolocation.city IS NOT NULL AND
connection_spec.client_geolocation.country_name = 'Canada' AND
(connection_spec.server_geolocation.country_name = 'Canada' OR connection_spec.server_geolocation.country_name = 'United States')
  )
  GROUP BY
  tiers
  ORDER BY
  tiers DESC

Best,
Fenwick","{'Chris Ritzo': 'Ah, I see. Yes, that change is also now reflected on our page about calculating common metrics. That value was recommended by our staff more familiar with the internals of NDT as a more sensible upward the time bound of a test.\n\ue5d3', 'Bob Ballance': 'I was looking at the time limits and comparing to what I’ve been using, and if I now count the zeros, you’ve decreased the upper limit: (my bad). However, the question is still pertinent.\n\nFrom an example you sent me a while back:\n\n AND (web100_log_entry.snap.SndLimTimeRwin +\n     web100_log_entry.snap.SndLimTimeCwnd +\n    web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n  AND (web100_log_entry.snap.SndLimTimeRwin +\n    web100_log_entry.snap.SndLimTimeCwnd +\n    web100_log_entry.snap.SndLimTimeSnd) < 3600000000\n\nvs. the example today\n\n   (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000 AND\n          (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000 AND\n      \n\n. . . Bob\n\ue5d3'}"
229,134605014971665371662285367781389079020,bandwidth-unit,"Nov 15, 2021, 9:27:25 AM",Sidik,"Dear all,
After ndt test, json files are stored.
please i have an incertitude about something, what is the unit of bandwidth recorded by BBR in the json file

Thanks in advance",{}
230,294826392821479419433265802726322295723,mlabs-client-script,"Apr 14, 2021, 10:25:51 AM",Ankur Khanna,"Hi I need to write a script in python for consecutive mLabs test for bandwidth measurement, has it been done before? Any help would be appreciated.","{'Chris Ritzo': 'Thanks for asking this question. Yes, this has been done before.\n\nYou might take a look at one of our community tools, Murakami, to either use directly or derive examples.\n\nWe also encourage anyone using command line clients, Murakami, or custom clients that use M-Lab tests to review our Developer Guidelines, which outline our general requirements and policies, as well as best practices for scheduled tests and the frequency of tests.\n\nPerhaps you might say more what you mean by consecutive tests. You may also reach out directly to sup...@measurementlab.net for individual assistance.\n\nBest regards,\nChris - M-Lab Support\n\ue5d3'}"
235,122003331909791702207832334345994168270,comcast-blocking-of-m-labs,"Sep 2, 2017, 10:35:41 AM",John Simpson,"I have noticed that since my conflict with Comcast has gone rather public... I am now being blocked somehow from M-Lab, Speakeasy, and other testing sites.  The only ones that currently can connect using Firefox (Chrome has too many resource hogging protocols), are Testmynet, Speedof.me, and Fast.com.  Fast.com is hosted by Netflix... and strangely is the only one that shows upwards of 70mbps... and it is a paid service, so you have that to tak into account as well.  My research is starting to reflect the FCC rulings against preferential bandwidth allocation to large media services already.  I fear this is going to get ugly here in the United States, before anything changes.  Anyway, I just thought that my friends here at M-Labs would like to know that M-Labs tests are currently BLOCKED from being run on any of my home PCs or Mobile (Android) Devices.  M-Labs may want to investigate this and sue Comcast/Xfinity.  Included are some screenshots I took before sending this email, for proof of my claim:","{'Livingood, Jason': 'Hi John – I work at Comcast and spend a lot of time on measurement-related issues. I am not sure what conflict you are referring to but I am happy to help with any service issues if you want to email me your account details off-list. I can assure you, however, that Comcast is not blocking any M-Labs tests.\n  Regards\nJason\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.', 'Rajan Patel': 'What browser and browser versions have you tried with? Do you have any plugins on the browser that may be interfering with the websockets implementation of NDT? Is it possible to try this test on an incognito version of the latest Chrome browser?\n\nHave you tried installing Neubot, and tracking it\'s progress over the course of a week?\n\nNeubot data is also tracked my mlabs.\n\n\n\nOn Sep 2, 2017 1:45 PM, ""Livingood, Jason"" <Jason_L...@comcast.com> wrote:\n...'}"
237,162692698485715136735013033080439217339,fw:-websocket-client---upload-speed-problem,"Jul 7, 2015, 8:51:13 AM",Jacques Latour,"FYI.
  From: ndt-dev...@internet2.edu [mailto:ndt-dev...@internet2.edu] On Behalf Of Don Slaunwhite
Sent: July-06-15 2:46 PM
To: ndt...@internet2.edu
Subject: [ndt-dev] Websocket Client - Upload Speed Problem
  Hi Everyone,
  My name is Don Slaunwhite and I’m a Product Manager at CIRA. We have been utilizing the NDT tests as part of our Internet Performance Test up here in Canada.
  We have been working on transitioning to the Websocket client with our test, but we have been seeing some very different results in upload speeds as compared to the flash client.
  We did a lot of internal/external testing and in every case the upload speeds for the websocket version were lower (most times significantly) than our current flash client. The download speeds are comparable, with websocket usually coming in a bit faster
  For example we setup a VM at Amazon to run some (hopefully!) controlled tests. Using Chrome and Firefox.
  Chrome Averages based on ~200 tests
Flash 19.3Mpbs Upload
Flash 49.8Mpbs Download
Websocket  9.3Mpbs Upload
Websocket  54.3Mpbs Download
  Firefox Averages based on ~300 tests
Flash 27.4 Mpbs Upload
Flash 50.1 Mpbs Download
Websocket  11.1 Mpbs Upload
Websocket  57.2 Mpbs Download
  In each case the websocket upload is significantly lower. I’m trying to determine if this is expected behaviour with the websocket code. If not what possible items might be causing this type of speed degradation.
  We are running with client versions 3.7.0 (Flash has a buffer size of 32K) against mlab servers in Toronto.
  I realize there will be new functionality/capability with the multiple stream releases, but right now I’d like to try and focus on one major change at a time, so any ideas on speed differences between Flash and Websocket using just 3.7.0 would be really helpful.
  Thanks,
Don
 ","{'Jordan McCarthy': ""-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nHi everybody,\nWe've also been monitoring the performance characteristics of\nthe WebSockets client closely, both before and after the client's\nofficial publication in NDT 3.7.0, and we haven't been able to\nreproduce the disparity that CIRA has encountered. We've run\nWebsocket-based tests from several different browser combinations on a\nvariety of operating systems and consumer-grade connections, during\nvarious times of the day, and haven't encountered any appreciable\ndifferences (within any given machine/connection/time of day\ncombination). Additionally, for the sake of thoroughness we've run\nC-client tests from the same connections, and the numbers we got from\nthe C client runs were pretty comparable with what we were getting out\nof all of the Websockets tests.\n\nDon: could you tell us a little bit more about your testing\nmethodology? I'm guessing you spun up a Linux VM, and used\nX-forwarding to get access to an instance of the browser running on\nthe VM?\n\nOff the top of my head that sounds reasonable, but we've\ndefinitely seen weird artifacts introduced by running tests out of VM\nenvironments, so perhaps that could be throwing things off somewhat.\n\nJordan\n\nJordan McCarthy\nOpen Technology Institute @ New America\nPublic Key: 0xC08D8042 | 4A61 3D39 4125 127D 65EA DDC2 BFBD A2E9 C08D 80\n42\n\ue5d3\n-----BEGIN PGP SIGNATURE-----\nVersion: GnuPG v1.4.11 (GNU/Linux)\n\niQEcBAEBCgAGBQJVnC4sAAoJEL+9ounAjYBCfVgH/2q3PGodloBkPZoa6dW5nTmx\npLRAitSZwD8DS12VP2Wdy9zWNhmDExJuCVtRVQo9jF+ZwPqghh7U+ZpGRqWvFYdq\nXOUYxwUzRlN4fkVF43k+huGdrfGrG5Guz+zkkiVKAD/4Z1vLB6tknVUFyo5gOXs5\nWcchPM8Hi/8V1x4i+nVY+FiwiVqJBDqG2EJXDPqMP/G60kguJGra2PhlljNl7j8t\nsM0X+jyzQQzuUTruBHvQFES0TDPtS+AO07eft2JWUqdt6PcPYQt1NcBn8WJ+b/Ks\nJF6KKBlG+vm0pJt7nuCflIgXDMe7CW885WhMf+rMGC5GByDa+rzxATHCS9TZANE=\n=Ai6W\n-----END PGP SIGNATURE-----"", 'Don Slaunwhite': 'Hi Jordan,\n\nIt seems we may have multiple email threads going on about this issue. I\'ll respond with details on the other thread. 8) But to help clarify for the people here.\n\nWe were running a Windows 2012 Server as the Amazon VM. At first we chose one with ""Low"" network bandwidth, but we also created another with ""High"" network bandwidth. On those Windows machines we have testing software which runs our IPT test through the Chrome browser. It basically just goes flash then websocket etc. The times between runs is roughly 30 seconds and we let it run overnight.\n\nWe did see slower values coming from the Toronto site, so we ran the same tests to Calgary and Montreal. Those sites gave us much better results (in both Flash and Websocket) but still Flash was significantly faster. I\'m not sure if it is our implementation of the Flash/websockets client or what.\n\nFor instance in Montreal\n\nFlash Upload - 304Mbps\nFlash Download - 220Mbps\nWebsocket Upload - 45Mbps\nWebscoket Download - 230Mbps\n\nAnd in Calgary\n\nFlash Upload - 616Mbps\nFlash Download - 542Mbps\nWebsocket Upload - 44Mbps\nWebscoket Download - 472Mbps\n\nSo even on other servers we are definitely seeing a degradation of Websocket upload. Now perhaps it truly is something with the VM. But even then it seems a bit odd. We have no firewall/anti-virus on. What sort of things have you seen gone wrong with VM testing?\n\nWe did do some external real life testing via our employee\'s home systems (not through VPN etc) and we still saw slower Websocket speeds. (But not anything of this magnitude of difference.)\n\nFor example:\n\n(about 200 tests from around Ottawa)\n\n20.8 Mbps - Flash Chrome Download Avg\n3.034 Mpbs - Flash Chrome Upload Avg\n21.2 Mpbs - Websocket Chrome Download Avg\n2.56 Mpbs - Websocket Chrome Upload Avg\n\nSo not as big a difference, but still large enough to wonder. Then combined with the VM testing above.\n\nDo you have a dataset from your testing that we could look at? Honestly if you have a good sample size of data that we can feel comfortable with, then we can start looking at what exactly on our implementation is going wrong. (if it is indeed our implementation.)\n\nThanks,\nDon\n\ue5d3'}"
240,291446266625000543244142828569675022002,gsoc-2013-group,"Apr 24, 2013, 8:25:25 AM",kara...@gmail.com,"I am a GSOC 2013 aspirant interested in the project Rewrite mlab ns in Go.
I had been following the group hosted at https://groups.google.com/a/measurementlab.net/forum/?hl=en&fromgroups=#!forum/gsoc, for many days, but found that it requires membership now. A request for membership hasn't been accepted yet. 
Please accept my request to join the group so that I can keep up with the latest developments.","{'Tiziana Refice': 'Yes, we decided to close the group to only the M-Lab mentors because\napplicants have started sending their proposals and it does not seem\nfair to share them with other applicants.\nYou can now use the group to send messages to M-Lab mentors.\n\ue5d3\n> --\n> You received this message because you are subscribed to the Google Groups\n> ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it, send an\n> email to discuss+u...@measurementlab.net.\n> To post to this group, send email to dis...@measurementlab.net.\n> Visit this group at\n> http://groups.google.com/a/measurementlab.net/group/discuss/?hl=en-US.\n>\n>', 'kara...@gmail.com': 'Ok. Thanks for the info.\n\ue5d3', 'Paul Gardner': ""Hi Dominic,\n\nSounds good - new Vuze users (the most likely to run an NDT test) are now getting an updated version that uses the json based approach so they should be OK - existing users will slowly update over the coming days/weeks so some maybe using cached DNS responses. This should be a relatively small set though and hopefully their results wouldn't affect your overall stats (if using the 'wrong' server can do so), even if it might impact their personal measurements.\n\nThanks again for the quick turn around,\nPaul\n\n\nOn 1/14/2014 1:09 PM, Dominic Hamon wrote:\nHi Paul\n\n\ue5d3"", 'Dominic Hamon': ""Hi Paul\n\nI think the root cause is fixed but we're just waiting for DNS to catch up. One thing to note: DNS servers will be caching responses from ns.measurementlab.net, so donar may not always be returning the geographically local server. Ie, 8.8.8.8 will get the closest server to it and then respond with that for all global users. This may not be ideal.\n\nAs such, if you can use ns.measurementlab.net directly, you will get better geolocated results.\n\ue5d3""}"
249,323349964092299264307142015328020512492,web-api?,"Jun 16, 2021, 9:16:25 AM",Vinay Lal,"Hi, 

How would it be possible to use MLab data via a web API? ie a user on a web page searches for internet speed data by location and receives MLab data via an API which then is displayed for the user on said web page.

Would I need a Custom Google Cloud Account and I pay for data queries or is there an existing API that MLab has I could use?

If there is an existing web API then can it use MLabs ability to query Big Query for free?

I saw that there were command line programs to do this but not web api's.

Thanks so much for any help!

V","{'Chris Ritzo': 'Hi Vinay,\n\nOn Thursday, June 17, 2021 at 7:38:05 AM UTC-4 oneth...@gmail.com wrote:\nThanks guys, appreciate the tips! I\'m looking through the pipeline to see if I can find what I want. I think the data is there but perhaps I may need to go deeper than current geo accuracy allows in aggregated data.\n\nCouple questions:\nThe pipeline mentions up coming additions and that \'block level\' may be possible. If so, is that scheduled anytime soon or no plans as yet?\nAggregation by US Census Tract is provided for comparison/advisory only, and we do not plan to add census block level at this time. Though this is possible, we do not advise aggregating below city or county level due to the limitations on the precision of IP address geo-location. \nAlso, \'Cities are identified from the IP address annotations present in NDT data after it is published.\' - is there a list of city codes or how else could I understand what this code is for any given city?\nWhen an NDT test is conducted, the IP address from the connection initiating the test and the measurement itself are collected on the server through which the test ran. From there, a service we maintain annotates the test using publicly available datasets. You can read more about how this is done, what datasets are used, and a history of NDT annotations in this blog post.\n\nCities in the API are provided in the statistics pipeline API by name, and if you need an index of city names you can use the Maxmind Geolite2 City dataset. I\'ll also make a note that index tables may be a useful addition to make available in a future release.\n\nThere are several types of codes or numbers used in the API:\n* if you are looking at a URL with `/asn/` in the path, this is the Autonomous System number of the provider assigned to a range of IPs in the selected geography\n* for the US County statistics, we use the GEOID of each county as identified by the US Census Bureau\n* other codes are all geographic and include: two character Continent Code, the two character Country Code, and the 2-3 alphanumeric Region Code. Region Code uses the ISO 3166-2 standard, which in the US identifies the state. For example, US-MD is the region code for the state of Maryland.\nAlso, the docs for pipeline say any geo unit is possible but not necessarily accurate. Can I pull data (even if not considered accurate at this time) from geo units smaller than City also?\nAs mentioned above, each test is annotated with geographic codes using Maxmind\'s free Geolite2 dataset. This includes latitude/longitude coordinates, but is not the same at all as a street address or GPS precise location. See this information from Maxmind regarding IP Geolocation Accuracy. For this reason, we do not advise using NDT statistics for geographies smaller than county or city at this time. This blog post provides more context, where I explored and demonstrated these limits.\n\nIf you desire, you can of course pull individual data using BigQuery, and aggregate by any geographic shape you would like, but we wouldn\'t advise that the aggregated statistics would be at all correct.\n\nThere is one option for aggregating NDT data at geo units smaller than City-- collecting new tests from the location of interest using your own NDT client integration. This means collecting new test data, where you ask for or know the exact location where the test was run. Some of the links on our Data / Tools page can enable this. For example, if you wanted to collect tests automatically from known locations using a small computer placed on premise, you could use Murakami. If you wanted to run a website to survey a particular area and ask users to run a test, you could use Piecewise. Both require new data collection, and campaigns/resources of course, and though the NDT test results from these tools still is sent to our public dataset in BigQuery, any additional location precision or survey results are not. Using these tools also then means you have to establish your own analysis workflow and tools. If using these tools to collect new data are of interest to your organization, we can advise and discuss with you. Reach out to us at sup...@measurementlab.net, or directly to my email address.\n\nBest regards,\nChris - M-Lab Support\n V\n\n\n\nOn Wed, 16 Jun 2021 at 13:57, Bob Ballance <ballance@internet-is-infrastructure.org> wrote:\nGoogle also provides a number of BigQuery API client libraries for various languages: https://cloud.google.com/bigquery/docs/reference/libraries which can make the coding easer.\n\n. . . Bob\nOn Jun 16, 2021, at 11:50 AM, Chris Ritzo <cri...@measurementlab.net> wrote:\n\nThanks for asking about this. We do provide an API for aggregated NDT statistics which does not require authentication:\nhttps://github.com/m-lab/stats-pipeline/#statistics-pipeline-service\n\nIf you are wanting non-aggregated NDT data or other M-Lab datasets however, you will need to use Google\'s web APIs to interact with BigQuery. For example, this is a link to Google\'s REST API for BigQuery: https://cloud.google.com/bigquery/docs/reference/rest\n\nTo use Google\'s APIs with our datasets, you will need to have your own Google Cloud Project: https://cloud.google.com/resource-manager/docs/creating-managing-projects and enable the APIs you need to use. Your account on this group can be used for authenticating your application. If you find that you need to use a service account for your application, you can let us know at sup...@measurementlab.net, and we\'ll add that service account to the access group.\n\nHope this helps.\n\nBest,\nChris\n\n\n\nOn Wednesday, June 16, 2021 at 12:16:25 PM UTC-4 oneth...@gmail.com wrote:\nHi, \n\nHow would it be possible to use MLab data via a web API? ie a user on a web page searches for internet speed data by location and receives MLab data via an API which then is displayed for the user on said web page.\n\nWould I need a Custom Google Cloud Account and I pay for data queries or is there an existing API that MLab has I could use?\n\nIf there is an existing web API then can it use MLabs ability to query Big Query for free?\n\nI saw that there were command line programs to do this but not web api\'s.\n\nThanks so much for any help!\n\nV\n\n\n-- \nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/99a4f406-1d93-45fa-8eb0-947ca7aebe1an%40measurementlab.net.\n\n\n\n--\nVinay Lal\noneth...@gmail.com', 'Bob Ballance': 'Google also provides a number of BigQuery API client libraries for various languages: https://cloud.google.com/bigquery/docs/reference/libraries which can make the coding easer.\n\n. . . Bob\n\n\n\ue5d3\n\ue5d3\n-- \nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/99a4f406-1d93-45fa-8eb0-947ca7aebe1an%40measurementlab.net.', 'Vinay': ""Thank you Chris! I'll go digest all that info.\n\nV\n\n\ue5d3\nHi Vinay,\n\n\ue5d3\nV\n\n\n\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\n\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/99a4f406-1d93-45fa-8eb0-947ca7aebe1an%40measurementlab.net.\n\n\n\n--\nVinay Lal\noneth...@gmail.com""}"
251,269637152055962152824214612989468261575,too-slow-conection-to-your-server.,"Mar 22, 2021, 5:35:47 AM",Ernest,"Hi,
Why are your tests showing such poor results? The same happens at the stadia where the game is still breaking me, I tested the speed on the stadia page and the same too low speed, the game cuts out after a few minutes. I run Geforce Now and play without any connection problems...","{'Chris Ritzo': 'Hello and thanks for posting.\n\nThe NDT test is a different measurement instrument than many other tests like Fast. You can learn more about the differences and our position on Internet ""speed"" in general in this blog post. Our servers are also outside of last mile networks, so your measurement with NDT also includes the impact of your provider\'s peering with upstream networks on your connection\'s performance beyond the last mile networks that they maintain.\n\nSince you mentioned Stadia, please know the we have informed them about how the use of our test results may be misleading, as shown in your screenshot. Because our code is open source, Stadia and others may instrument our test in their site or software without coordination with M-Lab, as long as their integration follows our policies. I would recommend complaining to Stadia support about this, and please feel free to reference this message.\n\nBest,\nChris - M-Lab Support\n\ue5d3'}"
256,272858363336488210701086709443734232054,ndt-query-server-returns-empty-list-[]-in-the-response,"May 20, 2019, 8:21:11 PM",David Tang,"Hi,

I wrote a Python script as a NDT client. My script will connect to the query server (http://mlab-ns.appspot.com/ndt?format=json) to ask for the closest NDT server.
Recently, the query server returns empty list[] in 8 out of 10 requests. Is there anyone seeing the same situation? Any suggestion to solve this issue?

Thank you,
David","{'Chris Ritzo': ""I'm sorry, but I don't have a tentative timeline for the API key addition at this time. You are correct, the limit is defined to ensure measurement capacity is reserved so that tests are conducted without impact to measurement quality.\n\nM-Lab provides a server locate service that your client code can query to select an available server. There are a number of ways you could use this service, from the default -- requesting the closest server available to you-- to something more complex like selecting a set of servers in a metro area, choosing one of them randomly, and falling back to the others depending on the server response to test initiation. More information on using the locate service is provided on our Developer resources page.\n\ue5d3"", 'Ma Uttaram': 'Since we plan to incorporate m-lab speed test as part of our product, do we have any rough tentative time lines for API key being added to the locate service?\n\nIn the current scenario, if we plan to scale , is there a possibility of us choosing different servers ""in near by locations"" for performing the test? Hoping the limit is defined at the server level due to capacity threshholds. \n\ue5d3', 'Peter Boothe ¶': 'We have no time lines we are willing to publicly commit to - being in the middle of a pandemic has added too much uncertainty for us to feel confident in our ability to make good on any new commitments. We can however say that it is being actively worked on in the https://github.com/m-lab/locate repository, and that the service in that repo is right now successfully running in our pre-production environment. So the situation is not quite as dire as you might initially assume from the response ""no tentative timeline"".  Multiple stakeholders want this functionality, we are interested in providing it, and it is under active development. \n\nWere it not for the pandemic, we would probably have a timeline for you.  Everything is slowed and strange recently - hope you (and everyone else reading this on the discuss list) are well.\n\n  -Peter\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/06ca224f-5133-49ff-8f58-dcdc85e701cc%40measurementlab.net.\n\n\n--\nᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful, always with the goal of making the Internet better for the people who use it.'}"
257,137672765369478820429747841267359653480,possible-to-run-'speed-test'-from-*nix?,"Apr 22, 2020, 6:07:13 AM",Ron,"Our office is Linux based (CentOS/RedHat).
I'd like to run the M-Lab 'speed test' from crontab, so I could collect historical data.
Is there an easy way to get the results of 'speed test' from the Linux shell?

The output of running `curl https://www.google.com/search?q=speed+test` is not helpful:

$ curl https://www.google.com/search?q=speed+test
<!DOCTYPE html><html lang=en><meta charset=utf-8><meta name=viewport content=""initial-scale=1, minimum-scale=1, width=device-width""><title>Error 403 (Forbidden)!!1</title><style>*{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}</style><a href=//www.google.com/><span id=logo aria-label=Google></span></a><p><b>403.</b> <ins>That’s an error.</ins><p>Your client does not have permission to get URL <code>/search?q=speed+test</code> from this server.  (Client IP address: 34.217.127.158)<br><br>
Please see Google's Terms of Service posted at http://www.google.com/terms_of_service.html
<BR><BR><P>If you believe that you have received this response in error, please <A HREF=""https://www.google.com/support/contact/user?hl=en"">report</A> your problem. However, please make sure to take a look at our Terms of Service (http://www.google.com/terms_of_service.html). In your email, please send us the <b>entire</b> code displayed below.  Please also send us any information you may know about how you are performing your Google searches-- for example, ""I'm using the Opera browser on Linux to do searches from home.  My Internet access is through a dial-up account I have with the FooCorp ISP."" or ""I'm using the Konqueror browser on Linux to search from my job at myFoo.com.  My machine's IP address is 10.20.30.40, but all of myFoo's web traffic goes through some kind of proxy server whose IP address is 10.11.12.13.""  (If you don't know any information like this, that's OK.  But this kind of information can help us track down problems, so please tell us what you can.)</P><P>We will use all this information to diagnose the problem, and we'll hopefully have you back up and searching with Google again quickly!</P>
<P>Please note that although we read all the email we receive, we are not always able to send a personal response to each and every email.  So don't despair if you don't hear back from us!</P>
<P>Also note that if you do not send us the <b>entire</b> code below, <i>we will not be able to help you</i>.</P><P>Best wishes,<BR>The Google Team</BR></P><BLOCKQUOTE>/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/+/<BR>
BbhA56ElLRZQWf6A2LgJbhBezOY_HmMu-BVJjqD5xefSfI-vp<BR>
tP8NGNLFWccVKnYDJ0nRqzezdAQfWQjneZLW9-JNL85ZmthYc<BR>
yXqI8W6CbyrpGBR1XW0sgGAVYLLGiWqkom1e5IaIQZ7FFUVWa<BR>
gC8CHtpQ-qXXXCgZJMiNCXvh_lQlGOv8Loi9oMJZh2Rz9qFjC<BR>
92ZRoFC-ggGzGxZs1d7uofaUwsNYVm897QtVYH1UswXO0EJ6d<BR>
L64ZGOi56wC1_eKCu2K5pWyl_uSpqcobCO2lt3WuUbe9hH38V<BR>
wRgsocwu3rdqzCt04agIGvnfdqnAiix5tiFpno4ngQ4pLS6kA<BR>
Dz7r5p6edsdlXEjHVNhzMI_EhOLhUH3KmJu5M0ZJ4Ug4ZEVkp<BR>
P5U18v3Z1rWSI-XuAY-m5KdjNSxaGL19_jXGtnMbrlKtWkOBZ<BR>
INL7C4ILyBpxPHbMpq8atR2q9GHXmKIxHrQleJ4MhKC3XqiH1<BR>
QY5gZptdqCAbCsQ2lAJRROPu_iwwYrJexO4ekk4jIdchSMjyY<BR>
dl_2a9go_K2PK-c436XxgDVJ1tyE7VhKM1PVP_Lkf7ncRIOUj<BR>
qCnwhWPKxj-ro8eED-LFAlV5EJ7hUt_xS2XS1jjpwB1HXHIO-<BR>
7klo2mShLDD-wVBk7ZBZKSXI1rl9MKqZwNS8DS3FWU8lhDxPA<BR>
Usvgf7zcu-XJY6draNwGGl4Rzt_jEr7D1PPRlg2wvxV7OhPdd<BR>
Z68-ytEQYOK8C4iOaQe4qCXaUdYMa1viaYS1QGfRC3gC37Iu3<BR>
3O-M34RfnHPj2wICVfrhBzpUCLCj2BeKolxtN1YpWYq4Y5e-1<BR>
U_pIg2LSH14fZruLNdjy9qAhsf8JXivAOkou04Awt8-xNMJOM<BR>
NafEmIAE7GrHyzOC4xyOhDSOm24DhrDAsHnGISDLJ2e7eT-pd<BR>
[...]","{'Chris Ritzo': 'Hello Ron,\nYou can certainly run the M-Lab test, NDT, from the Linux command line and schedule it using crontab.\n\nWe recommend that you use one or both of the NDT golang clients:\nhttps://github.com/m-lab/ndt5-client-go\nhttps://github.com/m-lab/ndt7-client-go\nThese clients output test results in JSON format.\nPer our developer recommendations, tests that are scheduled to run automatically should run no more than four times per day with all test times randomized.\n\nHope this is helpful.\n\ue5d3'}"
262,300077911925452749761906769559720713625,i-think-m-lab-testing-methods-are-poor,"Jan 15, 2019, 8:12:26 AM",C W,"I have run 11 internet speed tests, and this one from M-Lab is the only one that is consistently an outlier.  Your FAQs indicate that others use different testing methods.  While true, it appears that if you are the only outlier, your testing methods are the ones that are off.  Of the 11 tests I ran, 10 (non M-Lab) tests gave values of download speed between 65 and 70, while the M-Lab test consistently gives results between 1.74 and 8 Mb/s. I checked the other tests to ensure that the same units were being used, all were using megabits per second.  I do not claim to know how all this works, but it seems that running the test through a server halfway across the country may be part of the problem.  I am in central Colorado and the server used was in Los Angeles.  ",{}
264,327618731157130540308306847941806675409,"i-have-just-run-the-mlabs-test-on-my-sony-laptop-using-sucks-opps,-i-mean-cox-as-my-wireless-provider","Mar 1, 2018, 12:56:11 PM",btno...@gmail.com,"using Mlabs, speed tests no discernable actions needed to be taken  _ I am attaching the results of the tests

however, I work for and really believe in the Visualware performance and testing products-  there is a freemium model for tests and purchased testing that is used by over 3000 users. 
the results shown on the screenshots, are from the same date and time, provider and using a quality test point (that anyone can use) 

Visualware -every time is able to determine accurate results of why MY internet is so slow! when I am playing for the highest amount sold. 

with that said, anyone can use the Visualware site connectivity testing. 

We will work with anyone to provide testing resources for this or your services.

thanks and let me know how I can help

Noreen  
2093099522",{}
306,303346734147111780859554640297573663569,advice-on-why-collected-median-speeds-seem-so-much-lower-than-reality.,"May 18, 2020, 10:58:28 AM",Daniel Thomas,"Hi There,

I've written up some code in Python to go out and gather internet speeds in 500 major global cities as a part of a benchmarking effort. The data is pulled through BigQuery, within a Jupyter Notebook

I've tweaked the standard Common Metrics queries, and combined them with a bounding box of longitude and latitudes to gather metrics for each city. I pull the big query results into a pandas data frame from where I perform a whole bunch of aggregation.

My issue is that the results I pull for many Chinese/Asian cities seems to be substantially lower what we would expect, and substantially lower than is recorded in Measurement labs own visualisations. I am wondering if I need to filter out more tests or something along these lines. 

For example,
3 Mbs - Median speeds for Hong Kong based on the common metrics query.
19 Mbs - Median speeds for Hong Kong based on the Mlab visualisation 

My BigQuery query to  the collect download data is as follows:

  SELECT
      `connection_spec`.`client_geolocation`.city AS city,
      partition_date,
      8 * (web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration) AS mbps,
      `connection_spec`.`client_geolocation`.`country_code` AS country_code,
      `connection_spec`.`client_geolocation`.`country_name` AS country_name,
      `connection_spec`.`client_geolocation`.latitude AS latitude,
      `connection_spec`.`client_geolocation`.longitude AS longiude,
      `connection_spec`.`client_geolocation`.`metro_code` AS metro_code,
      `connection_spec`.`client_geolocation`.region AS region

  FROM
    `measurement-lab.ndt.recommended`
  WHERE

    `connection_spec`.`client_geolocation`.latitude 22.09912108658368 AND 22.4600543490944
    AND `connection_spec`.`client_geolocation`.longitude BETWEEN 113.99481156645193 AND 114.38262545045124
    AND partition_date BETWEEN '2019-08-01' AND '2019-10-30'

    # Default queries here
    AND connection_spec.data_direction = 0
    AND web100_log_entry.snap.HCThruOctetsReceived >= 8192
    AND web100_log_entry.snap.Duration >= 9000000
    AND web100_log_entry.snap.Duration < 600000000
    AND (web100_log_entry.snap.State = 1
        OR (web100_log_entry.snap.State >= 5
        AND web100_log_entry.snap.State <= 11))

    LIMIT 30000

To calculate medians in Python, I simply perform a .median() function on the 'mbps' column in a pandas data frame (returned from the query above)","{'Chris Ritzo': ""Hi Daniel,\nThanks for posting your question and the query you're using. Awesome!\n\nOn first glance, not related to the measurement difference you identified, a couple of things to note.\n- The Visualization website is in the process of being upgraded, so your second link will result in an error- wanted to mention in case others clicked on it.\n- The table/view you are querying,     `measurement-lab.ndt.recommended`   , has been recently replaced with a new set of NDT views that will simplify the query. `measurement-lab.ndt.unified_uploads` and `.unified_downloads` provide most of the core fields people are interested in, and allow querying NDT across our platform upgrade in November 2019. For data beyond November, you will need to use the new views. This blog post discusses the unified views in more detail.\n- Hong Kong is considered a country in our dataset. We use the ISO 3166-2 standard for the country code and country name fields, and the first level ISO 3166-2 subdivision for region. Soon we will also add the second level subdivision region codes and names for both to the schema.\n\nWhen we do analyses like the one you are doing, we typically will use a multi-step query that first computes the median per IP address, per day, over the desired date range, and within the geography of interest. Then we will compute the median of those daily medians. This is one way to reduce potential skew that could be introduced by many tests run from the same IP. Other methods might be to take one value per IP per day, like the Max value, and use those in the final aggregate.\n\nLastly, if you desire you could also do aggregation in your query. Below is an example rewrite of your query given some of the suggestions above, which also aggregates by country and combines both upload and download into a final set of descriptive statistics. The second query does the same, but also groups by country and city.\n\nI hope this helps. Please let us know if you have additional questions.\n\nBest, Chris Ritzo - M-Lab Support\n\nWITH\ncountry_dl AS (\n  SELECT\n    test_date,\n    client.geo.country_name AS country,\n    NET.SAFE_IP_FROM_STRING(client.IP) AS ip,\n    a.MeanThroughputMbps as mbps,\n    a.MinRTT AS MinRTT\n  FROM `measurement-lab.ndt.unified_downloads`\n  WHERE\n    client.geo.latitude BETWEEN 22.09912108658368 AND 22.4600543490944\n    AND client.geo.longitude BETWEEN 113.99481156645193 AND 114.38262545045124\n    AND test_date BETWEEN '2019-08-01' AND '2019-10-30'\n    AND client.IP IS NOT NULL\n    AND client.geo.country_name IS NOT NULL AND client.geo.country_name != ''\n),\ncountry_dl_sample AS (\n  SELECT\n    COUNT(*) AS dl_sample_size,\n    country\n  FROM country_dl\n  GROUP BY country\n),\ncountry_daily_per_ip_stats_dl AS (\n  SELECT\n    test_date, country, ip,\n    MIN(mbps) AS MIN_download_Mbps,\n    APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_download_Mbps,\n    APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(50)] AS MED_download_Mbps,\n    AVG(mbps) AS MEAN_download_Mbps,\n    APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_download_Mbps,\n    MAX(mbps) AS MAX_download_Mbps,\n    APPROX_QUANTILES(CAST(MinRTT AS FLOAT64), 100) [ORDINAL(50)] as MED_DL_min_rtt\n  FROM country_dl\n  GROUP BY test_date, ip, country\n),\ncountry_ul AS (\n  SELECT\n    test_date,\n    client.geo.country_name AS country,\n    NET.SAFE_IP_FROM_STRING(client.IP) AS ip,\n    a.MeanThroughputMbps as mbps,\n    a.MinRTT AS MinRTT\n  FROM `measurement-lab.ndt.unified_uploads`\n  WHERE\n    client.geo.latitude BETWEEN 22.09912108658368 AND 22.4600543490944\n    AND client.geo.longitude BETWEEN 113.99481156645193 AND 114.38262545045124\n    AND test_date BETWEEN '2019-08-01' AND '2019-10-30'\n    AND client.IP IS NOT NULL\n    AND client.geo.country_name IS NOT NULL AND client.geo.country_name != ''\n),\ncountry_ul_sample AS (\n  SELECT\n    COUNT(*) AS ul_sample_size,\n    country\n  FROM country_ul\n  GROUP BY country\n),\ncountry_daily_per_ip_stats_ul AS (\n  SELECT test_date, country, ip,\n    MIN(mbps) AS MIN_upload_Mbps,\n    APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_upload_Mbps,\n    APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(50)] AS MED_upload_Mbps,\n    AVG(mbps) AS MEAN_upload_Mbps,\n    APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_upload_Mbps,\n    MAX(mbps) AS MAX_upload_Mbps\n  FROM country_ul\n  GROUP BY test_date, ip, country\n),\ncountry_stats_dl AS (\n  SELECT\n    country,\n    MIN(MIN_download_Mbps) AS MIN_download_Mbps,\n    APPROX_QUANTILES(LOWER_QUART_download_Mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_download_Mbps,\n    APPROX_QUANTILES(MED_download_Mbps, 100) [SAFE_ORDINAL(50)] AS MED_download_Mbps,\n    AVG(MEAN_download_Mbps) AS MEAN_download_Mbps,\n    APPROX_QUANTILES(UPPER_QUART_download_Mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_download_Mbps,\n    MAX(MAX_download_Mbps) AS MAX_download_Mbps,\n    APPROX_QUANTILES(CAST(MED_DL_min_rtt AS FLOAT64), 100) [ORDINAL(50)] as MED_DL_min_rtt\n  FROM country_daily_per_ip_stats_dl\n  GROUP BY country\n),\ncountry_stats_ul AS (\n  SELECT\n    country,\n    MIN(MIN_upload_Mbps) AS MIN_upload_Mbps,\n    APPROX_QUANTILES(LOWER_QUART_upload_Mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_upload_Mbps,\n    APPROX_QUANTILES(MED_upload_Mbps, 100) [SAFE_ORDINAL(50)] AS MED_upload_Mbps,\n    AVG(MEAN_upload_Mbps) AS MEAN_upload_Mbps,\n    APPROX_QUANTILES(UPPER_QUART_upload_Mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_upload_Mbps,\n    MAX(MAX_upload_Mbps) AS MAX_upload_Mbps\n  FROM country_daily_per_ip_stats_ul\n  GROUP BY country\n)\nSELECT * FROM country_stats_dl\nJOIN country_stats_ul USING (country)\nJOIN country_dl_sample USING (country)\nJOIN country_ul_sample USING (country)\n\n\nWITH\ncountry_dl AS (\n  SELECT\n    test_date,\n    client.geo.country_name AS country,\n    client.Geo.city AS city,\n    NET.SAFE_IP_FROM_STRING(client.IP) AS ip,\n    a.MeanThroughputMbps as mbps,\n    a.MinRTT AS MinRTT\n  FROM `measurement-lab.ndt.unified_downloads`\n  WHERE\n    client.geo.latitude BETWEEN 22.09912108658368 AND 22.4600543490944\n    AND client.geo.longitude BETWEEN 113.99481156645193 AND 114.38262545045124\n    AND test_date BETWEEN '2019-08-01' AND '2019-10-30'\n    AND client.IP IS NOT NULL\n    AND client.geo.country_name IS NOT NULL AND client.geo.country_name != ''\n    AND client.geo.city IS NOT NULL AND client.geo.city != ''\n),\ncountry_dl_sample AS (\n  SELECT\n    COUNT(*) AS dl_sample_size,\n    country,\n    city\n  FROM country_dl\n  GROUP BY country, city\n),\ncountry_daily_per_ip_stats_dl AS (\n  SELECT\n    test_date, country, city, ip,\n    MIN(mbps) AS MIN_download_Mbps,\n    APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_download_Mbps,\n    APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(50)] AS MED_download_Mbps,\n    AVG(mbps) AS MEAN_download_Mbps,\n    APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_download_Mbps,\n    MAX(mbps) AS MAX_download_Mbps,\n    APPROX_QUANTILES(CAST(MinRTT AS FLOAT64), 100) [ORDINAL(50)] as MED_DL_min_rtt\n  FROM country_dl\n  GROUP BY test_date, ip, country, city\n),\ncountry_ul AS (\n  SELECT\n    test_date,\n    client.geo.country_name AS country,\n    client.Geo.city AS city,\n    NET.SAFE_IP_FROM_STRING(client.IP) AS ip,\n    a.MeanThroughputMbps as mbps,\n    a.MinRTT AS MinRTT\n  FROM `measurement-lab.ndt.unified_uploads`\n  WHERE\n    client.geo.latitude BETWEEN 22.09912108658368 AND 22.4600543490944\n    AND client.geo.longitude BETWEEN 113.99481156645193 AND 114.38262545045124\n    AND test_date BETWEEN '2019-08-01' AND '2019-10-30'\n    AND client.IP IS NOT NULL\n    AND client.geo.country_name IS NOT NULL AND client.geo.country_name != ''\n    AND client.geo.city IS NOT NULL AND client.geo.city != ''\n),\ncountry_ul_sample AS (\n  SELECT\n    COUNT(*) AS ul_sample_size,\n    country,\n    city\n  FROM country_ul\n  GROUP BY country, city\n),\ncountry_daily_per_ip_stats_ul AS (\n  SELECT test_date, country, city, ip,\n    MIN(mbps) AS MIN_upload_Mbps,\n    APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_upload_Mbps,\n    APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(50)] AS MED_upload_Mbps,\n    AVG(mbps) AS MEAN_upload_Mbps,\n    APPROX_QUANTILES(mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_upload_Mbps,\n    MAX(mbps) AS MAX_upload_Mbps\n  FROM country_ul\n  GROUP BY test_date, ip, country, city\n),\ncountry_stats_dl AS (\n  SELECT\n    country, city,\n    MIN(MIN_download_Mbps) AS MIN_download_Mbps,\n    APPROX_QUANTILES(LOWER_QUART_download_Mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_download_Mbps,\n    APPROX_QUANTILES(MED_download_Mbps, 100) [SAFE_ORDINAL(50)] AS MED_download_Mbps,\n    AVG(MEAN_download_Mbps) AS MEAN_download_Mbps,\n    APPROX_QUANTILES(UPPER_QUART_download_Mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_download_Mbps,\n    MAX(MAX_download_Mbps) AS MAX_download_Mbps,\n    APPROX_QUANTILES(CAST(MED_DL_min_rtt AS FLOAT64), 100) [ORDINAL(50)] as MED_DL_min_rtt\n  FROM country_daily_per_ip_stats_dl\n  GROUP BY country, city\n),\ncountry_stats_ul AS (\n  SELECT\n    country,\n    city,\n    MIN(MIN_upload_Mbps) AS MIN_upload_Mbps,\n    APPROX_QUANTILES(LOWER_QUART_upload_Mbps, 100) [SAFE_ORDINAL(25)] AS LOWER_QUART_upload_Mbps,\n    APPROX_QUANTILES(MED_upload_Mbps, 100) [SAFE_ORDINAL(50)] AS MED_upload_Mbps,\n    AVG(MEAN_upload_Mbps) AS MEAN_upload_Mbps,\n    APPROX_QUANTILES(UPPER_QUART_upload_Mbps, 100) [SAFE_ORDINAL(75)] AS UPPER_QUART_upload_Mbps,\n    MAX(MAX_upload_Mbps) AS MAX_upload_Mbps\n  FROM country_daily_per_ip_stats_ul\n  GROUP BY country, city\n)\nSELECT * FROM country_stats_dl\nJOIN country_stats_ul USING (country, city)\nJOIN country_dl_sample USING (country, city)\nJOIN country_ul_sample USING (country, city)\n\n\n\ue5d3\n\ue5d3"", 'David Farias-llerenas': 'Hello,\n\nI\'m having some trouble getting authorization to perform queries from BigQuery into Pandas under \'measurement-lab\' and was curious to know how you went about doing so. I\'ve created a service account and have performed the code below before querying: \n\n\nos.environ[""GOOGLE_APPLICATION_CREDENTIALS""]=""../../google_auth_credentials.json"" \ncredentials, your_project_id = google.auth.default(\n    scopes=[""https://www.googleapis.com/auth/cloud-platform""]\n)\nyour_project_id = \'measurement-lab\'\nbqclient = bigquery.Client(\n    credentials=credentials,\n    project=your_project_id,\n)\nbqstorageclient = bigquery_storage_v1beta1.BigQueryStorageClient(\n    credentials=credentials\n)\nquery_string = """"""\n        ...\n"""""" \ndataframe = (\n    bqclient.query(query_string)\n    .result()\n    .to_dataframe(bqstorage_client=bqstorageclient)\n)\n\n\n \nThe error message I receive is as follows: ""403 request failed: the user does not have \'bigquery.readsessions.create\' permission for \'projects/measurement-lab\' "". I\'ve confirmed that I am allowed to query with my service account (it works when querying with ""bq"" on the command line). Any help or input on the process you took would be much appreciated. Thank you!\n\ue5d3'}"
309,83930186919332742887816499195113780531,negative-average-download-speeds?,"Jun 12, 2019, 9:15:02 AM",Glenn Fishbine,"Using this query:

SELECT 
count(*), connection_spec.client.network.asn,
avg(8 * (web100_log_entry.snap.HCThruOctetsAcked /
    (web100_log_entry.snap.SndLimTimeRwin +
    web100_log_entry.snap.SndLimTimeCwnd +
    web100_log_entry.snap.SndLimTimeSnd))) AS download_Mbps,
    connection_spec.client_geolocation.city,
    connection_spec.client_geolocation.region,
    avg(connection_spec.client_geolocation.latitude) AS latitude,
    avg(connection_spec.client_geolocation.longitude) AS longitude
FROM `measurement-lab.ndt.web100` 
WHERE connection_spec.client_geolocation.country_name='United States' AND  log_time > ""2019-01-01"" AND connection_spec.client_geolocation.city IS NOT NULL
AND ((web100_log_entry.snap.SndLimTimeRwin +
    web100_log_entry.snap.SndLimTimeCwnd +
    web100_log_entry.snap.SndLimTimeSnd) >0)
group by      connection_spec.client.network.asn,connection_spec.client_geolocation.city,
    connection_spec.client_geolocation.region order by connection_spec.client_geolocation.region,connection_spec.client_geolocation.city

I get some negative download values, perhaps a floating point overflow?

Specific values that are negative
ASN=7019
   for Emeryville CA - average is -1420655
        Atlanta GA - average is -33789
        La Grange GA - average is -8035560

ASN=1239  for Houston TX - average is -257023


Any thoughts or suggestions?","{'Peter Boothe™': 'Whoah! That is certainly surprising.\n\nI do not know why that is happening. Whether it is an artifact of the raw data or a parsing artifact is also unknown. I have filed a bug in our ETL pipeline to track this issue. \n  https://github.com/m-lab/etl/issues/682\n\nUnfortunately, we are pretty swamped for the next 2 weeks and so unlikely to do a deep dive right now, but this is potentially an important issue, so by filing and triaging the bug we can make sure it doesn\'t get swept under the rug.\n\nThat said, there are only 33 (out of 2,265,022,904) records which have web100_log_entry.snap.HCThruOctetsAcked < 0, in our 10-year dataset so one fix is to change your query to:\n\nSELECT\ncount(*), connection_spec.client.network.asn,\navg(8 * (web100_log_entry.snap.HCThruOctetsAcked /\n    (web100_log_entry.snap.SndLimTimeRwin +\n    web100_log_entry.snap.SndLimTimeCwnd +\n    web100_log_entry.snap.SndLimTimeSnd))) AS download_Mbps,\n    connection_spec.client_geolocation.city,\n    connection_spec.client_geolocation.region,\n    avg(connection_spec.client_geolocation.latitude) AS latitude,\n    avg(connection_spec.client_geolocation.longitude) AS longitude\nFROM `measurement-lab.ndt.web100`\nWHERE connection_spec.client_geolocation.country_name=\'United States\' AND  log_time > ""2019-01-01"" AND connection_spec.client_geolocation.city IS NOT NULL\nAND ((web100_log_entry.snap.SndLimTimeRwin +\n    web100_log_entry.snap.SndLimTimeCwnd +\n    web100_log_entry.snap.SndLimTimeSnd) >0)\nAND web100_log_entry.snap.HCThruOctetsAcked >= 0\ngroup by      connection_spec.client.network.asn,connection_spec.client_geolocation.city,\n    connection_spec.client_geolocation.region order by connection_spec.client_geolocation.region,connection_spec.client_geolocation.city\n\nThen your query will not contain these 33 funky records. Why those 33 records are the way they are remains an open question.\n\n  -Peter\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\n\n--\nᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.\nPeter Boothe - Coder at Google, working in support of M-Lab', 'Glenn Fishbine': ""I'm good with trashing bad data. :)\n\nJust a hint for your team, while I didn't search for all 33 records, of the 5 that I extracted, 3 of them are with the same ASN.  7018 AT&T Services, Inc.  2 in Georgia, and 1 in California.  This may be a rabbit hole, but the commonality is interesting.\n\ue5d3\n--\nGlenn Fishbine\nC:  612 387 7536\nw:  http://www.breakingpointsolutions.com""}"
312,317435381725173054124589809320574022117,asn-specific-measurments,"Dec 4, 2017, 3:25:04 AM",Eireann Leverett,"Hello,

I'm back again using wonderful M-Lab data and thanks for all the hard work!

How would I look at all the test values in a given year for a specific ASN? 

Or more generally, could you give me some visibility into the
field/table/column names we use for Big Query?

Eireann","{'☕Peter Boothe': 'We are planning on adding ASN annotation to our BigQuery system in 2018.  Until then, when using BigQuery you must specify the netblocks of interest. Data that has been more heavily processed can be divided up by ISP at viz.measurementlab.net, but the processing that makes the data ready for visualization uses data from more sources besides BigQuery.\n\n  -Peter\n\n\ue5d3\n\ue5d3\n\nEireann\n\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.\n\n\n\n--\nᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful.', 'Ben Dowling': ""I don't think there are any netblock details in the table, you'd need to join to an ASN/netblock dataset. You can aggregate to an arbitrary netblock with NET.IP_TRUNC though, eg this will convert IPs into the equivalent /24:\n\nNET.IP_TRUNC(NET.SAFE_IP_FROM_STRING(web100_log_entry.connection_spec.remote_ip), 24)\n\ue5d3"", 'Eireann Leverett': 'So my goal query is something like quartiles for download and upload speeds across a netblock.\n\nFrom the documentation I see how to get specific for IP:\n\nweb100_log_entry.connection_spec.remote_ip == ""179.181.99.49"" or\nweb100_log_entry.connection_spec.remote_ip == ""179.181.99.50""\n\nHowever, it doesn\'t look like I can use CIDR notation:\n\n\nweb100_log_entry.connection_spec.remote_ip == ""179.181.99.49/32""\n\n...for example yields 0 results.\n\nThen once I solve that, I have another problem which is that my current query does quartiles like this:\n\nSELECT\nweb100_log_entry.connection_spec.remote_ip AS ip,\nNTH(1, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration, 101)) AS uploadMin,\nNTH(26, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration, 101)) AS uploadLower,\nNTH(51, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration, 101)) AS uploadMedian,\nNTH(76, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration, 101)) AS uploadUpper,\nNTH(101, QUANTILES(8 * web100_log_entry.snap.HCThruOctetsReceived/web100_log_entry.snap.Duration, 101)) AS uploadMax,\nFROM\n\nWhich produces quartiles per IP or Row in the results, when I would prefer one line for each netblock.\n\nAny advice?\n\ue5d3'}"
322,137005864404300295527246289258565971103,data-by-device-type,"Feb 2, 2022, 11:26:54 AM",Lizaveta Radzevich,"Hi,

Is there any way to see what device speed test was run on (PC vs mobile)?

Also, I remember I had my hands on some documentation for the meaning of each column, but cannot find it again. ","{'Chris Ritzo': ""Thanks for writing with this question.\n\nToday there is not a field that flags a test as coming from a mobile network or other service delivery media, but the tests can be segmented in analyses using ipinfo.io's API. See this past post for more info. I have suggested this as a feature for our annotations for some time now, so if this is something that would be helpful to your research please reply to let the team know.\n\nRegarding documentation on the meaning of each column, we assume you mean the NDT tables, but let us know if you mean otherwise. Also, I'm sorry that's been in a bit of transition as the engineering team has been moving our datatypes to a standard column layout. This has delayed publication of a final schema and description for several tables and views.\n\nHowever, you can find much of this information in a couple places for your immediate use.\nFirst, the best place to get the most current schemas with field names and data types is to use the BigQuery UI or `bq` command line tool. For example,this link will display the Schema for `measurement-lab.ndt.unified_downloads`. Unfortunately, the field or column descriptions are not published there (yet).\n\nOn the ndt7 datatype page you can find a table with descriptions of the fields/columns in `measurement-lab.ndt.ndt7`, many of which are the same as in the unified_ views. If you are using ndt5 or web100 datatypes, those pages also have complete field descriptions.\n\nI hope this is helpful.\n\ue5d3"", 'Glenn Fishbine': 'To supplement this, there are two fields, MNC and MCC in the ipinfo return which if non-zero indicate the cellular country and company.  If they are empty or zero, the IP address is not generated on a cellular network.\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/65008612-5bd3-4459-befe-2587d2a5cbe1n%40measurementlab.net.'}"
330,192701662405379737711513935235339637492,two-questions-🙏🏻,"Oct 12, 2020, 5:19:58 AM",Tyler Servais,"1. Is there any table/data source that shows if the speed test was run on a wired or cellular connection?

2. What is the best way to make sense of the Network.ASNumber? For example, does each provider (Comcast) have a unique number? Is there a reference table anywhere for these codes?

Appreciate any help this group can provide!","{'Prem Sylvester': 'Unsure about the first query, but this: https://asrank.caida.org/ might help with the ASNs\n\ue5d3', 'David Belson': 'Tools like bgpview.io also provide more information about who the ASN is owned by, and who it is connected to. For example: https://bgpview.io/asn/13335\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/1f76c170-0b0e-4cd2-b440-e2c4f6f6d2dan%40measurementlab.net.', 'Ben Dowling': 'You can lookup details on IPinfo.io too - eg. https://ipinfo.io/AS13335 or also through our API - see https://ipinfo.io/developers\n\n\n\nOn Tue, Oct 13, 2020 at 5:40 AM, David Belson <dbe...@gmail.com> wrote:\nTools like bgpview.io also provide more information about who the ASN is owned by, and who it is connected to. For example: https://bgpview.io/asn/13335\n\n\nOn Tue, Oct 13, 2020 at 8:06 AM Prem Sylvester <prem.xsylvester@gmail.com> wrote:\nUnsure about the first query, but this: https://asrank.caida.org/ might help with the ASNs\n\nOn Monday, October 12, 2020 at 5:49:58 PM UTC+5:30 tylers...@gmail.com wrote:\n1. Is there any table/data source that shows if the speed test was run on a wired or cellular connection?\n\n2. What is the best way to make sense of the Network.ASNumber? For example, does each provider (Comcast) have a unique number? Is there a reference table anywhere for these codes?\n\nAppreciate any help this group can provide!\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\n\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/1f76c170-0b0e-4cd2-b440-e2c4f6f6d2dan%40measurementlab.net.\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+unsubscribe@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAL3%2BC_6ipxh48OCe3XC1Uw1aUcOQdL-fO5JP5mhf-m4kK%3D_tcw%40mail.gmail.com.'}"
334,187385519483182867156719435184561462795,5g-speed-test,"Apr 22, 2020, 8:43:29 AM",Ma Uttaram,I plan to use ndt client  web100clt on my device to run speed test using the m-lab hosted ndt servers. However would like to check if m-lab speed test will work to report 5G speed tests.,"{'Chris Ritzo': ""Hi Avneesh,\nThe --throttle option is not available in ndt7-client-go. If you'd like to have that option, please feel free to file an issue request in the repo.\n\nThanks, Chris\n\ue5d3"", 'Ma Uttaram': 'Is there way we could  limit or explicitly specify the data limits when running the test?\n\nCould you provide references as developer who plans to write a client , how that could be achieved?\n\ue5d3', 'Avneesh Jain': 'I dont see --throttle option in ndt7-client-go, was this option removed for a reason in ndt7 client? Is there a way to thrttle the test in ndt7 client?\n\nThanks\nAvneesh\n\ue5d3'}"
380,258163580704850428741707196212006811235,mobile-speed-test-data-for-india,"Apr 20, 2022, 3:48:38 PM",Lizaveta Radzevich,"Hello,

I'm looking for mobile speed test data for India (ideally in a format close to Mlab, lat/long attributed included). Is there any noteworthy sources for it except Mlab (or any way to single out the mobile test in Mlab).

Thank you!
Liz",{}
410,142028909577930689866583998075225872636,ndt-oddness?-measurement-drop-late-2014,"Feb 24, 2015, 3:16:14 PM","Livingood, Jason","Is there anything odd going on with NDT? I noticed a prominent 1G FTTH ISP’s speeds declined 60% late in the year (to just 15.58 Mbps). I’m wondering what might have influenced that. I thought perhaps technical issues, but I don’t see that reflected with other ISPs.

Thoughts?

Thanks
- Jason

PS – As a separate matter, is there an M-Lab throughput test that can measure 50Mbps+ connections? Any potential ones in development (or in need of grants)?

Reference: http://www.google.com/publicdata/explore?ds=e9krd11m38onf_&ctype=l&strail=false&bcs=d&nselm=h&met_y=download_throughput&scale_y=lin&ind_y=false&rdim=country&idim=country:40:208:250:276&idim=city:36_nsw_sydney&idim=region:840_ca:840_ny&ifdim=country&hl=en_US&dl=en_US&ind=false&icfg#!ctype=l&strail=false&bcs=d&nselm=h&met_y=download_throughput&scale_y=lin&ind_y=false&rdim=country_isp&idim=country_isp:840_10456:840_19720:840_16787:840_11025:840_16591:840_12064:840_10784:840_11818:840_174:840_19108:840_10311&ifdim=country_isp:country:840&tstart=1395640800000&tend=1416812400000&hl=en_US&dl=en_US&ind=false","{'Steve Bauer': 'Looks like the RTT has been increasing....\n\nhttp://www.google.com/publicdata/explore?ds=e9krd11m38onf_&ctype=l&strail=false&bcs=d&nselm=h&met_y=download_throughput&scale_y=lin&ind_y=false&rdim=country&idim=country:40:208:250:276&idim=city:36_nsw_sydney&idim=region:840_ca:840_ny&ifdim=country&hl=en_US&dl=en_US&ind=false&icfg#!ctype=l&strail=false&bcs=d&nselm=h&met_y=rtt&scale_y=lin&ind_y=false&rdim=country_isp&idim=country_isp:840_16591&ifdim=country_isp:country:840&tstart=1314158400000&tend=1416805200000&hl=en_US&dl=en_US&ind=false\n\ue5d3\n> --\n> You received this message because you are subscribed to the Google Groups\n> ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it, send an\n> email to discuss+u...@measurementlab.net.\n> To post to this group, send email to dis...@measurementlab.net.\n> Visit this group at\n> http://groups.google.com/a/measurementlab.net/group/discuss/.', 'Stephen Stuart': 'If you click on the little questions marks by the metrics in PDE, you\'ll see that there is a minimum threshold for number of tests required to appear in PDE. The first thing to do is to observe the number of tests:\n\nhttp://www.google.com/publicdata/explore?ds=e9krd11m38onf_&ctype=l&strail=false&bcs=d&nselm=h&met_y=download_throughput&scale_y=lin&ind_y=false&rdim=country&idim=country:40:208:250:276&idim=city:36_nsw_sydney&idim=region:840_ca:840_ny&ifdim=country&hl=en_US&dl=en_US&ind=false&icfg#!ctype=l&strail=false&bcs=d&nselm=h&met_y=number_of_tests&scale_y=lin&ind_y=false&rdim=country_isp&idim=country_isp:840_10456:840_19720:840_16787:840_11025:840_16591:840_12064:840_10784:840_11818:840_174:840_19108:840_10311&ifdim=country_isp:country:840&tstart=1395640800000&tend=1416812400000&hl=en_US&dl=en_US&ind=false\n\nIsolating the bottom one shows a sample count just barely over the threshold to appear in PDE as a global aggregate (from having chosen ""all M-Lab sites""):\n\nhttp://www.google.com/publicdata/explore?ds=e9krd11m38onf_&ctype=l&strail=false&bcs=d&nselm=h&met_y=download_throughput&scale_y=lin&ind_y=false&rdim=country&idim=country:40:208:250:276&idim=city:36_nsw_sydney&idim=region:840_ca:840_ny&ifdim=country&hl=en_US&dl=en_US&ind=false&icfg#!ctype=l&strail=false&bcs=d&nselm=h&met_y=number_of_tests&scale_y=lin&ind_y=false&rdim=country_isp&idim=country_isp:840_16591&ifdim=country_isp:country:840&tstart=1395640800000&tend=1416812400000&hl=en_US&dl=en_US&ind=false\n\nIf you then switch over to ""compare by M-Lab site,"" you can see that M-Lab only had per-site samples from one site rising to the threshold required to appear in PDE, in the fall of 2013. The data here are sitting at the boundary condition where the global aggregate is over the threshold to appear but the individual sites (mostly) do not:\n\nhttp://www.google.com/publicdata/explore?ds=e9krd11m38onf_&ctype=l&strail=false&bcs=d&nselm=h&met_y=download_throughput&scale_y=lin&ind_y=false&rdim=country&idim=country:40:208:250:276&idim=city:36_nsw_sydney&idim=region:840_ca:840_ny&ifdim=country&hl=en_US&dl=en_US&ind=false&icfg#!ctype=l&strail=false&bcs=d&nselm=h&met_y=number_of_tests&fdim_y=isp:16591&scale_y=lin&ind_y=false&rdim=mlab_site&idim=mlab_site:US-IL-Chicago&ifdim=mlab_site&tdim=true&tstart=1377414000000&tend=1416902400000&hl=en_US&dl=en_US&ind=false\n\nSince the individual sites aren\'t meeting the threshold, the raw data needs to be consulted to even know which sites are contributing data, before speculating about the behavior of the global aggregate. In summary, all PDE can really tell you for this one case is ""low sample rate, go to the raw data for any insights.""\n\nStephen\n\ue5d3'}"
418,37497414443216443585171449863009270163,renaming-ndt-datasets-and-views-in-bigquery,"Apr 4, 2021, 10:17:06 PM",Matt Mathis,"We are reorganizing our NDT datasets and views to make them easier to find and navigate. The new datasets and views will be created on Wednesday, Apr 7th, including updating the documentation to match.   There are no schema changes in this update, but all dataset and view  names are changing.   Newly named datasets and views will be published on Wednesday, April 7th, and the following Wednesday, April 14th, old datasets and views will be deleted.  Please update your queries to use the new names as soon as possible.

This update also includes some minor bug fixes, that should not affect any properly functioning user queries:
some web100 queries that were causing BigQuery exceptions
incorrect congestion control algorithms were being reported for upload tests
a small amount of pre-production data that was collected on mlab4 nodes (0.1%)  during early platform migration will be suppressed from production data.

Updated documentation on all newly named datasets and views will be published at:  https://www.measurementlab.net/tests/ndt/ on Wednesday.

Summary of new NDT datasets and views:

Unified Views (only bug fixes):
measurement-lab.ndt.unified_downloads
measurement-lab.ndt.unified_uploads

Dataset Renaming
This update will change the name of two NDT datasets:

New Dataset Name  Old Dataset Name
ndt_intermediate   intermediate_ndt
ndt_raw           raw_ndt
 Extended views in ndt_intermediate:
ndt_intermediate.extended_ndt7_downloads
ndt_intermediate.extended_ndt7_uploads
ndt_intermediate.extended_ndt5_downloads
ndt_intermediate.extended_ndt5_uploads
ndt_intermediate.extended_web100_downloads
ndt_intermediate.extended_web100_uploads
(These were previously published in the intermediate_ndt dataset.)

Raw Views Renaming

In the ndt_raw dataset, several views will also be renamed. All views to be published are listed below, with their previous name if applicable:
New View Name          Old View Name
ndt_raw.ndt7                       raw_ndt.ndt7
ndt_raw.annotation             raw_ndt.annotation
ndt_raw.ndt5_legacy           ndt.ndt5
ndt_raw.web100_legacy     ndt.web100
ndt_raw.tcpinfo_legacy       ndt.tcpinfo
ndt_raw.traceroute_legacy  ndt.traceroute

Thanks,
--MM--
The best way to predict the future is to create it.  - Alan Kay","{'Livingood, Jason': 'Hi Matt – Are there more detailed release notes pertaining to the bug fixes? In particular on the query exceptions and congestion control algorithms. Since all old datasets and views will be replaced it seems helpful to be able to better understand the changes.\n  Thanks\nJason\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo view this discussion on the web visit https://groups.google.com/a/measurementlab.net/d/msgid/discuss/CAEsRLK_oDemNaJZtx4RY63vwnMy61uwm-joJxz24gi0T3JY%3DnA%40mail.gmail.com.', 'Matt Mathis': 'It has come to my attention that I failed to complete some of the cleanup following the table and view renaming announced earlier this year.  All of the new tables have been in place since the announcement, but I failed to remove the old names.\n\nI will start updating a couple of overlooked internal references to the old names, and then disabling access to them.  If this causes any problems, the first step will be to confirm that you are using the correct names as listed below.\n\nWe are not anticipating any user visible changes.\n\nThanks,\n--MM--\n\ue5d3\n--\nThanks,\n--MM--'}"
422,33692279301559729340828383917661956385,speed-test-data,"Aug 13, 2018, 3:57:28 PM",Jenny Abamu,"Good Morning, 

I am trying to get wifi speed test data for the DC area. I am a reporter and could use some helps with this. ","{'thieme': ""Hey Jenny,\n\nNice to speak again. I actually just used the D.C. speed test data from 2010 to 2018 for an event we had last week and wrote up a short tutorial on how to do something similar. There are a couple of steps involved in signing up for access to the data that I'd be happy to help with.\n\nIf you'd like to go that route, there's another page on the M-Lab GitHub that has some easy-to-use code for getting speed-test data and visualizing it in various ways. Alternatively, since I recently did something similar to what you're looking for, I could use the code I already have to get you the data.\n\nIt might be helpful to talk through exactly what you're interested in at some point, as well.\n\nLet me know if I can help,\n\nNick\n\ue5d3"", 'Livingood, Jason': 'Worth reading: https://groups.csail.mit.edu/ana/Publications/Understanding_broadband_speed_measurements_bauer_clark_lehr_TPRC_2010.pdf\n  It’d be cool to see an update of this analysis in the future.\n  Jason\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.', 'Nick Feamster': 'On August 14, 2018 5:12:10 PM EDT, Matt Mathis <mattm...@google.com> wrote:\n>""referenced below"" ?\n>\n\nYes, see the link below for a pre-BBR method:\nhttps://smartech.gatech.edu/handle/1853/46991\n\n-Nick\n\ue5d3', 'Matt Mathis': '""referenced below"" ?\n\nThe BBR version can definitely be done at the sender.   Actually BBR has the opposite problem: bad things happen if  the min_rtt or max_rate estimators are confused by batched or thinned ACKs.  There is a lot of logic in BBR to exclude ACKs that seem to have been delayed by the return path.     An ""ACK jitter"" parameter would be a side signal off of these algorithms, and the jitter distribution tells you about any half duplex in the path.  (There could also be congestion on the return path).\n\nI also suspect that some of the signatures appear in Web100 sidestream (TCP exit)  stats, and they are very likely to appear in the Web100 fast polling as well.   Less sure about TCP_INFO.\n\nThanks,\n--MM--\nThe best way to predict the future is to create it.  - Alan Kay\n\nWe must not tolerate intolerance;\n       however our response must be carefully measured: \n            too strong would be hypocritical and risks spiraling out of control;\n            too weak risks being mistaken for tacit approval.\n\n\ue5d3'}"
430,234061618488712888743606814810756827124,reverse-traceroute,"Jan 22, 2021, 12:52:50 PM",Colin McCann,"Hi all,
We are hoping to work with CIRA to expand on their internet performance testing tools (https://performance.cira.ca/), and had a couple of questions about your traceroute offerings.
What we hope to do is have users do reverse traceroutes (eg from target server to user IP), and then provide the user with direct feedback based on the results. Is this something that is achievable? Or do we need to wait for the results to be updated in That traceroute results would be returned is somewhat implied here: https://support.measurementlab.net/help/en-us/9-platform/1-what-is-m-lab. However, I'm not totally sure I'm parsing it correctly (eg is the traceroute offering a subcomponent of the NDT offering? The data structures seem to imply that...)

A couple other quick questions:
- where can I look at the source code for the reverse TR?
- I've been looking at the data in BigQuery / measurement-lab / ndt / traceroute. Is this the correct place to be looking? Are there other places in addition?
- is there a delay between when results are created and when they are available for query?

Thanks in advance!
Colin","{'Chris Ritzo': 'Hi Colin,\nThanks for posting these questions. I\'ll reply here since you had two very similar threads, and this is the most current.\n\nFirst, we should distinguish Traceroute from Reverse Traceroute. On our tests page, we distinguish Reverse Traceroute - a test (aka ""measurement service"") from the Traceroute ""M-Lab Core Service"".\n\nThe Traceroute M-Lab core service uses the Scamper traceroute tool provided by the Center for Applied Internet Data Analysis, CAIDA. For every TCP connection made to an M-Lab server, the traceroute service gathers a trace from our server back to the originating IP address. These traces are collected on a per server basis and parsed into BigQuery. \n\nTraces are associated with each measurement service like NDT and others, and are also available for TCP connections not associated with any M-Lab measurement service as well.\n\nAll traces for all connections are available in measurement-lab.aggregate.traceroute.\nTraces relevant to specific measurement services like NDT are provided within the dataset for supported services. For example, measurement-lab.ndt.traceroute contains the traces associated with NDT tests. You can obtain the traceroutes for specific NDT tests by joining or matching on the UUID field.\n\nWhere Traceroute provides path information from M-Lab server to client, Reverse Traceroute is a tool intended to provide the reverse path information -- client to server-- which would normally only be possible by running traceroute from the client side to the server. You can find more information about Reverse Traceroute on their project page. However, as noted on our landing page for Reverse Traceroute, this data is not currently parsed into BigQuery. However, our team is actively working with the developers of Reverse Traceroute make that a possibility. As for running Reverse Traceroute to gather new reverse traces, we will need to inquire with their team to document client usage once the team reaches their re-launch milestone for this test. It is in the process of being updated to be supported on our Kubernetes based server platform.\n\nOur Reverse Traceroute page provides links to the source code and currently available data.\n\nRegarding our data publication process, expect that there will be an ~2 business day delay between the point when a test like NDT is run, and the data for that test being available in BigQuery. I expect the same would be true for traceroute. So in terms of real time access, this isn\'t really possible now, but can be provided after the fact. For example for CIRA\'s IPT tool, this could be something you provide to users who create an account perhaps.\n\nI hope this response is helpful. Please let us know if you have additional questions.\n\nBest, Chris - M-Lab Support\n\ue5d3'}"
436,122566814195067088948865883206861389907,distinguishing-between-mobile-and-fixed-connections,"Sep 4, 2018, 2:16:34 AM",William Haslam,"Are there any datafields that would help me separate out mobile and fixed (wired/wireless) connections?

Specifically I'm pulling data from the `measurement-lab.release.ndt_all` bigquery table and then mapping the IP addresses to ISP's. I can map the IP's fine, but I'm unable to separate out to connection type. I'm aware of 3rd party databases (maxmind/neustar) which claim to map IP addresses to connection type but I was hoping there would be something in the dataset that would allow me to do this? Any suggestions?","{'Chris Ritzo': 'Hello William,\nWe were reviewing recent discuss group posts that had not received replies this week. Sorry that we or others haven\'t replied as yet.\n\nIn any case, there are some fields in the NDT dataset which could provide a rough way to distinguish tests conducted from mobile devices from desktops or laptops. This would be based on the device\'s operating system however, and would not be an indicator of connection type (mobile versus fixed). Thse fields would be:\nconnection_spec.client_kernel_version\nconnection_spec.client_os\nconnection_spec.client_browser\nTo properly separate mobile tests from non-mobile tests, you will need to use third party databases, as you mentioned. I have used the Maxmind connection type database for this, as well as the API provided by https://ipinfo.io . I find that the ipinfo.io API is more accurate, and had better global coverage. \n\nThanks for asking this question, and my apologies for the delayed reply. I hope this helps.\n\nAlso, we do hope to add this type of annotation in the future, and with respect to mobile specifically, M-Lab is coordinating with researchers on the issue of mobile measurement generally, most recently sponsoring this year\'s ACM Internet Measurement Conference, where we hosted a pre-conference workshop on mobile measurement. \n\nBest regards,\nChris\n--\nChris Ritzo\nMeasurement Lab Operations & Support\no...@measurementlab.net | sup...@measurementlab.net\n\n\nOn Tue, Sep 4, 2018 at 5:16 AM William Haslam <william...@gmail.com> wrote:\nAre there any datafields that would help me separate out mobile and fixed (wired/wireless) connections?\n\nSpecifically I\'m pulling data from the `measurement-lab.release.ndt_all` bigquery table and then mapping the IP addresses to ISP\'s. I can map the IP\'s fine, but I\'m unable to separate out to connection type. I\'m aware of 3rd party databases (maxmind/neustar) which claim to map IP addresses to connection type but I was hoping there would be something in the dataset that would allow me to do this? Any suggestions?\n--\nYou received this message because you are subscribed to the Google Groups ""discuss"" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\nVisit this group at https://groups.google.com/a/measurementlab.net/group/discuss/.'}"
442,68744442662571913710098717653513950353,relation-between-ndt-and-paris-traceroute-tests-on-m-lab,"Jul 30, 2015, 11:55:39 AM",Danny Lee,"Hi all,

I'm trying to do some analysis on the M-Lab dataset and part of it involves associating NDT tests with paris traceroutes. I couldn't find a file that maps one test to another, so had to infer a link by associating tests with the same client IP (destination IP for traceroute) within 10 minutes of each other.

Looking at set of NDT tests from lax01 in May 2015, I found that only about 46% of the NDT tests could be associated with a traceroute. I'm wondering whether there is some sampling (like 1 in 2) when choosing to perform a traceroute, and more details about the way the traceroute process is triggered so my inference is more accurate.

Thanks,
Danny","{'Peter Boothe': ""On Thu, Jul 30, 2015 at 8:04 PM, Danny Lee <dann...@gmail.com> wrote:\nThanks Peter and Chris for the replies.\n\nRE: Upgraded traceroute system\nIt's great to hear that this issue is being actively worked on. Is there a timeframe in which this upgraded system will be rolled out?\n\nHopefully September? If not then in October? That kind of time frame, anyway.  It is important to note that this system will fix *future* tests. The test data of the past will remain unchanged - it's open data, so what you have is also what we have.  We are fixing Paris-Traceroute so that, going forward, it will be easier to correlate tests and traceroutes and it will be more likely that a traceroute will be run for every test.\n\nAlso, thanks for your suggestions about the BigQuery schema!\n\n  -Peter\n \ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to discuss+u...@measurementlab.net.\nTo post to this group, send email to dis...@measurementlab.net.\n\nVisit this group at http://groups.google.com/a/measurementlab.net/group/discuss/.\n\n\n\n--\nᴹ̶LAB | Measure the Internet, save the data, and make it universally accessible and useful."", 'Chris Ritzo': 'Until that system is ready, you might try the method below to query the\ntraceroutes for a given set of NDT tests. *Disclaimer:* this is solely\nbased on my own test queries and could certainly be wrong.\n\nI\'ve done this using two queries, but I\'m sure the two could be nested\nfor simplicity.\n\nQuery the NDT data and include these two fields:\n""connection_spec.client_ip"" and ""connection_spec.server_ip""\n\nFor each NDT test returned, use another query like the one below to find\nthe corresponding PT data.\n\nSELECT test_id, log_time, connection_spec.client_ip,\nconnection_spec.server_ip, paris_traceroute_hop.src_ip,\nparis_traceroute_hop.dest_ip, paris_traceroute_hop.src_hostname,\nparis_traceroute_hop.dest_hostname FROM\n[plx.google:m_lab.m_lab.2015_01.all] WHERE project = 3 AND\nconnection_spec.client_ip = \'104.245.144.234\' AND\nconnection_spec.server_ip LIKE \'103.10.233.%\' ORDER BY test_id DESC\n\nObviously you\'ll need to substitute the IPs returned from your NDT query\nfor ""connection_spec.client_ip"" and ""connection_spec.server_ip"" and\nsearch for results in the same month table in both queries.\n\ue5d3\n> <mailto:discuss+u...@measurementlab.net>.\n> To post to this group, send email to dis...@measurementlab.net\n> <mailto:dis...@measurementlab.net>.\n> Visit this group at\n> http://groups.google.com/a/measurementlab.net/group/discuss/.\n>\n>\n>\n>\n> --\n> ᴹ̶LAB <http://measurementlab.net/> | Measure the Internet, save the data,\n> and make it universally accessible and useful.\n>\n> --\n> You received this message because you are subscribed to the Google\n> Groups ""discuss"" group.\n> To unsubscribe from this group and stop receiving emails from it, send\n> an email to discuss+u...@measurementlab.net\n> <mailto:discuss+u...@measurementlab.net>.\n> To post to this group, send email to dis...@measurementlab.net\n> <mailto:dis...@measurementlab.net>.\n\ue5d3', 'Danny Lee': ""Thanks Peter and Chris for the replies.\n\nRE: Upgraded traceroute system\nIt's great to hear that this issue is being actively worked on. Is there a timeframe in which this upgraded system will be rolled out?\n\nRE: Querying for tests\nThanks for the tip. I'm doing something similar in python already, integrating the additional step of limiting the search space based on time.\n\nI did have some issues with reconstructing the traceroute using BigQuery output, and ended up just getting the raw data using gsutil. To make BigQuery more useful, I have two suggestions:\n1. Include stars in the BigQuery table.\n2. The schema should be changed from a src and dest hop format to one based on hop count. It is easier to reconstruct the original traces rather than using a brute force match, and allows stars to be included in the schema.\n\nWithout the hopcount and stars, the complete traceroute can't be reconstructed if there are one or more timeouts in a middle of the trace.\n\nThanks,\nDanny\n\ue5d3"", 'm...@luckie.org.nz': ""On Saturday, August 1, 2015 at 2:16:40 AM UTC+12, Peter Boothe wrote:\nOn Thu, Jul 30, 2015 at 8:04 PM, Danny Lee <dann...@gmail.com> wrote:\nThanks Peter and Chris for the replies.\n\nRE: Upgraded traceroute system\nIt's great to hear that this issue is being actively worked on. Is there a timeframe in which this upgraded system will be rolled out?\n\nHopefully September? If not then in October? That kind of time frame, anyway.  It is important to note that this system will fix *future* tests. The test data of the past will remain unchanged - it's open data, so what you have is also what we have.  We are fixing Paris-Traceroute so that, going forward, it will be easier to correlate tests and traceroutes and it will be more likely that a traceroute will be run for every test.\n\n\nCould you use http://www.caida.org/tools/measurement/scamper/ to do parallel traceroutes?  it supports paris traceroute.  you could launch a scamper daemon and then send it work on demand using sc_attach.  if you need script-able output, pipe the output through sc_warts2json."", 'Ethan Katz-Bassett': 'It would be great to use scamper for the measurements--it tracks measurement best practices and offers a range of useful features. It is also what we are using in the reboot of reverse traceroute (uw_geoloc4 slice), so the measurements we publish will be in that format as well. \n\n\n\n\ue5d3\n\ue5d3\n--\n\ue5d3'}"
